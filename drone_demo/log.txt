2020-12-07 09:17:35,044 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-07 09:17:35,045 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-07 09:17:35,045 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-07 09:17:42,271 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-07 09:17:42,271 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-07 09:17:42,272 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro5_train" )
  TEST: ("giro1_test","giro4_test","giro5_test")
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000002
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-07 09:17:42,276 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro5_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro5_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 2e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-07 09:17:44,201 maskrcnn_benchmark INFO: reloading weigts from r1_fin.pth
2020-12-07 09:17:54,323 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-07 09:17:54,323 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-07 09:17:54,324 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-07 09:17:54,324 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-07 09:17:54,324 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-07 09:17:54,324 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-07 09:17:54,325 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-07 09:17:54,325 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-07 09:17:54,325 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-07 09:17:54,325 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-07 09:17:54,325 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-07 09:17:54,325 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-07 09:17:54,326 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-07 09:17:54,326 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-07 09:17:54,496 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-07 09:23:01,178 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-07 09:23:01,178 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-07 09:23:01,178 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-07 09:23:03,298 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-07 09:23:03,298 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-07 09:23:03,298 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro5_train" )
  TEST: ("giro1_test","giro4_test","giro5_test")
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000002
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-07 09:23:03,299 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro5_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro5_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 2e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-07 09:23:04,844 maskrcnn_benchmark INFO: reloading weigts from r1_fin.pth
2020-12-07 09:23:06,884 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-07 09:23:06,884 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-07 09:23:06,884 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-07 09:23:06,884 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-07 09:23:06,885 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-07 09:23:06,885 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-07 09:23:06,885 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-07 09:23:06,885 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-07 09:23:06,885 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-07 09:23:06,885 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-07 09:23:06,886 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-07 09:23:06,886 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-07 09:23:06,886 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-07 09:23:06,886 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-07 09:23:07,053 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-07 09:24:47,582 maskrcnn_benchmark.trainer INFO: Start training
2020-12-07 11:20:41,699 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-07 11:20:41,699 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-07 11:20:41,699 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-07 11:20:44,247 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-07 11:20:44,247 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-07 11:20:44,248 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train","giro9_train" )
  TEST: ("giro1_test","giro4_test","giro8_test","giro9_test")
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000002
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-07 11:20:44,250 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test', 'giro9_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train', 'giro9_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 2e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-07 11:20:45,812 maskrcnn_benchmark INFO: reloading weigts from r1_fin.pth
2020-12-07 11:20:47,918 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-07 11:20:47,918 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-07 11:20:47,918 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-07 11:20:47,919 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-07 11:20:47,919 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-07 11:20:47,919 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-07 11:20:47,919 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-07 11:20:47,919 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-07 11:20:47,920 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-07 11:20:47,920 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-07 11:20:47,920 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-07 11:20:47,920 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-07 11:20:47,920 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-07 11:20:47,920 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-07 11:20:48,091 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-07 11:22:48,634 maskrcnn_benchmark.trainer INFO: Start training
2020-12-07 11:47:34,902 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-07 11:47:34,902 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-07 11:47:34,902 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-07 11:47:37,237 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-07 11:47:37,237 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-07 11:47:37,237 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train","giro9_train" )
  TEST: ("giro1_test","giro4_test","giro8_test","giro9_test")
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000002
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-07 11:47:37,238 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test', 'giro9_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train', 'giro9_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 2e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-07 11:47:38,846 maskrcnn_benchmark INFO: reloading weigts from r1_fin.pth
2020-12-07 11:47:40,913 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-07 11:47:40,913 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-07 11:47:40,914 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-07 11:47:40,914 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-07 11:47:40,914 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-07 11:47:40,914 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-07 11:47:40,914 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-07 11:47:40,915 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-07 11:47:40,915 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-07 11:47:40,915 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-07 11:47:40,915 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-07 11:47:40,915 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-07 11:47:40,915 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-07 11:47:40,915 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-07 11:47:41,078 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-07 11:47:53,364 maskrcnn_benchmark.trainer INFO: Start training
2020-12-07 14:02:06,023 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-07 14:02:06,023 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-07 14:02:06,023 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-07 14:02:08,116 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-07 14:02:08,117 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-07 14:02:08,117 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train","giro9_train" )
  TEST: ("giro1_test","giro4_test","giro8_test","giro9_test")
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000002
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-07 14:02:08,118 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test', 'giro9_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train', 'giro9_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 2e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-07 14:02:09,712 maskrcnn_benchmark INFO: reloading weigts from r1_fin.pth
2020-12-07 14:02:11,918 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-07 14:02:11,918 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-07 14:02:11,918 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-07 14:02:11,918 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-07 14:02:11,919 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-07 14:02:11,919 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-07 14:02:11,919 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-07 14:02:11,919 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-07 14:02:11,919 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-07 14:02:11,919 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-07 14:02:11,920 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-07 14:02:11,920 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-07 14:02:11,920 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-07 14:02:11,920 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-07 14:02:12,089 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-07 14:02:14,260 maskrcnn_benchmark.trainer INFO: Start training
2020-12-07 14:03:30,023 maskrcnn_benchmark.trainer INFO: eta: 1:33:24  iter: 20  loss: 2.5566 (3.4951)  loss_classifier: 1.0181 (1.2778)  loss_box_reg: 0.4496 (0.5616)  loss_objectness: 0.9852 (1.1789)  loss_rpn_box_reg: 0.1162 (0.4769)  time: 3.7762 (3.7870)  data: 0.1460 (0.1467)  lr: 0.000000  max mem: 1423
2020-12-07 14:04:45,672 maskrcnn_benchmark.trainer INFO: eta: 1:32:06  iter: 40  loss: 2.1277 (3.4236)  loss_classifier: 0.7975 (1.2599)  loss_box_reg: 0.3463 (0.5468)  loss_objectness: 0.8722 (1.1339)  loss_rpn_box_reg: 0.0981 (0.4830)  time: 3.7835 (3.7852)  data: 0.1438 (0.1454)  lr: 0.000000  max mem: 1423
2020-12-07 14:06:01,389 maskrcnn_benchmark.trainer INFO: eta: 1:30:51  iter: 60  loss: 2.3792 (4.0782)  loss_classifier: 0.9687 (1.2546)  loss_box_reg: 0.4888 (0.5635)  loss_objectness: 0.6734 (1.1427)  loss_rpn_box_reg: 0.0935 (1.1174)  time: 3.7837 (3.7855)  data: 0.1356 (0.1434)  lr: 0.000000  max mem: 1423
2020-12-07 14:07:18,174 maskrcnn_benchmark.trainer INFO: eta: 1:29:54  iter: 80  loss: 3.1301 (4.3265)  loss_classifier: 1.1431 (1.2339)  loss_box_reg: 0.6410 (0.6040)  loss_objectness: 0.6379 (1.1570)  loss_rpn_box_reg: 0.0879 (1.3316)  time: 3.7918 (3.7989)  data: 0.1421 (0.1432)  lr: 0.000000  max mem: 1423
2020-12-07 14:08:34,545 maskrcnn_benchmark.trainer INFO: eta: 1:28:43  iter: 100  loss: 1.8773 (3.8440)  loss_classifier: 0.8139 (1.1583)  loss_box_reg: 0.4010 (0.5832)  loss_objectness: 0.4506 (1.0183)  loss_rpn_box_reg: 0.0352 (1.0842)  time: 3.7873 (3.8028)  data: 0.1415 (0.1428)  lr: 0.000000  max mem: 1423
2020-12-07 14:08:34,547 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-07 14:08:35,252 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(92 images).
2020-12-07 14:10:49,915 maskrcnn_benchmark.inference INFO: Total run time: 0:02:14.662649 (1.4637244473332944 s / img per device, on 1 devices)
2020-12-07 14:10:49,915 maskrcnn_benchmark.inference INFO: Model inference time: 0:02:08.797162 (1.399969150190768 s / img per device, on 1 devices)
2020-12-07 14:10:49,915 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 14:10:55,277 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 14:10:55,277 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0117, 0.0074, 0.0000, 0.0000, 0.0000, 0.0658, 0.0617, 0.0389, 0.0000,
        0.2791, 0.0395, 0.0793, 0.0000, 0.0000, 0.1209, 0.1341, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0453, 0.0023, 0.0817, 0.0576, 0.0000, 0.0000, 0.0104,
        0.0083, 0.0008, 0.0000, 0.0721, 0.0135, 0.0078, 0.0011, 0.0000, 0.0000,
        0.0000, 0.0148, 0.0000, 0.0078, 0.0362, 0.0116, 0.1333, 0.0672, 0.0000,
        0.0621, 0.0302, 0.0169, 0.0050, 0.2270, 0.0410, 0.0066, 0.0630, 0.0705,
        0.1050, 0.0174, 0.0000, 0.0000, 0.0000, 0.0221, 0.0000, 0.0639, 0.0000,
        0.0781, 0.0000, 0.1749, 0.0000, 0.0000, 0.0000, 0.0916, 0.0243, 0.0000,
        0.0000, 0.0341, 0.0038, 0.0396, 0.0000, 0.0020, 0.1105, 0.0320, 0.0174,
        0.0030, 0.0248, 0.0000, 0.0201, 0.0000, 0.0639, 0.1070, 0.0100, 0.0768,
        0.2434, 0.0000, 0.1192, 0.0213, 0.0000, 0.0000, 0.0000, 0.0416, 0.0000,
        0.0000, 0.0718, 0.0025, 0.0020, 0.0767, 0.0204, 0.0106, 0.0000, 0.0716,
        0.0822, 0.2383, 0.1741, 0.1099, 0.0214, 0.3021, 0.0000, 0.0000, 0.0000,
        0.0000, 0.2400, 0.0003, 0.0000, 0.0000, 0.0898, 0.0171, 0.1319, 0.1064,
        0.0082, 0.0000, 0.0237, 0.0216, 0.0158, 0.0000, 0.0148, 0.0133, 0.0017]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 3., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 6., 8., 8., 8., 8., 8., 8., 5., 6., 8., 8., 8., 8.,
        6., 8., 5., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 3., 8., 3., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 3., 8., 8., 3., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 3., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8.]), 'best match scores': tensor([0.7006, 1.0000, 0.2870, 1.0000, 1.0000, 1.0000, 0.3088, 1.0000, 1.0000,
        0.5760, 1.0000, 0.9997, 0.3551, 0.4928, 0.0762, 1.0000, 1.0000, 0.9931,
        1.0000, 1.0000, 0.0663, 1.0000, 0.7456, 1.0000, 1.0000, 0.9897, 0.1092,
        1.0000, 1.0000, 1.0000, 1.0000, 0.8724, 1.0000, 1.0000, 0.5657, 0.9914,
        1.0000, 0.9303, 0.9999, 1.0000, 0.9738, 1.0000, 1.0000, 0.6185, 0.9972,
        0.2512, 0.2116, 1.0000, 0.7716, 1.0000, 1.0000, 1.0000, 1.0000, 0.9993,
        1.0000, 0.9997, 1.0000, 0.0568, 0.9477, 1.0000, 0.8334, 1.0000, 1.0000,
        0.3853, 0.9929, 0.8692, 1.0000, 0.9980, 0.6057, 1.0000, 1.0000, 0.9758,
        1.0000, 0.0737, 0.9752, 0.9949, 1.0000, 0.4521, 1.0000, 1.0000, 1.0000,
        0.2407, 1.0000, 1.0000, 0.9971, 1.0000, 0.9999, 0.4639, 0.9812, 0.8532,
        0.9863, 0.0515, 1.0000, 0.9999, 1.0000, 0.9943, 0.6454, 0.9999, 1.0000,
        1.0000, 0.8890, 0.9872, 1.0000, 1.0000, 0.9852, 1.0000, 0.9997, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9974, 1.0000, 1.0000,
        0.3920, 0.0835, 1.0000, 0.1764, 0.1189, 0.9414, 0.4741, 1.0000, 0.0652,
        0.9875, 1.0000, 1.0000, 0.3099, 0.9841, 1.0000, 1.0000, 0.9693, 1.0000]), 'num_pos': 135}
2020-12-07 14:10:55,335 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.918519
2020-12-07 14:10:55,338 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r2.pth
2020-12-07 14:10:55,972 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r2
2020-12-07 14:12:13,118 maskrcnn_benchmark.trainer INFO: eta: 1:54:46  iter: 120  loss: 1.3526 (3.6044)  loss_classifier: 0.6780 (1.1139)  loss_box_reg: 0.3878 (0.5626)  loss_objectness: 0.4243 (0.9499)  loss_rpn_box_reg: 0.0337 (0.9780)  time: 3.7822 (4.9905)  data: 0.1388 (1.3338)  lr: 0.000000  max mem: 1423
2020-12-07 14:13:28,689 maskrcnn_benchmark.trainer INFO: eta: 1:49:11  iter: 140  loss: 1.4380 (3.5862)  loss_classifier: 0.4826 (1.0605)  loss_box_reg: 0.3032 (0.5388)  loss_objectness: 0.4175 (0.9334)  loss_rpn_box_reg: 0.0502 (1.0535)  time: 3.7789 (4.8173)  data: 0.1437 (1.1632)  lr: 0.000000  max mem: 1423
2020-12-07 14:14:44,259 maskrcnn_benchmark.trainer INFO: eta: 1:44:41  iter: 160  loss: 1.2674 (3.4358)  loss_classifier: 0.4827 (1.0199)  loss_box_reg: 0.2591 (0.5149)  loss_objectness: 0.4067 (0.8969)  loss_rpn_box_reg: 0.0648 (1.0042)  time: 3.7779 (4.6875)  data: 0.1372 (1.0353)  lr: 0.000000  max mem: 1423
2020-12-07 14:15:59,872 maskrcnn_benchmark.trainer INFO: eta: 1:40:54  iter: 180  loss: 1.6159 (3.4681)  loss_classifier: 0.6585 (1.0319)  loss_box_reg: 0.4190 (0.5116)  loss_objectness: 0.3810 (0.8980)  loss_rpn_box_reg: 0.0613 (1.0266)  time: 3.7806 (4.5867)  data: 0.1372 (0.9357)  lr: 0.000000  max mem: 1423
2020-12-07 14:17:15,459 maskrcnn_benchmark.trainer INFO: eta: 1:37:37  iter: 200  loss: 1.8057 (3.3995)  loss_classifier: 0.6948 (1.0439)  loss_box_reg: 0.5378 (0.5144)  loss_objectness: 0.3464 (0.8692)  loss_rpn_box_reg: 0.0468 (0.9719)  time: 3.7796 (4.5060)  data: 0.1381 (0.8561)  lr: 0.000000  max mem: 1423
2020-12-07 14:17:15,461 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-07 14:17:15,481 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(92 images).
2020-12-07 14:19:29,397 maskrcnn_benchmark.inference INFO: Total run time: 0:02:13.915151 (1.4555994712788125 s / img per device, on 1 devices)
2020-12-07 14:19:29,397 maskrcnn_benchmark.inference INFO: Model inference time: 0:02:08.878012 (1.4008479610733364 s / img per device, on 1 devices)
2020-12-07 14:19:29,397 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 14:19:34,737 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 14:19:34,737 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([8.8269e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9442e-02,
        1.0986e-01, 2.4734e-02, 0.0000e+00, 9.4378e-02, 1.1297e-05, 1.1775e-01,
        0.0000e+00, 0.0000e+00, 9.3024e-02, 1.0023e-01, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.6214e-02, 7.8242e-04, 2.4197e-02, 5.7581e-02,
        0.0000e+00, 0.0000e+00, 1.2090e-02, 7.5208e-03, 8.8889e-04, 0.0000e+00,
        1.4120e-01, 2.6796e-02, 7.7722e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.4777e-02, 0.0000e+00, 8.7929e-03, 3.6214e-02, 2.6793e-02,
        7.8021e-02, 0.0000e+00, 8.7033e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1278e-01, 0.0000e+00, 0.0000e+00, 6.3048e-02, 1.9244e-03,
        9.5325e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3198e-02, 6.3932e-02,
        0.0000e+00, 7.0456e-02, 0.0000e+00, 1.1975e-01, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.1601e-02, 3.4766e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.3032e-03, 0.0000e+00, 0.0000e+00, 7.2831e-02, 2.7927e-02,
        0.0000e+00, 0.0000e+00, 2.4133e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5296e-02, 0.0000e+00, 1.0086e-02, 7.6842e-02, 0.0000e+00, 0.0000e+00,
        1.1919e-01, 4.9979e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5222e-02,
        0.0000e+00, 0.0000e+00, 6.2997e-02, 0.0000e+00, 0.0000e+00, 3.7170e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1595e-02, 0.0000e+00, 2.3833e-01,
        1.7408e-01, 1.0994e-01, 4.1017e-02, 9.2377e-02, 1.3801e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3469e-02, 6.2192e-03, 0.0000e+00, 0.0000e+00,
        9.0247e-02, 5.6356e-03, 8.3650e-02, 8.3896e-03, 0.0000e+00, 0.0000e+00,
        3.9876e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8226e-02, 1.4777e-02,
        4.9532e-03]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  3.,  3.,
         8.,  3.,  8.,  8.,  8.,  8.,  8.,  3.,  3.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  5.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  5.,  8.,  8.,  8.,  8.,
         6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  6.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8., -1.,  8.,  6.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,  6.,  8.,  8.,
         6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         6.,  8.,  8.,  8.,  8.,  8.,  3.]), 'best match scores': tensor([0.8941, 1.0000, 0.4231, 0.0534, 0.9382, 0.9998, 0.0959, 1.0000, 0.9203,
        1.0000, 1.0000, 0.9710, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.1129,
        1.0000, 0.9991, 1.0000, 1.0000, 0.9986, 0.9996, 0.2589, 0.6588, 0.9999,
        1.0000, 1.0000, 0.8934, 0.9998, 0.9752, 1.0000, 1.0000, 0.1094, 1.0000,
        1.0000, 0.4250, 1.0000, 1.0000, 0.1642, 0.9998, 1.0000, 1.0000, 0.8709,
        0.8997, 0.3393, 0.2427, 0.9796, 0.9905, 0.9406, 0.4884, 1.0000, 0.6236,
        0.9992, 0.9552, 0.9898, 1.0000, 0.6241, 0.1542, 0.8210, 1.0000, 0.9981,
        0.1944, 1.0000, 0.9981, 0.6183, 1.0000, 1.0000, 1.0000, 0.2024, 0.0635,
        1.0000, 0.9998, 1.0000, 1.0000, 0.1967, 1.0000, 0.9900, 0.9976, 1.0000,
        0.9955, 0.9938, 1.0000, 1.0000, 1.0000, 0.0987, 0.8678, 0.9736, 1.0000,
        1.0000, 0.9999, 1.0000, 0.1877, 0.4973, 0.2398, 1.0000, 1.0000, 0.9998,
        0.0000, 0.9998, 1.0000, 0.9987, 0.9769, 1.0000, 1.0000, 1.0000, 0.9997,
        1.0000, 0.9873, 0.2041, 1.0000, 1.0000, 0.9948, 1.0000, 0.6196, 0.8435,
        0.9389, 0.9805, 1.0000, 0.9990, 0.8932, 1.0000, 0.1211, 1.0000, 0.9841,
        1.0000, 0.1130, 1.0000, 0.8413, 0.8726, 1.0000, 0.0673]), 'num_pos': 133}
2020-12-07 14:19:34,761 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.842105
2020-12-07 14:20:50,503 maskrcnn_benchmark.trainer INFO: eta: 1:48:14  iter: 220  loss: 2.0008 (3.5403)  loss_classifier: 0.8333 (1.0625)  loss_box_reg: 0.4736 (0.5211)  loss_objectness: 0.3493 (0.8853)  loss_rpn_box_reg: 0.1092 (1.0714)  time: 3.7787 (5.0738)  data: 0.1422 (1.4250)  lr: 0.000000  max mem: 1423
2020-12-07 14:22:06,190 maskrcnn_benchmark.trainer INFO: eta: 1:44:17  iter: 240  loss: 1.5741 (3.5063)  loss_classifier: 0.6711 (1.0548)  loss_box_reg: 0.4618 (0.5200)  loss_objectness: 0.3576 (0.8677)  loss_rpn_box_reg: 0.0757 (1.0637)  time: 3.7851 (4.9664)  data: 0.1348 (1.3176)  lr: 0.000000  max mem: 1423
2020-12-07 14:23:22,165 maskrcnn_benchmark.trainer INFO: eta: 1:40:46  iter: 260  loss: 1.3950 (3.4381)  loss_classifier: 0.7255 (1.0603)  loss_box_reg: 0.3501 (0.5118)  loss_objectness: 0.3513 (0.8455)  loss_rpn_box_reg: 0.0575 (1.0204)  time: 3.7785 (4.8765)  data: 0.1397 (1.2268)  lr: 0.000000  max mem: 1423
2020-12-07 14:24:37,997 maskrcnn_benchmark.trainer INFO: eta: 1:37:34  iter: 280  loss: 1.5021 (3.5120)  loss_classifier: 0.6430 (1.0670)  loss_box_reg: 0.3266 (0.5115)  loss_objectness: 0.3436 (0.8588)  loss_rpn_box_reg: 0.0765 (1.0746)  time: 3.7856 (4.7991)  data: 0.1349 (1.1492)  lr: 0.000000  max mem: 1423
2020-12-07 14:25:53,557 maskrcnn_benchmark.trainer INFO: eta: 1:34:37  iter: 300  loss: 1.5455 (3.5097)  loss_classifier: 0.5805 (1.0618)  loss_box_reg: 0.4904 (0.5253)  loss_objectness: 0.3240 (0.8493)  loss_rpn_box_reg: 0.0687 (1.0733)  time: 3.7768 (4.7310)  data: 0.1401 (1.0818)  lr: 0.000000  max mem: 1423
2020-12-07 14:25:53,559 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-07 14:25:53,578 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(92 images).
2020-12-07 14:28:07,324 maskrcnn_benchmark.inference INFO: Total run time: 0:02:13.745433 (1.4537547075230142 s / img per device, on 1 devices)
2020-12-07 14:28:07,324 maskrcnn_benchmark.inference INFO: Model inference time: 0:02:08.802790 (1.4000303304713706 s / img per device, on 1 devices)
2020-12-07 14:28:07,324 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 14:28:12,508 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 14:28:12,508 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([8.2893e-03, 7.7277e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6135e-02,
        8.5615e-02, 0.0000e+00, 4.0791e-02, 6.8122e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2737e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.0908e-01, 1.1418e-03, 8.2047e-03, 5.7581e-02, 0.0000e+00,
        0.0000e+00, 4.8473e-05, 2.2129e-07, 0.0000e+00, 0.0000e+00, 1.4672e-01,
        5.1217e-02, 4.6566e-02, 7.7722e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.3979e-02, 0.0000e+00, 7.7713e-03, 0.0000e+00, 2.2814e-02, 6.5961e-02,
        0.0000e+00, 6.2094e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.2377e-02,
        6.3048e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.9018e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8077e-02,
        0.0000e+00, 1.0270e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.1601e-02,
        4.7044e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1054e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4719e-03, 0.0000e+00, 0.0000e+00,
        3.9487e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4407e-02, 0.0000e+00,
        1.0381e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4762e-01, 1.9398e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4040e-03, 0.0000e+00, 0.0000e+00,
        6.2997e-02, 5.6486e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.1595e-02, 8.2207e-02, 2.3833e-01, 7.5443e-02, 1.3651e-01,
        0.0000e+00, 9.2377e-02, 8.3896e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.1172e-04, 0.0000e+00, 0.0000e+00, 3.6214e-02, 5.0070e-03,
        9.7924e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.9976e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.9532e-03, 1.3105e-03, 0.0000e+00]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  3.,  3.,  6.,
         3.,  6.,  8.,  8.,  8.,  8.,  3.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  6.,  8.,  3.,
         6.,  8.,  5.,  8.,  8.,  8., -1.,  5.,  6.,  8.,  8.,  8.,  6.,  8.,
         8.,  8.,  8.,  8.,  6.,  8.,  6.,  8.,  8.,  6.,  6.,  6.,  3.,  6.,
         3.,  8.,  6.,  8.,  8., -1.,  8.,  3.,  6.,  8.,  8.,  8.,  8., -1.,
         8.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,  6.,  3.,
         8.,  3.,  6.,  8.,  3.]), 'best match scores': tensor([0.9993, 1.0000, 0.2612, 1.0000, 1.0000, 1.0000, 0.9989, 1.0000, 0.1825,
        1.0000, 0.7534, 0.9999, 0.9996, 0.6807, 0.9998, 1.0000, 0.0675, 1.0000,
        0.3741, 0.0762, 1.0000, 1.0000, 0.6838, 0.1558, 0.4321, 1.0000, 0.9993,
        0.8138, 0.9632, 0.4260, 1.0000, 1.0000, 0.9909, 1.0000, 0.9940, 0.7909,
        1.0000, 0.9999, 0.4761, 0.8854, 0.9993, 0.9997, 1.0000, 1.0000, 0.1196,
        1.0000, 1.0000, 1.0000, 1.0000, 0.2419, 0.8225, 1.0000, 1.0000, 1.0000,
        0.3277, 0.6859, 1.0000, 0.6989, 0.1162, 1.0000, 0.5040, 0.9943, 0.0000,
        0.3694, 0.6724, 0.7895, 1.0000, 0.9999, 0.9882, 0.2415, 0.9793, 0.3044,
        0.0545, 0.9904, 1.0000, 0.9727, 1.0000, 0.0536, 1.0000, 0.3072, 0.9516,
        1.0000, 1.0000, 1.0000, 1.0000, 0.8337, 1.0000, 0.9993, 0.8848, 0.0000,
        0.9998, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0908, 0.0000, 0.1047,
        1.0000, 1.0000, 0.7980, 0.8352, 0.9992, 0.4054, 0.8657, 1.0000, 0.1323,
        0.8121, 0.9962, 0.7490, 0.7342, 0.4240, 0.7399, 1.0000, 0.3229, 0.9562,
        1.0000, 1.0000, 0.6257, 1.0000, 0.9998, 1.0000, 0.9998, 1.0000, 0.7483,
        1.0000, 0.8167, 0.0681, 0.9924, 1.0000]), 'num_pos': 131}
2020-12-07 14:28:12,531 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.687023
2020-12-07 14:29:28,080 maskrcnn_benchmark.trainer INFO: eta: 1:40:24  iter: 320  loss: 1.8553 (3.5591)  loss_classifier: 0.7772 (1.0662)  loss_box_reg: 0.3174 (0.5292)  loss_objectness: 0.3763 (0.8613)  loss_rpn_box_reg: 0.0410 (1.1024)  time: 3.7762 (5.1057)  data: 0.1395 (1.4573)  lr: 0.000000  max mem: 1423
2020-12-07 14:30:43,676 maskrcnn_benchmark.trainer INFO: eta: 1:37:12  iter: 340  loss: 1.3027 (3.4940)  loss_classifier: 0.4756 (1.0581)  loss_box_reg: 0.4270 (0.5252)  loss_objectness: 0.3179 (0.8457)  loss_rpn_box_reg: 0.0311 (1.0650)  time: 3.7812 (5.0277)  data: 0.1366 (1.3797)  lr: 0.000000  max mem: 1423
2020-12-07 14:31:59,212 maskrcnn_benchmark.trainer INFO: eta: 1:34:12  iter: 360  loss: 1.2321 (3.5790)  loss_classifier: 0.5466 (1.0688)  loss_box_reg: 0.3537 (0.5292)  loss_objectness: 0.3283 (0.8577)  loss_rpn_box_reg: 0.0655 (1.1234)  time: 3.7734 (4.9582)  data: 0.1334 (1.3106)  lr: 0.000000  max mem: 1423
2020-12-07 14:33:14,757 maskrcnn_benchmark.trainer INFO: eta: 1:31:23  iter: 380  loss: 2.4287 (3.6090)  loss_classifier: 0.8754 (1.0701)  loss_box_reg: 0.4098 (0.5241)  loss_objectness: 0.3863 (0.8571)  loss_rpn_box_reg: 0.2160 (1.1577)  time: 3.7752 (4.8960)  data: 0.1355 (1.2489)  lr: 0.000000  max mem: 1423
2020-12-07 14:34:30,357 maskrcnn_benchmark.trainer INFO: eta: 1:28:44  iter: 400  loss: 1.1463 (3.6065)  loss_classifier: 0.4767 (1.0582)  loss_box_reg: 0.4798 (0.5275)  loss_objectness: 0.2731 (0.8572)  loss_rpn_box_reg: 0.0482 (1.1636)  time: 3.7765 (4.8402)  data: 0.1400 (1.1935)  lr: 0.000000  max mem: 1423
2020-12-07 14:34:30,359 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-07 14:34:30,377 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(92 images).
2020-12-07 14:36:44,109 maskrcnn_benchmark.inference INFO: Total run time: 0:02:13.731782 (1.4536063282386116 s / img per device, on 1 devices)
2020-12-07 14:36:44,110 maskrcnn_benchmark.inference INFO: Model inference time: 0:02:08.668935 (1.3985753759093906 s / img per device, on 1 devices)
2020-12-07 14:36:44,110 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 14:36:49,085 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 14:36:49,085 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([7.7722e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0630e-01,
        2.0804e-03, 0.0000e+00, 0.0000e+00, 6.0429e-02, 0.0000e+00, 1.0117e-01,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.6214e-02, 1.9983e-04, 5.9955e-04, 5.7581e-02, 0.0000e+00,
        0.0000e+00, 1.0391e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4411e-01,
        5.2669e-02, 2.7769e-02, 7.7722e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.7713e-03, 0.0000e+00, 1.2366e-02, 6.4698e-02,
        0.0000e+00, 6.2094e-02, 3.0158e-02, 1.6980e-02, 0.0000e+00, 9.2377e-02,
        0.0000e+00, 0.0000e+00, 6.3048e-02, 2.0449e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.3198e-02, 0.0000e+00, 0.0000e+00, 3.4241e-06, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.7976e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.1691e-02, 0.0000e+00, 0.0000e+00, 2.0475e-08, 2.6596e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1919e-01,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0775e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.1595e-02, 1.3916e-01, 2.3833e-01, 3.2935e-02, 5.0319e-02, 0.0000e+00,
        0.0000e+00, 1.0825e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3469e-02,
        3.1172e-04, 0.0000e+00, 0.0000e+00, 3.6214e-02, 2.4139e-04, 1.0183e-01,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4797e-02, 4.9970e-02, 1.3105e-03, 0.0000e+00]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([-1.,  8.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  3.,
         6.,  6.,  8.,  8.,  8.,  8.,  3.,  3.,  8.,  8.,  8.,  6.,  8.,  8.,
         8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,  6.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8., -1.,  6.,  8.,  8.,  6.,  8.,  8.,  3.,
         3.,  6.,  6.,  5.,  6.,  8.,  8., -1., -1.,  6.,  5.,  6.,  8.,  8.,
         5.,  8.,  3.,  6.,  3.,  6.,  8.,  5.,  6.,  8.,  3.,  3.,  5.,  8.,
         6.,  8.,  8.,  6.,  8.,  8., -1., -1.,  3.,  6.,  8.,  8.,  8.,  6.,
         6.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,
         8.,  8.,  8.,  6.,  8.,  8.,  8.,  8., -1.,  6.,  8., -1.,  5.,  6.,
         8.,  6.,  8.,  3.]), 'best match scores': tensor([0.0000, 0.9901, 0.8743, 1.0000, 1.0000, 0.1074, 1.0000, 1.0000, 0.9999,
        1.0000, 1.0000, 1.0000, 0.9923, 0.9997, 1.0000, 1.0000, 0.1254, 0.1147,
        0.9387, 1.0000, 0.0880, 0.1886, 0.9991, 1.0000, 0.9096, 0.9990, 1.0000,
        0.8694, 0.8531, 0.9999, 0.7529, 1.0000, 1.0000, 1.0000, 0.9958, 0.9999,
        0.7540, 1.0000, 0.7013, 0.9325, 0.8423, 0.7920, 1.0000, 1.0000, 0.9990,
        1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0820, 0.9995, 0.9994,
        0.9975, 0.9989, 0.6869, 0.9359, 1.0000, 1.0000, 0.9997, 0.9892, 0.1312,
        0.0000, 0.0000, 0.9763, 0.2771, 1.0000, 0.8550, 0.2767, 0.6981, 0.9985,
        0.8729, 1.0000, 0.9882, 0.9997, 0.2088, 0.9116, 1.0000, 1.0000, 0.1327,
        0.1336, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 0.9936, 1.0000, 0.9999,
        0.0000, 0.0000, 0.9512, 1.0000, 0.9918, 1.0000, 1.0000, 0.2904, 1.0000,
        0.3359, 0.9702, 1.0000, 0.2100, 0.4405, 0.9967, 0.0681, 0.9989, 0.9184,
        0.1539, 1.0000, 1.0000, 1.0000, 0.0530, 0.8895, 1.0000, 0.3808, 0.7212,
        1.0000, 1.0000, 0.9999, 0.0000, 1.0000, 0.9986, 0.0000, 0.2804, 1.0000,
        0.8413, 0.9969, 0.4898, 1.0000]), 'num_pos': 130}
2020-12-07 14:36:49,104 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.576923
2020-12-07 14:38:04,518 maskrcnn_benchmark.trainer INFO: eta: 1:32:09  iter: 420  loss: 1.3588 (3.5894)  loss_classifier: 0.5169 (1.0519)  loss_box_reg: 0.4046 (0.5265)  loss_objectness: 0.3001 (0.8536)  loss_rpn_box_reg: 0.0427 (1.1575)  time: 3.7730 (5.1197)  data: 0.1375 (1.4735)  lr: 0.000000  max mem: 1423
2020-12-07 14:39:20,041 maskrcnn_benchmark.trainer INFO: eta: 1:29:22  iter: 440  loss: 1.0251 (3.5492)  loss_classifier: 0.3695 (1.0388)  loss_box_reg: 0.2964 (0.5211)  loss_objectness: 0.3215 (0.8476)  loss_rpn_box_reg: 0.0416 (1.1417)  time: 3.7696 (5.0586)  data: 0.1379 (1.4128)  lr: 0.000000  max mem: 1423
2020-12-07 14:40:35,596 maskrcnn_benchmark.trainer INFO: eta: 1:26:43  iter: 460  loss: 1.6836 (3.6053)  loss_classifier: 0.6251 (1.0295)  loss_box_reg: 0.4096 (0.5221)  loss_objectness: 0.3563 (0.8660)  loss_rpn_box_reg: 0.0794 (1.1877)  time: 3.7756 (5.0029)  data: 0.1373 (1.3573)  lr: 0.000000  max mem: 1423
2020-12-07 14:41:51,101 maskrcnn_benchmark.trainer INFO: eta: 1:24:10  iter: 480  loss: 1.1319 (3.5483)  loss_classifier: 0.4407 (1.0196)  loss_box_reg: 0.4017 (0.5215)  loss_objectness: 0.2523 (0.8500)  loss_rpn_box_reg: 0.0525 (1.1572)  time: 3.7726 (4.9517)  data: 0.1323 (1.3063)  lr: 0.000000  max mem: 1423
2020-12-07 14:43:06,989 maskrcnn_benchmark.trainer INFO: eta: 1:21:45  iter: 500  loss: 1.5927 (3.5796)  loss_classifier: 0.7242 (1.0179)  loss_box_reg: 0.4676 (0.5265)  loss_objectness: 0.2532 (0.8487)  loss_rpn_box_reg: 0.0639 (1.1866)  time: 3.7750 (4.9055)  data: 0.1337 (1.2594)  lr: 0.000000  max mem: 1423
2020-12-07 14:43:06,991 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-07 14:43:07,011 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(92 images).
2020-12-07 14:45:24,374 maskrcnn_benchmark.inference INFO: Total run time: 0:02:17.362164 (1.4930670054062554 s / img per device, on 1 devices)
2020-12-07 14:45:24,374 maskrcnn_benchmark.inference INFO: Model inference time: 0:02:11.991993 (1.4346955807312676 s / img per device, on 1 devices)
2020-12-07 14:45:24,374 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 14:45:29,534 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 14:45:29,534 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([7.7722e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9658e-02,
        2.0817e-03, 0.0000e+00, 0.0000e+00, 4.4395e-02, 3.9456e-02, 6.2644e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.9086e-02, 8.0449e-05, 2.0405e-01, 5.7581e-02, 0.0000e+00, 0.0000e+00,
        9.7490e-03, 1.8386e-03, 0.0000e+00, 0.0000e+00, 1.0217e-01, 5.1961e-02,
        7.7722e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6386e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0723e-02, 6.5961e-02, 0.0000e+00,
        0.0000e+00, 6.2094e-02, 3.0158e-02, 1.4777e-02, 0.0000e+00, 9.2377e-02,
        0.0000e+00, 0.0000e+00, 5.4738e-02, 2.0449e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.3198e-02, 0.0000e+00, 0.0000e+00, 3.0817e-06, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.7976e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1960e-02,
        0.0000e+00, 2.3431e-08, 1.9274e-02, 0.0000e+00, 0.0000e+00, 2.0848e-02,
        0.0000e+00, 0.0000e+00, 1.1919e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.0525e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1856e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.1593e-04, 2.3833e-01, 0.0000e+00, 5.2987e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6579e-02, 3.1172e-04,
        0.0000e+00, 0.0000e+00, 3.6214e-02, 2.4139e-04, 1.8472e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8]), 'best match labels': tensor([-1.,  8.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  6.,
         6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  6.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,
         8.,  8.,  8.,  8.,  8.,  8.,  3.,  6.,  8.,  8.,  5.,  8.,  8.,  8.,
        -1.,  3.,  6.,  8.,  6.,  8.,  8., -1., -1.,  6., -1.,  6.,  8.,  6.,
         8.,  3.,  6.,  6.,  8.,  3.,  3.,  8.,  6.,  5.,  8.,  6.,  8.,  8.,
         6.,  8.,  8., -1., -1.,  3.,  6.,  8.,  8.,  8.,  6.,  8., -1., -1.,
         6.,  8.,  8.,  6.,  3.,  8.,  8.,  8.,  8.,  5.,  8.,  8.,  8.,  8.,
         8.,  8.,  6.,  8.,  8.,  8.,  8., -1.,  6., -1., -1.,  6.]), 'best match scores': tensor([0.0000, 0.6965, 0.9735, 1.0000, 1.0000, 1.0000, 1.0000, 0.9883, 1.0000,
        0.9999, 1.0000, 0.3631, 0.7675, 1.0000, 1.0000, 1.0000, 0.0613, 0.9044,
        0.5475, 0.9481, 0.9981, 1.0000, 0.9998, 1.0000, 1.0000, 0.9993, 0.3078,
        0.8181, 0.4152, 0.7399, 0.9958, 0.9776, 0.1659, 1.0000, 0.9951, 0.9999,
        0.9973, 0.0673, 0.3615, 0.9700, 0.4411, 0.9915, 1.0000, 1.0000, 0.9778,
        0.9999, 0.0593, 0.9999, 0.3208, 0.9656, 1.0000, 0.8552, 0.8320, 0.9953,
        0.1402, 0.1033, 0.0000, 0.6859, 1.0000, 0.7175, 0.9994, 0.2973, 0.0793,
        0.0000, 0.0000, 0.9710, 0.0000, 1.0000, 0.3460, 0.9736, 0.9958, 0.6236,
        1.0000, 0.9962, 0.8449, 0.1156, 0.9643, 1.0000, 0.9982, 0.9991, 1.0000,
        0.9960, 1.0000, 1.0000, 0.9895, 0.8183, 1.0000, 0.0000, 0.0000, 0.9999,
        1.0000, 0.9998, 1.0000, 1.0000, 0.1050, 0.8843, 0.0000, 0.0000, 1.0000,
        0.9963, 1.0000, 0.1321, 1.0000, 0.9945, 0.9985, 0.9969, 0.9600, 0.7664,
        1.0000, 0.4926, 0.9990, 0.4407, 0.9837, 0.9961, 0.9986, 0.0641, 1.0000,
        1.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.9565]), 'num_pos': 124}
2020-12-07 14:45:29,553 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.612903
2020-12-07 14:46:46,586 maskrcnn_benchmark.trainer INFO: eta: 1:23:56  iter: 520  loss: 0.9991 (3.5312)  loss_classifier: 0.4136 (1.0044)  loss_box_reg: 0.3238 (0.5224)  loss_objectness: 0.2198 (0.8320)  loss_rpn_box_reg: 0.0361 (1.1724)  time: 3.8607 (5.1391)  data: 0.1434 (1.4905)  lr: 0.000000  max mem: 1423
2020-12-07 14:48:04,804 maskrcnn_benchmark.trainer INFO: eta: 1:21:29  iter: 540  loss: 2.1561 (3.5248)  loss_classifier: 0.6759 (1.0103)  loss_box_reg: 0.4369 (0.5212)  loss_objectness: 0.3584 (0.8331)  loss_rpn_box_reg: 0.1017 (1.1602)  time: 3.8948 (5.0936)  data: 0.1437 (1.4407)  lr: 0.000000  max mem: 1423
2020-12-07 14:49:22,927 maskrcnn_benchmark.trainer INFO: eta: 1:19:08  iter: 560  loss: 1.9880 (3.5375)  loss_classifier: 0.5070 (1.0086)  loss_box_reg: 0.3163 (0.5189)  loss_objectness: 0.3044 (0.8339)  loss_rpn_box_reg: 0.0995 (1.1761)  time: 3.8958 (5.0512)  data: 0.1431 (1.3944)  lr: 0.000000  max mem: 1423
2020-12-07 14:50:38,810 maskrcnn_benchmark.trainer INFO: eta: 1:16:47  iter: 580  loss: 1.4352 (3.5468)  loss_classifier: 0.5687 (1.0078)  loss_box_reg: 0.3013 (0.5187)  loss_objectness: 0.2806 (0.8337)  loss_rpn_box_reg: 0.0280 (1.1866)  time: 3.7752 (5.0078)  data: 0.1409 (1.3513)  lr: 0.000000  max mem: 1423
2020-12-07 14:51:54,280 maskrcnn_benchmark.trainer INFO: eta: 1:14:30  iter: 600  loss: 0.9591 (3.5541)  loss_classifier: 0.3353 (1.0005)  loss_box_reg: 0.3148 (0.5199)  loss_objectness: 0.2679 (0.8338)  loss_rpn_box_reg: 0.0250 (1.1999)  time: 3.7719 (4.9667)  data: 0.1358 (1.3108)  lr: 0.000000  max mem: 1423
2020-12-07 14:51:54,281 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-07 14:51:54,301 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(92 images).
2020-12-07 14:54:08,132 maskrcnn_benchmark.inference INFO: Total run time: 0:02:13.830884 (1.4546835215195366 s / img per device, on 1 devices)
2020-12-07 14:54:08,133 maskrcnn_benchmark.inference INFO: Model inference time: 0:02:08.760905 (1.3995750572370447 s / img per device, on 1 devices)
2020-12-07 14:54:08,133 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 14:54:13,348 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 14:54:13,348 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([7.7722e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7737e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2344e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.6214e-02, 8.0449e-05, 1.6624e-03, 1.9753e-03, 0.0000e+00, 0.0000e+00,
        1.0391e-02, 8.3154e-03, 8.7114e-04, 0.0000e+00, 0.0000e+00, 3.5819e-02,
        7.7722e-03, 1.1789e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.7713e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.2094e-02, 1.4279e-03, 4.9532e-03, 0.0000e+00, 9.2377e-02,
        5.0584e-03, 0.0000e+00, 5.8012e-02, 9.5325e-02, 1.7355e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7467e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2831e-02, 5.5914e-02,
        1.7355e-02, 0.0000e+00, 2.4051e-02, 0.0000e+00, 3.3428e-02, 0.0000e+00,
        9.7068e-04, 1.2633e-01, 0.0000e+00, 1.3768e-01, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.3032e-03, 0.0000e+00, 0.0000e+00, 1.3403e-02,
        6.9396e-02, 0.0000e+00, 4.9543e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.5659e-04, 2.3833e-01, 0.0000e+00, 7.0398e-02, 0.0000e+00, 9.2377e-02,
        9.1208e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.4478e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.1750e-02, 5.1870e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4777e-02,
        0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8]), 'best match labels': tensor([ 6.,  8.,  6.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  6.,  3.,  6.,
         8.,  8.,  8.,  5.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  6.,  8.,  8.,  6.,  8.,  6.,  6.,  8.,  8.,  6.,  8.,  8.,  6.,
         8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8., -1.,  8.,  6.,  6.,
         8.,  8.,  3.,  8.,  5., -1., -1.,  3., -1.,  6.,  8.,  3.,  3.,  3.,
         8.,  3.,  3.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1.,
         3.,  6.,  8.,  8.,  8.,  8., -1.,  8.,  3.,  3.,  6.,  8.,  3.,  8.,
         8.,  8.,  8.,  8.,  8.,  6.,  8.,  6.,  8.,  3.,  3.,  6.,  8.,  8.,
         8., -1., -1.,  3.,  3.,  6.,  8.,  3.,  6.,  8.]), 'best match scores': tensor([1.0000, 0.5307, 0.3731, 0.7857, 0.9907, 1.0000, 0.0620, 1.0000, 1.0000,
        0.9138, 0.9999, 1.0000, 0.9983, 1.0000, 0.5837, 1.0000, 0.9998, 1.0000,
        0.1148, 0.9148, 0.2577, 1.0000, 0.9328, 0.9246, 1.0000, 1.0000, 0.5225,
        0.9967, 0.9991, 0.9961, 0.1827, 0.9418, 1.0000, 0.9760, 0.9257, 0.0809,
        0.6437, 0.1975, 1.0000, 1.0000, 1.0000, 0.9564, 1.0000, 0.9995, 0.6168,
        0.8643, 0.9511, 1.0000, 0.9983, 0.9806, 1.0000, 0.5950, 0.0000, 0.9976,
        1.0000, 1.0000, 0.9156, 1.0000, 1.0000, 0.1487, 0.5488, 0.0000, 0.0000,
        0.0560, 0.0000, 1.0000, 1.0000, 0.9974, 0.9795, 0.1658, 0.0597, 0.6257,
        0.0530, 0.9936, 1.0000, 1.0000, 0.9083, 0.5114, 1.0000, 0.9309, 0.8719,
        1.0000, 0.0000, 0.0000, 0.9998, 1.0000, 0.9721, 0.9999, 0.9999, 0.2878,
        0.0000, 1.0000, 0.8718, 0.9999, 1.0000, 1.0000, 1.0000, 0.9798, 0.9307,
        0.7345, 0.6884, 0.0865, 0.9999, 1.0000, 1.0000, 0.1453, 1.0000, 0.9642,
        0.1518, 1.0000, 1.0000, 0.3279, 0.9990, 0.0000, 0.0000, 0.7124, 0.1717,
        1.0000, 1.0000, 1.0000, 0.4814, 0.2031]), 'num_pos': 122}
2020-12-07 14:54:13,369 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.581967
2020-12-07 14:55:28,870 maskrcnn_benchmark.trainer INFO: eta: 1:15:34  iter: 620  loss: 1.6004 (3.6190)  loss_classifier: 0.5555 (0.9890)  loss_box_reg: 0.5545 (0.5213)  loss_objectness: 0.3536 (0.8468)  loss_rpn_box_reg: 0.0738 (1.2620)  time: 3.7738 (5.1526)  data: 0.1383 (1.4973)  lr: 0.000000  max mem: 1423
2020-12-07 14:56:44,654 maskrcnn_benchmark.trainer INFO: eta: 1:13:14  iter: 640  loss: 2.3680 (3.5950)  loss_classifier: 0.8597 (0.9920)  loss_box_reg: 0.6448 (0.5302)  loss_objectness: 0.3076 (0.8357)  loss_rpn_box_reg: 0.0459 (1.2370)  time: 3.7807 (5.1100)  data: 0.1388 (1.4549)  lr: 0.000000  max mem: 1423
2020-12-07 14:58:02,453 maskrcnn_benchmark.trainer INFO: eta: 1:11:01  iter: 660  loss: 1.4193 (3.6244)  loss_classifier: 0.5517 (0.9825)  loss_box_reg: 0.4303 (0.5296)  loss_objectness: 0.3182 (0.8401)  loss_rpn_box_reg: 0.0541 (1.2721)  time: 3.8869 (5.0730)  data: 0.1459 (1.4153)  lr: 0.000000  max mem: 1423
2020-12-07 14:59:19,284 maskrcnn_benchmark.trainer INFO: eta: 1:08:50  iter: 680  loss: 1.4925 (3.5882)  loss_classifier: 0.5961 (0.9811)  loss_box_reg: 0.4905 (0.5309)  loss_objectness: 0.2850 (0.8272)  loss_rpn_box_reg: 0.0726 (1.2490)  time: 3.8287 (5.0368)  data: 0.1391 (1.3779)  lr: 0.000000  max mem: 1423
2020-12-07 15:00:37,330 maskrcnn_benchmark.trainer INFO: eta: 1:06:43  iter: 700  loss: 1.5726 (3.6041)  loss_classifier: 0.4835 (0.9860)  loss_box_reg: 0.4659 (0.5350)  loss_objectness: 0.2735 (0.8278)  loss_rpn_box_reg: 0.0709 (1.2553)  time: 3.8771 (5.0044)  data: 0.1442 (1.3432)  lr: 0.000000  max mem: 1423
2020-12-07 15:00:37,332 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-07 15:00:37,352 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(92 images).
2020-12-07 15:02:52,446 maskrcnn_benchmark.inference INFO: Total run time: 0:02:15.093864 (1.468411570009978 s / img per device, on 1 devices)
2020-12-07 15:02:52,446 maskrcnn_benchmark.inference INFO: Model inference time: 0:02:09.968882 (1.412705237450807 s / img per device, on 1 devices)
2020-12-07 15:02:52,447 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 15:02:57,636 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 15:02:57,636 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([2.5431e-02, 7.5106e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0493e-01,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9456e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6664e-05, 2.4904e-05,
        0.0000e+00, 1.9753e-03, 0.0000e+00, 0.0000e+00, 8.7561e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7722e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.5961e-02, 2.8442e-03, 0.0000e+00, 6.2094e-02,
        1.4279e-03, 0.0000e+00, 0.0000e+00, 9.2377e-02, 0.0000e+00, 0.0000e+00,
        3.6544e-02, 1.9265e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4687e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.7752e-04, 0.0000e+00, 0.0000e+00, 5.5465e-02, 0.0000e+00, 1.7456e-02,
        0.0000e+00, 0.0000e+00, 1.9818e-02, 0.0000e+00, 1.0172e-01, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0525e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.9746e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2240e-02,
        7.6090e-04, 2.3833e-01, 7.9472e-02, 6.4544e-02, 9.3084e-02, 0.0000e+00,
        8.3896e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5746e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.2063e-02, 2.4139e-04, 7.7217e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 8.,  8.,  3.,  6.,  8.,  8.,  5.,  8.,  6.,  8.,  3.,  6.,  8.,  8.,
         8.,  8.,  6.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  6., -1.,
         5.,  8.,  5.,  5.,  6.,  6.,  6.,  6.,  6.,  8.,  8.,  8.,  8.,  8.,
         8.,  6.,  8.,  8.,  6.,  8.,  8.,  8.,  5., -1.,  5.,  6.,  6.,  8.,
         8.,  8.,  8.,  6.,  6.,  8.,  8.,  3.,  3.,  6.,  8.,  3.,  3.,  8.,
         6.,  8.,  6.,  8.,  8.,  8.,  8., -1., -1., -1.,  6.,  8., -1.,  8.,
         8., -1.,  3.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  6.,  8.,  2.,
         6.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  6.,  8., -1.,  6.,
         8., -1.,  6.,  8.]), 'best match scores': tensor([0.1163, 0.1927, 1.0000, 1.0000, 0.0864, 0.9981, 0.9902, 1.0000, 1.0000,
        1.0000, 0.5752, 1.0000, 0.1281, 0.9996, 0.9997, 0.5864, 0.5154, 1.0000,
        0.8364, 0.7557, 0.8816, 1.0000, 1.0000, 1.0000, 0.2140, 0.9983, 0.9999,
        0.0000, 0.7600, 1.0000, 0.7161, 0.9768, 0.9888, 1.0000, 1.0000, 0.9994,
        1.0000, 1.0000, 0.9998, 0.5012, 1.0000, 1.0000, 0.9995, 1.0000, 0.4292,
        1.0000, 0.2994, 0.1212, 1.0000, 0.6621, 1.0000, 0.0000, 0.8718, 0.9991,
        1.0000, 0.6729, 1.0000, 0.9999, 0.7194, 1.0000, 1.0000, 0.6055, 0.2614,
        0.2948, 0.8969, 0.0641, 1.0000, 0.9966, 0.3154, 1.0000, 1.0000, 1.0000,
        0.9971, 1.0000, 0.9999, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.9637,
        0.3368, 0.0000, 1.0000, 0.3501, 0.0000, 1.0000, 1.0000, 1.0000, 0.9955,
        1.0000, 0.3547, 1.0000, 0.9886, 0.1787, 0.9872, 0.1738, 1.0000, 0.9999,
        0.9999, 0.8308, 0.0958, 0.7487, 1.0000, 1.0000, 0.4892, 0.1715, 0.9968,
        0.9993, 0.9945, 0.0000, 1.0000, 1.0000, 0.0000, 0.0561, 0.9339]), 'num_pos': 116}
2020-12-07 15:02:57,656 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.543103
2020-12-07 15:04:13,278 maskrcnn_benchmark.trainer INFO: eta: 1:07:08  iter: 720  loss: 1.1142 (3.5673)  loss_classifier: 0.4331 (0.9821)  loss_box_reg: 0.4773 (0.5353)  loss_objectness: 0.2554 (0.8177)  loss_rpn_box_reg: 0.0254 (1.2322)  time: 3.7821 (5.1653)  data: 0.1412 (1.5047)  lr: 0.000000  max mem: 1423
2020-12-07 15:05:29,552 maskrcnn_benchmark.trainer INFO: eta: 1:04:57  iter: 740  loss: 1.1797 (3.5769)  loss_classifier: 0.4836 (0.9782)  loss_box_reg: 0.4308 (0.5332)  loss_objectness: 0.2438 (0.8196)  loss_rpn_box_reg: 0.0480 (1.2459)  time: 3.7825 (5.1288)  data: 0.1391 (1.4680)  lr: 0.000000  max mem: 1423
2020-12-07 15:06:49,116 maskrcnn_benchmark.trainer INFO: eta: 1:02:52  iter: 760  loss: 0.8047 (3.5805)  loss_classifier: 0.2789 (0.9681)  loss_box_reg: 0.2550 (0.5289)  loss_objectness: 0.2685 (0.8203)  loss_rpn_box_reg: 0.0355 (1.2632)  time: 3.9524 (5.0985)  data: 0.1444 (1.4332)  lr: 0.000000  max mem: 1423
2020-12-07 15:08:06,107 maskrcnn_benchmark.trainer INFO: eta: 1:00:47  iter: 780  loss: 1.3902 (3.5639)  loss_classifier: 0.5586 (0.9644)  loss_box_reg: 0.3220 (0.5274)  loss_objectness: 0.2899 (0.8169)  loss_rpn_box_reg: 0.0546 (1.2552)  time: 3.8370 (5.0665)  data: 0.1437 (1.4002)  lr: 0.000000  max mem: 1423
2020-12-07 15:09:24,107 maskrcnn_benchmark.trainer INFO: eta: 0:58:46  iter: 800  loss: 0.8092 (3.5335)  loss_classifier: 0.4093 (0.9597)  loss_box_reg: 0.2942 (0.5249)  loss_objectness: 0.2233 (0.8082)  loss_rpn_box_reg: 0.0602 (1.2406)  time: 3.9092 (5.0373)  data: 0.1446 (1.3688)  lr: 0.000000  max mem: 1423
2020-12-07 15:09:24,109 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-07 15:09:24,130 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(92 images).
2020-12-07 15:11:40,823 maskrcnn_benchmark.inference INFO: Total run time: 0:02:16.693209 (1.4857957466788914 s / img per device, on 1 devices)
2020-12-07 15:11:40,824 maskrcnn_benchmark.inference INFO: Model inference time: 0:02:11.474759 (1.4290734710900679 s / img per device, on 1 devices)
2020-12-07 15:11:40,824 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 15:11:46,172 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 15:11:46,172 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([7.6715e-03, 3.5396e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8935e-01, 0.0000e+00, 1.2097e-03, 0.0000e+00, 1.6536e-01, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.6214e-02, 8.0449e-05, 1.6619e-03, 1.9753e-03, 0.0000e+00, 0.0000e+00,
        6.4899e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2095e-02, 5.1547e-02,
        7.7722e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5961e-02, 2.8442e-03, 0.0000e+00,
        6.2094e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.2377e-02, 0.0000e+00,
        0.0000e+00, 6.2703e-02, 1.9244e-03, 0.0000e+00, 0.0000e+00, 5.6280e-02,
        0.0000e+00, 0.0000e+00, 7.8077e-02, 0.0000e+00, 1.0270e-01, 2.2040e-02,
        0.0000e+00, 3.7467e-02, 0.0000e+00, 0.0000e+00, 2.3455e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0131e-02, 0.0000e+00, 0.0000e+00,
        1.6440e-02, 0.0000e+00, 9.7068e-04, 1.6619e-03, 0.0000e+00, 6.2796e-04,
        2.6984e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3032e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0955e-02, 2.3379e-01, 6.7869e-02, 7.6930e-04, 2.9798e-03, 9.2377e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3469e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.6043e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4777e-02,
        0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 8.,  8., -1.,  3.,  6.,  3.,  8.,  8.,  8.,  8.,  8.,  3.,  3.,  6.,
         8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  5.,  8.,  8.,  5.,  6.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  6.,  8.,  8., -1.,  8.,  8.,  8.,  5.,  6.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  6.,  8.,  3.,  3.,  8.,  6.,  6.,  3.,  6.,  8.,
         3.,  6.,  8.,  6.,  8.,  8.,  8.,  8., -1.,  8., -1.,  3.,  8.,  3.,
         8.,  8., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  6.,
         8.,  6.,  8.,  5.,  6.,  8.,  8.,  8.,  8., -1., -1.,  6., -1.,  6.,
         8.,  8., -1.,  8.]), 'best match scores': tensor([0.6952, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.2863, 1.0000, 0.3423,
        1.0000, 0.5572, 0.8167, 0.9855, 0.9939, 0.5250, 1.0000, 0.9985, 0.9565,
        0.8546, 0.0535, 0.9289, 0.9563, 1.0000, 1.0000, 0.8625, 0.1333, 1.0000,
        1.0000, 0.9964, 1.0000, 0.9997, 0.6474, 0.4173, 0.1872, 0.9164, 0.7632,
        0.0568, 0.5428, 0.8228, 0.4545, 0.0607, 1.0000, 1.0000, 0.7485, 1.0000,
        0.5699, 1.0000, 0.0000, 0.9989, 1.0000, 1.0000, 0.9844, 1.0000, 0.9999,
        0.9139, 0.8359, 1.0000, 0.1729, 0.2022, 0.4665, 0.9999, 0.9643, 0.1787,
        1.0000, 0.3333, 0.1028, 1.0000, 0.8352, 0.7494, 1.0000, 0.9994, 1.0000,
        0.7450, 1.0000, 0.9411, 0.9962, 0.9999, 0.9999, 0.0000, 0.9980, 0.0000,
        0.5883, 0.9973, 1.0000, 1.0000, 0.1708, 0.0000, 0.4246, 1.0000, 0.8483,
        0.0829, 0.1336, 1.0000, 0.2017, 0.1419, 0.5462, 0.7815, 0.9992, 1.0000,
        0.6791, 1.0000, 0.0931, 1.0000, 1.0000, 1.0000, 0.0754, 1.0000, 0.0000,
        0.0000, 0.0721, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.9835]), 'num_pos': 116}
2020-12-07 15:11:46,192 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.620690
2020-12-07 15:13:02,689 maskrcnn_benchmark.trainer INFO: eta: 0:58:43  iter: 820  loss: 1.2168 (3.5313)  loss_classifier: 0.5000 (0.9530)  loss_box_reg: 0.4719 (0.5252)  loss_objectness: 0.2545 (0.8099)  loss_rpn_box_reg: 0.0422 (1.2432)  time: 3.7870 (5.1810)  data: 0.1433 (1.5122)  lr: 0.000000  max mem: 1423
2020-12-07 15:14:20,362 maskrcnn_benchmark.trainer INFO: eta: 0:56:39  iter: 840  loss: 1.0123 (3.5107)  loss_classifier: 0.3956 (0.9512)  loss_box_reg: 0.2848 (0.5211)  loss_objectness: 0.2508 (0.8051)  loss_rpn_box_reg: 0.0728 (1.2332)  time: 3.8911 (5.1501)  data: 0.1399 (1.4797)  lr: 0.000000  max mem: 1423
2020-12-07 15:15:36,108 maskrcnn_benchmark.trainer INFO: eta: 0:54:35  iter: 860  loss: 2.1574 (3.5054)  loss_classifier: 0.9288 (0.9531)  loss_box_reg: 0.4848 (0.5224)  loss_objectness: 0.2966 (0.8008)  loss_rpn_box_reg: 0.1115 (1.2292)  time: 3.7851 (5.1184)  data: 0.1350 (1.4485)  lr: 0.000000  max mem: 1423
2020-12-07 15:16:51,708 maskrcnn_benchmark.trainer INFO: eta: 0:52:34  iter: 880  loss: 1.9667 (3.5468)  loss_classifier: 0.5892 (0.9499)  loss_box_reg: 0.2707 (0.5227)  loss_objectness: 0.3285 (0.8089)  loss_rpn_box_reg: 0.0700 (1.2653)  time: 3.7774 (5.0880)  data: 0.1401 (1.4187)  lr: 0.000000  max mem: 1423
2020-12-07 15:18:07,262 maskrcnn_benchmark.trainer INFO: eta: 0:50:35  iter: 900  loss: 1.4554 (3.5629)  loss_classifier: 0.5100 (0.9493)  loss_box_reg: 0.4915 (0.5229)  loss_objectness: 0.2726 (0.8105)  loss_rpn_box_reg: 0.0803 (1.2803)  time: 3.7747 (5.0589)  data: 0.1394 (1.3904)  lr: 0.000000  max mem: 1423
2020-12-07 15:18:07,264 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-07 15:18:07,285 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(92 images).
2020-12-07 15:20:21,347 maskrcnn_benchmark.inference INFO: Total run time: 0:02:14.061815 (1.4571936389674311 s / img per device, on 1 devices)
2020-12-07 15:20:21,347 maskrcnn_benchmark.inference INFO: Model inference time: 0:02:08.836769 (1.4003996641739556 s / img per device, on 1 devices)
2020-12-07 15:20:21,347 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 15:20:26,425 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 15:20:26,425 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([7.7696e-03, 3.5396e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1041e-03, 0.0000e+00, 4.0791e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.5482e-03, 9.1120e-07, 4.9093e-02, 1.9764e-03, 0.0000e+00, 0.0000e+00,
        8.3154e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1573e-02, 7.7722e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5961e-02, 0.0000e+00, 0.0000e+00,
        6.2094e-02, 0.0000e+00, 5.0568e-02, 0.0000e+00, 9.2377e-02, 0.0000e+00,
        0.0000e+00, 3.4914e-02, 2.0449e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.9025e-02, 0.0000e+00, 1.0755e-01,
        9.1601e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.4719e-03, 0.0000e+00, 0.0000e+00, 4.9070e-02,
        0.0000e+00, 0.0000e+00, 1.6423e-02, 0.0000e+00, 9.7068e-04, 1.6628e-03,
        0.0000e+00, 1.4250e-01, 3.8309e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2997e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.9255e-04, 2.3759e-01, 0.0000e+00, 2.3949e-02,
        4.1017e-02, 1.0293e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3469e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3799e-02, 2.4139e-04, 8.3650e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4777e-02, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 8.,  8., -1.,  3.,  6.,  8.,  2.,  8.,  8.,  8.,  5.,  3.,  3.,  6.,
         3.,  8.,  8.,  8.,  6.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8., -1.,  2.,  8.,  3.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,
         8.,  8.,  8.,  3.,  8., -1.,  8.,  3.,  8.,  3.,  5.,  8.,  5.,  6.,
         5.,  8.,  5.,  8.,  8., -1.,  6.,  8.,  6.,  3.,  8.,  6.,  8.,  3.,
         3.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,  8., -1.,  3.,
         8.,  8.,  8.,  6., -1.,  3.,  8.,  3.,  3.,  8.,  8.,  8.,  8.,  8.,
         2.,  6.,  8.,  8.,  3.,  3.,  6.,  8.,  8.,  8.,  5.,  6.,  8.,  6.,
         8.,  8.,  8., -1., -1.]), 'best match scores': tensor([0.8816, 0.9993, 0.0000, 0.9171, 1.0000, 0.7884, 0.9876, 1.0000, 0.2418,
        1.0000, 1.0000, 0.9692, 0.9486, 1.0000, 0.0668, 1.0000, 0.2291, 0.6825,
        0.9986, 1.0000, 0.0653, 0.4214, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,
        1.0000, 0.4695, 0.0000, 0.9996, 0.9965, 1.0000, 0.2523, 0.4838, 0.4681,
        0.9942, 0.0854, 1.0000, 0.9994, 0.8988, 1.0000, 1.0000, 1.0000, 0.3948,
        0.9977, 0.9988, 0.0000, 0.6486, 0.9660, 0.7617, 1.0000, 0.7358, 1.0000,
        0.9438, 1.0000, 0.3438, 0.3341, 0.9994, 0.3738, 0.4759, 0.0000, 0.9999,
        0.9100, 1.0000, 1.0000, 0.2293, 0.5831, 0.8785, 0.8168, 0.8745, 1.0000,
        0.2454, 0.8262, 0.3151, 0.9872, 1.0000, 0.6152, 0.9992, 1.0000, 0.0000,
        0.9998, 0.0000, 0.4585, 1.0000, 0.9820, 0.2645, 0.0580, 0.0000, 1.0000,
        0.9993, 0.2686, 0.2884, 0.7681, 0.5767, 0.9627, 0.6006, 1.0000, 1.0000,
        0.9971, 0.9859, 1.0000, 1.0000, 0.8739, 1.0000, 1.0000, 0.7206, 0.9979,
        1.0000, 1.0000, 0.9968, 1.0000, 1.0000, 0.9716, 1.0000, 0.0000, 0.0000]), 'num_pos': 117}
2020-12-07 15:20:26,443 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-07 15:21:41,914 maskrcnn_benchmark.trainer INFO: eta: 0:50:05  iter: 920  loss: 1.2642 (3.5744)  loss_classifier: 0.4723 (0.9430)  loss_box_reg: 0.3933 (0.5234)  loss_objectness: 0.2717 (0.8121)  loss_rpn_box_reg: 0.0396 (1.2958)  time: 3.7717 (5.1822)  data: 0.1425 (1.5145)  lr: 0.000000  max mem: 1423
2020-12-07 15:22:57,626 maskrcnn_benchmark.trainer INFO: eta: 0:48:05  iter: 940  loss: 1.2354 (3.5731)  loss_classifier: 0.4903 (0.9402)  loss_box_reg: 0.3955 (0.5242)  loss_objectness: 0.2661 (0.8095)  loss_rpn_box_reg: 0.0481 (1.2991)  time: 3.7843 (5.1525)  data: 0.1423 (1.4853)  lr: 0.000000  max mem: 1423
2020-12-07 15:24:13,212 maskrcnn_benchmark.trainer INFO: eta: 0:46:06  iter: 960  loss: 2.6104 (3.6312)  loss_classifier: 0.7033 (0.9404)  loss_box_reg: 0.3403 (0.5236)  loss_objectness: 0.3826 (0.8183)  loss_rpn_box_reg: 0.1418 (1.3489)  time: 3.7770 (5.1239)  data: 0.1337 (1.4572)  lr: 0.000000  max mem: 1423
2020-12-07 15:25:28,841 maskrcnn_benchmark.trainer INFO: eta: 0:44:10  iter: 980  loss: 1.3210 (3.6185)  loss_classifier: 0.4747 (0.9351)  loss_box_reg: 0.3866 (0.5219)  loss_objectness: 0.2869 (0.8156)  loss_rpn_box_reg: 0.0503 (1.3458)  time: 3.7789 (5.0965)  data: 0.1420 (1.4304)  lr: 0.000000  max mem: 1423
2020-12-07 15:26:44,445 maskrcnn_benchmark.trainer INFO: eta: 0:42:15  iter: 1000  loss: 1.6266 (3.6293)  loss_classifier: 0.7368 (0.9344)  loss_box_reg: 0.4812 (0.5222)  loss_objectness: 0.3172 (0.8157)  loss_rpn_box_reg: 0.0394 (1.3571)  time: 3.7800 (5.0702)  data: 0.1445 (1.4047)  lr: 0.000000  max mem: 1423
2020-12-07 15:26:44,447 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-07 15:26:44,467 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(92 images).
2020-12-07 15:28:58,471 maskrcnn_benchmark.inference INFO: Total run time: 0:02:14.003103 (1.456555470176365 s / img per device, on 1 devices)
2020-12-07 15:28:58,471 maskrcnn_benchmark.inference INFO: Model inference time: 0:02:08.920851 (1.4013135977413342 s / img per device, on 1 devices)
2020-12-07 15:28:58,471 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 15:29:03,547 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 15:29:03,547 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([7.8219e-03, 3.5396e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.9786e-03, 0.0000e+00, 3.0683e-03, 1.5787e-03, 1.6647e-01, 0.0000e+00,
        0.0000e+00, 1.5037e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3572e-04,
        9.1120e-07, 0.0000e+00, 1.9765e-03, 0.0000e+00, 0.0000e+00, 8.3154e-03,
        3.2958e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7722e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.3059e-01, 0.0000e+00, 6.2094e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.2377e-02, 0.0000e+00, 0.0000e+00, 2.1441e-02,
        2.0449e-03, 0.0000e+00, 0.0000e+00, 2.0693e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.8077e-02, 0.0000e+00, 1.1380e-01, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7982e-02, 0.0000e+00, 3.2837e-02,
        0.0000e+00, 0.0000e+00, 2.6093e-02, 0.0000e+00, 0.0000e+00, 1.3206e-02,
        2.0804e-03, 2.6411e-03, 1.6120e-03, 0.0000e+00, 1.1919e-01, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.0855e-01, 1.7408e-01, 3.4249e-02, 2.1546e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.7949e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.0299e-02, 2.4139e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4777e-02, 0.0000e+00,
        0.0000e+00]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 8.,  8.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  6.,  8.,
         8.,  8.,  8.,  6.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,
        -1.,  2.,  8.,  3.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         6.,  8.,  8., -1.,  8.,  3.,  8., -1.,  3.,  8.,  5.,  8.,  5.,  8.,
         8.,  8., -1.,  6.,  8.,  8.,  8.,  8.,  5.,  8., -1.,  3.,  8.,  3.,
         6.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1., -1.,  8.,  8.,  8.,  8.,
         3.,  3.,  6.,  8.,  8.,  6.,  8.,  3.,  8.,  8.,  2.,  6.,  8.,  3.,
         8.,  6.,  8.,  8.,  8.,  8.,  8.,  3.,  5.,  8., -1.,  3.,  8.,  3.,
         8., -1., -1.]), 'best match scores': tensor([0.9267, 0.9989, 0.9345, 1.0000, 0.9996, 1.0000, 0.9707, 1.0000, 0.0929,
        0.1052, 0.9688, 0.9897, 0.9997, 0.9957, 1.0000, 1.0000, 0.0566, 0.9620,
        1.0000, 1.0000, 0.5341, 1.0000, 1.0000, 1.0000, 0.9997, 0.9679, 0.9991,
        0.5009, 0.0000, 0.9998, 1.0000, 1.0000, 0.0853, 0.4819, 0.9990, 0.8888,
        0.4239, 1.0000, 0.2502, 1.0000, 1.0000, 0.9494, 1.0000, 0.7811, 0.9964,
        0.0000, 0.9649, 0.9852, 0.2949, 0.0000, 0.9825, 1.0000, 0.9502, 0.0887,
        0.2756, 0.0532, 0.1537, 0.3329, 0.0000, 1.0000, 0.5466, 0.1583, 0.9910,
        1.0000, 1.0000, 0.8948, 0.0000, 0.9760, 1.0000, 0.9506, 1.0000, 0.4508,
        0.9855, 0.1160, 0.0681, 0.9999, 0.9996, 0.0000, 0.0000, 0.0000, 0.9957,
        1.0000, 0.9701, 0.9135, 0.2694, 0.3538, 1.0000, 0.6462, 1.0000, 1.0000,
        0.9961, 1.0000, 0.8754, 1.0000, 0.0810, 0.3982, 0.9747, 0.1529, 1.0000,
        1.0000, 0.1592, 0.9989, 1.0000, 0.3752, 0.8028, 0.2008, 1.0000, 0.9989,
        0.0000, 0.1890, 1.0000, 0.7791, 1.0000, 0.0000, 0.0000]), 'num_pos': 115}
2020-12-07 15:29:03,565 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.600000
2020-12-07 15:30:19,217 maskrcnn_benchmark.trainer INFO: eta: 0:41:27  iter: 1020  loss: 0.7057 (3.6107)  loss_classifier: 0.2204 (0.9296)  loss_box_reg: 0.1900 (0.5219)  loss_objectness: 0.2272 (0.8103)  loss_rpn_box_reg: 0.0269 (1.3489)  time: 3.7753 (5.1813)  data: 0.1418 (1.5163)  lr: 0.000000  max mem: 1423
2020-12-07 15:31:35,363 maskrcnn_benchmark.trainer INFO: eta: 0:39:31  iter: 1040  loss: 1.4265 (3.6167)  loss_classifier: 0.6496 (0.9248)  loss_box_reg: 0.3024 (0.5209)  loss_objectness: 0.3341 (0.8097)  loss_rpn_box_reg: 0.0911 (1.3613)  time: 3.7807 (5.1549)  data: 0.1441 (1.4900)  lr: 0.000000  max mem: 1423
2020-12-07 15:32:51,041 maskrcnn_benchmark.trainer INFO: eta: 0:37:36  iter: 1060  loss: 1.4139 (3.6132)  loss_classifier: 0.5762 (0.9212)  loss_box_reg: 0.5163 (0.5219)  loss_objectness: 0.2972 (0.8087)  loss_rpn_box_reg: 0.0583 (1.3615)  time: 3.7839 (5.1290)  data: 0.1398 (1.4645)  lr: 0.000000  max mem: 1423
2020-12-07 15:34:06,668 maskrcnn_benchmark.trainer INFO: eta: 0:35:43  iter: 1080  loss: 0.9363 (3.5928)  loss_classifier: 0.3647 (0.9180)  loss_box_reg: 0.3705 (0.5231)  loss_objectness: 0.2331 (0.8019)  loss_rpn_box_reg: 0.0485 (1.3497)  time: 3.7806 (5.1041)  data: 0.1426 (1.4401)  lr: 0.000000  max mem: 1423
2020-12-07 15:35:22,211 maskrcnn_benchmark.trainer INFO: eta: 0:33:51  iter: 1100  loss: 1.8477 (3.6065)  loss_classifier: 0.7372 (0.9175)  loss_box_reg: 0.3526 (0.5226)  loss_objectness: 0.2671 (0.8013)  loss_rpn_box_reg: 0.0932 (1.3650)  time: 3.7768 (5.0800)  data: 0.1426 (1.4165)  lr: 0.000000  max mem: 1423
2020-12-07 15:35:22,213 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-07 15:35:22,233 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(92 images).
2020-12-07 15:37:37,028 maskrcnn_benchmark.inference INFO: Total run time: 0:02:14.795609 (1.4651696578316067 s / img per device, on 1 devices)
2020-12-07 15:37:37,029 maskrcnn_benchmark.inference INFO: Model inference time: 0:02:09.755525 (1.410386139931886 s / img per device, on 1 devices)
2020-12-07 15:37:37,029 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 15:37:42,275 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 15:37:42,276 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([7.7425e-03, 3.5396e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3527e-03,
        5.7850e-02, 0.0000e+00, 0.0000e+00, 1.5787e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.5051e-04, 3.0373e-07, 0.0000e+00, 1.9753e-03, 0.0000e+00, 0.0000e+00,
        1.0391e-02, 9.7319e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7722e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2094e-02, 0.0000e+00,
        4.9532e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1423e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6060e-02, 0.0000e+00, 1.2721e-01, 1.2774e-01, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2837e-02, 2.5213e-02,
        0.0000e+00, 0.0000e+00, 1.2940e-02, 3.0617e-02, 0.0000e+00, 1.6619e-03,
        1.3850e-03, 0.0000e+00, 1.1919e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.3545e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3833e-01, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.2377e-02, 1.8168e-02, 0.0000e+00, 0.0000e+00, 2.5327e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1542e-02, 0.0000e+00, 0.0000e+00,
        5.1792e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.4777e-02, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 8.,  8.,  3.,  6.,  6.,  8.,  8.,  8.,  6.,  8.,  3.,  3.,  6.,  8.,
         3.,  8.,  8.,  8.,  6.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         6., -1., -1.,  8.,  2.,  3.,  5.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  3.,  6.,  8.,  8.,  5., -1.,  3.,  8.,  5.,  8.,  5.,  8.,  8.,
         8.,  8.,  6.,  8.,  6.,  8.,  8.,  5.,  8.,  8.,  3.,  6.,  8.,  8.,
         8.,  8.,  8.,  8.,  8., -1., -1., -1.,  8.,  8.,  8.,  8.,  3.,  3.,
         6.,  8.,  6.,  8.,  8.,  3.,  8.,  8.,  3.,  6.,  8.,  8.,  6.,  8.,
         8.,  8.,  6.,  3.,  8.,  6.,  8., -1., -1.,  8.,  3.,  8., -1., -1.]), 'best match scores': tensor([0.8209, 1.0000, 1.0000, 1.0000, 0.2271, 1.0000, 0.6988, 1.0000, 0.7754,
        0.0598, 0.9920, 0.5908, 0.9650, 0.9995, 0.1511, 1.0000, 0.9970, 0.6169,
        0.9997, 1.0000, 1.0000, 0.9221, 0.9999, 1.0000, 1.0000, 1.0000, 0.6110,
        0.9701, 0.7825, 0.0000, 0.0000, 0.9999, 1.0000, 1.0000, 0.0623, 0.6732,
        1.0000, 0.9860, 0.3533, 0.9996, 1.0000, 0.7873, 0.9471, 0.9997, 0.9996,
        0.9483, 1.0000, 0.9993, 0.0000, 0.9998, 1.0000, 1.0000, 0.9124, 0.9885,
        1.0000, 0.2580, 0.0527, 0.4089, 0.9896, 0.9306, 0.9998, 0.9949, 0.2092,
        0.9104, 1.0000, 1.0000, 0.9991, 1.0000, 1.0000, 0.8313, 1.0000, 0.9978,
        0.9089, 0.9999, 0.9955, 0.0000, 0.0000, 0.0000, 0.8777, 0.0781, 1.0000,
        0.9992, 1.0000, 0.8333, 0.9989, 1.0000, 1.0000, 0.3054, 0.7348, 0.2006,
        0.1585, 0.7115, 1.0000, 0.8158, 0.9810, 0.6385, 0.9804, 1.0000, 0.9994,
        1.0000, 0.8190, 0.3188, 0.9648, 0.1502, 0.9669, 0.0000, 0.0000, 0.9961,
        0.2241, 0.9914, 0.0000, 0.0000]), 'num_pos': 112}
2020-12-07 15:37:42,296 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.571429
2020-12-07 15:38:58,512 maskrcnn_benchmark.trainer INFO: eta: 0:32:49  iter: 1120  loss: 1.4367 (3.5908)  loss_classifier: 0.5788 (0.9220)  loss_box_reg: 0.4203 (0.5239)  loss_objectness: 0.2194 (0.7956)  loss_rpn_box_reg: 0.0958 (1.3493)  time: 3.7803 (5.1824)  data: 0.1361 (1.5188)  lr: 0.000000  max mem: 1423
2020-12-07 15:40:14,508 maskrcnn_benchmark.trainer INFO: eta: 0:30:56  iter: 1140  loss: 1.1224 (3.5818)  loss_classifier: 0.3604 (0.9227)  loss_box_reg: 0.3981 (0.5229)  loss_objectness: 0.2352 (0.7920)  loss_rpn_box_reg: 0.0330 (1.3442)  time: 3.7845 (5.1581)  data: 0.1392 (1.4946)  lr: 0.000000  max mem: 1423
2020-12-07 15:41:30,603 maskrcnn_benchmark.trainer INFO: eta: 0:29:05  iter: 1160  loss: 2.3979 (3.6078)  loss_classifier: 0.7015 (0.9236)  loss_box_reg: 0.4561 (0.5233)  loss_objectness: 0.3868 (0.7964)  loss_rpn_box_reg: 0.2427 (1.3645)  time: 3.7855 (5.1348)  data: 0.1426 (1.4712)  lr: 0.000000  max mem: 1423
2020-12-07 15:42:46,208 maskrcnn_benchmark.trainer INFO: eta: 0:27:15  iter: 1180  loss: 1.0017 (3.5817)  loss_classifier: 0.3672 (0.9193)  loss_box_reg: 0.3001 (0.5215)  loss_objectness: 0.2149 (0.7890)  loss_rpn_box_reg: 0.0540 (1.3520)  time: 3.7721 (5.1118)  data: 0.1412 (1.4487)  lr: 0.000000  max mem: 1423
2020-12-07 15:44:01,946 maskrcnn_benchmark.trainer INFO: eta: 0:25:26  iter: 1200  loss: 1.4241 (3.5672)  loss_classifier: 0.4150 (0.9180)  loss_box_reg: 0.2992 (0.5192)  loss_objectness: 0.2318 (0.7843)  loss_rpn_box_reg: 0.0720 (1.3457)  time: 3.7784 (5.0897)  data: 0.1403 (1.4269)  lr: 0.000000  max mem: 1423
2020-12-07 15:44:01,948 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-07 15:44:01,968 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(92 images).
2020-12-07 15:46:16,184 maskrcnn_benchmark.inference INFO: Total run time: 0:02:14.215695 (1.4588662515515867 s / img per device, on 1 devices)
2020-12-07 15:46:16,184 maskrcnn_benchmark.inference INFO: Model inference time: 0:02:09.120035 (1.4034786405770674 s / img per device, on 1 devices)
2020-12-07 15:46:16,185 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 15:46:21,345 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 15:46:21,345 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([2.7198e-02, 7.4190e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6471e-02,
        1.3214e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.8376e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5689e-03,
        0.0000e+00, 0.0000e+00, 5.7581e-02, 0.0000e+00, 0.0000e+00, 4.5437e-02,
        7.6317e-03, 3.2815e-03, 0.0000e+00, 7.2095e-02, 7.7722e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9532e-03, 0.0000e+00,
        0.0000e+00, 3.6214e-02, 0.0000e+00, 0.0000e+00, 6.2094e-02, 1.4279e-03,
        4.9532e-03, 0.0000e+00, 1.1873e-01, 0.0000e+00, 0.0000e+00, 6.3048e-02,
        7.5149e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7976e-03, 1.1518e-03, 0.0000e+00,
        0.0000e+00, 2.0741e-02, 0.0000e+00, 3.7467e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.2837e-02, 1.7355e-02, 0.0000e+00, 2.4133e-02, 1.1725e-02,
        0.0000e+00, 1.2940e-02, 3.2071e-04, 9.7068e-04, 1.6619e-03, 0.0000e+00,
        1.1919e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3032e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5882e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.7914e-01, 0.0000e+00, 4.6555e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5276e-02, 3.1172e-04,
        0.0000e+00, 0.0000e+00, 1.0274e-01, 1.6499e-03, 8.8302e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6960e-05,
        0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 8.,  8.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  2.,  3.,  6.,  8.,
         8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
        -1., -1.,  8.,  2.,  5.,  6.,  5.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         6.,  8.,  8., -1.,  6.,  8.,  8.,  3.,  6.,  6.,  6.,  6.,  5.,  3.,
         8.,  8.,  8., -1.,  3.,  8.,  8.,  8., -1.,  3.,  6.,  8.,  3.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1.,  2.,  8.,  8.,
         8.,  8.,  6., -1.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  2.,  2.,
         2.,  3.,  8.,  8.,  5.,  8.,  8.,  8.,  8., -1., -1.,  6.,  3.,  6.,
         8., -1., -1.,  3.]), 'best match scores': tensor([0.1700, 0.1813, 1.0000, 1.0000, 1.0000, 0.7656, 0.9996, 1.0000, 0.9958,
        0.9948, 0.7235, 0.3697, 1.0000, 0.9876, 1.0000, 1.0000, 0.8856, 0.8537,
        1.0000, 0.9832, 0.7854, 1.0000, 0.9578, 1.0000, 0.0924, 0.9517, 1.0000,
        0.9992, 0.0000, 0.0000, 0.7506, 0.9663, 0.0917, 0.2116, 0.9945, 0.3367,
        0.2337, 0.1192, 0.9865, 0.9977, 1.0000, 1.0000, 1.0000, 0.0736, 1.0000,
        0.0000, 0.8120, 0.9973, 0.0814, 1.0000, 0.9992, 1.0000, 1.0000, 0.9999,
        0.9057, 0.9998, 0.6234, 0.9965, 0.7639, 0.0000, 0.2360, 1.0000, 0.2039,
        0.9088, 0.0000, 0.2653, 0.6211, 1.0000, 0.5268, 0.9996, 1.0000, 0.5693,
        0.9940, 1.0000, 0.9087, 1.0000, 0.9997, 0.1660, 0.9900, 0.0000, 0.0000,
        0.0568, 0.1163, 0.6036, 1.0000, 0.6954, 0.6361, 0.0000, 0.5812, 0.4262,
        1.0000, 0.9884, 0.9526, 0.9531, 0.8406, 1.0000, 0.0613, 1.0000, 0.9997,
        0.1353, 1.0000, 1.0000, 1.0000, 0.9999, 0.6809, 0.9999, 0.3706, 0.0000,
        0.0000, 0.9999, 0.9902, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000]), 'num_pos': 116}
2020-12-07 15:46:21,366 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.577586
2020-12-07 15:47:36,888 maskrcnn_benchmark.trainer INFO: eta: 0:24:11  iter: 1220  loss: 0.9978 (3.5847)  loss_classifier: 0.3440 (0.9096)  loss_box_reg: 0.3365 (0.5169)  loss_objectness: 0.2312 (0.7870)  loss_rpn_box_reg: 0.0272 (1.3712)  time: 3.7762 (5.1825)  data: 0.1397 (1.5201)  lr: 0.000000  max mem: 1423
2020-12-07 15:48:52,537 maskrcnn_benchmark.trainer INFO: eta: 0:22:21  iter: 1240  loss: 1.4666 (3.5987)  loss_classifier: 0.6421 (0.9085)  loss_box_reg: 0.5143 (0.5171)  loss_objectness: 0.2511 (0.7906)  loss_rpn_box_reg: 0.1235 (1.3825)  time: 3.7805 (5.1599)  data: 0.1364 (1.4978)  lr: 0.000000  max mem: 1423
2020-12-07 15:50:08,193 maskrcnn_benchmark.trainer INFO: eta: 0:20:33  iter: 1260  loss: 1.2044 (3.5987)  loss_classifier: 0.4200 (0.9047)  loss_box_reg: 0.4244 (0.5171)  loss_objectness: 0.2454 (0.7900)  loss_rpn_box_reg: 0.0502 (1.3868)  time: 3.7800 (5.1380)  data: 0.1422 (1.4763)  lr: 0.000000  max mem: 1423
2020-12-07 15:51:24,540 maskrcnn_benchmark.trainer INFO: eta: 0:18:45  iter: 1280  loss: 1.0862 (3.5927)  loss_classifier: 0.4692 (0.9021)  loss_box_reg: 0.3503 (0.5157)  loss_objectness: 0.2579 (0.7888)  loss_rpn_box_reg: 0.0327 (1.3861)  time: 3.7847 (5.1174)  data: 0.1381 (1.4554)  lr: 0.000000  max mem: 1423
2020-12-07 15:52:40,578 maskrcnn_benchmark.trainer INFO: eta: 0:16:59  iter: 1300  loss: 1.4969 (3.5787)  loss_classifier: 0.5688 (0.8986)  loss_box_reg: 0.4415 (0.5159)  loss_objectness: 0.2466 (0.7854)  loss_rpn_box_reg: 0.0729 (1.3788)  time: 3.7796 (5.0972)  data: 0.1387 (1.4352)  lr: 0.000000  max mem: 1423
2020-12-07 15:52:40,580 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-07 15:52:40,601 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(92 images).
2020-12-07 15:54:57,953 maskrcnn_benchmark.inference INFO: Total run time: 0:02:17.352219 (1.4929589007211768 s / img per device, on 1 devices)
2020-12-07 15:54:57,953 maskrcnn_benchmark.inference INFO: Model inference time: 0:02:11.983536 (1.4346036574114924 s / img per device, on 1 devices)
2020-12-07 15:54:57,953 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 15:55:03,279 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 15:55:03,280 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([2.6850e-02, 7.5106e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8032e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2226e-02,
        9.2267e-04, 7.5145e-03, 1.9753e-03, 0.0000e+00, 0.0000e+00, 3.3136e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4777e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.2094e-02, 5.6989e-02, 0.0000e+00, 0.0000e+00,
        9.2377e-02, 6.3048e-02, 2.4383e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7976e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.2831e-02, 3.2837e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2940e-02, 0.0000e+00, 9.7068e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1919e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2659e-04, 2.1914e-01, 5.1399e-02,
        9.2377e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3469e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.6214e-02, 2.4139e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8]), 'best match labels': tensor([ 8.,  8.,  3.,  5.,  6.,  3.,  5.,  8.,  8.,  8.,  8.,  3.,  6.,  8.,
         8.,  8.,  8.,  8.,  3.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,
        -1., -1., -1., -1.,  2.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,
         8.,  8.,  8.,  3.,  6.,  6.,  6.,  6.,  5.,  5.,  8.,  8.,  8., -1.,
         6.,  8.,  3.,  6.,  8.,  8.,  3.,  5.,  8.,  6.,  8.,  8.,  8.,  8.,
         8.,  8.,  8., -1.,  8.,  8.,  8., -1.,  3.,  3.,  8.,  3.,  8.,  8.,
         8.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,  3.,  6.,
        -1., -1.,  3.]), 'best match scores': tensor([0.9916, 0.0625, 1.0000, 1.0000, 0.3824, 0.9975, 0.2830, 0.9964, 1.0000,
        0.9303, 0.9961, 0.6998, 1.0000, 1.0000, 1.0000, 1.0000, 0.0573, 0.0618,
        1.0000, 0.9517, 0.6505, 0.9100, 0.5479, 1.0000, 0.9997, 1.0000, 0.1035,
        0.4260, 0.0000, 0.0000, 0.0000, 0.0000, 0.9999, 1.0000, 0.9882, 1.0000,
        1.0000, 1.0000, 1.0000, 0.8117, 0.8428, 0.8503, 1.0000, 0.9999, 0.9905,
        0.7169, 0.9219, 0.9992, 0.9825, 0.9922, 0.9224, 0.6070, 0.1863, 1.0000,
        1.0000, 0.0000, 1.0000, 0.5946, 0.1666, 0.9999, 0.3065, 0.9756, 0.3551,
        0.9992, 0.0514, 1.0000, 1.0000, 0.8816, 1.0000, 0.1765, 0.8004, 1.0000,
        0.9898, 0.0000, 1.0000, 0.3343, 0.2253, 0.0000, 0.7226, 0.2514, 0.0831,
        1.0000, 1.0000, 1.0000, 0.3825, 1.0000, 0.2347, 0.2841, 1.0000, 0.9972,
        0.9999, 0.0939, 1.0000, 0.3999, 0.1913, 0.0000, 0.3890, 1.0000, 0.0000,
        0.0000, 0.3457]), 'num_pos': 101}
2020-12-07 15:55:03,298 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.564356
2020-12-07 15:56:20,601 maskrcnn_benchmark.trainer INFO: eta: 0:15:33  iter: 1320  loss: 1.3948 (3.5647)  loss_classifier: 0.5671 (0.9011)  loss_box_reg: 0.6491 (0.5182)  loss_objectness: 0.1876 (0.7800)  loss_rpn_box_reg: 0.0285 (1.3654)  time: 3.8491 (5.1866)  data: 0.1463 (1.5237)  lr: 0.000000  max mem: 1423
2020-12-07 15:57:38,016 maskrcnn_benchmark.trainer INFO: eta: 0:13:46  iter: 1340  loss: 1.1009 (3.5380)  loss_classifier: 0.3888 (0.8974)  loss_box_reg: 0.2935 (0.5155)  loss_objectness: 0.2082 (0.7741)  loss_rpn_box_reg: 0.0428 (1.3511)  time: 3.8681 (5.1670)  data: 0.1418 (1.5031)  lr: 0.000000  max mem: 1423
2020-12-07 15:58:54,641 maskrcnn_benchmark.trainer INFO: eta: 0:12:00  iter: 1360  loss: 1.6135 (3.5245)  loss_classifier: 0.6629 (0.8996)  loss_box_reg: 0.5871 (0.5175)  loss_objectness: 0.1974 (0.7681)  loss_rpn_box_reg: 0.0638 (1.3393)  time: 3.7813 (5.1473)  data: 0.1435 (1.4832)  lr: 0.000000  max mem: 1423
2020-12-07 16:00:10,324 maskrcnn_benchmark.trainer INFO: eta: 0:10:15  iter: 1380  loss: 0.9397 (3.5174)  loss_classifier: 0.3847 (0.8952)  loss_box_reg: 0.3189 (0.5170)  loss_objectness: 0.1717 (0.7651)  loss_rpn_box_reg: 0.0285 (1.3401)  time: 3.7831 (5.1276)  data: 0.1417 (1.4637)  lr: 0.000000  max mem: 1423
2020-12-07 16:01:25,942 maskrcnn_benchmark.trainer INFO: eta: 0:08:30  iter: 1400  loss: 1.5225 (3.4939)  loss_classifier: 0.5590 (0.8947)  loss_box_reg: 0.4628 (0.5182)  loss_objectness: 0.1875 (0.7583)  loss_rpn_box_reg: 0.0319 (1.3226)  time: 3.7791 (5.1083)  data: 0.1409 (1.4448)  lr: 0.000000  max mem: 1423
2020-12-07 16:01:25,944 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-07 16:01:25,964 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(92 images).
2020-12-07 16:03:41,560 maskrcnn_benchmark.inference INFO: Total run time: 0:02:15.596512 (1.4738751287045686 s / img per device, on 1 devices)
2020-12-07 16:03:41,561 maskrcnn_benchmark.inference INFO: Model inference time: 0:02:10.348616 (1.4168327787648076 s / img per device, on 1 devices)
2020-12-07 16:03:41,561 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 16:03:46,803 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 16:03:46,803 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8261e-03,
        5.8146e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3540e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3564e-03,
        0.0000e+00, 3.2631e-02, 1.9753e-03, 0.0000e+00, 0.0000e+00, 4.3074e-02,
        7.8538e-03, 7.4161e-05, 0.0000e+00, 4.8304e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4777e-02, 4.9532e-03,
        0.0000e+00, 6.2094e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1560e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7976e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.9020e-02, 0.0000e+00, 1.1023e-02, 1.3178e-04,
        3.2837e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5137e-02,
        2.0804e-03, 7.6768e-04, 2.6660e-01, 0.0000e+00, 1.1919e-01, 6.6586e-02,
        0.0000e+00, 0.0000e+00, 7.9132e-02, 0.0000e+00, 0.0000e+00, 6.0927e-04,
        1.7408e-01, 6.3981e-02, 4.1017e-02, 9.2377e-02, 1.4935e-02, 0.0000e+00,
        0.0000e+00, 2.3469e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6214e-02,
        2.4139e-04, 9.6661e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([-1.,  3.,  3.,  5.,  8.,  8.,  8.,  8.,  6.,  2.,  3.,  6.,  3.,  8.,
         8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  2.,  8.,  8.,
        -1., -1., -1.,  2.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  5.,
         8.,  8., -1.,  3.,  6.,  6.,  6.,  8.,  5.,  6.,  8., -1., -1.,  3.,
         8.,  3.,  8.,  8.,  8., -1.,  5.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1.,  8.,  8.,  8.,  6.,  3.,  8.,  8.,  8.,  8.,  2.,  3.,
         8.,  8.,  5.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  8.]), 'best match scores': tensor([0.0000, 1.0000, 0.1861, 1.0000, 0.2378, 0.9990, 0.8442, 0.8782, 1.0000,
        1.0000, 0.9982, 1.0000, 0.8685, 1.0000, 1.0000, 0.9930, 0.9999, 0.9999,
        1.0000, 0.6940, 1.0000, 0.8690, 0.4056, 1.0000, 1.0000, 0.1276, 0.5089,
        0.5439, 0.0000, 0.0000, 0.0000, 0.3344, 0.3464, 1.0000, 1.0000, 0.8720,
        0.9997, 1.0000, 0.3387, 0.9602, 0.9964, 0.9997, 0.9890, 0.7969, 0.0000,
        0.9679, 0.9979, 0.0791, 0.9053, 0.3693, 0.5480, 0.9961, 1.0000, 0.0000,
        0.0000, 0.9925, 0.1622, 0.9926, 0.8087, 0.1359, 0.9972, 0.0000, 0.9989,
        1.0000, 1.0000, 1.0000, 0.1240, 1.0000, 0.9249, 0.5396, 0.8811, 0.1736,
        0.0000, 1.0000, 0.1722, 0.6172, 0.6767, 0.8470, 1.0000, 0.3714, 1.0000,
        0.1180, 0.9999, 0.9771, 0.8314, 1.0000, 1.0000, 1.0000, 0.9825, 0.7755,
        0.2124, 0.3971, 1.0000, 0.0878, 0.9547]), 'num_pos': 95}
2020-12-07 16:03:46,821 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.578947
2020-12-07 16:05:02,718 maskrcnn_benchmark.trainer INFO: eta: 0:06:55  iter: 1420  loss: 1.1765 (3.4873)  loss_classifier: 0.5111 (0.8893)  loss_box_reg: 0.5095 (0.5180)  loss_objectness: 0.1539 (0.7559)  loss_rpn_box_reg: 0.0535 (1.3241)  time: 3.7825 (5.1891)  data: 0.1413 (1.5257)  lr: 0.000000  max mem: 1423
2020-12-07 16:06:18,475 maskrcnn_benchmark.trainer INFO: eta: 0:05:10  iter: 1440  loss: 1.2029 (3.4661)  loss_classifier: 0.5094 (0.8910)  loss_box_reg: 0.4130 (0.5179)  loss_objectness: 0.2034 (0.7493)  loss_rpn_box_reg: 0.0522 (1.3079)  time: 3.7794 (5.1696)  data: 0.1429 (1.5065)  lr: 0.000000  max mem: 1423
2020-12-07 16:07:34,502 maskrcnn_benchmark.trainer INFO: eta: 0:03:26  iter: 1460  loss: 1.5654 (3.4754)  loss_classifier: 0.6576 (0.8944)  loss_box_reg: 0.5755 (0.5181)  loss_objectness: 0.2809 (0.7507)  loss_rpn_box_reg: 0.1086 (1.3122)  time: 3.7845 (5.1508)  data: 0.1398 (1.4878)  lr: 0.000000  max mem: 1423
2020-12-07 16:08:53,591 maskrcnn_benchmark.trainer INFO: eta: 0:01:42  iter: 1480  loss: 1.2448 (3.4490)  loss_classifier: 0.5859 (0.8922)  loss_box_reg: 0.4383 (0.5173)  loss_objectness: 0.1826 (0.7438)  loss_rpn_box_reg: 0.0276 (1.2957)  time: 3.9420 (5.1347)  data: 0.1433 (1.4696)  lr: 0.000000  max mem: 1423
2020-12-07 16:10:12,906 maskrcnn_benchmark.trainer INFO: eta: 0:00:00  iter: 1500  loss: 1.7853 (3.4795)  loss_classifier: 0.7360 (0.8922)  loss_box_reg: 0.3751 (0.5175)  loss_objectness: 0.4744 (0.7496)  loss_rpn_box_reg: 0.1030 (1.3202)  time: 3.9636 (5.1191)  data: 0.1451 (1.4520)  lr: 0.000000  max mem: 1423
2020-12-07 16:10:12,908 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-07 16:10:12,930 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(92 images).
2020-12-07 16:12:30,021 maskrcnn_benchmark.inference INFO: Total run time: 0:02:17.090690 (1.4901161997214607 s / img per device, on 1 devices)
2020-12-07 16:12:30,021 maskrcnn_benchmark.inference INFO: Model inference time: 0:02:11.526673 (1.4296377482621565 s / img per device, on 1 devices)
2020-12-07 16:12:30,021 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 16:12:35,401 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 16:12:35,401 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([4.6972e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.0809e-03, 0.0000e+00, 4.0791e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0431e-03, 0.0000e+00, 7.3006e-02, 1.9779e-03, 0.0000e+00, 0.0000e+00,
        8.3154e-03, 3.6611e-03, 1.0876e-04, 0.0000e+00, 0.0000e+00, 7.7722e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0878e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2094e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4897e-02, 9.5325e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.7976e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2837e-02, 0.0000e+00, 0.0000e+00,
        4.5259e-02, 0.0000e+00, 0.0000e+00, 1.2940e-02, 1.6997e-04, 8.0527e-04,
        7.6842e-02, 0.0000e+00, 1.2859e-01, 2.1645e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.9427e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1531e-01,
        6.2402e-06, 1.6267e-01, 0.0000e+00, 0.0000e+00, 8.3896e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3469e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.6617e-02, 2.4139e-04, 8.3650e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6960e-05, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 8., -1.,  3.,  6.,  8.,  3.,  8.,  8.,  8.,  8.,  2.,  3.,  3.,  8.,
         8.,  8.,  8.,  5.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  2.,  8.,
         6., -1., -1.,  8., -1.,  2.,  5.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,
         8., -1.,  6.,  8.,  8.,  6.,  8.,  6.,  6.,  6.,  5.,  8.,  3.,  8.,
         8., -1.,  6.,  8.,  6.,  8.,  5.,  8., -1.,  8.,  8.,  2.,  6.,  8.,
         8.,  8.,  8.,  8.,  8.,  8., -1.,  8.,  6., -1.,  3.,  3.,  8.,  8.,
         3.,  8.,  8.,  8.,  8.,  3.,  6.,  3.,  8.,  5.,  8.,  8.,  8.,  8.,
         8., -1., -1.,  6., -1., -1.,  6., -1., -1.,  3.]), 'best match scores': tensor([0.9999, 0.0000, 1.0000, 0.2534, 0.2893, 0.9587, 0.9992, 1.0000, 0.9977,
        0.9996, 0.9998, 0.9330, 0.3782, 0.8671, 0.9990, 1.0000, 0.6910, 0.7793,
        1.0000, 0.9983, 0.8166, 0.1662, 1.0000, 0.2178, 1.0000, 0.8336, 0.2255,
        1.0000, 0.7631, 0.0000, 0.0000, 0.2492, 0.0000, 0.9997, 0.4658, 0.0637,
        1.0000, 0.9997, 1.0000, 0.9840, 0.9993, 0.3871, 0.9614, 0.0000, 0.9989,
        1.0000, 0.9999, 0.9802, 0.9986, 0.9529, 1.0000, 0.9999, 0.9999, 0.9999,
        0.9998, 1.0000, 1.0000, 0.0000, 1.0000, 0.3415, 0.7038, 0.4428, 1.0000,
        1.0000, 0.0000, 1.0000, 1.0000, 0.3295, 1.0000, 0.7195, 0.9821, 1.0000,
        0.0631, 0.9945, 1.0000, 0.9033, 0.0000, 1.0000, 0.9827, 0.0000, 1.0000,
        0.9365, 0.1312, 0.0538, 1.0000, 0.9996, 0.1390, 1.0000, 0.9452, 1.0000,
        0.2549, 0.4762, 1.0000, 0.9559, 1.0000, 1.0000, 0.4337, 0.2604, 0.9825,
        0.0000, 0.0000, 0.6816, 0.0000, 0.0000, 0.7245, 0.0000, 0.0000, 0.0991]), 'num_pos': 108}
2020-12-07 16:12:35,420 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.527778
2020-12-07 16:12:35,425 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./final_mode_r2.pth
2020-12-07 16:12:36,026 maskrcnn_benchmark.trainer INFO: final model, saving model to: final_mode_r2
2020-12-07 16:12:36,036 maskrcnn_benchmark.trainer INFO: Total training time: 2:10:21.774350 (5.2145 s / it)
2020-12-07 16:12:48,731 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_test dataset(140 images).
2020-12-07 16:16:17,310 maskrcnn_benchmark.inference INFO: Total run time: 0:03:28.578046 (1.4898431846073696 s / img per device, on 1 devices)
2020-12-07 16:16:17,310 maskrcnn_benchmark.inference INFO: Model inference time: 0:03:19.201674 (1.4228690998894828 s / img per device, on 1 devices)
2020-12-07 16:16:17,344 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 16:16:25,423 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 16:16:25,423 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7841e-02, 3.4309e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.1550e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.3589e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.7152e-04, 2.1064e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7210e-02, 4.0342e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1633e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.1617e-02, 0.0000e+00, 0.0000e+00, 1.8319e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8221e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.5169e-03, 0.0000e+00, 0.0000e+00, 9.9961e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.1918e-02, 2.3520e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.0703e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0950e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.7068e-02, 5.2027e-02, 1.9076e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.8555e-03, 6.2794e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.4006e-03, 0.0000e+00, 0.0000e+00, 4.4930e-02, 3.3471e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2087e-03, 4.9433e-06, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5695e-03,
        0.0000e+00, 0.0000e+00, 3.2460e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.0342e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.2941e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.0262e-02, 4.0342e-03, 0.0000e+00, 0.0000e+00,
        3.6216e-03, 9.9006e-04, 1.6333e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6216e-03,
        1.4403e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9941e-01,
        2.0507e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3417e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.2479e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3389e-03,
        3.2056e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3411e-03, 1.9815e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.5600e-02, 6.4282e-02, 3.1186e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3055e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8462e-01,
        2.7584e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6394e-03, 1.0876e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.0052e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2609e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1393e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1080e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.5182e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1904e-03,
        1.8095e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00]), 'gt_labels': tensor([7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 5, 5, 7, 7, 4, 7, 7, 7,
        7, 4, 7, 7, 8, 8, 8, 7, 7, 4, 7, 7, 4, 7, 7, 8, 8, 8, 7, 7, 8, 8, 7, 7,
        5, 5, 7, 7, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7,
        7, 4, 7, 7, 4, 7, 7, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7,
        4, 7, 7, 4, 7, 7, 8, 8, 8, 8, 8, 8, 5, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 5,
        7, 7, 5, 5, 7, 7, 5, 5, 7, 7, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7,
        7, 7, 8, 8, 7, 7, 4, 7, 7, 8, 8, 8, 8, 5, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 7, 7, 8, 7, 7, 4, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8,
        8, 5, 7, 7, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8,
        8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 7, 5, 5, 7, 7, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7,
        7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 5, 7,
        7, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 5, 8, 7,
        7, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 5, 5, 7, 7, 8, 8, 8, 8, 8, 5, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 7, 7, 5, 5, 7, 7, 5, 5, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1.,  6., -1., -1., -1., -1.,
        -1., -1., -1., -1.,  8., -1., -1., -1., -1., -1., -1., -1., -1.,  8.,
        -1., -1., -1., -1.,  2., -1.,  8., -1., -1.,  6., -1., -1.,  3.,  8.,
        -1.,  8.,  8., -1.,  6., -1., -1.,  8., -1., -1.,  8.,  6.,  8., -1.,
        -1.,  2., -1., -1.,  6.,  5.,  6.,  8.,  3.,  8., -1., -1.,  8.,  8.,
        -1.,  6.,  8.,  8., -1., -1.,  2., -1., -1., -1., -1.,  3.,  3.,  3.,
         3.,  3., -1., -1., -1., -1., -1., -1.,  2.,  2.,  3., -1., -1.,  8.,
        -1., -1.,  2.,  6.,  8., -1., -1.,  8., -1., -1., -1., -1.,  2.,  2.,
         6.,  8.,  8.,  8.,  8., -1., -1., -1., -1., -1., -1., -1., -1.,  3.,
        -1., -1., -1.,  8., -1., -1., -1., -1., -1., -1., -1., -1.,  8., -1.,
        -1.,  8.,  2.,  8.,  2., -1.,  2.,  3., -1., -1., -1., -1., -1., -1.,
        -1., -1.,  3., -1., -1.,  8., -1., -1.,  8., -1., -1., -1., -1.,  3.,
        -1.,  6.,  8.,  8., -1.,  3.,  6.,  8., -1., -1.,  6., -1., -1., -1.,
        -1., -1., -1.,  3.,  8.,  8., -1., -1.,  6., -1., -1., -1., -1., -1.,
        -1., -1., -1.,  8., -1.,  2.,  6.,  8.,  8., -1., -1.,  8., -1., -1.,
         2., -1., -1.,  8.,  8.,  8., -1., -1., -1.,  8., -1.,  2.,  2., -1.,
        -1.,  8.,  8.,  6.,  8.,  2., -1., -1.,  2.,  2.,  2.,  3.,  6.,  8.,
         8.,  8.,  8., -1.,  8.,  8.,  8., -1., -1., -1., -1.,  8., -1.,  3.,
         5.,  6.,  8., -1., -1., -1., -1., -1., -1., -1.,  8.,  8., -1., -1.,
        -1., -1., -1., -1., -1.,  3.,  8., -1.,  5.,  8.,  3.,  6., -1.,  2.,
         6., -1., -1.,  8., -1., -1., -1.,  8., -1., -1., -1., -1., -1., -1.,
        -1., -1., -1., -1.,  8., -1., -1.,  8.,  6., -1., -1., -1., -1., -1.,
        -1., -1., -1., -1., -1.,  8., -1.,  6.,  8.,  8.,  8., -1., -1., -1.,
         6.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1., -1., -1., -1.,  8.,
        -1., -1., -1.,  2., -1., -1.,  8., -1., -1., -1., -1., -1., -1., -1.,
         3.,  8., -1., -1., -1., -1.,  3.,  3.,  8.,  8.,  8., -1., -1., -1.,
         6., -1.,  2.,  8.,  8.,  3.,  5., -1., -1.,  6., -1., -1., -1., -1.,
        -1., -1., -1., -1.,  2.,  6.,  8., -1., -1., -1., -1., -1., -1., -1.,
        -1.,  8., -1., -1.,  8., -1., -1., -1., -1., -1., -1., -1., -1.,  8.,
        -1., -1., -1., -1., -1., -1.,  8., -1., -1., -1.,  8.,  3.,  8.,  6.,
         8.,  8.,  8.,  8., -1., -1., -1., -1.,  8.,  8., -1., -1.,  5.,  5.,
         6., -1., -1., -1., -1., -1., -1., -1., -1.,  2., -1., -1., -1., -1.,
         8.,  8., -1.,  3.,  3.,  6.,  8., -1., -1.,  6., -1., -1., -1., -1.,
        -1.,  8., -1., -1.,  8., -1., -1., -1., -1., -1.,  8., -1., -1., -1.,
        -1.,  8.,  3., -1., -1., -1., -1., -1.,  8., -1., -1., -1., -1., -1.,
        -1.,  6.,  8., -1., -1., -1.,  8., -1., -1., -1., -1., -1., -1., -1.,
         8., -1., -1., -1., -1.,  2.,  8.,  8., -1., -1., -1., -1., -1., -1.,
        -1.,  3.,  8.,  8., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,
         8.,  8.,  6.,  8.,  2.,  8., -1., -1., -1., -1., -1., -1., -1.,  8.,
         8.,  8., -1., -1., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,
        -1., -1., -1., -1.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1.,  8., -1.,
        -1., -1., -1.,  3.,  6.,  8., -1., -1., -1., -1., -1., -1., -1., -1.,
         8.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0559, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.9998, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.2186, 0.0000, 0.0000, 0.0000, 0.0000, 0.9352, 0.0000, 0.9990, 0.0000,
        0.0000, 0.9997, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.9987, 0.0874,
        0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.3704, 0.0844,
        0.9999, 0.0000, 0.0000, 0.9359, 0.0000, 0.0000, 1.0000, 0.0569, 0.1309,
        0.9994, 0.9999, 1.0000, 0.0000, 0.0000, 0.9895, 0.2089, 0.0000, 1.0000,
        0.9973, 1.0000, 0.0000, 0.0000, 0.6840, 0.0000, 0.0000, 0.0000, 0.0000,
        0.9996, 0.9937, 0.4259, 1.0000, 0.7590, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0942, 0.9289, 0.2430, 0.0000, 0.0000, 0.9999, 0.0000,
        0.0000, 0.7304, 1.0000, 1.0000, 0.0000, 0.0000, 0.9999, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0744, 0.9788, 1.0000, 1.0000, 1.0000, 0.9903, 1.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6962,
        0.0000, 0.0000, 0.0000, 0.1109, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0514, 0.1367, 1.0000,
        1.0000, 0.0000, 0.3881, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.9808, 0.0000, 0.0000, 0.7918, 0.0000, 0.0000,
        0.9999, 0.0000, 0.0000, 0.0000, 0.0000, 0.2437, 0.0000, 0.9941, 1.0000,
        0.2558, 0.0000, 0.0578, 0.9022, 0.2359, 0.0000, 0.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3237, 1.0000, 1.0000, 0.0000,
        0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0870, 0.0000, 1.0000, 1.0000, 0.1267, 1.0000, 0.0000, 0.0000,
        0.9059, 0.0000, 0.0000, 0.4158, 0.0000, 0.0000, 0.9855, 1.0000, 0.0573,
        0.0000, 0.0000, 0.0000, 0.2490, 0.0000, 0.9999, 0.9194, 0.0000, 0.0000,
        0.9997, 0.9997, 0.5462, 0.8917, 1.0000, 0.0000, 0.0000, 1.0000, 0.9989,
        0.9955, 1.0000, 1.0000, 1.0000, 0.9946, 0.9501, 1.0000, 0.0000, 0.7217,
        0.7403, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8253, 0.0000, 0.9867,
        0.1142, 1.0000, 0.5421, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.6566, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.9698, 0.8156, 0.0000, 0.8647, 1.0000, 0.0873, 0.0543, 0.0000,
        0.9867, 0.9999, 0.0000, 0.0000, 0.2064, 0.0000, 0.0000, 0.0000, 0.9995,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 1.0000, 0.0000, 0.0000, 0.0719, 1.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,
        0.1175, 0.9820, 0.8782, 0.9872, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 0.9993, 0.0631, 0.9021, 0.2548, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.9998, 0.0000, 0.0000, 0.0000, 0.6978, 0.0000, 0.0000,
        0.9916, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9828,
        1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9435, 0.9773, 0.9997, 0.0526,
        1.0000, 0.0000, 0.0000, 0.0000, 0.5916, 0.0000, 0.9999, 1.0000, 0.8036,
        1.0000, 0.9981, 0.0000, 0.0000, 0.9137, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.2254, 1.0000, 0.8996, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1289, 0.0000, 0.0000,
        0.7742, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.9592, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1368, 0.0000,
        0.0000, 0.0000, 1.0000, 0.8256, 1.0000, 1.0000, 0.9953, 0.9992, 1.0000,
        0.9562, 0.0000, 0.0000, 0.0000, 0.0000, 0.8611, 1.0000, 0.0000, 0.0000,
        0.9634, 0.7297, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.1725, 0.0000, 0.0000, 0.0000, 0.0000, 0.7267, 0.9961,
        0.0000, 0.5446, 0.9982, 0.7857, 0.5149, 0.0000, 0.0000, 0.5703, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.1781, 0.0000, 0.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.9745, 0.0000, 0.0000, 0.0000, 0.0000,
        0.8837, 0.1419, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9259, 0.9023, 0.0000, 0.0000,
        0.0000, 0.6292, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.9999, 0.0000, 0.0000, 0.0000, 0.0000, 0.9999, 0.6433, 0.9946, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9839, 0.0532, 1.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.9637, 1.0000, 0.0501, 0.3726, 1.0000, 1.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.9488, 0.0000, 0.0000, 0.0000, 0.0000, 0.7451, 0.8931, 0.9996,
        0.9176, 0.9235, 0.1932, 0.0000, 0.0000, 0.7418, 0.0000, 0.0000, 0.0000,
        0.0000, 0.9981, 1.0000, 0.9975, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 1.0000]), 'num_pos': 589}
2020-12-07 16:16:25,486 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_test dataset(243 images).
2020-12-07 16:22:25,502 maskrcnn_benchmark.inference INFO: Total run time: 0:06:00.016109 (1.4815477746013752 s / img per device, on 1 devices)
2020-12-07 16:22:25,502 maskrcnn_benchmark.inference INFO: Model inference time: 0:05:43.997540 (1.4156277385758764 s / img per device, on 1 devices)
2020-12-07 16:22:25,531 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 16:22:39,090 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 16:22:39,090 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0000e+00, 7.9090e-02, 4.2205e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1969e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.4288e-02, 0.0000e+00, 2.0490e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.6068e-02, 0.0000e+00, 1.7043e-02, 0.0000e+00,
        1.2269e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2081e-02,
        0.0000e+00, 5.2437e-02, 1.6303e-03, 0.0000e+00, 5.2853e-02, 0.0000e+00,
        2.8900e-01, 6.5872e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.4669e-02, 1.6375e-01, 1.2052e-01, 0.0000e+00, 0.0000e+00,
        8.3165e-02, 1.2077e-03, 1.2389e-01, 8.5239e-02, 0.0000e+00, 0.0000e+00,
        3.4537e-02, 0.0000e+00, 0.0000e+00, 3.6214e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.3888e-03, 0.0000e+00, 0.0000e+00, 4.9109e-02, 1.9753e-03,
        0.0000e+00, 0.0000e+00, 1.0323e-01, 1.2148e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5118e-02, 5.4893e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4808e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0490e-02, 0.0000e+00, 0.0000e+00,
        1.1463e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1495e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.7991e-06, 4.3011e-03, 0.0000e+00, 5.2660e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4800e-02, 4.2205e-03, 0.0000e+00,
        3.3880e-02, 0.0000e+00, 7.7361e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4285e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0962e-02, 4.1073e-02,
        0.0000e+00, 1.6365e-01, 0.0000e+00, 1.4777e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.6806e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.9786e-02, 1.8620e-04, 0.0000e+00, 1.0723e-02, 7.6660e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9532e-03, 0.0000e+00,
        8.2459e-02, 0.0000e+00, 0.0000e+00, 1.4734e-02, 4.6759e-04, 1.1562e-01,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.2279e-02, 0.0000e+00, 0.0000e+00, 1.9620e-02, 0.0000e+00,
        0.0000e+00, 1.4857e-03, 2.0039e-02, 1.5811e-02, 5.4221e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.5383e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.7220e-02, 3.3198e-02, 1.6422e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.9003e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.6250e-02, 0.0000e+00, 2.6721e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0999e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2831e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7056e-02, 0.0000e+00,
        0.0000e+00, 3.7615e-01, 1.9753e-03, 0.0000e+00, 3.3397e-02, 0.0000e+00,
        1.8197e-03, 6.9299e-03, 1.1099e-01, 8.8594e-03, 0.0000e+00, 0.0000e+00,
        1.4216e-03, 0.0000e+00, 7.7936e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2980e-02, 2.8063e-01, 0.0000e+00,
        0.0000e+00, 4.9672e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.9548e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6650e-03, 0.0000e+00, 4.5460e-04, 2.8780e-02, 3.2985e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 6.,  8.,  8.,  2.,  6.,  6.,  8.,  8.,  8.,  8.,  8.,  6.,  5.,  8.,
         8.,  8.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  3.,
         3.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,  8.,
         3.,  8.,  8.,  8.,  3.,  6.,  8.,  8.,  3.,  8.,  3.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         5.,  8.,  8.,  8.,  6.,  8.,  3.,  8., -1.,  6.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  3.,  8., -1.,  5.,  8., -1., -1.,  8.,
         3.,  8.,  8.,  8., -1.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,
         8.,  8.,  8.,  8.,  3.,  5.,  8.,  8.,  3.,  8.,  3.,  8., -1., -1.,
         8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  6.,  3.,
         8.,  6.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,
        -1., -1.,  3.,  8.,  8.,  8.,  8.,  8.,  3.,  5.,  8.,  8.,  8.,  8.,
         3.,  8.,  8., -1.,  8.,  8.,  6.,  3.,  3.,  8.,  8.,  8.,  3.,  8.,
         2.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,  3.,  8., -1.,
         3.,  8.,  8.,  2.,  8.,  3.,  8.,  6.,  3.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8., -1.,  2.,  3.,  8.,  3.,  8.,  8., -1., -1.,  8.,  6.,
         5.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  3.,  8.,  8.,  8.,
         8.,  6.,  8.,  8.,  3.,  8.,  8.,  8., -1., -1.,  8.]), 'best match scores': tensor([0.9938, 1.0000, 0.9999, 0.3053, 1.0000, 1.0000, 0.9992, 0.9999, 1.0000,
        0.2131, 1.0000, 1.0000, 0.9988, 1.0000, 1.0000, 0.9972, 0.9861, 1.0000,
        1.0000, 0.4071, 0.4214, 0.9983, 1.0000, 0.9999, 1.0000, 0.5687, 0.9985,
        0.2150, 0.7314, 1.0000, 1.0000, 1.0000, 0.9049, 1.0000, 1.0000, 1.0000,
        0.9999, 0.9967, 0.9985, 1.0000, 1.0000, 0.4008, 0.9968, 1.0000, 1.0000,
        0.9029, 0.8313, 0.9690, 1.0000, 0.9906, 0.5755, 0.8933, 0.8916, 0.8247,
        1.0000, 1.0000, 0.3019, 0.0529, 0.9993, 0.1555, 1.0000, 1.0000, 0.9997,
        0.9997, 0.9964, 0.9967, 0.9875, 0.9998, 0.9734, 0.4268, 1.0000, 0.0514,
        0.9927, 0.9918, 1.0000, 0.1158, 0.0558, 0.0684, 0.0000, 1.0000, 0.3831,
        1.0000, 0.9986, 0.0587, 0.5687, 0.9998, 1.0000, 0.2933, 1.0000, 1.0000,
        0.9946, 0.0577, 0.0000, 1.0000, 0.9969, 0.0000, 0.0000, 0.9924, 1.0000,
        0.9816, 0.1305, 1.0000, 0.0000, 1.0000, 0.7433, 0.9972, 0.8808, 0.9990,
        0.9646, 1.0000, 0.3841, 0.9716, 0.9985, 1.0000, 0.8135, 0.9071, 0.9921,
        1.0000, 0.9954, 0.5977, 1.0000, 0.9328, 0.9953, 0.3590, 0.0000, 0.0000,
        0.9896, 0.8296, 1.0000, 0.6948, 0.9122, 0.9999, 0.0771, 0.9984, 0.9340,
        0.9994, 0.7168, 0.7326, 1.0000, 0.0618, 0.9645, 1.0000, 1.0000, 0.1100,
        0.9957, 0.9997, 1.0000, 0.1003, 1.0000, 1.0000, 0.7998, 1.0000, 0.9807,
        1.0000, 0.0000, 0.0000, 0.9729, 0.9710, 0.9913, 1.0000, 1.0000, 1.0000,
        1.0000, 0.8336, 0.9590, 0.9983, 1.0000, 1.0000, 0.8522, 0.9942, 0.4075,
        0.0000, 0.3015, 0.9496, 0.9870, 0.1301, 0.9442, 0.5581, 0.8856, 0.9992,
        0.3247, 1.0000, 0.0884, 0.0512, 0.9993, 0.0648, 0.9990, 0.2026, 1.0000,
        0.5591, 0.0518, 0.9998, 0.6167, 0.4885, 0.5475, 0.0000, 0.9436, 0.2311,
        0.1030, 1.0000, 0.9985, 1.0000, 0.8918, 0.8996, 0.9948, 1.0000, 0.1012,
        1.0000, 0.9999, 0.1482, 0.9921, 0.0586, 0.9994, 0.0000, 1.0000, 0.8754,
        1.0000, 0.0928, 0.9897, 0.9881, 0.0000, 0.0000, 1.0000, 1.0000, 0.1119,
        0.9362, 0.9552, 0.5901, 0.9840, 0.6169, 0.9574, 1.0000, 1.0000, 0.9999,
        0.8580, 0.2262, 1.0000, 1.0000, 0.9774, 1.0000, 0.9999, 1.0000, 0.8858,
        0.3269, 0.8918, 0.9842, 0.0000, 0.0000, 1.0000]), 'num_pos': 249}
2020-12-07 16:22:39,130 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_test dataset(8 images).
2020-12-07 16:22:50,884 maskrcnn_benchmark.inference INFO: Total run time: 0:00:11.754254 (1.469281792640686 s / img per device, on 1 devices)
2020-12-07 16:22:50,884 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:11.223729 (1.4029660820960999 s / img per device, on 1 devices)
2020-12-07 16:22:50,886 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 16:22:51,333 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 16:22:51,333 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0111, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0287, 0.0113, 0.0085, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0064, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1069, 0.1993, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1.,  6.,  8.,  8., -1., -1.,  6.,  8.,  8.,
         8.,  8.,  8.,  8., -1., -1., -1., -1., -1., -1.,  6., -1., -1., -1.,
        -1.,  6.,  6.,  8.,  8.,  8., -1., -1., -1., -1., -1., -1.,  3.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.9996,
        0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.9538, 0.5233, 0.8499, 0.3238,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2656, 0.0000, 0.0000,
        0.0000, 0.0000, 0.9700, 1.0000, 1.0000, 1.0000, 0.9973, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0817]), 'num_pos': 41}
2020-12-07 16:22:51,341 maskrcnn_benchmark.inference INFO: Start evaluation on giro9_test dataset(696 images).
2020-12-07 16:40:34,935 maskrcnn_benchmark.inference INFO: Total run time: 0:17:43.594210 (1.5281526007871518 s / img per device, on 1 devices)
2020-12-07 16:40:34,936 maskrcnn_benchmark.inference INFO: Model inference time: 0:16:49.132715 (1.4499033254453506 s / img per device, on 1 devices)
2020-12-07 16:40:35,039 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-07 16:41:14,646 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-07 16:41:14,647 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.1137e-02, 5.3020e-02, 0.0000e+00, 0.0000e+00, 1.5823e-01, 3.2663e-03,
        0.0000e+00, 2.9796e-02, 0.0000e+00, 3.4120e-02, 2.0769e-03, 0.0000e+00,
        0.0000e+00, 1.0011e-03, 2.1189e-03, 0.0000e+00, 1.9208e-02, 1.6659e-01,
        2.9796e-02, 1.1553e-01, 1.5569e-01, 5.4362e-02, 0.0000e+00, 5.3799e-02,
        3.2633e-03, 0.0000e+00, 2.2226e-01, 1.5196e-01, 1.7940e-05, 1.9316e-02,
        0.0000e+00, 0.0000e+00, 3.2783e-03, 2.9796e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5144e-01, 1.3510e-01,
        0.0000e+00, 0.0000e+00, 4.9882e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5374e-01,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4119e-03, 6.0942e-02, 0.0000e+00,
        1.2024e-02, 0.0000e+00, 0.0000e+00, 8.1129e-02, 0.0000e+00, 1.1990e-01,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1055e-03, 0.0000e+00, 2.8956e-02, 8.2153e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9187e-01, 0.0000e+00,
        8.4914e-02, 1.7906e-01, 0.0000e+00, 1.3386e-01, 0.0000e+00, 0.0000e+00,
        7.9424e-02, 6.3432e-03, 0.0000e+00, 8.9497e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.9018e-03, 0.0000e+00, 4.4474e-02, 6.4844e-02, 5.8191e-02,
        0.0000e+00, 1.1868e-01, 1.8186e-01, 3.7676e-02, 2.8874e-02, 1.0526e-01,
        1.1485e-01, 1.5924e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1440e-01, 1.6959e-02, 0.0000e+00, 0.0000e+00, 2.1821e-01,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0383e-01, 1.5842e-01, 1.4444e-01,
        0.0000e+00, 0.0000e+00, 1.1186e-01, 1.6326e-03, 0.0000e+00, 3.7080e-03,
        0.0000e+00, 5.2097e-02, 1.5307e-01, 0.0000e+00, 0.0000e+00, 1.2240e-02,
        4.8217e-02, 0.0000e+00, 2.0393e-03, 6.7542e-02, 1.2090e-01, 0.0000e+00,
        7.0218e-02, 1.5561e-01, 5.1102e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1231e-01, 0.0000e+00, 8.0697e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.8082e-01, 1.4761e-05, 1.1904e-03, 4.2981e-02, 0.0000e+00,
        0.0000e+00, 7.4007e-02, 0.0000e+00, 1.4954e-01, 0.0000e+00, 0.0000e+00,
        8.8839e-02, 1.1331e-02, 1.0376e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3810e-02, 1.2731e-01, 9.3238e-02, 2.1632e-03,
        0.0000e+00, 0.0000e+00, 1.1354e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.6114e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5426e-03, 1.0294e-01,
        0.0000e+00, 0.0000e+00, 4.1731e-02, 2.2718e-02, 0.0000e+00, 0.0000e+00,
        2.1028e-04, 0.0000e+00, 0.0000e+00, 1.0013e-03, 1.5729e-03, 2.9540e-06,
        0.0000e+00, 6.9867e-02, 1.9715e-03, 9.8914e-03, 0.0000e+00, 0.0000e+00,
        1.4734e-01, 1.2125e-01, 1.5440e-01, 1.7746e-01, 0.0000e+00, 1.7460e-02,
        0.0000e+00, 0.0000e+00, 1.8068e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.8704e-01, 0.0000e+00, 0.0000e+00, 2.9796e-02, 0.0000e+00,
        7.6463e-02, 4.9737e-02, 4.3796e-02, 3.8394e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.0697e-02, 1.1868e-01, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.2738e-01, 2.9317e-02, 3.2087e-01, 7.3854e-02, 0.0000e+00,
        2.5109e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.6403e-02, 0.0000e+00, 0.0000e+00, 6.4935e-02, 0.0000e+00, 1.2125e-01,
        1.7361e-01, 2.2218e-01, 0.0000e+00, 5.8034e-02, 0.0000e+00, 2.9746e-01,
        0.0000e+00, 1.5111e-01, 1.1485e-01, 0.0000e+00, 2.4888e-02, 1.8885e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.9681e-02, 1.3801e-03, 0.0000e+00, 1.0662e-01, 3.2099e-03,
        0.0000e+00, 2.5582e-03, 2.3887e-02, 0.0000e+00, 0.0000e+00, 5.1076e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1765e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.0596e-01, 7.8852e-02, 6.3591e-02, 2.9796e-02,
        0.0000e+00, 6.2580e-02, 1.1033e-01, 1.2412e-01, 0.0000e+00, 2.6037e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6720e-02, 4.6070e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0150e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.9119e-03, 4.9603e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.6531e-02, 0.0000e+00, 0.0000e+00, 4.4790e-02, 9.0022e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2068e-01, 1.7933e-02, 5.1864e-02, 6.9717e-03, 0.0000e+00, 1.5729e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3572e-01, 0.0000e+00, 1.7219e-02,
        0.0000e+00, 0.0000e+00, 1.5453e-01, 1.9148e-02, 8.2023e-03, 0.0000e+00,
        3.0878e-03, 0.0000e+00, 0.0000e+00, 2.8344e-02, 8.6600e-02, 2.8529e-02,
        0.0000e+00, 8.2867e-03, 2.6427e-03, 8.5079e-02, 0.0000e+00, 0.0000e+00,
        4.9196e-02, 0.0000e+00, 1.0851e-02, 1.3035e-01, 0.0000e+00, 1.0729e-01,
        0.0000e+00, 0.0000e+00, 2.8179e-01, 0.0000e+00, 1.9826e-01, 0.0000e+00,
        0.0000e+00, 1.7577e-01, 0.0000e+00, 1.5100e-01, 4.3081e-02, 1.1016e-01,
        0.0000e+00, 1.6410e-04, 0.0000e+00, 0.0000e+00, 1.7982e-02, 5.9257e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.2875e-02, 0.0000e+00, 2.0117e-01, 0.0000e+00, 8.1547e-02, 3.3239e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4581e-02, 3.0038e-01, 0.0000e+00,
        0.0000e+00, 1.3629e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.0659e-03, 0.0000e+00, 8.8957e-03, 7.7207e-02, 1.5729e-03, 4.0228e-03,
        0.0000e+00, 1.6913e-01, 0.0000e+00, 0.0000e+00, 2.9644e-01, 1.4610e-02,
        1.0958e-01, 1.1327e-03, 0.0000e+00, 1.1298e-01, 2.4452e-01, 0.0000e+00,
        0.0000e+00, 2.1404e-01, 0.0000e+00, 1.2755e-01, 0.0000e+00, 1.3163e-01,
        0.0000e+00, 1.0957e-01, 3.0350e-03, 2.9796e-02, 3.7720e-03, 1.9246e-02,
        2.2672e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3090e-01, 0.0000e+00,
        0.0000e+00, 1.1485e-01, 1.1698e-01, 0.0000e+00, 0.0000e+00, 1.3476e-03,
        1.3119e-01, 0.0000e+00, 0.0000e+00, 2.7876e-02, 0.0000e+00, 5.9886e-02,
        1.4848e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7354e-02,
        0.0000e+00, 5.5342e-06, 1.9103e-03, 0.0000e+00, 0.0000e+00, 1.7093e-01,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1701e-01, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.5729e-03, 1.6404e-02, 3.8093e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1485e-01, 2.9085e-02, 1.5098e-03, 6.7960e-02, 0.0000e+00,
        1.2790e-02, 3.4580e-02, 5.3190e-02, 2.9796e-02, 0.0000e+00, 2.9796e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8544e-03, 0.0000e+00, 0.0000e+00,
        1.1096e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1632e-01,
        6.3833e-02, 2.5949e-02, 0.0000e+00, 2.0833e-03, 0.0000e+00, 9.0367e-02,
        0.0000e+00, 8.8216e-02, 0.0000e+00, 2.3416e-01, 0.0000e+00, 0.0000e+00,
        7.8423e-04, 3.1696e-02, 4.5946e-01, 0.0000e+00, 2.6114e-02, 1.3640e-02,
        7.3273e-02, 0.0000e+00, 0.0000e+00, 2.6541e-03, 0.0000e+00, 6.7906e-02,
        8.5707e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.5819e-04, 1.7763e-01,
        2.9478e-02, 1.7192e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9968e-03,
        0.0000e+00, 1.1612e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.7780e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8035e-01, 1.3195e-02,
        1.2540e-03, 2.9796e-02, 3.8320e-03, 9.6724e-02, 0.0000e+00, 0.0000e+00,
        2.2164e-01, 0.0000e+00, 0.0000e+00, 1.5175e-01, 0.0000e+00, 0.0000e+00,
        1.4054e-01, 6.9120e-02, 6.0854e-02, 1.7275e-01, 0.0000e+00, 0.0000e+00,
        1.1299e-01, 1.1110e-01, 0.0000e+00, 4.9254e-02, 1.5683e-01, 0.0000e+00,
        8.1264e-02, 3.5959e-02, 1.0097e-01, 5.4515e-02, 5.2909e-03, 0.0000e+00,
        0.0000e+00, 6.6463e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2310e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.2023e-03, 0.0000e+00, 0.0000e+00, 2.1628e-02,
        5.8765e-02, 2.9796e-02, 0.0000e+00, 1.5965e-01, 2.6457e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7475e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6282e-02, 0.0000e+00, 0.0000e+00,
        2.1821e-01, 7.5112e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7876e-02,
        0.0000e+00, 0.0000e+00, 3.4272e-02, 0.0000e+00, 0.0000e+00, 1.8848e-02,
        0.0000e+00, 0.0000e+00, 3.9119e-03, 1.4125e-02, 0.0000e+00, 1.1593e-05,
        2.2916e-03, 1.7964e-03, 0.0000e+00, 0.0000e+00, 9.5467e-03, 0.0000e+00,
        1.1173e-01, 1.8453e-01, 0.0000e+00, 1.3096e-03, 3.9542e-02, 5.4942e-02,
        2.9796e-02, 0.0000e+00, 2.0393e-03, 1.3875e-02, 2.3467e-02, 2.2280e-02,
        2.0275e-01, 0.0000e+00, 1.5225e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.1577e-02, 1.3193e-02, 0.0000e+00, 4.1659e-02, 2.9796e-02,
        0.0000e+00, 4.9603e-02, 9.7298e-02, 0.0000e+00, 2.4992e-03, 0.0000e+00,
        3.2806e-02, 0.0000e+00, 0.0000e+00, 9.8310e-02, 7.9552e-05, 0.0000e+00,
        1.4078e-01, 4.3165e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0880e-01,
        0.0000e+00, 7.8568e-02, 1.8929e-03, 1.0162e-01, 0.0000e+00, 5.4896e-02,
        0.0000e+00, 2.9796e-02, 1.4824e-01, 0.0000e+00, 1.5192e-05, 1.0034e-03,
        7.1529e-03, 0.0000e+00, 1.7578e-01, 3.2290e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.1302e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00]), 'gt_labels': tensor([1, 1, 2, 8, 2, 1, 1, 1, 1, 8, 1, 1, 1, 8, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,
        1, 1, 8, 2, 1, 1, 1, 1, 1, 1, 1, 8, 2, 2, 2, 3, 1, 1, 1, 8, 1, 1, 1, 1,
        1, 1, 2, 2, 1, 8, 3, 3, 3, 8, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 8, 2,
        2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 8, 2, 1, 8, 8, 1, 1, 1, 1, 2, 1, 1, 2, 2,
        8, 2, 2, 2, 1, 1, 1, 8, 1, 1, 1, 1, 3, 2, 1, 8, 1, 1, 1, 1, 1, 1, 1, 2,
        2, 2, 2, 2, 8, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 8, 1, 1, 2, 2,
        1, 3, 3, 3, 3, 3, 8, 1, 1, 2, 1, 1, 1, 8, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1,
        3, 3, 3, 3, 3, 3, 8, 1, 2, 8, 2, 1, 8, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1,
        1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 8, 1, 1, 8, 2, 1, 8, 1, 1,
        2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1,
        1, 1, 1, 8, 2, 2, 2, 1, 1, 1, 1, 1, 8, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 8,
        2, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 3, 1, 1, 1, 1, 1, 8, 2,
        2, 1, 1, 1, 1, 2, 8, 3, 1, 1, 1, 8, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 3,
        3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 8,
        3, 3, 3, 1, 2, 1, 1, 8, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3,
        1, 2, 8, 1, 2, 1, 2, 1, 2, 2, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 8, 1, 2, 1,
        3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 8, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 3,
        1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 8, 1, 1, 1, 3, 8, 1, 1, 1, 1, 1,
        1, 2, 8, 1, 1, 8, 1, 3, 1, 1, 1, 1, 8, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 8,
        1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 1, 1, 1, 1,
        1, 8, 8, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 8, 2, 1, 3, 1, 1, 2, 2, 1, 1, 1,
        1, 1, 2, 2, 1, 2, 2, 1, 8, 1, 1, 1, 8, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2,
        1, 1, 1, 1, 1, 2, 2, 8, 8, 1, 1, 1, 1, 1, 1, 2, 8, 1, 8, 1, 1, 1, 2, 2,
        2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 8, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 3, 3, 3,
        3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 1, 8, 2, 1, 1, 1, 1, 3, 3, 3,
        3, 3, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 8, 1, 1, 8, 1, 1, 2, 1, 1, 1, 1,
        1, 8, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        2, 1, 1, 1, 2, 2, 1, 1, 3, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2,
        3, 3, 3, 3, 3, 1, 8, 1, 2, 1, 2, 1, 1, 1, 3, 1, 2, 2, 1, 1, 2, 1, 1, 1,
        2, 2, 3, 3, 3, 3, 8]), 'best match labels': tensor([ 8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  6.,  8.,  8.,  6.,  8.,  8.,
         8.,  8.,  5.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,
         5.,  8.,  3.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,  8.,  3.,  8.,  8.,
         8.,  8.,  8., -1., -1.,  8.,  3.,  8.,  3.,  6.,  8.,  8., -1.,  3.,
         6.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,  8., -1.,  2.,  8.,  8.,
         3., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  3.,  8., -1.,  8.,  8.,  8.,
         8.,  8.,  8.,  8., -1.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  3.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,
         5., -1.,  2.,  8.,  8.,  6.,  3.,  8.,  3.,  6.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  5.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  6.,  2.,  3.,  8.,  2.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  3.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  2.,  8.,  2.,  2.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,
        -1., -1., -1., -1., -1., -1., -1.,  8.,  6.,  8., -1.,  8.,  3.,  8.,
         8.,  8.,  6.,  8.,  8., -1.,  3.,  8.,  3.,  3.,  8.,  8.,  8.,  8.,
         2.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,  8.,
         8.,  8.,  8.,  3.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,
         8., -1.,  6.,  8.,  8.,  8., -1.,  2.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  6.,  8.,  8., -1.,  2.,  8.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1., -1.,  3.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,  5.,  8.,
         8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,
         8.,  8.,  3., -1.,  8., -1.,  3.,  8.,  8.,  6.,  3.,  6.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  5.,  8.,  8.,  8.,  8., -1.,  8., -1., -1.,
        -1., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3., -1.,  8., -1.,  8.,
         8.,  8.,  6.,  8.,  3.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,
        -1.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,
        -1.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1., -1., -1.,  5.,  8.,  8.,  8.,  3.,  8.,  8.,
         8.,  8.,  8.,  3.,  8.,  8.,  8.,  5.,  8.,  3.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  6.,  8.,  8.,  8.,  8., -1.,  6.,  8.,  8.,  8.,
         5.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8., -1.,  3.,  8.,  8.,  3.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  6.,
         3.,  8.,  8.,  8.,  8., -1.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  3.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  3.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,
         8.,  6.,  5.,  3.,  8.,  8.,  8.,  8.,  8.,  3.,  3.,  8.,  8.,  8.,
         8.,  3.,  8.,  8.,  8.,  8.,  3.,  3.,  6.,  6.,  8., -1.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  6.,  8.,  6.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,
         8.,  8.,  6.,  8.,  8.,  5.,  8.,  8.,  8.,  3.,  8., -1., -1., -1.,
        -1., -1., -1., -1., -1., -1.,  3.,  8., -1.,  8., -1.,  6.,  8.,  8.,
         2.,  8.,  8.,  8.,  8.,  2.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  3.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,  3.,  3.,  8.,  8.,  8.,
         8.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  6.,  8.,  8., -1.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  2.,  8.,
         8.,  8.,  3.,  8.,  8.,  3.,  8.,  8.,  3.,  8.,  3.,  8.,  8.,  5.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         6.,  8.,  8.,  8.,  8.,  5.,  8.,  8.,  8., -1., -1., -1.,  8.]), 'best match scores': tensor([1.0000, 1.0000, 0.9885, 0.7680, 0.9999, 0.5223, 0.9197, 1.0000, 1.0000,
        1.0000, 0.9989, 1.0000, 0.9012, 1.0000, 0.1843, 1.0000, 1.0000, 0.0722,
        1.0000, 0.9999, 1.0000, 1.0000, 0.3891, 0.6044, 1.0000, 0.9996, 0.9561,
        0.1228, 1.0000, 1.0000, 0.9590, 0.1642, 1.0000, 1.0000, 0.6168, 1.0000,
        0.9959, 0.9997, 1.0000, 0.1392, 1.0000, 0.0595, 1.0000, 0.9994, 1.0000,
        0.0000, 0.0000, 1.0000, 0.9942, 1.0000, 0.9753, 0.3837, 1.0000, 0.9764,
        0.0000, 0.2210, 0.9997, 0.9758, 0.6893, 0.5286, 0.9987, 0.2339, 1.0000,
        1.0000, 0.0000, 0.9981, 0.0000, 1.0000, 0.7356, 1.0000, 1.0000, 0.0000,
        0.9754, 0.0557, 0.9200, 0.9967, 1.0000, 1.0000, 0.5652, 0.9970, 0.0000,
        1.0000, 0.2124, 0.5327, 0.9304, 0.4722, 0.9996, 1.0000, 0.0000, 0.8608,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9954, 0.9982, 0.9774, 0.7029, 0.9973,
        0.9999, 0.9963, 0.4381, 0.9985, 0.9611, 0.7100, 0.1565, 0.9987, 0.9990,
        0.9854, 0.9999, 0.5764, 0.4980, 1.0000, 0.0000, 0.8812, 0.0532, 1.0000,
        1.0000, 0.1168, 0.9984, 0.8983, 1.0000, 1.0000, 1.0000, 0.0986, 0.5553,
        0.6656, 1.0000, 0.9497, 0.3292, 1.0000, 0.9999, 1.0000, 0.9297, 0.9994,
        1.0000, 0.1521, 0.8311, 1.0000, 0.5772, 1.0000, 1.0000, 0.9955, 1.0000,
        1.0000, 0.2881, 1.0000, 0.9914, 1.0000, 0.9527, 0.8953, 0.9688, 0.9999,
        1.0000, 1.0000, 0.1863, 0.9976, 1.0000, 1.0000, 0.6865, 1.0000, 0.8621,
        0.1364, 1.0000, 1.0000, 0.9969, 1.0000, 1.0000, 1.0000, 0.9838, 1.0000,
        0.9229, 0.9999, 0.9778, 0.2374, 1.0000, 0.9931, 0.5109, 1.0000, 0.9990,
        0.8252, 0.0524, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0759, 0.1316, 1.0000, 0.0000, 0.7510, 1.0000, 0.9959, 0.9984, 0.9876,
        0.9932, 1.0000, 1.0000, 0.0000, 0.0734, 1.0000, 1.0000, 0.8416, 0.0724,
        1.0000, 1.0000, 0.9956, 1.0000, 0.9483, 0.9283, 1.0000, 0.6837, 0.9977,
        1.0000, 0.1305, 0.9990, 0.0597, 0.2506, 1.0000, 0.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.4870, 1.0000, 1.0000, 1.0000, 0.9780,
        0.2061, 1.0000, 0.9999, 1.0000, 0.9549, 0.0000, 0.9999, 0.9996, 1.0000,
        0.5819, 0.0000, 0.2011, 1.0000, 1.0000, 0.9858, 1.0000, 0.0949, 0.8598,
        1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.8114, 1.0000, 1.0000, 0.0769,
        1.0000, 0.6255, 1.0000, 0.9773, 0.9999, 1.0000, 0.9802, 0.9958, 0.9675,
        1.0000, 0.9999, 0.9998, 0.1799, 1.0000, 0.0000, 0.0000, 0.0000, 0.9675,
        0.0752, 0.9849, 1.0000, 0.9362, 0.4031, 0.9976, 1.0000, 0.2924, 0.0628,
        1.0000, 0.9956, 0.2498, 1.0000, 1.0000, 0.0650, 1.0000, 0.6290, 1.0000,
        0.8245, 0.3423, 0.8226, 1.0000, 0.6401, 1.0000, 0.9991, 0.9996, 0.6385,
        0.9996, 1.0000, 0.9172, 0.9998, 0.6538, 0.0000, 0.9872, 0.0000, 0.0526,
        1.0000, 1.0000, 1.0000, 0.9998, 1.0000, 0.9803, 1.0000, 0.9997, 0.9999,
        0.9111, 0.9996, 0.9984, 1.0000, 0.1139, 0.9958, 0.4125, 1.0000, 0.0000,
        0.0919, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9887, 1.0000, 1.0000,
        1.0000, 0.1441, 0.0609, 1.0000, 0.9988, 1.0000, 1.0000, 1.0000, 0.9963,
        0.8537, 0.0541, 0.9248, 1.0000, 0.9586, 1.0000, 0.1087, 0.0605, 0.9098,
        0.0000, 0.0986, 0.0000, 0.0825, 0.9956, 0.9999, 1.0000, 1.0000, 1.0000,
        1.0000, 0.2112, 0.9914, 0.9942, 0.9889, 0.1145, 1.0000, 1.0000, 1.0000,
        0.0000, 0.9849, 1.0000, 1.0000, 0.8272, 0.8096, 1.0000, 1.0000, 0.9999,
        0.9915, 0.3356, 0.0532, 0.0752, 0.9881, 0.0000, 0.7964, 0.9909, 0.9146,
        1.0000, 0.8713, 0.1014, 0.9956, 0.9669, 1.0000, 0.7355, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,
        0.9996, 0.9997, 0.2092, 1.0000, 0.9994, 0.9985, 1.0000, 1.0000, 1.0000,
        0.2095, 0.9998, 0.8967, 1.0000, 0.9993, 0.9995, 0.0857, 0.2474, 0.1370,
        1.0000, 0.9315, 1.0000, 0.0522, 1.0000, 0.3891, 1.0000, 1.0000, 0.2937,
        0.9992, 0.9990, 0.0000, 0.9985, 1.0000, 0.3857, 0.9906, 0.9997, 0.7077,
        1.0000, 0.8550, 0.0748, 1.0000, 0.9991, 1.0000, 0.9998, 0.9997, 0.9991,
        0.9998, 0.9999, 0.0987, 0.3009, 0.9973, 0.9046, 1.0000, 0.6689, 0.9991,
        1.0000, 0.8112, 1.0000, 0.9943, 0.8754, 0.0655, 0.4560, 0.8257, 1.0000,
        0.0000, 1.0000, 0.8383, 1.0000, 0.9988, 0.1225, 0.9984, 1.0000, 1.0000,
        1.0000, 0.0923, 1.0000, 0.7886, 1.0000, 1.0000, 1.0000, 1.0000, 0.9604,
        0.0000, 0.9978, 0.9846, 0.9703, 1.0000, 0.9979, 1.0000, 0.5711, 0.9974,
        0.1857, 1.0000, 0.9879, 1.0000, 0.8297, 0.9754, 0.6183, 1.0000, 0.8063,
        0.9997, 1.0000, 1.0000, 0.5015, 0.1156, 1.0000, 1.0000, 1.0000, 0.6327,
        0.9968, 1.0000, 1.0000, 0.9972, 1.0000, 1.0000, 0.0940, 0.9685, 0.0660,
        1.0000, 1.0000, 0.0826, 1.0000, 0.1752, 1.0000, 0.2750, 0.8996, 0.1683,
        1.0000, 1.0000, 1.0000, 1.0000, 0.0956, 1.0000, 0.2554, 1.0000, 0.9039,
        0.9949, 0.6950, 0.9741, 0.2203, 0.9998, 1.0000, 0.8541, 1.0000, 0.0000,
        0.9999, 0.9997, 1.0000, 1.0000, 1.0000, 1.0000, 0.9964, 0.9911, 1.0000,
        0.9604, 0.9997, 0.9998, 1.0000, 1.0000, 0.9962, 1.0000, 1.0000, 0.1039,
        1.0000, 0.1326, 1.0000, 1.0000, 1.0000, 0.9911, 0.5429, 0.7363, 1.0000,
        0.9844, 0.2734, 0.9828, 0.9993, 1.0000, 0.9362, 0.0581, 0.3024, 1.0000,
        1.0000, 0.9930, 0.0570, 0.5873, 0.0595, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9841, 1.0000, 0.0000, 0.5423,
        0.0000, 1.0000, 0.9994, 0.9997, 0.9997, 1.0000, 0.9996, 1.0000, 1.0000,
        0.9972, 0.0698, 1.0000, 0.4372, 1.0000, 1.0000, 1.0000, 0.1080, 0.8334,
        1.0000, 1.0000, 0.9947, 0.9999, 0.9573, 0.9994, 0.9999, 0.0519, 0.0000,
        0.9690, 1.0000, 1.0000, 1.0000, 0.9701, 0.5185, 1.0000, 1.0000, 0.9902,
        0.1086, 0.1648, 0.0677, 1.0000, 1.0000, 1.0000, 0.9889, 1.0000, 1.0000,
        0.0866, 1.0000, 0.9998, 1.0000, 1.0000, 1.0000, 0.7645, 0.0883, 0.0573,
        1.0000, 1.0000, 0.9775, 0.9377, 0.9947, 1.0000, 1.0000, 1.0000, 0.9998,
        0.8373, 0.0000, 0.4963, 0.9459, 0.9941, 1.0000, 0.4947, 1.0000, 1.0000,
        1.0000, 1.0000, 0.6745, 0.0524, 0.3186, 1.0000, 0.9986, 0.8995, 0.7978,
        1.0000, 1.0000, 0.9702, 0.2358, 0.6832, 1.0000, 0.9709, 0.9368, 0.8444,
        0.9991, 1.0000, 0.9989, 0.0926, 0.9987, 0.0524, 0.8669, 0.1211, 0.5174,
        0.9963, 0.9997, 0.9997, 1.0000, 0.0688, 0.8164, 0.6247, 0.9960, 0.9999,
        0.4026, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.5264]), 'num_pos': 727}
2020-12-11 11:03:09,609 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-11 11:03:09,609 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='draw_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-11 11:03:09,609 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-11 11:03:18,399 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-11 11:03:18,400 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-11 11:03:18,400 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train","giro9_train" )
  TEST: ("giro1_test","giro4_test","giro8_test","giro9_test")
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000002
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-11 11:03:18,404 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test', 'giro9_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train', 'giro9_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 2e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-11 11:03:20,513 maskrcnn_benchmark INFO: reloading weigts from r2_best.pth
2020-12-11 14:16:17,522 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-11 14:16:17,539 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-11 14:16:17,540 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-11 14:16:22,673 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-11 14:16:22,673 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-11 14:16:22,674 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train","giro9_train" )
  TEST: ("giro1_test","giro4_test","giro8_test","giro9_test")
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000002
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-11 14:16:22,678 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test', 'giro9_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train', 'giro9_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 2e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-11 14:16:24,358 maskrcnn_benchmark INFO: reloading weigts from wtf_r2.pth
2020-12-11 14:16:29,580 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-11 14:16:29,580 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-11 14:16:29,580 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-11 14:16:29,580 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-11 14:16:29,580 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-11 14:16:29,581 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-11 14:16:29,581 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-11 14:16:29,581 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-11 14:16:29,581 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-11 14:16:29,581 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-11 14:16:29,581 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-11 14:16:29,582 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-11 14:16:29,582 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-11 14:16:29,582 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-11 14:16:29,762 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-11 14:18:51,295 maskrcnn_benchmark.trainer INFO: Start training
2020-12-11 14:20:09,415 maskrcnn_benchmark.trainer INFO: eta: 1:36:20  iter: 20  loss: 5.8162 (6.4134)  loss_classifier: 2.2257 (2.6709)  loss_box_reg: 1.3246 (1.5911)  loss_objectness: 0.9872 (1.3598)  loss_rpn_box_reg: 0.6852 (0.7917)  time: 3.8775 (3.9057)  data: 0.2345 (0.2450)  lr: 0.000000  max mem: 1424
2020-12-11 14:21:27,068 maskrcnn_benchmark.trainer INFO: eta: 1:34:45  iter: 40  loss: 3.6638 (5.4600)  loss_classifier: 1.4865 (2.2955)  loss_box_reg: 0.8460 (1.2649)  loss_objectness: 0.8272 (1.2038)  loss_rpn_box_reg: 0.6281 (0.6957)  time: 3.8838 (3.8942)  data: 0.2365 (0.2412)  lr: 0.000000  max mem: 1424
2020-12-11 14:22:44,832 maskrcnn_benchmark.trainer INFO: eta: 1:33:24  iter: 60  loss: 4.4215 (5.2794)  loss_classifier: 1.4555 (2.2009)  loss_box_reg: 1.4242 (1.3460)  loss_objectness: 0.7541 (1.0821)  loss_rpn_box_reg: 0.5058 (0.6504)  time: 3.8853 (3.8922)  data: 0.2368 (0.2409)  lr: 0.000000  max mem: 1424
2020-12-11 14:24:02,757 maskrcnn_benchmark.trainer INFO: eta: 1:32:08  iter: 80  loss: 4.6736 (5.2789)  loss_classifier: 1.8901 (2.2315)  loss_box_reg: 1.2878 (1.3549)  loss_objectness: 0.7855 (1.0309)  loss_rpn_box_reg: 0.7191 (0.6616)  time: 3.8940 (3.8932)  data: 0.2408 (0.2416)  lr: 0.000000  max mem: 1424
2020-12-11 14:25:20,673 maskrcnn_benchmark.trainer INFO: eta: 1:30:51  iter: 100  loss: 5.9815 (5.5119)  loss_classifier: 2.7388 (2.4464)  loss_box_reg: 1.2624 (1.3752)  loss_objectness: 0.9147 (1.0312)  loss_rpn_box_reg: 0.5246 (0.6591)  time: 3.8906 (3.8937)  data: 0.2349 (0.2410)  lr: 0.000000  max mem: 1424
2020-12-11 14:25:20,675 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 14:25:21,169 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(92 images).
2020-12-11 14:27:40,971 maskrcnn_benchmark.inference INFO: Total run time: 0:02:19.801250 (1.5195788041405056 s / img per device, on 1 devices)
2020-12-11 14:27:40,971 maskrcnn_benchmark.inference INFO: Model inference time: 0:02:09.595955 (1.4086516836415166 s / img per device, on 1 devices)
2020-12-11 14:27:40,971 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 14:27:50,619 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 14:27:50,619 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0113, 0.0037, 0.0000, 0.0000, 0.0000, 0.0538, 0.0384, 0.0000, 0.0039,
        0.0185, 0.0459, 0.0833, 0.0000, 0.0530, 0.0330, 0.0563, 0.0262, 0.0076,
        0.1830, 0.0479, 0.0162, 0.0752, 0.0477, 0.0122, 0.0036, 0.2233, 0.0537,
        0.0239, 0.0087, 0.0989, 0.0437, 0.0189, 0.0090, 0.0037, 0.0000, 0.0000,
        0.0252, 0.0155, 0.0035, 0.0162, 0.0124, 0.0610, 0.0247, 0.0278, 0.0477,
        0.0517, 0.0322, 0.0087, 0.0940, 0.0303, 0.0000, 0.1832, 0.0000, 0.1004,
        0.0093, 0.0000, 0.0000, 0.0148, 0.0000, 0.0000, 0.0508, 0.1706, 0.0508,
        0.0658, 0.3360, 0.0315, 0.0040, 0.0000, 0.0471, 0.0052, 0.0000, 0.0000,
        0.0051, 0.0538, 0.0000, 0.0000, 0.1010, 0.0745, 0.0151, 0.0479, 0.0172,
        0.0212, 0.0000, 0.0185, 0.0591, 0.0058, 0.0662, 0.0050, 0.1019, 0.0000,
        0.0000, 0.1011, 0.0458, 0.0213, 0.0139, 0.0043, 0.1303, 0.0104, 0.0000,
        0.0281, 0.0000, 0.0000, 0.0052, 0.0000, 0.0000, 0.0413, 0.0721, 0.0421,
        0.3428, 0.1299, 0.0948, 0.0531, 0.0718, 0.0073, 0.0042, 0.0000, 0.0000,
        0.0272, 0.1211, 0.0128, 0.0000, 0.0423, 0.0344, 0.0816, 0.0042, 0.0000,
        0.0000, 0.0124, 0.0107, 0.0000, 0.0172, 0.0332, 0.0078, 0.0000]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 6., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 6., 3., 3., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 3., 8., 8., 3., 8., 8., 3., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8.]), 'best match scores': tensor([0.9999, 0.8971, 1.0000, 0.9996, 0.1581, 1.0000, 0.9991, 0.9999, 0.2777,
        1.0000, 1.0000, 0.9215, 0.1411, 0.9977, 0.9989, 1.0000, 1.0000, 1.0000,
        0.2712, 1.0000, 0.2046, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0565,
        0.5790, 0.9469, 0.1469, 0.9996, 1.0000, 0.7380, 1.0000, 0.9931, 1.0000,
        0.9999, 0.9914, 1.0000, 1.0000, 0.5281, 0.3156, 1.0000, 0.9991, 0.1178,
        0.9966, 0.9983, 1.0000, 0.5335, 0.9999, 0.0962, 0.9399, 0.7159, 0.9942,
        1.0000, 1.0000, 0.9467, 0.9914, 1.0000, 0.0733, 1.0000, 1.0000, 1.0000,
        0.9252, 0.0942, 1.0000, 0.9998, 1.0000, 1.0000, 1.0000, 0.0732, 1.0000,
        0.9822, 1.0000, 0.6920, 0.9939, 1.0000, 1.0000, 1.0000, 1.0000, 0.1970,
        0.6321, 0.5121, 1.0000, 0.9549, 1.0000, 0.9303, 1.0000, 1.0000, 1.0000,
        0.5184, 0.4288, 1.0000, 0.2638, 1.0000, 1.0000, 0.0826, 1.0000, 0.9996,
        0.9999, 1.0000, 0.9906, 0.9240, 0.8270, 0.9998, 0.6935, 0.9415, 0.9998,
        1.0000, 1.0000, 1.0000, 0.9971, 1.0000, 1.0000, 0.1350, 0.9986, 1.0000,
        1.0000, 1.0000, 1.0000, 0.9994, 0.1597, 0.9953, 0.1835, 1.0000, 1.0000,
        0.9941, 0.3520, 0.9720, 1.0000, 1.0000, 0.0796, 1.0000, 0.9713]), 'num_pos': 134}
2020-12-11 14:27:50,642 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.947761
2020-12-11 14:27:50,644 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-11 14:27:51,572 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-11 14:29:17,442 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-11 14:29:17,443 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-11 14:29:17,443 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-11 14:29:20,337 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-11 14:29:20,338 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-11 14:29:20,338 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train","giro9_train" )
  TEST: ("giro1_test","giro4_test","giro8_test","giro9_test")
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000000005
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-11 14:29:20,340 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test', 'giro9_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train', 'giro9_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 5e-09
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-11 14:29:22,042 maskrcnn_benchmark INFO: reloading weigts from wtf_r2.pth
2020-12-11 14:29:25,633 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-11 14:29:25,633 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-11 14:29:25,633 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-11 14:29:25,634 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-11 14:29:25,634 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-11 14:29:25,634 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-11 14:29:25,634 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-11 14:29:25,634 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-11 14:29:25,635 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-11 14:29:25,635 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-11 14:29:25,635 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-11 14:29:25,635 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-11 14:29:25,635 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-11 14:29:25,635 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-11 14:29:25,814 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-11 14:29:50,713 maskrcnn_benchmark.trainer INFO: Start training
2020-12-11 14:31:08,610 maskrcnn_benchmark.trainer INFO: eta: 1:36:04  iter: 20  loss: 4.6295 (5.1679)  loss_classifier: 1.8996 (2.0814)  loss_box_reg: 1.0932 (1.2581)  loss_objectness: 0.9583 (1.2002)  loss_rpn_box_reg: 0.5914 (0.6283)  time: 3.8804 (3.8947)  data: 0.2386 (0.2441)  lr: 0.000000  max mem: 1424
2020-12-11 14:32:26,377 maskrcnn_benchmark.trainer INFO: eta: 1:34:41  iter: 40  loss: 5.1530 (5.6323)  loss_classifier: 2.3860 (2.4088)  loss_box_reg: 1.2761 (1.3423)  loss_objectness: 1.0241 (1.1921)  loss_rpn_box_reg: 0.6603 (0.6892)  time: 3.8852 (3.8915)  data: 0.2363 (0.2416)  lr: 0.000000  max mem: 1424
2020-12-11 14:33:44,170 maskrcnn_benchmark.trainer INFO: eta: 1:33:22  iter: 60  loss: 5.1633 (5.5959)  loss_classifier: 2.4680 (2.4634)  loss_box_reg: 1.0127 (1.2916)  loss_objectness: 1.0175 (1.1947)  loss_rpn_box_reg: 0.6013 (0.6462)  time: 3.8890 (3.8909)  data: 0.2381 (0.2407)  lr: 0.000000  max mem: 1424
2020-12-11 14:35:02,215 maskrcnn_benchmark.trainer INFO: eta: 1:32:09  iter: 80  loss: 4.6462 (5.5040)  loss_classifier: 1.7848 (2.3915)  loss_box_reg: 1.3737 (1.3496)  loss_objectness: 0.9147 (1.1486)  loss_rpn_box_reg: 0.4336 (0.6144)  time: 3.8932 (3.8937)  data: 0.2439 (0.2417)  lr: 0.000000  max mem: 1424
2020-12-11 14:36:20,119 maskrcnn_benchmark.trainer INFO: eta: 1:30:51  iter: 100  loss: 5.7277 (5.7008)  loss_classifier: 2.0250 (2.4520)  loss_box_reg: 1.3626 (1.4316)  loss_objectness: 0.9050 (1.1838)  loss_rpn_box_reg: 0.5753 (0.6334)  time: 3.8982 (3.8940)  data: 0.2446 (0.2423)  lr: 0.000000  max mem: 1424
2020-12-11 14:36:20,121 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 14:36:20,377 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 14:37:04,548 maskrcnn_benchmark.inference INFO: Total run time: 0:00:44.170178 (1.5231095840191018 s / img per device, on 1 devices)
2020-12-11 14:37:04,548 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:40.853264 (1.4087332445999672 s / img per device, on 1 devices)
2020-12-11 14:37:04,548 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 14:37:07,649 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 14:37:07,649 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0375, 0.0005, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.1163, 0.0000, 0.0000, 0.0714, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0317, 0.0007, 0.0000,
        0.0517, 0.0317, 0.0230, 0.0094, 0.0070, 0.0038, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0507, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0330, 0.0000, 0.0000, 0.0981, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0851, 0.0217, 0.0000,
        0.0455, 0.0389, 0.0154, 0.0048, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0186, 0.0105, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0366, 0.0080, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0330, 0.0272, 0.0000, 0.0981,
        0.0036, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0646, 0.0502, 0.0232, 0.0217, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0148, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.1085, 0.0000, 0.0000, 0.0137, 0.0105, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0499, 0.0333, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0981, 0.0128,
        0.0035, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0110,
        0.0072, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0110,
        0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0139,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0360, 0.0290, 0.0173, 0.0858, 0.0000, 0.0000, 0.0113, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0981, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  3.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  5.,  5.,  6.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8., -1., -1., -1., -1.,  3.,  3.,  6.,  8.,  8.,
         3.,  8.,  6.,  8., -1., -1., -1., -1.,  5.,  6.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
        -1., -1.,  6.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1.,  3.,  5.,
         6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
        -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1.,  3.,  5.,  5.,  6.,  8.,  8.,  8.,  8.,  3.,  3.,  3.,
         6.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  3.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  3.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
        -1.,  3.,  3.,  5.,  5.,  6.,  8.,  8.]), 'best match scores': tensor([0.9995, 1.0000, 0.9521, 0.9253, 1.0000, 1.0000, 0.2873, 1.0000, 1.0000,
        1.0000, 0.1610, 0.9986, 0.0525, 1.0000, 0.9998, 1.0000, 0.9733, 0.9776,
        0.9924, 1.0000, 0.2593, 0.2194, 0.3180, 1.0000, 0.6371, 0.0620, 1.0000,
        1.0000, 1.0000, 0.9302, 0.2443, 0.9614, 0.9972, 1.0000, 0.9011, 0.6576,
        1.0000, 1.0000, 0.9869, 1.0000, 0.9934, 0.0680, 1.0000, 0.0586, 0.1772,
        0.7721, 0.9907, 0.0000, 0.0000, 0.0000, 0.0000, 0.0681, 1.0000, 1.0000,
        1.0000, 1.0000, 0.0603, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 1.0000, 0.9910, 0.9933, 0.0772, 0.9998, 1.0000, 0.9990, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.6702, 0.9994, 1.0000, 1.0000,
        0.7461, 0.9819, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.2892, 0.9999,
        0.9326, 0.9993, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.8797, 0.9999,
        0.9344, 1.0000, 0.9974, 1.0000, 1.0000, 0.9401, 0.0816, 1.0000, 1.0000,
        0.0000, 0.0000, 0.5700, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.0648, 1.0000, 0.9923, 1.0000, 1.0000, 1.0000, 0.9985, 1.0000, 0.6034,
        1.0000, 0.9625, 0.0000, 0.2787, 0.9495, 1.0000, 0.9558, 0.5551, 1.0000,
        0.8040, 1.0000, 1.0000, 0.9544, 0.9885, 0.0000, 0.0000, 1.0000, 1.0000,
        1.0000, 0.7158, 1.0000, 0.2053, 0.8486, 1.0000, 0.9993, 1.0000, 0.0825,
        0.9028, 1.0000, 0.5631, 1.0000, 0.9996, 1.0000, 1.0000, 1.0000, 0.5535,
        1.0000, 1.0000, 1.0000, 0.9858, 0.2010, 1.0000, 1.0000, 1.0000, 0.0000,
        0.6928, 0.9859, 0.9964, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000,
        1.0000, 0.9999, 1.0000, 0.0539, 0.2267, 0.9999, 1.0000, 1.0000, 1.0000,
        0.9209, 0.9999, 1.0000, 1.0000, 0.9998, 0.9666, 0.4245, 0.9646, 0.9588,
        0.8782, 0.4771, 0.5701, 1.0000, 1.0000, 1.0000, 0.9975, 1.0000, 1.0000,
        1.0000, 1.0000, 0.2008, 0.9983, 0.9999, 0.9168, 1.0000, 1.0000, 0.9997,
        1.0000, 0.1232, 1.0000, 1.0000, 1.0000, 1.0000, 0.1463, 0.0000, 0.0000,
        1.0000, 0.7418, 1.0000, 0.6324, 0.9993, 0.9337, 1.0000]), 'num_pos': 232}
2020-12-11 14:37:07,682 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.538793
2020-12-11 14:37:07,685 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-11 14:37:12,456 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-11 14:38:31,248 maskrcnn_benchmark.trainer INFO: eta: 1:39:46  iter: 120  loss: 5.2072 (5.7968)  loss_classifier: 2.0752 (2.5506)  loss_box_reg: 1.2328 (1.4580)  loss_objectness: 1.0227 (1.1610)  loss_rpn_box_reg: 0.3137 (0.6273)  time: 3.8973 (4.3378)  data: 0.2441 (0.6804)  lr: 0.000000  max mem: 1424
2020-12-11 14:39:49,126 maskrcnn_benchmark.trainer INFO: eta: 1:36:53  iter: 140  loss: 5.9921 (5.9120)  loss_classifier: 2.1556 (2.6187)  loss_box_reg: 1.4084 (1.5013)  loss_objectness: 0.9339 (1.1423)  loss_rpn_box_reg: 0.7157 (0.6497)  time: 3.8906 (4.2744)  data: 0.2421 (0.6180)  lr: 0.000000  max mem: 1424
2020-12-11 14:41:07,064 maskrcnn_benchmark.trainer INFO: eta: 1:34:24  iter: 160  loss: 6.4840 (5.9891)  loss_classifier: 2.1277 (2.6318)  loss_box_reg: 1.2491 (1.5221)  loss_objectness: 1.1054 (1.1685)  loss_rpn_box_reg: 0.7706 (0.6667)  time: 3.8900 (4.2272)  data: 0.2431 (0.5717)  lr: 0.000000  max mem: 1424
2020-12-11 14:42:24,707 maskrcnn_benchmark.trainer INFO: eta: 1:32:09  iter: 180  loss: 5.4950 (5.9037)  loss_classifier: 1.9866 (2.5804)  loss_box_reg: 1.3769 (1.5084)  loss_objectness: 0.7088 (1.1406)  loss_rpn_box_reg: 0.7121 (0.6743)  time: 3.8826 (4.1888)  data: 0.2345 (0.5345)  lr: 0.000000  max mem: 1424
2020-12-11 14:43:42,493 maskrcnn_benchmark.trainer INFO: eta: 1:30:06  iter: 200  loss: 4.4856 (5.8695)  loss_classifier: 2.3130 (2.5867)  loss_box_reg: 0.9882 (1.4952)  loss_objectness: 0.6590 (1.1067)  loss_rpn_box_reg: 0.5402 (0.6809)  time: 3.8833 (4.1589)  data: 0.2410 (0.5052)  lr: 0.000000  max mem: 1424
2020-12-11 14:43:42,495 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 14:43:42,555 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 14:44:26,503 maskrcnn_benchmark.inference INFO: Total run time: 0:00:43.947600 (1.5154344953339676 s / img per device, on 1 devices)
2020-12-11 14:44:26,504 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:40.851255 (1.408663955228082 s / img per device, on 1 devices)
2020-12-11 14:44:26,504 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 14:44:29,641 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 14:44:29,641 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([7.7605e-02, 1.3161e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6239e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7727e-02,
        1.1084e-02, 8.3083e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02, 0.0000e+00, 0.0000e+00,
        5.6224e-02, 2.4944e-02, 2.4778e-02, 2.2902e-02, 2.3751e-06, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02, 0.0000e+00, 0.0000e+00,
        8.9912e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.4744e-02, 4.7664e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.3724e-03, 0.0000e+00, 0.0000e+00, 1.1584e-01,
        3.1879e-02, 8.4858e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.9007e-02, 7.3185e-02, 2.3274e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.6125e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1826e-02, 5.5728e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.8067e-02, 1.1380e-02, 6.1989e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1610e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.7495e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0999e-02, 2.1682e-02, 0.0000e+00,
        5.4774e-03, 4.4536e-03, 0.0000e+00, 1.0956e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2574e-01, 5.9326e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3., -1.,  3.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  5., -1., -1.,  3.,  6.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,
         6.,  8.,  8.,  8., -1.,  3.,  3.,  5.,  5.,  6.,  8.,  8.,  8.,  8.,
         8.,  8.,  5.,  8.,  6.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
        -1.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  3., -1.,  3.,  3.,  6.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
        -1., -1., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,
         8.,  8., -1.,  8., -1.,  3.,  5.,  5.,  6.,  8.,  8., -1.,  3.,  3.,
         3.,  3.,  6.,  8.,  8.,  8., -1.,  8., -1., -1.,  6.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1.,  3.,  3.,  6.,  8.,  8.,  8.,  3.,  8.,  8.,
         8.,  3.,  8.,  3.,  3.,  3.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,  3.,
         8.,  3.,  3.,  3.,  6.,  8.,  8.,  8.]), 'best match scores': tensor([1.0000, 0.7330, 0.4084, 1.0000, 0.4037, 0.9724, 1.0000, 0.0764, 1.0000,
        0.9999, 0.0802, 0.0000, 1.0000, 0.1524, 1.0000, 0.3407, 0.9891, 0.2295,
        0.6289, 1.0000, 0.9506, 0.9451, 1.0000, 1.0000, 0.0000, 0.0000, 0.9991,
        1.0000, 1.0000, 1.0000, 0.7979, 1.0000, 0.4883, 1.0000, 0.9926, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.8009, 1.0000, 0.8231, 1.0000, 0.9982,
        0.7661, 1.0000, 0.0000, 0.0000, 0.0000, 0.2964, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.9995, 0.4816, 0.4130, 0.0000, 1.0000, 0.9997,
        1.0000, 0.3412, 0.9668, 0.9831, 0.2438, 1.0000, 0.1884, 0.9999, 1.0000,
        0.4535, 1.0000, 1.0000, 0.9194, 0.9927, 0.7410, 1.0000, 0.9207, 1.0000,
        1.0000, 1.0000, 0.0000, 0.0000, 0.8994, 0.0686, 1.0000, 1.0000, 0.9977,
        1.0000, 0.9616, 0.3757, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000,
        0.3074, 1.0000, 1.0000, 1.0000, 1.0000, 0.2865, 0.2134, 0.9985, 0.9992,
        0.0000, 0.9999, 0.0652, 1.0000, 1.0000, 0.4505, 1.0000, 0.9868, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9998, 0.9999, 0.8643, 1.0000, 0.1729,
        1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 0.9998, 0.0890, 0.0974, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.9905, 1.0000, 0.9815, 0.2274, 1.0000, 1.0000, 0.7328,
        1.0000, 0.3856, 0.0602, 0.9995, 1.0000, 1.0000, 0.0901, 1.0000, 1.0000,
        1.0000, 1.0000, 0.0626, 1.0000, 0.9955, 0.9999, 1.0000, 0.9982, 0.0000,
        0.4530, 0.0000, 0.6940, 1.0000, 1.0000, 1.0000, 0.9954, 1.0000, 0.0000,
        0.5083, 0.4572, 0.8747, 0.8560, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,
        0.9991, 0.0000, 0.0000, 1.0000, 1.0000, 0.9999, 1.0000, 0.0794, 0.9954,
        0.0000, 0.0000, 0.0000, 0.9999, 0.9396, 0.9991, 0.0701, 1.0000, 1.0000,
        1.0000, 0.9545, 0.9948, 0.1205, 0.9998, 0.9999, 1.0000, 1.0000, 0.9998,
        0.9529, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0535, 0.3847,
        0.4641, 0.9999, 0.9571, 1.0000, 1.0000, 0.0810, 1.0000]), 'num_pos': 232}
2020-12-11 14:44:29,673 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.487069
2020-12-11 14:45:47,453 maskrcnn_benchmark.trainer INFO: eta: 1:32:46  iter: 220  loss: 4.6162 (5.8667)  loss_classifier: 1.6996 (2.5882)  loss_box_reg: 1.1792 (1.5091)  loss_objectness: 0.5747 (1.1013)  loss_rpn_box_reg: 0.2915 (0.6681)  time: 3.8853 (4.3488)  data: 0.2394 (0.6957)  lr: 0.000000  max mem: 1424
2020-12-11 14:47:05,136 maskrcnn_benchmark.trainer INFO: eta: 1:30:30  iter: 240  loss: 5.2445 (5.8305)  loss_classifier: 1.9950 (2.5834)  loss_box_reg: 1.3845 (1.5065)  loss_objectness: 0.6921 (1.0783)  loss_rpn_box_reg: 0.5038 (0.6623)  time: 3.8786 (4.3101)  data: 0.2356 (0.6575)  lr: 0.000000  max mem: 1424
2020-12-11 14:48:22,652 maskrcnn_benchmark.trainer INFO: eta: 1:28:23  iter: 260  loss: 4.1871 (5.7969)  loss_classifier: 1.9007 (2.5682)  loss_box_reg: 1.2726 (1.5196)  loss_objectness: 0.5807 (1.0507)  loss_rpn_box_reg: 0.5822 (0.6585)  time: 3.8735 (4.2767)  data: 0.2318 (0.6250)  lr: 0.000000  max mem: 1424
2020-12-11 14:49:40,556 maskrcnn_benchmark.trainer INFO: eta: 1:26:24  iter: 280  loss: 5.5263 (5.8215)  loss_classifier: 2.5709 (2.5877)  loss_box_reg: 1.1333 (1.5318)  loss_objectness: 0.6173 (1.0472)  loss_rpn_box_reg: 0.5016 (0.6548)  time: 3.8937 (4.2494)  data: 0.2392 (0.5980)  lr: 0.000000  max mem: 1424
2020-12-11 14:50:58,270 maskrcnn_benchmark.trainer INFO: eta: 1:24:30  iter: 300  loss: 3.6237 (5.7244)  loss_classifier: 1.8608 (2.5482)  loss_box_reg: 1.1770 (1.5149)  loss_objectness: 0.5514 (1.0213)  loss_rpn_box_reg: 0.2535 (0.6399)  time: 3.8846 (4.2252)  data: 0.2400 (0.5742)  lr: 0.000000  max mem: 1424
2020-12-11 14:50:58,272 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 14:50:58,330 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 14:51:42,226 maskrcnn_benchmark.inference INFO: Total run time: 0:00:43.895199 (1.5136275620296085 s / img per device, on 1 devices)
2020-12-11 14:51:42,226 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:40.752018 (1.4052420073542102 s / img per device, on 1 devices)
2020-12-11 14:51:42,226 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 14:51:45,304 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 14:51:45,304 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([8.4360e-02, 3.1843e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9315e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3145e-01,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.2409e-02, 3.5089e-02, 1.0349e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        2.3492e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0187e-01,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3483e-01, 0.0000e+00, 0.0000e+00,
        1.6455e-01, 4.8644e-02, 2.3757e-02, 1.4902e-03, 1.2299e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        9.0514e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.3877e-01, 4.3554e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.7354e-02, 2.1682e-02, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1740e-02, 5.1474e-02, 2.8243e-02,
        2.2262e-02, 1.7836e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.6014e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02,
        1.0008e-02, 0.0000e+00, 3.3972e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7448e-02, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2367e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1770e-02, 5.7616e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4838e-01,
        9.8067e-02, 9.4179e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8642e-02, 2.9150e-02, 2.1682e-02,
        3.1749e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1., -1.,
        -1., -1.,  3., -1., -1.,  8.,  8.,  8.,  8.,  8., -1., -1., -1., -1.,
        -1., -1.,  3.,  5.,  6., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8., -1., -1., -1., -1., -1.,  6.,  8.,  8.,  8.,
         3.,  6.,  8.,  8.,  3.,  3.,  5.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
        -1., -1.,  8., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1., -1., -1.,
        -1.,  3.,  3.,  6.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1., -1.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,
        -1., -1., -1., -1., -1., -1.,  3.,  8.,  6.,  3.,  3.,  8.,  5.,  5.,
         6.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         3., -1., -1., -1., -1., -1.,  5.,  6.,  8.,  8.,  8., -1., -1., -1.,
        -1.,  6.,  8.,  8.,  8.,  8., -1., -1., -1.,  8.,  6.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,
         8.,  8.,  8.,  3.,  3.,  3.,  3.,  6.,  8.,  8.,  8.,  8., -1., -1.,
        -1., -1., -1., -1.,  3.,  3.,  6.,  8.]), 'best match scores': tensor([0.6651, 0.9994, 1.0000, 0.1234, 1.0000, 0.8601, 0.9999, 1.0000, 0.2613,
        1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9956, 0.0000,
        0.0000, 1.0000, 0.9999, 0.8742, 1.0000, 0.9996, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.9053, 1.0000, 1.0000, 0.0000, 1.0000, 0.1179,
        0.1250, 1.0000, 1.0000, 1.0000, 1.0000, 0.9977, 1.0000, 1.0000, 0.7263,
        1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,
        0.9750, 1.0000, 0.9998, 1.0000, 0.0773, 0.9999, 1.0000, 1.0000, 1.0000,
        0.9982, 1.0000, 0.8128, 1.0000, 0.5896, 0.0649, 0.8739, 0.6467, 1.0000,
        0.4860, 0.9997, 1.0000, 0.0553, 0.8373, 1.0000, 1.0000, 1.0000, 0.8686,
        1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9990, 1.0000, 0.9982, 0.9881,
        0.9997, 0.2501, 0.9370, 1.0000, 1.0000, 0.9764, 0.9943, 0.9590, 0.1312,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9999, 0.9752, 1.0000, 1.0000,
        0.9998, 0.2498, 0.9995, 1.0000, 0.9480, 1.0000, 0.8143, 1.0000, 0.9982,
        0.7072, 0.2917, 0.0000, 0.0000, 0.0000, 0.0000, 0.9985, 1.0000, 0.9999,
        1.0000, 1.0000, 0.6976, 0.9995, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.9843, 0.9984, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,
        0.9986, 1.0000, 0.9951, 0.9843, 1.0000, 0.2844, 1.0000, 1.0000, 0.9997,
        0.3513, 1.0000, 0.7032, 1.0000, 0.9998, 0.9998, 0.9954, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.1006, 1.0000, 0.9948, 0.0958, 0.8705, 0.0000,
        0.0000, 0.0000, 0.0000, 1.0000, 0.9999, 0.9965, 0.9982, 1.0000, 0.0000,
        0.0000, 0.0000, 1.0000, 1.0000, 0.2374, 0.1124, 1.0000, 1.0000, 0.9999,
        1.0000, 1.0000, 0.9999, 0.2526, 1.0000, 0.9897, 0.9987, 0.9903, 0.9823,
        1.0000, 1.0000, 1.0000, 0.2672, 0.9993, 0.3580, 0.1710, 1.0000, 1.0000,
        1.0000, 0.9631, 1.0000, 1.0000, 1.0000, 0.9999, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.9747, 0.6721, 1.0000, 0.3259]), 'num_pos': 232}
2020-12-11 14:51:45,337 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.413793
2020-12-11 14:53:07,407 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-11 14:53:07,408 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-11 14:53:07,408 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-11 14:53:09,660 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-11 14:53:09,660 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-11 14:53:09,661 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train","giro9_train" )
  TEST: ("giro1_test","giro4_test","giro8_test","giro9_test")
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000000005
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-11 14:53:09,661 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test', 'giro9_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train', 'giro9_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 5e-09
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-11 14:53:11,350 maskrcnn_benchmark INFO: reloading weigts from wtf_r2.pth
2020-12-11 14:53:13,744 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-11 14:53:13,744 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-11 14:53:13,745 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-11 14:53:13,745 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-11 14:53:13,745 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-11 14:53:13,745 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-11 14:53:13,926 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-11 14:53:16,198 maskrcnn_benchmark.trainer INFO: Start training
2020-12-11 14:54:33,077 maskrcnn_benchmark.trainer INFO: eta: 1:34:48  iter: 20  loss: 4.7319 (5.9266)  loss_classifier: 1.9245 (2.3255)  loss_box_reg: 1.1822 (1.6187)  loss_objectness: 1.1149 (1.2101)  loss_rpn_box_reg: 0.7983 (0.7724)  time: 3.8332 (3.8438)  data: 0.2276 (0.2318)  lr: 0.000000  max mem: 1317
2020-12-11 14:55:49,664 maskrcnn_benchmark.trainer INFO: eta: 1:33:21  iter: 40  loss: 5.4736 (6.4072)  loss_classifier: 2.6128 (2.7574)  loss_box_reg: 1.2793 (1.6379)  loss_objectness: 1.1705 (1.2604)  loss_rpn_box_reg: 0.6324 (0.7515)  time: 3.8264 (3.8366)  data: 0.2265 (0.2294)  lr: 0.000000  max mem: 1317
2020-12-11 14:57:06,504 maskrcnn_benchmark.trainer INFO: eta: 1:32:07  iter: 60  loss: 7.5228 (6.8577)  loss_classifier: 3.1262 (3.0244)  loss_box_reg: 1.2736 (1.6856)  loss_objectness: 1.0635 (1.2862)  loss_rpn_box_reg: 1.0292 (0.8615)  time: 3.8400 (3.8384)  data: 0.2307 (0.2318)  lr: 0.000000  max mem: 1317
2020-12-11 14:58:26,821 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-11 14:58:26,822 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-11 14:58:26,822 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-11 14:58:29,154 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-11 14:58:29,155 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-11 14:58:29,155 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train","giro9_train" )
  TEST: ("giro1_test","giro4_test","giro8_test","giro9_test")
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000000005
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-11 14:58:29,158 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test', 'giro9_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train', 'giro9_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 5e-09
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-11 14:58:30,814 maskrcnn_benchmark INFO: reloading weigts from wtf_r2.pth
2020-12-11 14:58:33,032 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-11 14:58:33,033 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-11 14:58:33,033 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-11 14:58:33,033 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-11 14:58:33,033 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-11 14:58:33,033 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-11 14:58:33,034 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-11 14:58:33,034 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-11 14:58:33,211 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-11 14:58:35,380 maskrcnn_benchmark.trainer INFO: Start training
2020-12-11 14:59:52,474 maskrcnn_benchmark.trainer INFO: eta: 1:35:04  iter: 20  loss: 5.8479 (7.1839)  loss_classifier: 2.3193 (3.3253)  loss_box_reg: 1.4481 (1.4732)  loss_objectness: 1.3469 (1.4482)  loss_rpn_box_reg: 0.7347 (0.9372)  time: 3.8445 (3.8546)  data: 0.2300 (0.2329)  lr: 0.000000  max mem: 1318
2020-12-11 15:01:09,368 maskrcnn_benchmark.trainer INFO: eta: 1:33:40  iter: 40  loss: 3.9133 (5.7681)  loss_classifier: 1.5039 (2.5739)  loss_box_reg: 0.9397 (1.2351)  loss_objectness: 1.0389 (1.2891)  loss_rpn_box_reg: 0.1466 (0.6699)  time: 3.8376 (3.8496)  data: 0.2303 (0.2337)  lr: 0.000000  max mem: 1318
2020-12-11 15:02:26,468 maskrcnn_benchmark.trainer INFO: eta: 1:32:26  iter: 60  loss: 5.1531 (5.6988)  loss_classifier: 2.0115 (2.5530)  loss_box_reg: 1.0072 (1.1893)  loss_objectness: 0.9549 (1.2844)  loss_rpn_box_reg: 0.6915 (0.6721)  time: 3.8545 (3.8514)  data: 0.2355 (0.2353)  lr: 0.000000  max mem: 1318
2020-12-11 15:03:43,497 maskrcnn_benchmark.trainer INFO: eta: 1:31:09  iter: 80  loss: 6.4380 (5.8428)  loss_classifier: 2.2635 (2.6233)  loss_box_reg: 1.5806 (1.3101)  loss_objectness: 0.9663 (1.2416)  loss_rpn_box_reg: 0.6723 (0.6679)  time: 3.8480 (3.8514)  data: 0.2338 (0.2355)  lr: 0.000000  max mem: 1318
2020-12-11 15:05:00,519 maskrcnn_benchmark.trainer INFO: eta: 1:29:51  iter: 100  loss: 6.3232 (6.0546)  loss_classifier: 2.5782 (2.7605)  loss_box_reg: 1.4054 (1.3620)  loss_objectness: 1.0199 (1.2385)  loss_rpn_box_reg: 0.7171 (0.6935)  time: 3.8466 (3.8514)  data: 0.2340 (0.2355)  lr: 0.000000  max mem: 1318
2020-12-11 15:05:00,521 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 15:05:00,577 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 15:05:44,463 maskrcnn_benchmark.inference INFO: Total run time: 0:00:43.886588 (1.5133306322426632 s / img per device, on 1 devices)
2020-12-11 15:05:44,464 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:40.826763 (1.407819419071592 s / img per device, on 1 devices)
2020-12-11 15:05:44,464 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 15:05:47,640 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 15:05:47,640 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([8.2595e-02, 5.2189e-02, 3.3205e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1826e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.6333e-02, 0.0000e+00, 0.0000e+00, 7.1445e-02,
        9.9436e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.9920e-02, 2.1682e-02, 0.0000e+00,
        3.1749e-02, 2.4420e-02, 2.3005e-02, 4.7265e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6956e-02,
        2.5277e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5207e-02, 2.1682e-02, 0.0000e+00,
        6.9338e-02, 6.3564e-02, 4.2322e-02, 3.7255e-02, 1.5416e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7148e-02,
        1.0956e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.1108e-02, 8.4530e-03, 1.0347e-03, 7.5515e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 2.1466e-02, 0.0000e+00, 9.8067e-02,
        2.0160e-02, 3.6502e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1685e-01, 5.3216e-02, 3.1749e-02,
        2.3328e-02, 1.7836e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7982e-02,
        6.1592e-03, 0.0000e+00, 1.2483e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2692e-02,
        4.0470e-02, 3.8432e-02, 2.5113e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4280e-02, 3.3772e-02,
        1.0956e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.6033e-03, 2.8194e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        2.7087e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0956e-02, 5.5598e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5156e-02,
        1.0971e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7374e-02, 3.2977e-02, 1.5360e-02,
        9.1783e-02, 4.2685e-02, 1.1326e-02, 1.7117e-01, 1.1385e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.8067e-02, 3.9263e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,  3.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,
         6.,  8.,  8.,  8., -1., -1., -1.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
         3., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  5.,  6.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  3.,  3.,  5.,  5.,  6.,  8.,  8.,  8.,  8.,  8., -1.,  3.,  3.,
         3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,
         8.,  8.,  8.,  3.,  6.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,
         3.,  5.,  5.,  6.,  8.,  8.,  8.,  3.]), 'best match scores': tensor([1.0000, 1.0000, 0.9623, 1.0000, 1.0000, 0.9979, 0.9596, 1.0000, 0.5988,
        1.0000, 0.4573, 0.0000, 0.9997, 1.0000, 1.0000, 0.9998, 0.9995, 1.0000,
        0.9999, 1.0000, 0.9889, 0.0837, 0.8611, 1.0000, 1.0000, 1.0000, 0.9999,
        0.9999, 0.9885, 0.3110, 0.9996, 0.9991, 0.6079, 0.9998, 0.7844, 1.0000,
        1.0000, 1.0000, 0.9853, 1.0000, 0.8348, 0.7824, 1.0000, 0.9999, 0.9566,
        0.2422, 0.7319, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.3076, 1.0000, 1.0000, 0.1150, 1.0000, 0.0000, 0.0000, 0.0000,
        1.0000, 1.0000, 0.9974, 0.8086, 0.1370, 1.0000, 1.0000, 1.0000, 0.9965,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9931, 0.9963,
        1.0000, 0.6499, 0.0000, 0.0958, 0.0000, 1.0000, 1.0000, 0.9692, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,
        1.0000, 0.9988, 1.0000, 0.9999, 0.9057, 1.0000, 0.8342, 0.9989, 1.0000,
        0.4301, 1.0000, 1.0000, 0.0912, 0.1119, 1.0000, 1.0000, 1.0000, 1.0000,
        0.9959, 0.9731, 1.0000, 0.7688, 1.0000, 1.0000, 0.9999, 0.9934, 1.0000,
        0.0816, 0.9991, 1.0000, 0.9951, 1.0000, 0.9923, 1.0000, 0.7496, 0.4510,
        0.9941, 0.7152, 1.0000, 0.7939, 0.1339, 1.0000, 1.0000, 1.0000, 0.0640,
        0.8568, 0.8985, 0.6111, 0.9416, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.7898, 0.9979, 1.0000, 0.5485, 0.7772, 1.0000, 0.0934, 1.0000, 0.4485,
        1.0000, 1.0000, 1.0000, 0.9448, 1.0000, 1.0000, 0.6367, 0.9900, 0.1590,
        0.6118, 0.9997, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9431, 0.9859, 1.0000, 0.0948, 1.0000,
        0.9821, 0.9999, 1.0000, 0.0931, 0.1559, 1.0000, 0.8128, 0.8905, 0.7954,
        0.3302, 0.5607, 0.2046, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9998,
        1.0000, 1.0000, 0.9989, 1.0000, 0.9999, 0.1488, 0.6311, 1.0000, 0.0744,
        0.8456, 0.1122, 1.0000, 1.0000, 1.0000, 1.0000, 0.9745, 0.9972, 1.0000,
        1.0000, 0.9996, 0.9999, 1.0000, 0.1226, 1.0000, 1.0000]), 'num_pos': 232}
2020-12-11 15:05:47,676 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.629310
2020-12-11 15:05:47,679 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-11 15:05:51,760 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-11 15:07:09,323 maskrcnn_benchmark.trainer INFO: eta: 1:38:30  iter: 120  loss: 4.8873 (5.9855)  loss_classifier: 2.1672 (2.7320)  loss_box_reg: 0.9282 (1.3619)  loss_objectness: 0.8418 (1.2082)  loss_rpn_box_reg: 0.5811 (0.6834)  time: 3.8701 (4.2828)  data: 0.2421 (0.6650)  lr: 0.000000  max mem: 1318
2020-12-11 15:08:26,481 maskrcnn_benchmark.trainer INFO: eta: 1:35:42  iter: 140  loss: 4.2409 (5.9011)  loss_classifier: 1.6378 (2.7109)  loss_box_reg: 1.0071 (1.3529)  loss_objectness: 0.7358 (1.1620)  loss_rpn_box_reg: 0.5428 (0.6753)  time: 3.8577 (4.2221)  data: 0.2386 (0.6042)  lr: 0.000000  max mem: 1318
2020-12-11 15:09:43,784 maskrcnn_benchmark.trainer INFO: eta: 1:33:17  iter: 160  loss: 4.7886 (5.9086)  loss_classifier: 2.3225 (2.7082)  loss_box_reg: 1.3840 (1.3784)  loss_objectness: 0.8172 (1.1475)  loss_rpn_box_reg: 0.5805 (0.6745)  time: 3.8586 (4.1775)  data: 0.2397 (0.5592)  lr: 0.000000  max mem: 1318
2020-12-11 15:11:00,796 maskrcnn_benchmark.trainer INFO: eta: 1:31:06  iter: 180  loss: 5.1516 (5.9316)  loss_classifier: 2.2972 (2.7337)  loss_box_reg: 1.5372 (1.3973)  loss_objectness: 0.6853 (1.1145)  loss_rpn_box_reg: 0.8086 (0.6861)  time: 3.8511 (4.1412)  data: 0.2389 (0.5236)  lr: 0.000000  max mem: 1318
2020-12-11 15:12:18,046 maskrcnn_benchmark.trainer INFO: eta: 1:29:07  iter: 200  loss: 5.5607 (5.9387)  loss_classifier: 2.1650 (2.7322)  loss_box_reg: 1.2253 (1.4073)  loss_objectness: 0.8497 (1.1103)  loss_rpn_box_reg: 0.7969 (0.6889)  time: 3.8612 (4.1133)  data: 0.2328 (0.4948)  lr: 0.000000  max mem: 1318
2020-12-11 15:12:18,048 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 15:12:18,105 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 15:13:02,071 maskrcnn_benchmark.inference INFO: Total run time: 0:00:43.965258 (1.5160433917210019 s / img per device, on 1 devices)
2020-12-11 15:13:02,071 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:40.882301 (1.4097345204188907 s / img per device, on 1 devices)
2020-12-11 15:13:02,071 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 15:13:05,230 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 15:13:05,230 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([4.7155e-02, 1.6330e-05, 3.7676e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1826e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6113e-01,
        5.1567e-02, 1.2835e-02, 7.4215e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02, 9.0204e-03, 0.0000e+00,
        1.7674e-01, 4.5508e-02, 4.3841e-02, 2.4913e-02, 2.5808e-06, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5217e-02,
        1.0956e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.4785e-02, 3.2977e-02, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3362e-02, 2.1682e-02, 1.1483e-02,
        5.8915e-02, 3.8156e-02, 1.5201e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.2480e-02, 2.1081e-02, 1.0334e-02, 4.1956e-03,
        1.8627e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.0096e-02, 3.2977e-02, 0.0000e+00, 1.5917e-01,
        9.3799e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1855e-01, 1.1108e-01, 9.9601e-02,
        5.7193e-02, 3.9839e-02, 2.3456e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.5005e-02, 1.3254e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2260e-01,
        2.2572e-02, 0.0000e+00, 4.3809e-02, 1.6813e-02, 7.0083e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02,
        2.5506e-02, 1.0108e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5740e-02, 1.5254e-02,
        2.7704e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.8047e-02, 2.2928e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5834e-02,
        4.1631e-02, 2.1612e-02, 9.4126e-03, 8.9231e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.8053e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        5.1408e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0389e-02, 2.1682e-02, 0.0000e+00,
        3.7614e-02, 4.5843e-03, 0.0000e+00, 1.0956e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7749e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  3.,  3.,  3.,  5.,  5.,  6.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,
         3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  6.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,
         8.,  8.,  3.,  3.,  5.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  5.,  6.,  8.,  8.,  8.,  8.,
         8.,  8.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,
         8.,  8.,  8.,  3.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
        -1., -1.,  3.,  3.,  3.,  6.,  8.,  8.]), 'best match scores': tensor([1.0000, 0.9999, 0.9999, 0.0797, 1.0000, 0.9995, 1.0000, 0.9987, 1.0000,
        1.0000, 1.0000, 0.9992, 1.0000, 0.9845, 0.9998, 1.0000, 0.9992, 1.0000,
        1.0000, 1.0000, 0.9970, 1.0000, 0.8374, 0.5281, 1.0000, 1.0000, 1.0000,
        0.9998, 0.9978, 0.5570, 0.1495, 1.0000, 1.0000, 1.0000, 1.0000, 0.4916,
        0.1588, 1.0000, 1.0000, 0.9944, 1.0000, 1.0000, 0.0552, 1.0000, 1.0000,
        1.0000, 0.9995, 0.9752, 1.0000, 1.0000, 1.0000, 1.0000, 0.4787, 0.9996,
        1.0000, 0.4172, 0.9206, 1.0000, 0.2727, 0.9988, 0.1915, 0.7859, 0.9932,
        1.0000, 1.0000, 0.9999, 0.0566, 1.0000, 0.9997, 1.0000, 0.9172, 1.0000,
        0.9976, 1.0000, 1.0000, 1.0000, 1.0000, 0.9376, 0.1745, 1.0000, 0.6203,
        0.7699, 1.0000, 0.8853, 0.7390, 1.0000, 1.0000, 1.0000, 0.9998, 0.9621,
        1.0000, 1.0000, 0.9816, 0.0973, 1.0000, 0.6646, 0.9789, 0.9906, 0.4662,
        0.0602, 1.0000, 1.0000, 1.0000, 0.6271, 0.9429, 0.6873, 1.0000, 1.0000,
        1.0000, 0.9529, 0.2889, 1.0000, 0.7695, 1.0000, 0.9995, 1.0000, 1.0000,
        0.9447, 0.9996, 1.0000, 0.9999, 0.9931, 1.0000, 0.7387, 0.9896, 0.1087,
        1.0000, 1.0000, 0.0000, 0.0000, 0.9903, 1.0000, 1.0000, 1.0000, 1.0000,
        0.5901, 1.0000, 0.2823, 0.6777, 0.7221, 1.0000, 0.5911, 1.0000, 0.9986,
        0.9972, 0.9995, 0.6760, 1.0000, 0.9338, 0.9996, 1.0000, 1.0000, 1.0000,
        0.3862, 1.0000, 0.0725, 0.8470, 0.9759, 1.0000, 0.9994, 1.0000, 1.0000,
        1.0000, 0.9849, 0.9973, 0.9875, 0.3176, 1.0000, 0.9431, 1.0000, 1.0000,
        0.9999, 1.0000, 0.9947, 1.0000, 1.0000, 1.0000, 0.7790, 1.0000, 0.9848,
        0.2062, 0.2110, 1.0000, 0.9319, 0.1173, 1.0000, 0.1417, 0.9988, 0.1757,
        1.0000, 0.3845, 1.0000, 1.0000, 1.0000, 1.0000, 0.1076, 1.0000, 1.0000,
        0.0767, 0.9995, 0.9999, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 0.7146,
        1.0000, 0.9981, 1.0000, 0.8390, 0.9568, 0.1949, 0.9323, 0.9926, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9718, 1.0000, 0.0000, 0.0000,
        0.0000, 0.8709, 1.0000, 0.1086, 1.0000, 0.8043, 1.0000]), 'num_pos': 232}
2020-12-11 15:13:05,267 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.633621
2020-12-11 15:13:05,270 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-11 15:13:09,336 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-11 15:14:26,802 maskrcnn_benchmark.trainer INFO: eta: 1:32:15  iter: 220  loss: 5.0710 (5.8763)  loss_classifier: 1.9060 (2.7168)  loss_box_reg: 0.8302 (1.3953)  loss_objectness: 0.6413 (1.0796)  loss_rpn_box_reg: 0.7469 (0.6845)  time: 3.8661 (4.3246)  data: 0.2362 (0.7051)  lr: 0.000000  max mem: 1318
2020-12-11 15:15:44,176 maskrcnn_benchmark.trainer INFO: eta: 1:30:01  iter: 240  loss: 6.2423 (5.9479)  loss_classifier: 2.5050 (2.7821)  loss_box_reg: 1.1714 (1.3828)  loss_objectness: 0.8984 (1.0856)  loss_rpn_box_reg: 0.7902 (0.6974)  time: 3.8705 (4.2866)  data: 0.2404 (0.6663)  lr: 0.000000  max mem: 1318
2020-12-11 15:17:01,601 maskrcnn_benchmark.trainer INFO: eta: 1:27:55  iter: 260  loss: 4.8592 (5.9605)  loss_classifier: 2.8356 (2.7868)  loss_box_reg: 1.2653 (1.3989)  loss_objectness: 0.6159 (1.0723)  loss_rpn_box_reg: 0.7229 (0.7025)  time: 3.8703 (4.2547)  data: 0.2364 (0.6337)  lr: 0.000000  max mem: 1318
2020-12-11 15:18:18,698 maskrcnn_benchmark.trainer INFO: eta: 1:25:55  iter: 280  loss: 4.6415 (5.9761)  loss_classifier: 1.7839 (2.7990)  loss_box_reg: 1.3664 (1.4017)  loss_objectness: 0.6267 (1.0584)  loss_rpn_box_reg: 0.7818 (0.7170)  time: 3.8508 (4.2261)  data: 0.2338 (0.6053)  lr: 0.000000  max mem: 1318
2020-12-11 15:19:36,003 maskrcnn_benchmark.trainer INFO: eta: 1:24:02  iter: 300  loss: 4.5102 (5.9013)  loss_classifier: 2.0089 (2.7661)  loss_box_reg: 1.3008 (1.4001)  loss_objectness: 0.5312 (1.0306)  loss_rpn_box_reg: 0.4519 (0.7046)  time: 3.8634 (4.2021)  data: 0.2360 (0.5809)  lr: 0.000000  max mem: 1318
2020-12-11 15:19:36,005 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 15:19:36,062 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 15:20:19,945 maskrcnn_benchmark.inference INFO: Total run time: 0:00:43.883589 (1.5132272161286453 s / img per device, on 1 devices)
2020-12-11 15:20:19,946 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:40.817699 (1.4075068523143899 s / img per device, on 1 devices)
2020-12-11 15:20:19,946 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 15:20:23,069 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 15:20:23,070 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.6937e-01, 2.1682e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1826e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.8977e-02, 1.1236e-02, 0.0000e+00, 1.4981e-01,
        1.8540e-02, 9.3799e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4853e-02, 0.0000e+00, 0.0000e+00,
        9.3720e-02, 4.7138e-02, 3.1648e-02, 1.9676e-02, 7.2457e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1000e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0550e-01, 0.0000e+00, 0.0000e+00, 1.1107e-01,
        9.3799e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2885e-02, 3.1749e-02, 0.0000e+00,
        6.7226e-02, 3.3401e-02, 2.4537e-02, 1.6543e-02, 4.3406e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0915e-01, 4.7664e-02, 3.7678e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.3214e-01, 1.1525e-01, 2.5918e-02, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2381e-02, 2.9098e-02, 2.7601e-02,
        2.1682e-02, 1.4322e-02, 5.6160e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.3673e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02,
        1.4612e-02, 0.0000e+00, 3.4263e-02, 1.0956e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4331e-01,
        7.4403e-02, 3.3155e-02, 1.5217e-02, 9.5128e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2906e-02, 1.5535e-02,
        1.0956e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.4994e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4954e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1497e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1820e-01,
        9.8067e-02, 3.2017e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1583e-02, 4.3029e-02, 9.4547e-03,
        1.0999e-01, 2.1682e-02, 0.0000e+00, 1.0956e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.8067e-02, 3.7711e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,
         3.,  8.,  8.,  8.,  3.,  5.,  5.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1.,  3.,  3.,
         6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
        -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8., -1.,  3.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1., -1.,
        -1.,  3.,  6.,  8.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,
         8.,  8.,  8.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
         3.,  3.,  3.,  6.,  8.,  8.,  8.,  8.]), 'best match scores': tensor([0.3607, 1.0000, 0.4944, 1.0000, 1.0000, 0.9885, 1.0000, 0.9995, 1.0000,
        1.0000, 1.0000, 0.9500, 0.8583, 0.9984, 0.9997, 1.0000, 0.9985, 1.0000,
        1.0000, 0.9473, 0.9999, 0.1871, 0.9983, 1.0000, 1.0000, 0.9506, 0.9978,
        0.9081, 1.0000, 1.0000, 0.9985, 0.9888, 0.9999, 0.9996, 0.2949, 0.7323,
        1.0000, 0.4342, 1.0000, 0.9999, 0.7173, 0.6255, 0.9988, 0.8549, 1.0000,
        0.0556, 1.0000, 1.0000, 0.7688, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6302, 0.4309, 0.8069, 0.9920, 0.5098, 0.9996, 0.0688, 0.8575,
        0.9857, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.6138, 0.5831, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9995, 1.0000,
        0.1572, 1.0000, 0.9987, 0.8715, 1.0000, 1.0000, 0.1079, 0.9968, 0.9463,
        1.0000, 0.9640, 1.0000, 1.0000, 0.2844, 0.9998, 0.9877, 1.0000, 1.0000,
        1.0000, 0.9937, 0.1012, 0.9841, 1.0000, 0.0894, 1.0000, 0.7036, 1.0000,
        0.0000, 0.0000, 1.0000, 0.9992, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 0.1670, 0.0768, 1.0000, 1.0000,
        0.1588, 0.9594, 1.0000, 1.0000, 0.8994, 0.9713, 0.7711, 0.9996, 1.0000,
        1.0000, 0.5644, 1.0000, 1.0000, 0.8895, 0.0000, 0.3618, 1.0000, 0.9978,
        0.2750, 1.0000, 0.8877, 1.0000, 0.8758, 1.0000, 1.0000, 1.0000, 0.6944,
        0.9933, 1.0000, 0.4669, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 0.2290, 0.9983, 0.9307, 1.0000, 1.0000, 0.0000, 1.0000,
        1.0000, 1.0000, 0.9976, 0.9967, 1.0000, 0.1673, 0.5638, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.9974, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.9951, 0.8713, 1.0000, 0.9998, 1.0000, 0.2036, 1.0000, 0.2649, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9921,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9833, 1.0000, 0.9984, 1.0000, 0.9200,
        0.9995, 1.0000, 1.0000, 1.0000, 0.9969, 1.0000, 0.2972, 0.0000, 1.0000,
        0.2166, 0.2700, 1.0000, 1.0000, 1.0000, 0.9991, 1.0000]), 'num_pos': 232}
2020-12-11 15:20:23,105 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.642241
2020-12-11 15:20:23,108 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-11 15:20:27,055 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-11 15:22:42,230 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-11 15:22:42,230 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-11 15:22:42,230 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-11 15:22:44,511 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-11 15:22:44,512 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-11 15:22:44,512 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train","giro9_train" )
  TEST: ("giro1_test","giro4_test","giro8_test","giro9_test")
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000000005
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-11 15:22:44,513 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test', 'giro9_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train', 'giro9_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 5e-09
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-11 15:22:46,224 maskrcnn_benchmark INFO: reloading weigts from wtf_r2.pth
2020-12-11 15:23:27,336 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-11 15:23:27,336 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-11 15:23:27,336 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-11 15:23:29,606 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-11 15:23:29,606 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-11 15:23:29,607 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train","giro9_train" )
  TEST: ("giro1_test","giro4_test","giro8_test","giro9_test")
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000000005
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-11 15:23:29,607 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test', 'giro9_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train', 'giro9_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 5e-09
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-11 15:23:31,281 maskrcnn_benchmark INFO: reloading weigts from bbox_best_r1.pth
2020-12-11 15:23:36,889 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-11 15:23:36,890 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-11 15:23:36,890 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-11 15:23:36,890 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-11 15:23:37,067 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-11 15:23:48,769 maskrcnn_benchmark.trainer INFO: Start training
2020-12-11 15:25:11,121 maskrcnn_benchmark.trainer INFO: eta: 1:41:33  iter: 20  loss: 17.7455 (19.5672)  loss_classifier: 3.9853 (4.7660)  loss_box_reg: 1.6062 (1.7515)  loss_objectness: 12.3212 (12.2403)  loss_rpn_box_reg: 0.7144 (0.8094)  time: 4.1367 (4.1175)  data: 0.2850 (0.3181)  lr: 0.000000  max mem: 1313
2020-12-11 15:26:35,559 maskrcnn_benchmark.trainer INFO: eta: 1:41:27  iter: 40  loss: 16.5481 (18.4797)  loss_classifier: 2.1358 (3.9404)  loss_box_reg: 1.2971 (1.7375)  loss_objectness: 11.4959 (12.0440)  loss_rpn_box_reg: 0.7051 (0.7578)  time: 4.2124 (4.1697)  data: 0.2798 (0.3051)  lr: 0.000000  max mem: 1313
2020-12-11 15:27:59,480 maskrcnn_benchmark.trainer INFO: eta: 1:40:16  iter: 60  loss: 17.3531 (18.7778)  loss_classifier: 3.8543 (3.9938)  loss_box_reg: 1.2740 (1.9128)  loss_objectness: 12.4933 (12.0894)  loss_rpn_box_reg: 0.8080 (0.7818)  time: 4.1844 (4.1785)  data: 0.2765 (0.2979)  lr: 0.000000  max mem: 1313
2020-12-11 15:29:22,295 maskrcnn_benchmark.trainer INFO: eta: 1:38:40  iter: 80  loss: 17.0903 (18.3075)  loss_classifier: 2.0385 (3.6393)  loss_box_reg: 1.1212 (1.8490)  loss_objectness: 12.5067 (12.1200)  loss_rpn_box_reg: 0.3405 (0.6992)  time: 4.1391 (4.1690)  data: 0.2628 (0.2903)  lr: 0.000000  max mem: 1313
2020-12-11 15:30:45,664 maskrcnn_benchmark.trainer INFO: eta: 1:37:16  iter: 100  loss: 17.0142 (18.2660)  loss_classifier: 2.3662 (3.4955)  loss_box_reg: 2.2585 (1.9583)  loss_objectness: 11.9219 (12.1237)  loss_rpn_box_reg: 0.4708 (0.6886)  time: 4.1846 (4.1689)  data: 0.2758 (0.2880)  lr: 0.000000  max mem: 1313
2020-12-11 15:30:45,666 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 15:30:45,940 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 15:31:33,795 maskrcnn_benchmark.inference INFO: Total run time: 0:00:47.855388 (1.650185798776561 s / img per device, on 1 devices)
2020-12-11 15:31:33,796 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:43.912668 (1.514229914237713 s / img per device, on 1 devices)
2020-12-11 15:31:33,796 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 15:31:37,456 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 15:31:37,456 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([7.7937e-02, 5.9353e-02, 4.6550e-02, 7.0083e-07, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3937e-01,
        6.4379e-02, 4.0253e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.5423e-02, 3.6173e-02, 6.0316e-03, 7.1445e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7844e-01, 2.8575e-02, 0.0000e+00,
        3.1749e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6171e-02,
        1.1353e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.7592e-02, 8.7587e-03, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5027e-02, 0.0000e+00, 0.0000e+00,
        3.1749e-02, 9.5350e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8962e-02,
        1.7325e-02, 1.3693e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1793e-01, 6.8814e-02, 5.8309e-02, 4.5593e-02,
        2.9960e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.1025e-02, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        1.2789e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9096e-01, 3.1749e-02, 2.4461e-02,
        1.9739e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0391e-02, 1.0956e-02, 2.6360e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9926e-02,
        2.5361e-02, 0.0000e+00, 1.4746e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2397e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2522e-02, 1.1826e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.1124e-01, 9.3799e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5319e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.5318e-02, 1.5667e-02, 5.0206e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1432e-02, 2.1682e-02, 0.0000e+00,
        4.2058e-02, 3.1749e-02, 0.0000e+00, 1.2710e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0258e-01, 6.3608e-02, 8.4858e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  3.,  3.,  8.,  8., -1., -1., -1.,  3.,
         6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8., -1., -1., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  6.,
         8.,  8.,  6.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
         3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3., -1., -1.,  3.,  3.,
         6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
        -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8., -1.,  3.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  8., -1., -1., -1.,
        -1., -1., -1.,  6.,  8.,  8., -1., -1., -1., -1., -1.,  8.,  3.,  8.,
         8.,  8., -1., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
        -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.]), 'best match scores': tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9417, 1.0000, 1.0000, 1.0000, 0.9980,
        0.9999, 0.9999, 0.9784, 1.0000, 1.0000, 0.9759, 0.1937, 1.0000, 0.9998,
        0.3400, 0.5607, 0.1098, 0.9994, 1.0000, 0.9993, 0.0000, 0.0000, 0.0000,
        0.7995, 1.0000, 0.2414, 0.9983, 1.0000, 0.9838, 0.9987, 0.0860, 1.0000,
        0.2375, 0.9999, 0.9999, 1.0000, 1.0000, 0.9190, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 0.1182, 0.9999, 0.9997, 1.0000, 0.9999, 0.2072, 0.5643,
        1.0000, 0.1281, 0.9953, 0.9968, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000,
        1.0000, 1.0000, 1.0000, 0.9704, 0.9997, 1.0000, 1.0000, 1.0000, 0.1973,
        1.0000, 1.0000, 0.9999, 0.9994, 0.1964, 0.9994, 0.9338, 1.0000, 0.1165,
        0.9828, 0.9993, 0.0000, 0.9918, 0.5043, 1.0000, 0.2603, 1.0000, 0.9999,
        0.9092, 0.7070, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.1010, 0.9987, 0.0759, 0.0549,
        0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0513, 1.0000, 1.0000, 0.8967,
        0.1348, 1.0000, 1.0000, 1.0000, 0.9849, 0.9968, 0.6073, 1.0000, 0.7904,
        0.0969, 0.3759, 0.0000, 0.0000, 0.0000, 0.9790, 1.0000, 1.0000, 0.2556,
        1.0000, 0.9061, 0.3370, 1.0000, 0.2738, 0.0000, 0.0000, 0.0000, 0.0000,
        1.0000, 1.0000, 0.9979, 1.0000, 0.9479, 0.0000, 1.0000, 1.0000, 1.0000,
        0.3415, 1.0000, 1.0000, 0.2706, 1.0000, 1.0000, 0.9994, 0.4692, 0.9722,
        1.0000, 0.9977, 0.9952, 0.9688, 1.0000, 1.0000, 0.9998, 1.0000, 0.0000,
        0.9987, 0.4780, 1.0000, 0.9999, 1.0000, 0.1358, 1.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.3040, 1.0000,
        0.9995, 0.8962, 0.3739, 1.0000, 1.0000, 0.8146, 0.0000, 0.0000, 0.9997,
        1.0000, 1.0000, 1.0000, 0.9971, 1.0000, 0.8730, 1.0000, 0.0000, 0.0000,
        0.0000, 1.0000, 1.0000, 0.9078, 1.0000, 0.9999, 1.0000]), 'num_pos': 232}
2020-12-11 15:31:37,499 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.534483
2020-12-11 15:31:37,501 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-11 15:31:41,653 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-11 15:33:06,478 maskrcnn_benchmark.trainer INFO: eta: 1:46:53  iter: 120  loss: 17.0210 (18.2876)  loss_classifier: 2.4218 (3.4683)  loss_box_reg: 1.6602 (1.9781)  loss_objectness: 12.2707 (12.1707)  loss_rpn_box_reg: 0.3992 (0.6706)  time: 4.2238 (4.6476)  data: 0.2819 (0.7567)  lr: 0.000000  max mem: 1313
2020-12-11 15:34:32,920 maskrcnn_benchmark.trainer INFO: eta: 1:44:17  iter: 140  loss: 16.7711 (18.2047)  loss_classifier: 2.6882 (3.4479)  loss_box_reg: 1.2202 (1.9372)  loss_objectness: 11.9702 (12.1532)  loss_rpn_box_reg: 0.4737 (0.6664)  time: 4.3142 (4.6011)  data: 0.2906 (0.6903)  lr: 0.000000  max mem: 1313
2020-12-11 15:35:50,364 maskrcnn_benchmark.trainer INFO: eta: 1:40:43  iter: 160  loss: 17.4105 (18.3269)  loss_classifier: 2.5300 (3.4869)  loss_box_reg: 1.5952 (1.9649)  loss_objectness: 12.2372 (12.2016)  loss_rpn_box_reg: 0.5219 (0.6736)  time: 3.8565 (4.5100)  data: 0.2402 (0.6348)  lr: 0.000000  max mem: 1313
2020-12-11 15:37:07,067 maskrcnn_benchmark.trainer INFO: eta: 1:37:34  iter: 180  loss: 16.4425 (18.4941)  loss_classifier: 3.0059 (3.6233)  loss_box_reg: 1.3105 (2.0389)  loss_objectness: 11.8243 (12.1742)  loss_rpn_box_reg: 0.2355 (0.6577)  time: 3.8286 (4.4350)  data: 0.2347 (0.5912)  lr: 0.000000  max mem: 1313
2020-12-11 15:42:23,139 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-11 15:42:23,140 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-11 15:42:23,140 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-11 15:42:42,357 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-11 15:42:42,357 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-11 15:42:42,357 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-11 15:42:46,621 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-11 15:42:46,622 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-11 15:42:46,623 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train","giro9_train" )
  TEST: ("giro1_test","giro4_test","giro8_test","giro9_test")
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000002
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-11 15:42:46,626 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test', 'giro9_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train', 'giro9_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 2e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-11 15:42:48,379 maskrcnn_benchmark INFO: reloading weigts from bbox_best_r1.pth
2020-12-11 15:42:51,892 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-11 15:42:51,892 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-11 15:42:51,893 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-11 15:42:51,893 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-11 15:42:52,072 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-11 15:42:54,379 maskrcnn_benchmark.trainer INFO: Start training
2020-12-11 15:44:11,249 maskrcnn_benchmark.trainer INFO: eta: 1:34:48  iter: 20  loss: 17.9145 (19.4804)  loss_classifier: 4.9449 (4.8096)  loss_box_reg: 1.5597 (1.8259)  loss_objectness: 11.7838 (12.1028)  loss_rpn_box_reg: 0.6648 (0.7422)  time: 3.8336 (3.8434)  data: 0.2360 (0.2393)  lr: 0.000000  max mem: 1313
2020-12-11 15:45:28,015 maskrcnn_benchmark.trainer INFO: eta: 1:33:27  iter: 40  loss: 16.9752 (18.5575)  loss_classifier: 2.8346 (4.1331)  loss_box_reg: 1.2296 (1.7753)  loss_objectness: 11.7170 (12.0082)  loss_rpn_box_reg: 0.2997 (0.6411)  time: 3.8321 (3.8408)  data: 0.2371 (0.2401)  lr: 0.000000  max mem: 1313
2020-12-11 15:46:44,734 maskrcnn_benchmark.trainer INFO: eta: 1:32:08  iter: 60  loss: 17.6726 (18.4552)  loss_classifier: 2.9888 (3.9180)  loss_box_reg: 2.1843 (1.8907)  loss_objectness: 12.0245 (11.9786)  loss_rpn_box_reg: 0.7157 (0.6679)  time: 3.8311 (3.8392)  data: 0.2377 (0.2394)  lr: 0.000000  max mem: 1313
2020-12-11 15:48:01,495 maskrcnn_benchmark.trainer INFO: eta: 1:30:51  iter: 80  loss: 16.0597 (18.0424)  loss_classifier: 2.1807 (3.6145)  loss_box_reg: 1.0589 (1.7672)  loss_objectness: 11.5008 (12.0326)  loss_rpn_box_reg: 0.2747 (0.6281)  time: 3.8321 (3.8389)  data: 0.2390 (0.2392)  lr: 0.000000  max mem: 1313
2020-12-11 15:49:18,355 maskrcnn_benchmark.trainer INFO: eta: 1:29:35  iter: 100  loss: 18.8705 (18.2763)  loss_classifier: 3.4527 (3.6587)  loss_box_reg: 1.5526 (1.8737)  loss_objectness: 12.0863 (12.1150)  loss_rpn_box_reg: 0.4880 (0.6289)  time: 3.8389 (3.8397)  data: 0.2378 (0.2392)  lr: 0.000000  max mem: 1313
2020-12-11 15:49:18,356 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 15:49:18,412 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 15:50:02,224 maskrcnn_benchmark.inference INFO: Total run time: 0:00:43.811764 (1.5107504992649472 s / img per device, on 1 devices)
2020-12-11 15:50:02,224 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:40.751605 (1.405227751567446 s / img per device, on 1 devices)
2020-12-11 15:50:02,224 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 15:50:05,373 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 15:50:05,373 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([8.4129e-02, 5.9660e-02, 2.2161e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8717e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1296e-01, 3.1749e-02, 0.0000e+00, 7.1445e-02,
        2.5538e-02, 2.5037e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9875e-01, 2.8135e-02, 0.0000e+00,
        3.1749e-02, 9.8228e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0262e-01, 9.0665e-03, 0.0000e+00, 8.7114e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5109e-02, 0.0000e+00, 0.0000e+00,
        5.8338e-02, 2.4950e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2680e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1626e-01, 1.1612e-01, 6.6779e-02, 5.6798e-02,
        4.5922e-02, 2.9960e-02, 2.7561e-02, 4.1060e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.3115e-02, 5.4185e-02, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8565e-02, 6.3781e-02, 3.1749e-02,
        2.7226e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0956e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6980e-02,
        2.2693e-02, 0.0000e+00, 1.4305e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6895e-02,
        3.1749e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3740e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.8067e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.4484e-02, 7.2864e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        4.4097e-02, 3.5129e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9927e-02, 2.1682e-02, 0.0000e+00,
        6.3338e-02, 3.1749e-02, 9.7016e-03, 2.6046e-02, 1.2907e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.8067e-02, 4.3258e-02, 1.5069e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8., -1.,  3.,  6.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8., -1., -1., -1.,  3.,  3.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8., -1., -1., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  6.,
         8.,  8.,  6.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
        -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3., -1., -1.,  3.,  3.,
         3.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,
        -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8., -1., -1., -1.,
        -1.,  3.,  6.,  8.,  8.,  8., -1., -1., -1., -1.,  8.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
         3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.]), 'best match scores': tensor([1.0000, 0.8620, 1.0000, 1.0000, 0.9834, 0.9951, 1.0000, 1.0000, 1.0000,
        1.0000, 0.9999, 0.9800, 0.9999, 1.0000, 1.0000, 0.9997, 0.3248, 1.0000,
        0.2404, 0.8007, 0.0788, 0.9950, 0.7115, 1.0000, 0.0000, 0.8353, 1.0000,
        0.9996, 0.1644, 0.3403, 0.9893, 0.9989, 0.5760, 0.9967, 0.2299, 1.0000,
        1.0000, 0.1271, 1.0000, 1.0000, 1.0000, 0.1927, 0.7331, 0.0926, 1.0000,
        1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.5811, 1.0000, 0.7230, 0.4088,
        1.0000, 0.9872, 0.9962, 0.9890, 1.0000, 0.9995, 0.0000, 0.0000, 0.0000,
        1.0000, 1.0000, 1.0000, 0.9994, 1.0000, 1.0000, 1.0000, 1.0000, 0.2216,
        1.0000, 0.9990, 0.9860, 1.0000, 0.9967, 1.0000, 0.9670, 0.9959, 0.9933,
        0.9994, 0.2411, 0.0000, 0.0000, 0.0000, 0.0000, 0.9132, 1.0000, 1.0000,
        1.0000, 0.9995, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.1334, 0.9985,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0602, 0.9999, 0.9995, 0.0992,
        0.0000, 0.0000, 0.0525, 1.0000, 1.0000, 0.1338, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.9999, 0.2061, 0.0504, 0.1140, 0.5386, 0.9546,
        1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9984, 1.0000, 1.0000,
        1.0000, 0.3282, 0.3495, 0.9999, 0.0969, 0.0000, 0.0000, 0.0000, 0.1467,
        1.0000, 0.1586, 0.9749, 1.0000, 0.9801, 1.0000, 0.9989, 1.0000, 1.0000,
        0.0951, 0.9993, 1.0000, 1.0000, 1.0000, 0.5278, 0.8893, 1.0000, 0.7214,
        1.0000, 0.9963, 0.2574, 0.9950, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 1.0000, 0.9989, 1.0000, 0.9928, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 1.0000, 0.0921, 0.3173, 1.0000, 1.0000, 0.9640,
        0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.7182, 0.9998, 0.9895, 1.0000,
        0.9999, 0.7755, 0.7512, 1.0000, 1.0000, 0.9999, 0.0000, 0.0000, 0.9981,
        1.0000, 1.0000, 0.9979, 0.8632, 1.0000, 1.0000, 1.0000, 0.0000, 0.9399,
        1.0000, 1.0000, 0.0601, 1.0000, 1.0000, 0.9949, 1.0000]), 'num_pos': 232}
2020-12-11 15:50:05,408 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.525862
2020-12-11 15:50:05,410 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-11 15:50:09,683 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-11 15:51:26,657 maskrcnn_benchmark.trainer INFO: eta: 1:38:11  iter: 120  loss: 17.5371 (18.1549)  loss_classifier: 2.7706 (3.5962)  loss_box_reg: 1.0985 (1.8551)  loss_objectness: 11.7404 (12.0864)  loss_rpn_box_reg: 0.2195 (0.6173)  time: 3.8391 (4.2690)  data: 0.2367 (0.6679)  lr: 0.000000  max mem: 1313
2020-12-11 15:52:43,389 maskrcnn_benchmark.trainer INFO: eta: 1:35:21  iter: 140  loss: 17.0431 (18.0538)  loss_classifier: 2.7396 (3.5284)  loss_box_reg: 1.4022 (1.8104)  loss_objectness: 12.2129 (12.0921)  loss_rpn_box_reg: 0.5742 (0.6228)  time: 3.8344 (4.2072)  data: 0.2361 (0.6065)  lr: 0.000000  max mem: 1313
2020-12-11 15:54:00,271 maskrcnn_benchmark.trainer INFO: eta: 1:32:56  iter: 160  loss: 17.7593 (18.1190)  loss_classifier: 3.2826 (3.5840)  loss_box_reg: 2.3466 (1.8942)  loss_objectness: 11.1217 (11.9835)  loss_rpn_box_reg: 0.7622 (0.6573)  time: 3.8403 (4.1618)  data: 0.2393 (0.5609)  lr: 0.000000  max mem: 1313
2020-12-11 15:55:17,060 maskrcnn_benchmark.trainer INFO: eta: 1:30:46  iter: 180  loss: 17.7360 (18.2300)  loss_classifier: 3.7601 (3.6748)  loss_box_reg: 1.3886 (1.9377)  loss_objectness: 11.9632 (11.9570)  loss_rpn_box_reg: 0.5879 (0.6605)  time: 3.8364 (4.1260)  data: 0.2357 (0.5254)  lr: 0.000000  max mem: 1313
2020-12-11 15:56:33,637 maskrcnn_benchmark.trainer INFO: eta: 1:28:45  iter: 200  loss: 18.7165 (18.3481)  loss_classifier: 3.7711 (3.7133)  loss_box_reg: 2.1669 (2.0000)  loss_objectness: 11.9160 (11.9516)  loss_rpn_box_reg: 0.8993 (0.6832)  time: 3.8229 (4.0963)  data: 0.2307 (0.4965)  lr: 0.000000  max mem: 1313
2020-12-11 15:56:33,639 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 15:56:33,697 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 15:57:17,527 maskrcnn_benchmark.inference INFO: Total run time: 0:00:43.829511 (1.5113624375441979 s / img per device, on 1 devices)
2020-12-11 15:57:17,527 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:40.754598 (1.4053309785908665 s / img per device, on 1 devices)
2020-12-11 15:57:17,527 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 15:57:20,667 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 15:57:20,667 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0694, 0.0638, 0.0390, 0.0217, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.2851, 0.1177, 0.0186, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0317, 0.0000, 0.0000, 0.0017, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2268, 0.0266, 0.0000,
        0.0467, 0.0374, 0.0317, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0110, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.1495, 0.0768, 0.0217, 0.0043, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0348, 0.0000, 0.0000,
        0.1888, 0.0391, 0.0289, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0110, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.1158, 0.0700, 0.0531, 0.0461, 0.0337, 0.0040, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0547, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0317, 0.0269, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0127, 0.0034, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0651, 0.0000, 0.0000, 0.0146, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0317, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0307, 0.0191,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0981, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0110,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0067,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0981,
        0.0104, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0330, 0.0000, 0.0000, 0.0459, 0.0308, 0.0045, 0.0059, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0981, 0.0261, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,  8., -1., -1., -1.,
        -1.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8., -1., -1., -1., -1., -1., -1.,  8.,  8.,  8.,
         3.,  8.,  8., -1., -1.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  3.,  6.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
        -1., -1.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  3.,  3.,  6.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8., -1., -1., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
        -1., -1.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1., -1.,  3.,  3.,  5.,  6.,  8.,  8.,  8., -1., -1., -1.,
        -1., -1., -1., -1.,  8.,  8., -1., -1., -1., -1., -1.,  3.,  8.,  8.,
         8.,  3., -1., -1., -1.,  3.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  3.,  8.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8., -1.,
        -1., -1., -1.,  6.,  8.,  8.,  8.,  8.]), 'best match scores': tensor([0.9289, 0.2846, 0.9998, 0.5158, 0.1970, 1.0000, 1.0000, 1.0000, 1.0000,
        0.9976, 1.0000, 0.9723, 1.0000, 1.0000, 0.9952, 1.0000, 0.9998, 0.0804,
        0.7136, 0.9910, 0.2418, 0.9995, 0.0620, 0.0000, 0.6362, 0.0000, 0.0000,
        0.0000, 0.0000, 1.0000, 0.8974, 0.2672, 0.9647, 1.0000, 0.9569, 1.0000,
        1.0000, 0.9989, 0.9955, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,
        1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,
        1.0000, 0.0973, 0.9550, 0.8114, 0.9975, 0.0000, 0.0000, 0.9991, 0.0867,
        1.0000, 1.0000, 1.0000, 0.4313, 0.9999, 1.0000, 0.2953, 1.0000, 0.8361,
        0.9881, 1.0000, 1.0000, 1.0000, 1.0000, 0.9547, 0.2081, 0.9997, 0.1381,
        1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.7886, 0.5390, 0.2100, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 0.9982, 1.0000, 1.0000, 0.9243, 0.9996, 0.0913, 0.9998,
        1.0000, 1.0000, 1.0000, 0.9932, 0.9983, 0.9993, 0.9997, 1.0000, 0.9998,
        0.3384, 1.0000, 0.9977, 0.1022, 1.0000, 1.0000, 1.0000, 0.9989, 0.9996,
        1.0000, 0.9978, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9987, 1.0000,
        1.0000, 1.0000, 0.0791, 1.0000, 0.3639, 0.0000, 0.0000, 0.9828, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9842, 0.7282, 1.0000,
        0.3938, 1.0000, 0.5374, 1.0000, 0.9988, 1.0000, 1.0000, 1.0000, 0.1242,
        1.0000, 0.9903, 1.0000, 0.8104, 1.0000, 0.9504, 1.0000, 1.0000, 0.0000,
        0.0000, 1.0000, 0.9998, 0.9993, 1.0000, 0.4164, 0.9715, 0.9993, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9281, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9980, 1.0000, 1.0000, 0.9945,
        0.0000, 0.0000, 0.0000, 0.0747, 1.0000, 1.0000, 0.9992, 1.0000, 1.0000,
        0.4606, 1.0000, 0.9899, 1.0000, 0.0679, 1.0000, 0.3955, 1.0000, 0.9970,
        1.0000, 0.0566, 1.0000, 0.9986, 0.7977, 0.9976, 1.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 1.0000, 0.9791, 0.9899, 1.0000, 1.0000]), 'num_pos': 232}
2020-12-11 15:57:20,702 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.525862
2020-12-11 15:58:37,471 maskrcnn_benchmark.trainer INFO: eta: 1:31:27  iter: 220  loss: 18.4969 (18.4045)  loss_classifier: 3.1588 (3.7588)  loss_box_reg: 1.3517 (1.9968)  loss_objectness: 11.8488 (11.9625)  loss_rpn_box_reg: 0.7359 (0.6863)  time: 3.8256 (4.2868)  data: 0.2380 (0.6872)  lr: 0.000000  max mem: 1313
2020-12-11 15:59:54,007 maskrcnn_benchmark.trainer INFO: eta: 1:29:13  iter: 240  loss: 16.7542 (18.3473)  loss_classifier: 3.4249 (3.7404)  loss_box_reg: 1.4785 (2.0084)  loss_objectness: 11.2949 (11.9168)  loss_rpn_box_reg: 0.4890 (0.6817)  time: 3.8230 (4.2484)  data: 0.2385 (0.6499)  lr: 0.000000  max mem: 1313
2020-12-11 16:01:10,671 maskrcnn_benchmark.trainer INFO: eta: 1:27:08  iter: 260  loss: 18.1435 (18.3574)  loss_classifier: 2.1596 (3.7359)  loss_box_reg: 1.8402 (2.0213)  loss_objectness: 11.7605 (11.9217)  loss_rpn_box_reg: 0.4828 (0.6785)  time: 3.8343 (4.2165)  data: 0.2321 (0.6181)  lr: 0.000000  max mem: 1313
2020-12-11 16:02:27,632 maskrcnn_benchmark.trainer INFO: eta: 1:25:12  iter: 280  loss: 18.4113 (18.3949)  loss_classifier: 3.5368 (3.7230)  loss_box_reg: 1.5870 (2.0414)  loss_objectness: 12.1561 (11.9484)  loss_rpn_box_reg: 0.7752 (0.6820)  time: 3.8397 (4.1902)  data: 0.2375 (0.5912)  lr: 0.000000  max mem: 1313
2020-12-11 16:04:44,329 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-11 16:04:44,329 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-11 16:04:44,330 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-11 16:04:46,587 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-11 16:04:46,588 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-11 16:04:46,588 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train","giro9_train" )
  TEST: ("giro1_test","giro4_test","giro8_test","giro9_test")
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000002
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-11 16:04:46,589 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test', 'giro9_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train', 'giro9_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 2e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-11 16:04:48,308 maskrcnn_benchmark INFO: reloading weigts from bbox_best_r1.pth
2020-12-11 16:04:50,512 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-11 16:04:50,513 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-11 16:04:50,513 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-11 16:04:50,513 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-11 16:04:50,692 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-11 16:04:52,970 maskrcnn_benchmark.trainer INFO: Start training
2020-12-11 16:06:09,897 maskrcnn_benchmark.trainer INFO: eta: 1:34:52  iter: 20  loss: 17.2612 (18.6789)  loss_classifier: 2.5700 (3.9523)  loss_box_reg: 1.3963 (1.7910)  loss_objectness: 12.1668 (12.2695)  loss_rpn_box_reg: 0.2902 (0.6661)  time: 3.8347 (3.8463)  data: 0.2322 (0.2408)  lr: 0.000000  max mem: 1313
2020-12-11 16:07:26,688 maskrcnn_benchmark.trainer INFO: eta: 1:33:30  iter: 40  loss: 16.5703 (17.7458)  loss_classifier: 2.4752 (3.3766)  loss_box_reg: 1.4760 (1.8194)  loss_objectness: 11.1743 (11.9793)  loss_rpn_box_reg: 0.2920 (0.5706)  time: 3.8444 (3.8429)  data: 0.2341 (0.2376)  lr: 0.000000  max mem: 1313
2020-12-11 16:08:43,601 maskrcnn_benchmark.trainer INFO: eta: 1:32:15  iter: 60  loss: 19.4321 (18.5995)  loss_classifier: 4.2473 (3.8493)  loss_box_reg: 1.8305 (2.0255)  loss_objectness: 11.7457 (12.0467)  loss_rpn_box_reg: 0.7790 (0.6781)  time: 3.8369 (3.8438)  data: 0.2396 (0.2393)  lr: 0.000000  max mem: 1313
2020-12-11 16:10:00,249 maskrcnn_benchmark.trainer INFO: eta: 1:30:54  iter: 80  loss: 16.2879 (18.3261)  loss_classifier: 2.1498 (3.6201)  loss_box_reg: 1.3166 (1.9994)  loss_objectness: 11.7105 (12.0637)  loss_rpn_box_reg: 0.4289 (0.6429)  time: 3.8294 (3.8410)  data: 0.2359 (0.2385)  lr: 0.000000  max mem: 1313
2020-12-11 16:11:16,942 maskrcnn_benchmark.trainer INFO: eta: 1:29:35  iter: 100  loss: 19.2993 (18.8084)  loss_classifier: 3.0862 (3.8072)  loss_box_reg: 2.5726 (2.2146)  loss_objectness: 11.7731 (12.0754)  loss_rpn_box_reg: 0.8966 (0.7111)  time: 3.8302 (3.8397)  data: 0.2365 (0.2383)  lr: 0.000000  max mem: 1313
2020-12-11 16:11:16,944 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 16:11:17,002 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 16:12:00,855 maskrcnn_benchmark.inference INFO: Total run time: 0:00:43.852261 (1.5121469333254058 s / img per device, on 1 devices)
2020-12-11 16:12:00,855 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:40.779739 (1.4061979014298012 s / img per device, on 1 devices)
2020-12-11 16:12:00,855 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 16:12:04,003 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 16:12:04,003 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([8.9342e-02, 2.9123e-02, 2.3300e-02, 7.0083e-07, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5467e-01,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.1749e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6854e-02, 0.0000e+00, 0.0000e+00,
        3.1749e-02, 1.3824e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4384e-02,
        1.0457e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.0631e-02, 8.7822e-03, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4948e-02, 0.0000e+00, 0.0000e+00,
        3.1749e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1861e-01, 6.9394e-02, 6.8552e-02, 4.5264e-02,
        2.9960e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00, 1.4068e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02, 7.5513e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0956e-02, 5.4561e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9444e-02,
        0.0000e+00, 0.0000e+00, 1.4514e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2056e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6026e-02, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2275e-02, 1.5282e-02, 4.9666e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7345e-02, 2.1682e-02, 0.0000e+00,
        3.1749e-02, 2.6742e-02, 0.0000e+00, 2.2064e-02, 1.2476e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6069e-01, 3.7936e-02, 3.0998e-02, 8.5356e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 6.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1.,  8.,
         3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1., -1., -1.,  3.,
         6.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8., -1., -1., -1., -1.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  3.,
         8.,  6., -1.,  3.,  8.,  3.,  3.,  6.,  6.,  8.,  8.,  8.,  8., -1.,
        -1., -1., -1.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1., -1.,  3.,
         3.,  3.,  6.,  8.,  8.,  3.,  3.,  8.,  5.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1., -1., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,
        -1., -1., -1., -1., -1., -1.,  6.,  8.,  8., -1., -1.,  8.,  3.,  8.,
         8.,  8.,  8.,  8.,  8.,  8., -1.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8., -1., -1., -1.,
        -1., -1., -1.,  3.,  8.,  6., -1., -1., -1., -1., -1.,  8., -1.,  8.,
         8.,  8., -1., -1., -1., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  3.,
         8.,  8.,  8., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
         8., -1., -1.,  3.,  6.,  8.,  8.,  8.]), 'best match scores': tensor([1.0000, 0.9996, 0.0833, 0.9964, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,
        0.9593, 0.2858, 0.0000, 0.0000, 1.0000, 0.3389, 0.8404, 1.0000, 0.8550,
        1.0000, 0.9991, 0.1255, 1.0000, 0.2152, 0.0000, 0.0000, 0.0000, 0.0000,
        0.1387, 1.0000, 0.9629, 0.9999, 1.0000, 0.8411, 1.0000, 0.9930, 0.8566,
        0.4251, 0.2131, 0.9205, 0.9860, 0.9998, 1.0000, 0.9974, 0.9998, 1.0000,
        1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9998, 1.0000, 1.0000,
        0.3891, 1.0000, 0.3635, 0.2512, 1.0000, 0.9978, 0.0000, 0.0000, 0.0000,
        0.0686, 1.0000, 1.0000, 0.9314, 0.9985, 0.9995, 0.9993, 1.0000, 1.0000,
        0.0000, 0.9984, 0.4827, 1.0000, 0.9878, 1.0000, 1.0000, 0.2046, 1.0000,
        1.0000, 0.0528, 0.0000, 0.0000, 0.0000, 0.0000, 0.0517, 1.0000, 0.6370,
        1.0000, 0.1381, 0.9999, 0.7750, 0.9998, 0.9974, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 0.9988, 1.0000, 1.0000, 1.0000, 1.0000, 0.8453, 1.0000,
        0.0000, 0.0000, 0.0000, 0.1577, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.7184, 0.9819, 1.0000, 0.9641, 1.0000, 0.5563, 0.9999, 0.9990, 1.0000,
        1.0000, 0.9708, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.2587,
        1.0000, 1.0000, 1.0000, 0.9996, 0.9442, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 1.0000, 1.0000, 0.0651, 0.0000, 0.0000, 0.9989, 1.0000,
        0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 0.9977, 0.6417, 0.0000, 0.0520,
        1.0000, 0.7129, 0.2452, 1.0000, 0.9554, 0.8898, 0.0501, 0.0000, 0.0000,
        0.0000, 0.0000, 0.9869, 1.0000, 0.6608, 1.0000, 0.9998, 0.8850, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9525, 1.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.2628, 0.8818, 1.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,
        0.8260, 0.7782, 0.2218, 0.9995, 0.9998, 0.9922, 0.0000, 0.0000, 0.9998,
        1.0000, 1.0000, 0.9995, 0.0666, 1.0000, 1.0000, 0.8945, 0.0000, 0.5243,
        0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.9102, 1.0000]), 'num_pos': 232}
2020-12-11 16:12:04,037 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.418103
2020-12-11 16:12:04,039 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-11 16:12:08,600 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-11 16:12:36,281 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-11 16:12:36,281 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-11 16:12:36,281 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-11 16:12:38,525 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-11 16:12:38,526 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-11 16:12:38,526 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train","giro9_train" )
  TEST: ("giro1_test","giro4_test","giro8_test","giro9_test")
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000002
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-11 16:12:38,527 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test', 'giro9_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train', 'giro9_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 2e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-11 16:12:40,267 maskrcnn_benchmark INFO: reloading weigts from bbox_best_r1.pth
2020-12-11 16:12:42,551 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-11 16:12:42,551 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-11 16:12:42,731 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-11 16:12:45,032 maskrcnn_benchmark.trainer INFO: Start training
2020-12-11 16:14:02,243 maskrcnn_benchmark.trainer INFO: eta: 1:35:13  iter: 20  loss: 16.4049 (18.6739)  loss_classifier: 2.4221 (4.0831)  loss_box_reg: 1.5466 (2.0123)  loss_objectness: 11.8937 (11.8400)  loss_rpn_box_reg: 0.3802 (0.7385)  time: 3.8426 (3.8604)  data: 0.2395 (0.2423)  lr: 0.000000  max mem: 1313
2020-12-11 16:15:18,928 maskrcnn_benchmark.trainer INFO: eta: 1:33:37  iter: 40  loss: 15.8087 (17.6322)  loss_classifier: 1.9376 (3.2967)  loss_box_reg: 1.5294 (1.8090)  loss_objectness: 11.7282 (11.9161)  loss_rpn_box_reg: 0.2345 (0.6104)  time: 3.8271 (3.8473)  data: 0.2314 (0.2386)  lr: 0.000000  max mem: 1313
2020-12-11 16:16:35,618 maskrcnn_benchmark.trainer INFO: eta: 1:32:13  iter: 60  loss: 16.8131 (17.4756)  loss_classifier: 2.5221 (3.1835)  loss_box_reg: 1.3176 (1.7751)  loss_objectness: 12.1521 (11.9322)  loss_rpn_box_reg: 0.2603 (0.5848)  time: 3.8352 (3.8430)  data: 0.2326 (0.2378)  lr: 0.000000  max mem: 1313
2020-12-11 16:17:52,395 maskrcnn_benchmark.trainer INFO: eta: 1:30:55  iter: 80  loss: 16.7525 (17.5349)  loss_classifier: 2.8997 (3.3129)  loss_box_reg: 0.9412 (1.7599)  loss_objectness: 11.0932 (11.8435)  loss_rpn_box_reg: 0.2851 (0.6187)  time: 3.8377 (3.8420)  data: 0.2382 (0.2378)  lr: 0.000000  max mem: 1313
2020-12-11 16:19:09,078 maskrcnn_benchmark.trainer INFO: eta: 1:29:36  iter: 100  loss: 18.4713 (17.7926)  loss_classifier: 3.6385 (3.4833)  loss_box_reg: 1.6294 (1.8021)  loss_objectness: 11.8486 (11.8325)  loss_rpn_box_reg: 0.8418 (0.6747)  time: 3.8344 (3.8404)  data: 0.2327 (0.2378)  lr: 0.000000  max mem: 1313
2020-12-11 16:19:09,079 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 16:19:09,135 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 16:19:53,013 maskrcnn_benchmark.inference INFO: Total run time: 0:00:43.878008 (1.5130347547859981 s / img per device, on 1 devices)
2020-12-11 16:19:53,014 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:40.780968 (1.4062402741662388 s / img per device, on 1 devices)
2020-12-11 16:19:53,014 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 16:19:56,146 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 16:19:56,147 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([9.1431e-02, 6.7668e-02, 2.9517e-02, 2.4526e-02, 1.9578e-02, 7.0083e-07,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2380e-01,
        1.3532e-01, 5.0204e-02, 2.6966e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1588e-01, 3.1749e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2331e-01, 3.4013e-02, 0.0000e+00,
        3.1749e-02, 1.3388e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2214e-01,
        1.8647e-02, 1.0457e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.2791e-02, 8.7615e-03, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4928e-02, 0.0000e+00, 0.0000e+00,
        3.1749e-02, 1.5441e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1894e-01, 7.0166e-02, 6.8643e-02, 4.5157e-02,
        3.3140e-02, 2.9960e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00, 1.3911e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02, 2.4090e-02, 5.6453e-03,
        1.9914e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0956e-02, 5.4427e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3807e-02,
        0.0000e+00, 0.0000e+00, 1.3927e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0120e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5700e-02, 1.1826e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2740e-02, 1.5274e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6384e-02, 3.2977e-02, 0.0000e+00,
        3.1749e-02, 2.9156e-02, 0.0000e+00, 2.2124e-02, 1.2480e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6598e-01, 3.6389e-02, 3.1874e-02, 8.5385e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8., -1., -1., -1.,  6.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8., -1., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,
         8.,  8.,  3.,  6.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
        -1., -1.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1.,  3.,  3.,
         3.,  3.,  6.,  8.,  8.,  8.,  5.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
        -1., -1., -1., -1., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8., -1.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8., -1., -1., -1.,
        -1.,  3.,  6.,  8.,  8.,  8., -1., -1., -1., -1., -1., -1.,  8.,  8.,
         8.,  8., -1., -1., -1., -1., -1., -1.,  3.,  6.,  8.,  3.,  8.,  8.,
         8.,  8.,  8., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
         8., -1., -1.,  3.,  6.,  8.,  8.,  8.]), 'best match scores': tensor([1.0000, 1.0000, 0.4286, 1.0000, 1.0000, 0.7800, 0.4001, 1.0000, 1.0000,
        0.9999, 0.9966, 1.0000, 0.9990, 1.0000, 0.4953, 0.2305, 1.0000, 0.9998,
        0.5482, 0.7419, 0.2461, 1.0000, 0.9955, 0.0000, 0.0000, 0.0000, 1.0000,
        0.0682, 0.1893, 0.9999, 1.0000, 1.0000, 0.9719, 1.0000, 0.0504, 0.9998,
        1.0000, 1.0000, 0.9999, 0.3096, 0.2201, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 0.9852, 1.0000, 0.9648, 1.0000, 1.0000, 0.0940, 0.4173,
        0.9993, 1.0000, 0.9933, 0.9993, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000,
        0.0673, 1.0000, 0.2628, 0.9862, 0.9998, 1.0000, 1.0000, 1.0000, 0.1523,
        0.8800, 1.0000, 0.9992, 1.0000, 0.9936, 0.4184, 0.9679, 1.0000, 1.0000,
        0.1200, 0.9743, 0.0000, 0.0000, 0.0000, 0.8214, 0.9202, 1.0000, 0.9996,
        1.0000, 0.9967, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.1230, 1.0000, 0.0937, 1.0000, 0.0766, 1.0000,
        0.0000, 0.0000, 0.2260, 0.0990, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.8888, 0.9949, 1.0000, 1.0000, 0.9986, 1.0000, 0.9486, 1.0000, 1.0000,
        1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9884, 0.9655, 0.3222,
        1.0000, 1.0000, 1.0000, 0.6245, 0.3217, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 1.0000, 0.9948, 1.0000, 0.9118, 0.9820, 1.0000, 0.4350, 0.2931,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9994, 1.0000, 0.0000, 0.9893,
        1.0000, 0.9984, 0.9925, 1.0000, 1.0000, 0.9868, 0.9998, 0.0000, 0.0000,
        0.0000, 0.0000, 0.9994, 1.0000, 0.9997, 1.0000, 1.0000, 0.9995, 0.0000,
        0.0000, 0.0000, 0.0000, 0.7980, 1.0000, 0.0887, 1.0000, 0.2020, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9091, 0.9999, 1.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.1053,
        1.0000, 0.9991, 0.9627, 1.0000, 1.0000, 0.8245, 0.0000, 0.9981, 1.0000,
        1.0000, 1.0000, 0.9958, 0.8732, 1.0000, 1.0000, 0.9997, 0.0000, 0.9973,
        0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000]), 'num_pos': 232}
2020-12-11 16:19:56,183 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.538793
2020-12-11 16:19:56,186 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-11 16:20:00,443 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-11 16:21:17,409 maskrcnn_benchmark.trainer INFO: eta: 1:38:12  iter: 120  loss: 15.4177 (17.8488)  loss_classifier: 1.5877 (3.4408)  loss_box_reg: 1.1403 (1.8582)  loss_objectness: 11.6629 (11.8795)  loss_rpn_box_reg: 0.5078 (0.6703)  time: 3.8497 (4.2698)  data: 0.2345 (0.6663)  lr: 0.000000  max mem: 1313
2020-12-11 16:22:34,041 maskrcnn_benchmark.trainer INFO: eta: 1:35:21  iter: 140  loss: 15.5599 (17.7422)  loss_classifier: 1.8517 (3.3581)  loss_box_reg: 1.3068 (1.8444)  loss_objectness: 11.3712 (11.8763)  loss_rpn_box_reg: 0.5894 (0.6634)  time: 3.8262 (4.2072)  data: 0.2341 (0.6046)  lr: 0.000000  max mem: 1313
2020-12-11 16:23:50,732 maskrcnn_benchmark.trainer INFO: eta: 1:32:55  iter: 160  loss: 18.2913 (18.0439)  loss_classifier: 4.3858 (3.5822)  loss_box_reg: 1.4392 (1.9037)  loss_objectness: 11.9121 (11.8743)  loss_rpn_box_reg: 0.5971 (0.6837)  time: 3.8329 (4.1606)  data: 0.2327 (0.5587)  lr: 0.000000  max mem: 1313
2020-12-11 16:25:07,586 maskrcnn_benchmark.trainer INFO: eta: 1:30:45  iter: 180  loss: 16.9007 (18.0584)  loss_classifier: 2.5011 (3.5700)  loss_box_reg: 1.7459 (1.9037)  loss_objectness: 12.2610 (11.9150)  loss_rpn_box_reg: 0.6163 (0.6696)  time: 3.8424 (4.1253)  data: 0.2366 (0.5231)  lr: 0.000000  max mem: 1313
2020-12-11 16:26:39,291 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-11 16:26:39,291 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-11 16:26:39,292 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-11 16:26:41,589 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-11 16:26:41,589 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-11 16:26:41,589 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train","giro9_train" )
  TEST: ("giro1_test","giro4_test","giro8_test","giro9_test")
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000002
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-11 16:26:41,590 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test', 'giro9_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train', 'giro9_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 2e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-11 16:26:43,318 maskrcnn_benchmark INFO: reloading weigts from bbox_best_r1.pth
2020-12-11 16:26:45,591 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-11 16:26:45,592 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-11 16:26:45,592 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-11 16:26:45,592 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-11 16:26:45,770 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-11 16:26:48,034 maskrcnn_benchmark.trainer INFO: Start training
2020-12-11 16:28:04,914 maskrcnn_benchmark.trainer INFO: eta: 1:34:48  iter: 20  loss: 18.1494 (19.5916)  loss_classifier: 3.2229 (4.9181)  loss_box_reg: 1.4602 (1.9040)  loss_objectness: 11.6962 (12.1391)  loss_rpn_box_reg: 0.5232 (0.6305)  time: 3.8335 (3.8439)  data: 0.2356 (0.2382)  lr: 0.000000  max mem: 1313
2020-12-11 16:29:21,539 maskrcnn_benchmark.trainer INFO: eta: 1:33:22  iter: 40  loss: 17.0028 (18.5360)  loss_classifier: 2.5536 (3.9750)  loss_box_reg: 1.5182 (1.9346)  loss_objectness: 11.4794 (12.0312)  loss_rpn_box_reg: 0.2751 (0.5951)  time: 3.8315 (3.8376)  data: 0.2355 (0.2366)  lr: 0.000000  max mem: 1313
2020-12-11 16:30:38,108 maskrcnn_benchmark.trainer INFO: eta: 1:32:01  iter: 60  loss: 16.1974 (18.2278)  loss_classifier: 2.4255 (3.7183)  loss_box_reg: 1.2759 (1.8997)  loss_objectness: 11.3144 (12.0078)  loss_rpn_box_reg: 0.5763 (0.6021)  time: 3.8224 (3.8345)  data: 0.2389 (0.2369)  lr: 0.000000  max mem: 1313
2020-12-11 16:31:54,916 maskrcnn_benchmark.trainer INFO: eta: 1:30:47  iter: 80  loss: 16.9334 (17.9918)  loss_classifier: 2.3199 (3.4977)  loss_box_reg: 1.2544 (1.8129)  loss_objectness: 12.3139 (12.0739)  loss_rpn_box_reg: 0.5568 (0.6073)  time: 3.8318 (3.8360)  data: 0.2362 (0.2380)  lr: 0.000000  max mem: 1313
2020-12-11 16:33:11,433 maskrcnn_benchmark.trainer INFO: eta: 1:29:27  iter: 100  loss: 16.9739 (17.9485)  loss_classifier: 2.9169 (3.4597)  loss_box_reg: 1.2446 (1.8190)  loss_objectness: 12.0759 (12.0729)  loss_rpn_box_reg: 0.4161 (0.5968)  time: 3.8235 (3.8340)  data: 0.2331 (0.2372)  lr: 0.000000  max mem: 1313
2020-12-11 16:33:11,435 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 16:33:11,497 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 16:33:55,380 maskrcnn_benchmark.inference INFO: Total run time: 0:00:43.882976 (1.5132060544244175 s / img per device, on 1 devices)
2020-12-11 16:33:55,380 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:40.739775 (1.4048198338212639 s / img per device, on 1 devices)
2020-12-11 16:33:55,380 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 16:33:58,612 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 16:33:58,613 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([4.3385e-02, 7.0083e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2782e-01,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.1749e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2518e-02, 0.0000e+00, 0.0000e+00,
        3.1749e-02, 1.2650e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.7498e-03, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4906e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1923e-01, 7.7528e-02, 7.0404e-02, 4.5120e-02,
        2.9960e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00, 1.3824e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02, 4.6415e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0956e-02, 5.4353e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8967e-02,
        0.0000e+00, 0.0000e+00, 1.3732e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1015e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1826e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.3389e-02, 1.5265e-02, 4.9465e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6647e-02, 3.2977e-02, 0.0000e+00,
        3.1749e-02, 3.0919e-02, 0.0000e+00, 2.3549e-02, 1.2481e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6764e-01, 3.6976e-02, 3.2320e-02, 8.5400e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 6.,  3.,  8.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,  8., -1.,  8., -1.,
         3.,  6.,  8.,  8.,  8.,  8.,  3.,  8.,  3., -1., -1., -1., -1.,  3.,
         6.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8., -1., -1., -1., -1., -1.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  3.,
         8.,  6., -1., -1., -1., -1.,  3.,  3.,  3.,  6.,  6.,  8.,  8., -1.,
        -1., -1., -1., -1., -1.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1., -1.,  3.,
         3.,  3.,  6.,  8.,  8.,  3.,  3.,  8.,  5.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1., -1., -1., -1.,  6.,  8.,  8.,  8.,  8.,  8.,
        -1., -1., -1., -1., -1., -1., -1.,  8.,  6., -1., -1.,  8.,  3.,  8.,
         8.,  8.,  8.,  8.,  8.,  8., -1., -1., -1., -1.,  8.,  8.,  8.,  8.,
         8., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8., -1., -1., -1.,
        -1., -1., -1.,  3.,  8.,  6., -1., -1., -1., -1., -1.,  8., -1.,  8.,
         8.,  8., -1., -1., -1., -1., -1., -1., -1.,  3.,  6.,  3.,  8.,  8.,
         8.,  8.,  8., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8., -1.,
         8., -1., -1.,  3.,  6.,  8.,  8.,  8.]), 'best match scores': tensor([0.9999, 0.9568, 0.9910, 0.4606, 0.9892, 1.0000, 0.9997, 1.0000, 1.0000,
        0.9989, 0.5768, 0.0000, 0.9997, 0.0000, 0.0545, 0.5703, 1.0000, 0.4258,
        0.9997, 0.9982, 0.9841, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.2083, 1.0000, 0.6721, 0.9986, 1.0000, 0.6827, 0.9998, 0.9520, 0.2722,
        1.0000, 1.0000, 0.3787, 0.8288, 0.9976, 1.0000, 0.9580, 0.9968, 1.0000,
        1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9932, 1.0000,
        1.0000, 1.0000, 1.0000, 0.0555, 1.0000, 0.9514, 0.0000, 0.0000, 0.0000,
        0.1165, 1.0000, 0.9994, 0.8834, 0.9969, 0.9924, 0.3653, 1.0000, 1.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.9981, 1.0000, 0.9946, 1.0000, 1.0000,
        0.9997, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,
        1.0000, 0.0764, 0.9991, 0.1874, 0.9996, 1.0000, 1.0000, 0.9665, 1.0000,
        1.0000, 1.0000, 0.9821, 0.9997, 1.0000, 1.0000, 1.0000, 0.3471, 1.0000,
        0.0000, 0.0000, 0.0000, 0.2819, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.3430, 0.9887, 1.0000, 0.8254, 1.0000, 0.0859, 0.9977, 0.9936, 1.0000,
        1.0000, 0.6916, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.9954, 0.5645, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.9815, 1.0000,
        0.9988, 1.0000, 1.0000, 1.0000, 0.9999, 0.9615, 0.0943, 0.0000, 0.0000,
        0.0000, 0.0000, 1.0000, 0.2038, 1.0000, 0.5061, 0.3785, 0.0000, 0.0000,
        0.0000, 0.0000, 0.9512, 1.0000, 0.0853, 1.0000, 0.9931, 0.4319, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9723, 1.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0825, 0.2835, 1.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,
        0.3636, 0.3367, 0.6364, 0.9948, 0.9970, 0.9340, 0.0000, 0.0000, 0.0000,
        0.9998, 1.0000, 1.0000, 0.9875, 1.0000, 1.0000, 0.3968, 0.0000, 0.0918,
        0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.3320, 1.0000]), 'num_pos': 232}
2020-12-11 16:33:58,644 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.370690
2020-12-11 16:33:58,647 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-11 16:34:02,646 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-11 16:35:19,382 maskrcnn_benchmark.trainer INFO: eta: 1:38:00  iter: 120  loss: 15.6986 (17.8623)  loss_classifier: 2.1137 (3.4100)  loss_box_reg: 1.4272 (1.7891)  loss_objectness: 11.7003 (12.0858)  loss_rpn_box_reg: 0.2272 (0.5775)  time: 3.8346 (4.2612)  data: 0.2303 (0.6639)  lr: 0.000000  max mem: 1313
2020-12-11 16:36:36,226 maskrcnn_benchmark.trainer INFO: eta: 1:35:13  iter: 140  loss: 16.8423 (18.0768)  loss_classifier: 2.6574 (3.4539)  loss_box_reg: 1.8574 (1.8984)  loss_objectness: 11.9558 (12.1369)  loss_rpn_box_reg: 0.3882 (0.5876)  time: 3.8431 (4.2014)  data: 0.2374 (0.6036)  lr: 0.000000  max mem: 1313
2020-12-11 16:37:52,989 maskrcnn_benchmark.trainer INFO: eta: 1:32:48  iter: 160  loss: 18.0084 (18.2336)  loss_classifier: 3.2639 (3.5401)  loss_box_reg: 1.8045 (1.9778)  loss_objectness: 11.2445 (12.1021)  loss_rpn_box_reg: 0.5954 (0.6135)  time: 3.8403 (4.1560)  data: 0.2347 (0.5575)  lr: 0.000000  max mem: 1313
2020-12-11 16:39:09,853 maskrcnn_benchmark.trainer INFO: eta: 1:30:39  iter: 180  loss: 17.2490 (18.2333)  loss_classifier: 2.1018 (3.5100)  loss_box_reg: 2.2587 (2.0271)  loss_objectness: 11.2501 (12.0669)  loss_rpn_box_reg: 0.5528 (0.6293)  time: 3.8415 (4.1212)  data: 0.2361 (0.5223)  lr: 0.000000  max mem: 1313
2020-12-11 16:40:26,465 maskrcnn_benchmark.trainer INFO: eta: 1:28:39  iter: 200  loss: 17.7962 (18.2172)  loss_classifier: 2.6045 (3.4905)  loss_box_reg: 1.9140 (2.0448)  loss_objectness: 11.5033 (12.0378)  loss_rpn_box_reg: 0.7850 (0.6440)  time: 3.8211 (4.0921)  data: 0.2440 (0.4952)  lr: 0.000000  max mem: 1313
2020-12-11 16:40:26,467 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 16:40:26,527 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 16:41:10,561 maskrcnn_benchmark.inference INFO: Total run time: 0:00:44.032928 (1.5183768272399902 s / img per device, on 1 devices)
2020-12-11 16:41:10,561 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:40.881467 (1.4097057622054527 s / img per device, on 1 devices)
2020-12-11 16:41:10,561 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 16:41:13,685 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 16:41:13,685 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([4.3979e-02, 7.0083e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4608e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.1749e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8398e-02, 0.0000e+00, 0.0000e+00,
        9.8031e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.6840e-03, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4812e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2118e-01, 7.1370e-02, 4.4954e-02, 2.9960e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00, 1.3335e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0956e-02, 5.3935e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6836e-02,
        0.0000e+00, 0.0000e+00, 1.2863e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.8656e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7822e-02, 0.0000e+00, 0.0000e+00,
        4.0688e-02, 3.1749e-02, 4.9749e-04, 3.1554e-02, 1.2492e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.6456e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 6.,  3.,  8.,  3.,  5.,  6.,  8.,  8.,  8.,  8.,  8., -1.,  8., -1.,
        -1., -1.,  6.,  8.,  8.,  8.,  3.,  8.,  3., -1., -1., -1., -1., -1.,
         3.,  6.,  8.,  8.,  8., -1.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8., -1., -1., -1., -1., -1.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  3.,
         8.,  6., -1., -1., -1., -1.,  3.,  3.,  3.,  6.,  6.,  8.,  8., -1.,
        -1., -1., -1., -1., -1., -1.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8., -1.,  8.,  8.,  8., -1., -1., -1.,  3.,
         3.,  3.,  6.,  8.,  8., -1., -1.,  8., -1.,  3.,  5.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1., -1., -1., -1.,  6.,  8.,  8.,  3.,  8.,  8.,
        -1., -1., -1., -1., -1., -1., -1.,  8.,  6., -1., -1., -1.,  3.,  8.,
         8.,  8.,  8.,  8.,  8.,  8., -1., -1., -1., -1., -1., -1., -1.,  8.,
         8., -1., -1., -1., -1., -1., -1.,  3.,  6.,  8.,  8., -1., -1., -1.,
        -1., -1., -1.,  3.,  8.,  6., -1., -1., -1., -1., -1., -1., -1., -1.,
         8.,  8., -1., -1., -1., -1., -1., -1., -1.,  3.,  6.,  3.,  3.,  8.,
         8.,  8.,  8., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8., -1., -1.,
        -1., -1., -1., -1.,  3.,  6.,  8.,  8.]), 'best match scores': tensor([0.9996, 0.9979, 0.3539, 0.9468, 0.1350, 0.9534, 1.0000, 0.9568, 1.0000,
        1.0000, 0.8804, 0.0000, 0.9353, 0.0000, 0.0000, 0.0000, 0.1626, 1.0000,
        0.9251, 0.9927, 0.6540, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.1102, 1.0000, 0.8711, 0.9897, 0.1566, 0.0000, 0.2706, 0.9835,
        1.0000, 1.0000, 0.9999, 1.0000, 0.7634, 1.0000, 0.1327, 0.5777, 1.0000,
        1.0000, 0.9973, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2701, 0.9998,
        1.0000, 1.0000, 0.9999, 1.0000, 0.9986, 0.0725, 0.0000, 0.0000, 0.0000,
        0.2245, 1.0000, 0.9476, 0.7751, 0.9907, 0.4646, 0.9999, 1.0000, 1.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.9909, 1.0000, 0.9948, 1.0000, 1.0000,
        0.9587, 0.9997, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        1.0000, 1.0000, 0.9105, 1.0000, 0.9989, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.2139, 0.2939, 0.9841, 0.9998, 0.0000, 1.0000, 0.9996, 1.0000,
        0.0000, 0.0000, 0.0000, 0.5187, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.0000, 0.0000, 1.0000, 0.0000, 0.9290, 0.3969, 0.9998, 0.7488, 0.8333,
        1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,
        1.0000, 1.0000, 0.9999, 0.7608, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000,
        0.8400, 1.0000, 1.0000, 0.9962, 0.9865, 0.1373, 0.2450, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.5584, 1.0000, 1.0000, 0.2702, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9870, 1.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9999, 1.0000,
        0.9982, 0.5938, 0.4061, 0.7167, 0.7346, 1.0000, 0.0000, 0.0000, 0.0000,
        0.9977, 1.0000, 1.0000, 0.1740, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.9997]), 'num_pos': 232}
2020-12-11 16:41:13,714 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.306034
2020-12-11 16:42:30,575 maskrcnn_benchmark.trainer INFO: eta: 1:31:23  iter: 220  loss: 16.8967 (18.3459)  loss_classifier: 3.0886 (3.5605)  loss_box_reg: 1.6156 (2.0765)  loss_objectness: 12.0906 (12.0473)  loss_rpn_box_reg: 0.7924 (0.6616)  time: 3.8274 (4.2843)  data: 0.2378 (0.6868)  lr: 0.000000  max mem: 1313
2020-12-11 16:43:47,168 maskrcnn_benchmark.trainer INFO: eta: 1:29:10  iter: 240  loss: 16.4892 (18.3855)  loss_classifier: 3.6356 (3.6148)  loss_box_reg: 1.5282 (2.0714)  loss_objectness: 11.8508 (12.0315)  loss_rpn_box_reg: 0.7492 (0.6677)  time: 3.8268 (4.2464)  data: 0.2390 (0.6496)  lr: 0.000000  max mem: 1313
2020-12-11 16:45:03,779 maskrcnn_benchmark.trainer INFO: eta: 1:27:05  iter: 260  loss: 15.5842 (18.2933)  loss_classifier: 1.9592 (3.5674)  loss_box_reg: 1.3610 (2.0594)  loss_objectness: 11.7618 (12.0051)  loss_rpn_box_reg: 0.2987 (0.6614)  time: 3.8256 (4.2144)  data: 0.2324 (0.6176)  lr: 0.000000  max mem: 1313
2020-12-11 16:46:20,261 maskrcnn_benchmark.trainer INFO: eta: 1:25:07  iter: 280  loss: 17.7851 (18.2839)  loss_classifier: 3.2892 (3.5540)  loss_box_reg: 1.2705 (2.0483)  loss_objectness: 11.8653 (12.0106)  loss_rpn_box_reg: 0.7993 (0.6710)  time: 3.8242 (4.1865)  data: 0.2333 (0.5901)  lr: 0.000000  max mem: 1313
2020-12-11 16:47:36,865 maskrcnn_benchmark.trainer INFO: eta: 1:23:15  iter: 300  loss: 17.2559 (18.2085)  loss_classifier: 2.6699 (3.5480)  loss_box_reg: 1.3641 (2.0134)  loss_objectness: 11.1003 (11.9700)  loss_rpn_box_reg: 0.7490 (0.6770)  time: 3.8289 (4.1628)  data: 0.2324 (0.5666)  lr: 0.000000  max mem: 1313
2020-12-11 16:47:36,867 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 16:47:36,925 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 16:48:20,720 maskrcnn_benchmark.inference INFO: Total run time: 0:00:43.795237 (1.5101805966475914 s / img per device, on 1 devices)
2020-12-11 16:48:20,720 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:40.554210 (1.3984210326753814 s / img per device, on 1 devices)
2020-12-11 16:48:20,720 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 16:48:23,928 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 16:48:23,929 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([7.0083e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.1749e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8262e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.6319e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4727e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2263e-01, 7.2608e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00, 1.2948e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0956e-02, 5.3604e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1928e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.8330e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9261e-02, 0.0000e+00, 0.0000e+00,
        4.7197e-04, 0.0000e+00, 0.0000e+00, 3.8535e-02, 1.3096e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.3224e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 6., -1., -1., -1.,  3.,  3.,  6.,  8.,  8.,  8.,  8., -1., -1., -1.,
        -1., -1., -1., -1.,  8.,  8., -1.,  8.,  3., -1., -1., -1., -1., -1.,
        -1., -1., -1.,  6.,  8., -1., -1.,  8.,  6.,  6.,  6.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8., -1., -1., -1., -1., -1., -1.,  8.,  8.,  8.,
         8.,  8.,  8., -1., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  3.,
         8.,  6., -1., -1., -1., -1., -1.,  3.,  3.,  3.,  6.,  6.,  8., -1.,
        -1., -1., -1., -1., -1., -1.,  8.,  8., -1., -1.,  8.,  3.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8., -1.,  8.,  8.,  8., -1., -1., -1.,  3.,
         3.,  3.,  6.,  8.,  8., -1., -1.,  8., -1., -1.,  3.,  5.,  8.,  8.,
         8.,  8., -1., -1., -1., -1., -1., -1.,  6.,  8.,  8.,  3.,  3.,  8.,
        -1., -1., -1., -1., -1., -1., -1.,  8.,  6., -1., -1., -1., -1., -1.,
        -1.,  3.,  8.,  8.,  8.,  8., -1., -1., -1., -1., -1., -1., -1.,  8.,
         8., -1., -1., -1., -1., -1., -1., -1., -1.,  6.,  8., -1., -1., -1.,
        -1., -1., -1.,  3.,  8.,  6., -1., -1., -1., -1., -1., -1., -1., -1.,
         8.,  8., -1., -1., -1., -1., -1., -1., -1.,  3.,  6.,  3.,  3.,  8.,
         3.,  3.,  8., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8., -1., -1.,
        -1., -1., -1., -1.,  3.,  6.,  8.,  8.]), 'best match scores': tensor([0.9960, 0.0000, 0.0000, 0.0000, 0.8137, 0.3499, 0.7576, 0.9476, 0.0521,
        1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.9977, 0.8022, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0654, 0.0000, 0.0000, 0.2170,
        0.9873, 1.0000, 1.0000, 1.0000, 1.0000, 0.9898, 1.0000, 0.9999, 0.9926,
        1.0000, 0.4875, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7913,
        1.0000, 1.0000, 0.9757, 1.0000, 0.5596, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.4342, 1.0000, 0.0635, 0.5539, 0.8575, 1.0000, 1.0000, 1.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8975, 1.0000, 0.8149, 1.0000,
        1.0000, 0.6922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        1.0000, 1.0000, 0.0000, 0.0000, 0.9964, 0.9294, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.3445, 0.9385, 0.0000, 1.0000, 0.9185, 0.9816,
        0.0000, 0.0000, 0.0000, 0.7919, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.2146, 0.0620, 0.9853, 0.0687,
        1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,
        1.0000, 1.0000, 0.8711, 1.0000, 0.9975, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 1.0000, 0.9945, 1.0000, 0.4087, 0.1313, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9923, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9950, 1.0000, 0.9999, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9997, 0.9703,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9973, 1.0000,
        0.9190, 0.8253, 0.1716, 1.0000, 0.9995, 1.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.8671, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.9999, 0.2129]), 'num_pos': 232}
2020-12-11 16:48:23,958 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.232759
2020-12-11 16:49:40,638 maskrcnn_benchmark.trainer INFO: eta: 1:24:21  iter: 320  loss: 17.2067 (18.2093)  loss_classifier: 2.2135 (3.5815)  loss_box_reg: 1.9977 (2.0225)  loss_objectness: 10.8714 (11.9095)  loss_rpn_box_reg: 0.9326 (0.6957)  time: 3.8335 (4.2894)  data: 0.2395 (0.6934)  lr: 0.000000  max mem: 1313
2020-12-11 16:50:57,339 maskrcnn_benchmark.trainer INFO: eta: 1:22:24  iter: 340  loss: 15.2897 (18.1194)  loss_classifier: 1.3412 (3.5093)  loss_box_reg: 1.1553 (2.0060)  loss_objectness: 11.5145 (11.9199)  loss_rpn_box_reg: 0.2057 (0.6843)  time: 3.8302 (4.2627)  data: 0.2334 (0.6664)  lr: 0.000000  max mem: 1313
2020-12-11 16:52:15,577 maskrcnn_benchmark.trainer INFO: eta: 1:20:37  iter: 360  loss: 16.2798 (18.1562)  loss_classifier: 2.4077 (3.5464)  loss_box_reg: 1.5840 (2.0111)  loss_objectness: 11.3603 (11.9062)  loss_rpn_box_reg: 0.6910 (0.6925)  time: 3.8792 (4.2432)  data: 0.2361 (0.6430)  lr: 0.000000  max mem: 1313
2020-12-11 16:58:01,184 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-11 16:58:01,184 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-11 16:58:01,184 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-11 16:58:04,000 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-11 16:58:04,001 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-11 16:58:04,002 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train",)
  TEST: ("giro1_test","giro4_test","giro8_test","giro9_test")
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000002
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-11 16:58:04,005 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test', 'giro9_test')
  TRAIN: ('giro1_train',)
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 2e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-11 16:58:05,635 maskrcnn_benchmark INFO: reloading weigts from bbox_best_r1.pth
2020-12-11 16:58:07,820 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-11 16:58:07,820 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-11 16:58:07,821 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-11 16:58:07,821 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-11 16:58:07,997 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-11 16:58:09,116 maskrcnn_benchmark.trainer INFO: Start training
2020-12-11 16:59:25,041 maskrcnn_benchmark.trainer INFO: eta: 1:33:38  iter: 20  loss: 20.6466 (21.4213)  loss_classifier: 4.0018 (4.6330)  loss_box_reg: 3.0363 (3.0469)  loss_objectness: 12.8635 (12.6186)  loss_rpn_box_reg: 1.1258 (1.1229)  time: 3.7823 (3.7961)  data: 0.2211 (0.2278)  lr: 0.000000  max mem: 1313
2020-12-11 17:00:41,034 maskrcnn_benchmark.trainer INFO: eta: 1:32:24  iter: 40  loss: 20.4765 (21.0428)  loss_classifier: 3.8623 (4.5245)  loss_box_reg: 2.2726 (2.7833)  loss_objectness: 12.9316 (12.6773)  loss_rpn_box_reg: 1.0794 (1.0577)  time: 3.7996 (3.7979)  data: 0.2273 (0.2265)  lr: 0.000000  max mem: 1313
2020-12-11 17:01:57,135 maskrcnn_benchmark.trainer INFO: eta: 1:31:12  iter: 60  loss: 21.2357 (21.2656)  loss_classifier: 4.7058 (4.6060)  loss_box_reg: 2.7419 (2.9005)  loss_objectness: 12.7598 (12.6874)  loss_rpn_box_reg: 1.0209 (1.0718)  time: 3.8007 (3.8003)  data: 0.2260 (0.2276)  lr: 0.000000  max mem: 1313
2020-12-11 17:03:13,100 maskrcnn_benchmark.trainer INFO: eta: 1:29:55  iter: 80  loss: 23.4268 (21.9780)  loss_classifier: 6.2199 (4.9753)  loss_box_reg: 2.7273 (3.1520)  loss_objectness: 13.0948 (12.7589)  loss_rpn_box_reg: 0.9760 (1.0918)  time: 3.7952 (3.7998)  data: 0.2286 (0.2283)  lr: 0.000000  max mem: 1313
2020-12-11 17:04:28,977 maskrcnn_benchmark.trainer INFO: eta: 1:28:38  iter: 100  loss: 20.8853 (21.8643)  loss_classifier: 4.1590 (5.0107)  loss_box_reg: 2.4700 (3.0599)  loss_objectness: 12.2235 (12.6744)  loss_rpn_box_reg: 1.2114 (1.1194)  time: 3.7927 (3.7986)  data: 0.2225 (0.2276)  lr: 0.000000  max mem: 1313
2020-12-11 17:04:28,979 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 17:04:29,033 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 17:05:12,630 maskrcnn_benchmark.inference INFO: Total run time: 0:00:43.596548 (1.5033292359319226 s / img per device, on 1 devices)
2020-12-11 17:05:12,630 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:40.520647 (1.3972636995644405 s / img per device, on 1 devices)
2020-12-11 17:05:12,630 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 17:05:15,665 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 17:05:15,665 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([9.7079e-02, 9.3959e-02, 3.0569e-02, 2.7144e-02, 8.6137e-04, 7.0083e-07,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6628e-01,
        9.8135e-02, 2.7599e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1753e-01, 3.1749e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8335e-02, 0.0000e+00, 0.0000e+00,
        3.1749e-02, 1.0732e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3438e-01,
        2.9295e-02, 1.0457e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.8800e-02, 8.7148e-03, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4830e-02, 0.0000e+00, 0.0000e+00,
        3.1749e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1962e-01, 1.1760e-01, 7.2185e-02, 4.4865e-02,
        2.9960e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00, 1.3561e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02, 2.4132e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0956e-02, 5.4128e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7988e-02,
        2.0213e-02, 0.0000e+00, 1.2401e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3645e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4870e-02, 1.1826e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.5499e-02, 1.5234e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8501e-02, 3.2977e-02, 0.0000e+00,
        3.3829e-02, 3.1749e-02, 4.8514e-04, 2.6850e-02, 1.2487e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8069e-01, 3.6664e-02, 3.4143e-02, 8.5447e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8., -1., -1., -1., -1.,  3.,
         6.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8., -1.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8., -1., -1., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  3.,
         8.,  6.,  3.,  3.,  8.,  6.,  6.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
        -1., -1.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,  3.,  3.,  3.,
         3.,  3.,  6.,  8.,  8.,  5.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
        -1., -1., -1., -1., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8., -1.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8., -1., -1., -1.,
        -1., -1.,  3.,  6.,  8.,  8., -1., -1., -1., -1., -1., -1.,  8.,  8.,
         8.,  8., -1., -1., -1., -1., -1., -1., -1.,  3.,  6.,  3.,  8.,  8.,
         8.,  8.,  8., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
         8., -1., -1.,  3.,  6.,  8.,  8.,  8.]), 'best match scores': tensor([1.0000, 1.0000, 0.2126, 1.0000, 1.0000, 1.0000, 1.0000, 0.9998, 0.9867,
        0.3873, 0.1215, 0.9773, 1.0000, 1.0000, 0.1698, 0.9972, 1.0000, 0.9996,
        0.1905, 0.3854, 0.2275, 1.0000, 0.9821, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0630, 1.0000, 0.9997, 1.0000, 1.0000, 0.9364, 0.9999, 0.9992, 1.0000,
        0.9999, 1.0000, 0.9997, 0.0960, 0.0651, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 0.0000, 0.9314, 1.0000, 0.8482, 1.0000, 1.0000, 0.1148,
        0.9965, 1.0000, 0.9791, 0.9960, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000,
        1.0000, 1.0000, 0.0925, 0.9696, 0.9995, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.9595, 0.9963, 1.0000, 1.0000, 0.9762, 0.1470, 1.0000, 0.8844,
        1.0000, 0.9061, 0.0000, 0.0000, 0.0000, 0.7942, 0.7773, 1.0000, 0.9982,
        1.0000, 0.9841, 1.0000, 0.9983, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9964, 1.0000,
        0.0000, 0.0594, 0.1918, 0.0855, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.9976, 1.0000, 1.0000, 0.9945, 1.0000, 1.0000, 0.6465, 0.9998, 1.0000,
        1.0000, 0.8042, 0.0000, 0.0000, 0.0000, 1.0000, 0.9639, 0.8141, 0.0687,
        1.0000, 1.0000, 0.0883, 1.0000, 0.3566, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 1.0000, 0.9735, 1.0000, 0.7402, 0.9057, 1.0000, 0.1547, 0.0932,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9976, 1.0000, 0.0000, 0.9504,
        1.0000, 0.9949, 0.9738, 1.0000, 0.9999, 0.9430, 0.9992, 0.0000, 0.0000,
        0.0000, 0.0000, 0.9993, 1.0000, 0.9986, 1.0000, 1.0000, 0.9985, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.8963, 1.0000, 1.0000, 0.1037, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.8319, 0.9995, 1.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,
        0.0924, 0.9972, 0.9076, 1.0000, 1.0000, 1.0000, 0.0000, 0.9994, 1.0000,
        1.0000, 1.0000, 0.9775, 0.5859, 1.0000, 1.0000, 0.9991, 0.0000, 0.9912,
        0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.9997, 1.0000]), 'num_pos': 232}
2020-12-11 17:05:15,698 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.500000
2020-12-11 17:05:15,700 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-11 17:05:19,643 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-11 17:06:35,582 maskrcnn_benchmark.trainer INFO: eta: 1:37:04  iter: 120  loss: 18.2635 (21.4489)  loss_classifier: 3.3928 (4.7768)  loss_box_reg: 1.7229 (2.9552)  loss_objectness: 12.3706 (12.6270)  loss_rpn_box_reg: 0.9778 (1.0899)  time: 3.7831 (4.2205)  data: 0.2275 (0.6506)  lr: 0.000000  max mem: 1313
2020-12-11 17:07:51,520 maskrcnn_benchmark.trainer INFO: eta: 1:34:17  iter: 140  loss: 18.2925 (21.0897)  loss_classifier: 2.7719 (4.6015)  loss_box_reg: 2.2875 (2.8659)  loss_objectness: 12.1474 (12.5406)  loss_rpn_box_reg: 0.9027 (1.0818)  time: 3.7929 (4.1600)  data: 0.2248 (0.5897)  lr: 0.000000  max mem: 1313
2020-12-11 17:09:07,633 maskrcnn_benchmark.trainer INFO: eta: 1:31:55  iter: 160  loss: 21.6228 (21.1883)  loss_classifier: 3.9274 (4.6231)  loss_box_reg: 2.8342 (2.8970)  loss_objectness: 12.7565 (12.5724)  loss_rpn_box_reg: 1.2421 (1.0958)  time: 3.8065 (4.1157)  data: 0.2265 (0.5448)  lr: 0.000000  max mem: 1313
2020-12-11 17:10:23,406 maskrcnn_benchmark.trainer INFO: eta: 1:29:44  iter: 180  loss: 18.9626 (21.1587)  loss_classifier: 4.1309 (4.6562)  loss_box_reg: 1.9716 (2.8770)  loss_objectness: 12.1744 (12.5448)  loss_rpn_box_reg: 1.0350 (1.0807)  time: 3.7875 (4.0794)  data: 0.2215 (0.5090)  lr: 0.000000  max mem: 1313
2020-12-11 17:11:39,476 maskrcnn_benchmark.trainer INFO: eta: 1:27:47  iter: 200  loss: 22.4703 (21.4421)  loss_classifier: 4.8567 (4.8752)  loss_box_reg: 2.8458 (2.9109)  loss_objectness: 12.2459 (12.5365)  loss_rpn_box_reg: 1.4058 (1.1195)  time: 3.8044 (4.0518)  data: 0.2256 (0.4807)  lr: 0.000000  max mem: 1313
2020-12-11 17:11:39,478 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 17:11:39,531 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 17:12:23,051 maskrcnn_benchmark.inference INFO: Total run time: 0:00:43.519738 (1.5006806192726925 s / img per device, on 1 devices)
2020-12-11 17:12:23,051 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:40.552084 (1.3983477230729728 s / img per device, on 1 devices)
2020-12-11 17:12:23,051 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 17:12:26,132 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 17:12:26,133 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.0576e-01, 3.2307e-02, 7.0083e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6735e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1753e-01, 3.1749e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8030e-02, 0.0000e+00, 0.0000e+00,
        3.1749e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8285e-02,
        1.0457e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.8378e-02, 8.5728e-03, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4649e-02, 0.0000e+00, 0.0000e+00,
        3.1749e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2419e-01, 7.4704e-02, 4.6827e-02, 2.9960e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.3037e-02, 0.0000e+00, 0.0000e+00, 1.2499e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02, 2.7771e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0956e-02, 5.3219e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5379e-02,
        0.0000e+00, 0.0000e+00, 1.0147e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6907e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3644e-02, 1.1826e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0112e-02, 1.5160e-02, 4.8370e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1745e-02, 3.2977e-02, 0.0000e+00,
        5.1725e-02, 3.1749e-02, 4.3181e-04, 3.5842e-02, 1.3107e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.0197e-01, 4.3422e-02, 1.6156e-02, 8.5636e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,  3.,  6.,
         8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8., -1., -1., -1., -1.,  3.,
         6.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8., -1., -1.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8., -1., -1.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  3.,
         8.,  6.,  3.,  3.,  8.,  3.,  6.,  6.,  8.,  8.,  8.,  8.,  8., -1.,
        -1., -1.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1., -1.,  3.,
         3.,  3.,  6.,  8.,  8.,  5.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
        -1., -1., -1., -1., -1.,  6.,  8.,  8.,  8., -1.,  3.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8., -1.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8., -1., -1., -1.,
        -1., -1., -1.,  3.,  8.,  6., -1., -1., -1., -1., -1.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1., -1., -1., -1., -1.,  3.,  6.,  3.,  8.,  8.,
         8.,  8.,  8., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
         8., -1., -1.,  3.,  6.,  8.,  8.,  8.]), 'best match scores': tensor([1.0000, 1.0000, 0.0582, 1.0000, 0.2089, 1.0000, 1.0000, 0.8195, 1.0000,
        1.0000, 0.9964, 0.0000, 0.8900, 0.9706, 1.0000, 0.9764, 1.0000, 0.9987,
        1.0000, 0.0629, 0.1219, 1.0000, 0.7604, 0.0000, 0.0000, 0.0000, 0.0000,
        0.1855, 1.0000, 0.9963, 1.0000, 1.0000, 0.8108, 0.9997, 0.9857, 1.0000,
        0.8903, 0.9998, 0.9937, 0.7987, 0.9987, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 0.0000, 0.0000, 0.3570, 1.0000, 0.1844, 1.0000, 1.0000,
        0.9154, 1.0000, 0.8192, 0.8781, 1.0000, 0.9999, 0.0000, 0.0000, 0.0909,
        0.1402, 1.0000, 1.0000, 0.9091, 0.9978, 1.0000, 1.0000, 1.0000, 1.0000,
        0.9990, 1.0000, 0.9271, 0.9922, 1.0000, 1.0000, 0.7320, 1.0000, 0.3234,
        1.0000, 0.3763, 0.0000, 0.0000, 0.0000, 0.5572, 0.2325, 1.0000, 0.9624,
        1.0000, 0.7173, 1.0000, 1.0000, 0.9997, 1.0000, 0.4971, 1.0000, 1.0000,
        1.0000, 0.9999, 0.9997, 1.0000, 1.0000, 1.0000, 1.0000, 0.9708, 1.0000,
        0.0000, 0.0000, 0.0000, 0.2169, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.9985, 1.0000, 1.0000, 0.9251, 1.0000, 0.9998, 0.0844, 0.9973, 1.0000,
        1.0000, 0.1627, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.7208, 0.0924,
        1.0000, 1.0000, 0.9939, 0.9999, 0.0561, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 1.0000, 0.5602, 0.1713, 1.0000, 0.0000, 1.0000, 0.2210, 1.0000,
        1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 0.9998, 0.9565, 0.0000, 0.4444,
        1.0000, 0.9483, 0.7437, 1.0000, 0.9968, 0.4335, 0.9880, 0.0000, 0.0000,
        0.0000, 0.0000, 0.9984, 1.0000, 0.9675, 1.0000, 1.0000, 0.9836, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9641, 1.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.5440, 0.9904, 1.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,
        0.2906, 0.9716, 0.7094, 0.9999, 1.0000, 1.0000, 0.0000, 0.9999, 1.0000,
        1.0000, 1.0000, 0.5818, 0.0551, 1.0000, 1.0000, 0.9874, 0.0000, 0.9083,
        0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9931]), 'num_pos': 232}
2020-12-11 17:12:26,166 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.469828
2020-12-11 17:13:42,097 maskrcnn_benchmark.trainer INFO: eta: 1:30:28  iter: 220  loss: 20.8681 (21.3653)  loss_classifier: 3.9098 (4.8385)  loss_box_reg: 3.1208 (2.9282)  loss_objectness: 11.5062 (12.4841)  loss_rpn_box_reg: 1.1610 (1.1144)  time: 3.7966 (4.2408)  data: 0.2263 (0.6698)  lr: 0.000000  max mem: 1313
2020-12-11 17:14:58,222 maskrcnn_benchmark.trainer INFO: eta: 1:28:17  iter: 240  loss: 20.1221 (21.4360)  loss_classifier: 4.3704 (4.9768)  loss_box_reg: 2.9117 (2.9430)  loss_objectness: 10.5490 (12.3601)  loss_rpn_box_reg: 1.5523 (1.1561)  time: 3.8016 (4.2046)  data: 0.2249 (0.6334)  lr: 0.000000  max mem: 1313
2020-12-11 17:16:14,112 maskrcnn_benchmark.trainer INFO: eta: 1:26:14  iter: 260  loss: 21.9877 (21.4979)  loss_classifier: 4.2011 (4.9700)  loss_box_reg: 2.6520 (2.9522)  loss_objectness: 12.6171 (12.4245)  loss_rpn_box_reg: 0.8510 (1.1512)  time: 3.7929 (4.1731)  data: 0.2228 (0.6019)  lr: 0.000000  max mem: 1313
2020-12-11 17:17:30,137 maskrcnn_benchmark.trainer INFO: eta: 1:24:18  iter: 280  loss: 19.2219 (21.5878)  loss_classifier: 3.8678 (5.0035)  loss_box_reg: 2.9375 (3.0029)  loss_objectness: 12.2117 (12.4242)  loss_rpn_box_reg: 1.2311 (1.1573)  time: 3.8003 (4.1465)  data: 0.2286 (0.5752)  lr: 0.000000  max mem: 1313
2020-12-11 17:18:46,160 maskrcnn_benchmark.trainer INFO: eta: 1:22:28  iter: 300  loss: 20.9736 (21.6797)  loss_classifier: 4.1788 (5.0443)  loss_box_reg: 3.2159 (3.0427)  loss_objectness: 12.2276 (12.4322)  loss_rpn_box_reg: 1.1915 (1.1605)  time: 3.7989 (4.1235)  data: 0.2288 (0.5521)  lr: 0.000000  max mem: 1313
2020-12-11 17:18:46,162 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 17:18:46,217 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 17:19:29,751 maskrcnn_benchmark.inference INFO: Total run time: 0:00:43.533998 (1.5011723370387637 s / img per device, on 1 devices)
2020-12-11 17:19:29,752 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:40.547617 (1.398193696449543 s / img per device, on 1 devices)
2020-12-11 17:19:29,752 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 17:19:32,851 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 17:19:32,852 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([5.3910e-02, 7.0083e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1753e-01, 3.1749e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7653e-02, 0.0000e+00, 0.0000e+00,
        3.1749e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6982e-02,
        1.0457e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.1135e-02, 8.4815e-03, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5801e-02, 0.0000e+00, 0.0000e+00,
        3.1749e-02, 7.0903e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.3036e-01, 1.2718e-01, 8.1074e-02, 2.9960e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.2067e-02, 2.3788e-02, 0.0000e+00, 1.2457e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02, 2.5168e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0956e-02, 5.2640e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2332e-02,
        0.0000e+00, 0.0000e+00, 5.1748e-02, 7.5943e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0059e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2161e-02, 1.1826e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.5684e-02, 1.5256e-02, 4.7811e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1802e-02, 3.2977e-02, 0.0000e+00,
        6.3835e-02, 3.1749e-02, 3.7725e-04, 1.5550e-02, 1.3122e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3251e-01, 4.4795e-02, 9.8482e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1.,  3.,
         6.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8., -1., -1., -1., -1.,  3.,
         6.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8., -1., -1.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8., -1., -1.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  3.,
         8.,  6.,  3.,  8.,  8.,  3.,  3.,  6.,  6.,  8.,  8.,  8.,  8., -1.,
        -1., -1.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,  3.,  3.,  3.,  3.,
         6.,  8.,  8.,  8.,  8.,  3.,  5.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1., -1., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,
        -1., -1., -1., -1., -1.,  6.,  8.,  8.,  8., -1.,  3.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8., -1.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8., -1., -1., -1.,
        -1., -1., -1.,  3.,  8.,  6., -1., -1., -1., -1., -1.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1., -1., -1., -1., -1.,  3.,  6.,  3.,  8.,  8.,
         8.,  8.,  8., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
        -1.,  3.,  5.,  6.,  8.,  8.,  8.,  8.]), 'best match scores': tensor([1.0000, 1.0000, 0.9999, 0.1090, 1.0000, 1.0000, 1.0000, 0.6744, 1.0000,
        1.0000, 0.9924, 0.0000, 0.0000, 0.9510, 0.9873, 1.0000, 0.9591, 1.0000,
        0.9972, 1.0000, 0.1494, 1.0000, 0.5804, 0.0000, 0.0000, 0.0000, 0.0000,
        0.3320, 1.0000, 0.9924, 1.0000, 1.0000, 0.6626, 0.9998, 0.9657, 1.0000,
        0.9995, 0.6288, 0.9853, 0.9971, 1.0000, 1.0000, 1.0000, 0.9949, 1.0000,
        1.0000, 1.0000, 0.0000, 0.0000, 0.1840, 1.0000, 0.0841, 1.0000, 1.0000,
        0.8150, 1.0000, 0.7040, 0.7338, 1.0000, 0.9996, 0.0000, 0.0000, 0.1732,
        0.3287, 1.0000, 1.0000, 0.8268, 0.9944, 0.9999, 1.0000, 1.0000, 1.0000,
        0.9994, 1.0000, 0.8397, 1.0000, 0.9968, 1.0000, 1.0000, 0.5622, 0.1788,
        1.0000, 0.2170, 0.0000, 0.0000, 0.0000, 0.6443, 0.1363, 1.0000, 0.9163,
        1.0000, 0.5136, 1.0000, 1.0000, 0.9993, 1.0000, 0.3037, 1.0000, 1.0000,
        1.0000, 0.9998, 0.9994, 1.0000, 1.0000, 1.0000, 0.7076, 0.9368, 0.0000,
        0.4172, 0.0884, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.9955, 0.9997, 1.0000, 1.0000, 0.8521, 1.0000, 0.9985, 0.9997, 0.9941,
        1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.5660,
        1.0000, 1.0000, 1.0000, 0.9999, 0.9869, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 1.0000, 0.0882, 0.3321, 1.0000, 0.0000, 1.0000, 0.1010, 1.0000,
        1.0000, 1.0000, 0.9998, 1.0000, 1.0000, 0.9995, 0.9076, 0.0000, 0.2459,
        1.0000, 0.9026, 0.5798, 1.0000, 0.9921, 0.2511, 0.9743, 0.0000, 0.0000,
        0.0000, 0.0000, 0.9987, 1.0000, 0.9221, 1.0000, 1.0000, 0.9680, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9824, 1.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.4367, 0.9772, 1.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,
        0.5011, 0.9449, 0.4989, 0.9999, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000,
        1.0000, 1.0000, 0.9999, 0.3453, 1.0000, 1.0000, 0.9728, 0.0000, 0.0000,
        1.0000, 0.0748, 1.0000, 1.0000, 1.0000, 0.8417, 0.9834]), 'num_pos': 232}
2020-12-11 17:19:32,885 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.461207
2020-12-11 17:20:48,828 maskrcnn_benchmark.trainer INFO: eta: 1:23:33  iter: 320  loss: 21.2944 (21.7801)  loss_classifier: 5.1990 (5.1094)  loss_box_reg: 2.6852 (3.0655)  loss_objectness: 12.1432 (12.4443)  loss_rpn_box_reg: 1.2008 (1.1609)  time: 3.7922 (4.2491)  data: 0.2235 (0.6777)  lr: 0.000000  max mem: 1313
2020-12-11 17:22:04,923 maskrcnn_benchmark.trainer INFO: eta: 1:21:38  iter: 340  loss: 20.4129 (21.7644)  loss_classifier: 4.1896 (5.1102)  loss_box_reg: 2.4522 (3.0481)  loss_objectness: 12.1662 (12.4363)  loss_rpn_box_reg: 1.1116 (1.1697)  time: 3.7971 (4.2230)  data: 0.2210 (0.6513)  lr: 0.000000  max mem: 1313
2020-12-11 17:23:21,414 maskrcnn_benchmark.trainer INFO: eta: 1:19:48  iter: 360  loss: 18.8377 (21.6904)  loss_classifier: 3.2409 (5.0832)  loss_box_reg: 2.1944 (3.0303)  loss_objectness: 11.0669 (12.4018)  loss_rpn_box_reg: 1.1366 (1.1751)  time: 3.7941 (4.2008)  data: 0.2223 (0.6280)  lr: 0.000000  max mem: 1313
2020-12-11 17:24:37,140 maskrcnn_benchmark.trainer INFO: eta: 1:18:00  iter: 380  loss: 21.5057 (21.7293)  loss_classifier: 4.9570 (5.1060)  loss_box_reg: 2.1738 (3.0398)  loss_objectness: 12.3071 (12.4065)  loss_rpn_box_reg: 1.1005 (1.1770)  time: 3.7845 (4.1790)  data: 0.2208 (0.6066)  lr: 0.000000  max mem: 1313
2020-12-11 17:25:52,905 maskrcnn_benchmark.trainer INFO: eta: 1:16:15  iter: 400  loss: 20.7521 (21.7020)  loss_classifier: 5.0346 (5.1174)  loss_box_reg: 2.0906 (3.0192)  loss_objectness: 12.1582 (12.3951)  loss_rpn_box_reg: 0.9804 (1.1703)  time: 3.7851 (4.1595)  data: 0.2246 (0.5876)  lr: 0.000000  max mem: 1313
2020-12-11 17:25:52,907 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 17:25:52,958 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 17:26:36,405 maskrcnn_benchmark.inference INFO: Total run time: 0:00:43.446706 (1.4981622860349457 s / img per device, on 1 devices)
2020-12-11 17:26:36,405 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:40.514442 (1.3970497312216923 s / img per device, on 1 devices)
2020-12-11 17:26:36,406 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 17:26:39,459 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 17:26:39,459 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([6.3131e-02, 7.0083e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1753e-01, 3.1749e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7154e-02, 0.0000e+00, 0.0000e+00,
        3.1749e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5284e-02,
        1.0457e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.3788e-02, 8.3034e-03, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7906e-02, 5.9729e-03, 0.0000e+00,
        5.3313e-02, 2.7910e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.3552e-01, 9.0943e-02, 2.9960e-02, 2.9068e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.1639e-02, 1.2078e-02, 0.0000e+00, 1.2490e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4435e-02, 3.1749e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0956e-02, 5.1504e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7629e-02,
        0.0000e+00, 0.0000e+00, 7.4127e-02, 4.1891e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0293e-02, 1.1826e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.3535e-02, 2.2894e-02, 4.6714e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.6583e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9444e-02, 3.2977e-02, 0.0000e+00,
        1.4594e-01, 2.1682e-02, 1.1631e-04, 1.5279e-02, 1.3152e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7318e-01, 4.4327e-02, 9.8751e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,  3.,  5.,
         6.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8., -1., -1., -1., -1.,  3.,
         6.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8., -1., -1.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8., -1., -1.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  6.,
         8.,  8.,  3.,  8.,  8.,  3.,  6.,  6.,  8.,  8.,  8.,  8.,  8., -1.,
        -1., -1.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  3.,  3.,  3.,  3.,
         6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1., -1., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,
        -1., -1., -1., -1., -1.,  6.,  8.,  8.,  8., -1.,  3.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8., -1.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8., -1., -1., -1.,
        -1., -1., -1.,  3.,  8.,  6., -1., -1., -1., -1., -1.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1., -1., -1., -1., -1.,  3.,  6.,  3.,  8.,  8.,
         8.,  8.,  8., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
        -1.,  3.,  5.,  6.,  8.,  8.,  8.,  8.]), 'best match scores': tensor([1.0000, 1.0000, 0.9999, 0.0738, 1.0000, 1.0000, 1.0000, 0.5700, 1.0000,
        1.0000, 0.9886, 0.0000, 0.9768, 0.1508, 0.9961, 1.0000, 0.9458, 1.0000,
        0.9945, 1.0000, 0.1991, 1.0000, 0.4575, 0.0000, 0.0000, 0.0000, 0.0000,
        0.4910, 1.0000, 0.9887, 1.0000, 1.0000, 0.5033, 0.9999, 0.9413, 1.0000,
        0.9992, 0.5117, 0.9766, 0.9954, 1.0000, 1.0000, 1.0000, 0.9907, 1.0000,
        1.0000, 1.0000, 0.0000, 0.0000, 0.1165, 0.9999, 0.0510, 1.0000, 1.0000,
        0.7279, 1.0000, 0.6278, 0.6209, 1.0000, 0.9994, 0.0000, 0.0000, 0.2811,
        0.5516, 1.0000, 1.0000, 0.7189, 0.9875, 0.9999, 1.0000, 1.0000, 0.1147,
        1.0000, 0.7560, 0.1074, 0.9769, 1.0000, 1.0000, 0.4563, 1.0000, 0.1209,
        1.0000, 0.1500, 0.0000, 0.0000, 0.0000, 0.7537, 0.1009, 1.0000, 0.8730,
        1.0000, 0.3935, 1.0000, 1.0000, 0.9984, 0.2118, 1.0000, 1.0000, 1.0000,
        0.6998, 0.9991, 1.0000, 0.9996, 1.0000, 0.8928, 0.6107, 1.0000, 0.6164,
        0.1939, 0.0663, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.6746, 0.8250, 1.0000, 1.0000, 0.7855, 1.0000, 0.9996, 0.9908, 1.0000,
        1.0000, 0.9975, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.4634,
        1.0000, 1.0000, 1.0000, 0.9998, 0.9796, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 1.0000, 0.0581, 1.0000, 0.2253, 0.0000, 1.0000, 0.0632, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9992, 0.8603, 0.9997, 0.0000, 0.1592,
        1.0000, 0.8607, 0.4664, 1.0000, 0.9862, 0.1767, 0.9596, 0.0000, 0.0000,
        0.0000, 0.0000, 0.9991, 1.0000, 0.8740, 1.0000, 0.9999, 0.9522, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9903, 1.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.3734, 0.9621, 1.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,
        0.6806, 0.9191, 0.3194, 0.9999, 0.9998, 1.0000, 0.0000, 0.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 0.2320, 0.9574, 0.0000, 0.0000,
        1.0000, 0.4144, 1.0000, 1.0000, 1.0000, 0.7945, 0.9721]), 'num_pos': 232}
2020-12-11 17:26:39,490 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.469828
2020-12-11 17:27:55,380 maskrcnn_benchmark.trainer INFO: eta: 1:16:33  iter: 420  loss: 20.6315 (21.6310)  loss_classifier: 3.6475 (5.0702)  loss_box_reg: 1.9686 (2.9918)  loss_objectness: 12.4416 (12.3982)  loss_rpn_box_reg: 1.0741 (1.1707)  time: 3.7976 (4.2530)  data: 0.2216 (0.6812)  lr: 0.000000  max mem: 1313
2020-12-11 17:29:12,076 maskrcnn_benchmark.trainer INFO: eta: 1:14:48  iter: 440  loss: 19.4472 (21.6102)  loss_classifier: 4.2522 (5.0642)  loss_box_reg: 2.7990 (2.9898)  loss_objectness: 11.4431 (12.3849)  loss_rpn_box_reg: 1.0949 (1.1712)  time: 3.8224 (4.2340)  data: 0.2263 (0.6608)  lr: 0.000000  max mem: 1313
2020-12-11 17:30:31,017 maskrcnn_benchmark.trainer INFO: eta: 1:13:10  iter: 460  loss: 20.3630 (21.6285)  loss_classifier: 4.8800 (5.0689)  loss_box_reg: 2.3364 (2.9932)  loss_objectness: 12.0725 (12.3941)  loss_rpn_box_reg: 1.1705 (1.1724)  time: 3.8999 (4.2215)  data: 0.2408 (0.6430)  lr: 0.000000  max mem: 1313
2020-12-11 17:31:54,682 maskrcnn_benchmark.trainer INFO: eta: 1:11:44  iter: 480  loss: 19.7372 (21.5681)  loss_classifier: 3.7737 (5.0422)  loss_box_reg: 1.9631 (2.9639)  loss_objectness: 12.2435 (12.3968)  loss_rpn_box_reg: 0.8834 (1.1652)  time: 4.1870 (4.2199)  data: 0.2802 (0.6285)  lr: 0.000000  max mem: 1313
2020-12-11 17:33:18,794 maskrcnn_benchmark.trainer INFO: eta: 1:10:19  iter: 500  loss: 19.5536 (21.5281)  loss_classifier: 4.1475 (5.0290)  loss_box_reg: 2.5411 (2.9470)  loss_objectness: 11.8224 (12.3913)  loss_rpn_box_reg: 0.8889 (1.1608)  time: 4.1788 (4.2194)  data: 0.2795 (0.6154)  lr: 0.000000  max mem: 1313
2020-12-11 17:33:18,796 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 17:33:18,859 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 17:34:05,714 maskrcnn_benchmark.inference INFO: Total run time: 0:00:46.855440 (1.6157048241845493 s / img per device, on 1 devices)
2020-12-11 17:34:05,715 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:43.690013 (1.506552161841557 s / img per device, on 1 devices)
2020-12-11 17:34:05,715 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 17:34:09,324 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 17:34:09,324 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([5.5494e-02, 7.0083e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1753e-01, 3.1749e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6690e-02, 0.0000e+00, 0.0000e+00,
        3.1749e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3750e-02,
        1.0457e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.3305e-02, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02, 0.0000e+00, 0.0000e+00,
        5.3284e-02, 3.4758e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.4831e-01, 1.0034e-01, 4.3360e-02, 2.9960e-02,
        3.1758e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.0758e-02, 5.4626e-03, 0.0000e+00, 1.2531e-02,
        1.0315e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2175e-02, 3.1749e-02, 6.9346e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0956e-02, 5.0128e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2585e-02,
        0.0000e+00, 0.0000e+00, 1.2028e-02, 1.4858e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8659e-02, 1.1826e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.1102e-02, 3.4207e-02, 4.5434e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9703e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2107e-02, 3.5630e-02, 2.1682e-02,
        2.4070e-01, 2.1682e-02, 0.0000e+00, 1.3189e-02, 1.1901e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0923e-01, 4.3877e-02, 9.9080e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 6.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,  3.,  5.,
         6.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8., -1., -1., -1., -1.,  3.,
         6.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8., -1., -1., -1., -1.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8., -1., -1.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  6.,
         8.,  8.,  5.,  8.,  8.,  6.,  6.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
        -1., -1.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  3.,  3.,  3.,  3.,
         6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1., -1., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,
        -1., -1., -1., -1., -1.,  6.,  8.,  8.,  8., -1., -1.,  3.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8., -1.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8., -1., -1., -1.,
        -1., -1., -1.,  3.,  8.,  6., -1., -1., -1., -1., -1.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,
         8.,  8.,  8., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
        -1.,  3.,  5.,  6.,  8.,  8.,  8.,  8.]), 'best match scores': tensor([1.0000, 0.9999, 0.9998, 1.0000, 1.0000, 1.0000, 1.0000, 0.4319, 1.0000,
        1.0000, 0.9804, 0.0000, 0.9839, 0.5140, 0.9972, 1.0000, 0.9213, 1.0000,
        0.9906, 1.0000, 0.2176, 1.0000, 0.3079, 0.0000, 0.0000, 0.0000, 0.0000,
        0.6239, 1.0000, 0.9809, 1.0000, 1.0000, 0.3694, 0.9999, 0.8873, 1.0000,
        0.9985, 0.3641, 0.9573, 0.9917, 0.9999, 1.0000, 0.9999, 0.9805, 1.0000,
        1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0637, 0.9998, 1.0000,
        0.5828, 1.0000, 0.0573, 0.5167, 0.4526, 0.9989, 0.0000, 0.0000, 0.3954,
        0.7000, 1.0000, 1.0000, 0.6046, 0.9760, 0.9998, 1.0000, 1.0000, 1.0000,
        0.0963, 0.6146, 0.1590, 1.0000, 1.0000, 0.3301, 1.0000, 0.0723, 0.0573,
        1.0000, 0.0916, 0.0000, 0.0000, 0.0000, 0.7887, 0.0664, 1.0000, 0.7893,
        1.0000, 0.2570, 1.0000, 0.1265, 0.9970, 1.0000, 1.0000, 1.0000, 1.0000,
        0.9984, 1.0000, 0.9993, 0.5673, 1.0000, 0.8191, 0.4751, 1.0000, 0.0758,
        0.2736, 0.0741, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.5376, 0.6979, 1.0000, 1.0000, 0.9999, 0.6776, 0.9993, 0.9841, 1.0000,
        1.0000, 0.9954, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.3410,
        1.0000, 1.0000, 1.0000, 0.9997, 0.9648, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 1.0000, 0.1290, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9986, 0.7740, 0.9994, 0.0000, 0.0888,
        1.0000, 0.7818, 0.3225, 1.0000, 0.9732, 0.1073, 0.9277, 0.0000, 0.0000,
        0.0000, 0.0000, 0.9991, 1.0000, 0.7783, 1.0000, 0.9998, 0.9208, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9941, 1.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.2958, 0.9292, 1.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,
        0.8684, 0.0804, 0.2034, 0.9998, 0.9997, 0.7973, 0.0000, 0.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.9998, 1.0000, 0.1310, 0.9225, 0.0000, 0.0000,
        1.0000, 0.7858, 1.0000, 0.9999, 1.0000, 0.7113, 0.9476]), 'num_pos': 232}
2020-12-11 17:34:09,368 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.465517
2020-12-11 17:35:33,191 maskrcnn_benchmark.trainer INFO: eta: 1:10:29  iter: 520  loss: 20.0252 (21.5370)  loss_classifier: 4.0659 (5.0287)  loss_box_reg: 2.1995 (2.9487)  loss_objectness: 12.7477 (12.3948)  loss_rpn_box_reg: 1.2294 (1.1647)  time: 4.1957 (4.3155)  data: 0.2721 (0.7005)  lr: 0.000000  max mem: 1313
2020-12-11 17:36:57,521 maskrcnn_benchmark.trainer INFO: eta: 1:08:59  iter: 540  loss: 20.5600 (21.5003)  loss_classifier: 4.0323 (5.0051)  loss_box_reg: 1.7629 (2.9287)  loss_objectness: 12.4097 (12.4027)  loss_rpn_box_reg: 1.1831 (1.1638)  time: 4.2106 (4.3119)  data: 0.3022 (0.6856)  lr: 0.000000  max mem: 1313
2020-12-11 17:38:20,667 maskrcnn_benchmark.trainer INFO: eta: 1:07:27  iter: 560  loss: 19.5100 (21.4850)  loss_classifier: 3.0674 (4.9945)  loss_box_reg: 2.1346 (2.9257)  loss_objectness: 12.1291 (12.4003)  loss_rpn_box_reg: 1.0858 (1.1645)  time: 4.1435 (4.3063)  data: 0.2603 (0.6710)  lr: 0.000000  max mem: 1313
2020-12-11 17:39:44,253 maskrcnn_benchmark.trainer INFO: eta: 1:05:57  iter: 580  loss: 17.5661 (21.4412)  loss_classifier: 3.1239 (4.9928)  loss_box_reg: 1.9212 (2.9047)  loss_objectness: 11.7655 (12.3787)  loss_rpn_box_reg: 0.8783 (1.1650)  time: 4.1751 (4.3020)  data: 0.2778 (0.6579)  lr: 0.000000  max mem: 1313
2020-12-11 17:41:07,818 maskrcnn_benchmark.trainer INFO: eta: 1:04:28  iter: 600  loss: 20.6926 (21.4114)  loss_classifier: 4.3789 (4.9884)  loss_box_reg: 2.5594 (2.8938)  loss_objectness: 12.0802 (12.3654)  loss_rpn_box_reg: 1.1496 (1.1638)  time: 4.1687 (4.2978)  data: 0.2876 (0.6458)  lr: 0.000000  max mem: 1313
2020-12-11 17:41:07,820 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-11 17:41:07,875 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(29 images).
2020-12-11 17:41:54,367 maskrcnn_benchmark.inference INFO: Total run time: 0:00:46.491234 (1.6031459939890895 s / img per device, on 1 devices)
2020-12-11 17:41:54,367 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:43.275310 (1.4922520538856243 s / img per device, on 1 devices)
2020-12-11 17:41:54,367 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-11 17:41:57,609 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-11 17:41:57,609 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([4.8015e-02, 9.8068e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1753e-01, 3.1749e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6081e-02, 0.0000e+00, 0.0000e+00,
        3.1749e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1765e-02,
        1.0457e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.3941e-02, 0.0000e+00, 0.0000e+00, 9.8067e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02, 0.0000e+00, 0.0000e+00,
        5.3188e-02, 4.4805e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.5791e-01, 1.1298e-01, 5.6358e-02, 2.9960e-02,
        2.1172e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0324e-01, 0.0000e+00, 0.0000e+00, 1.2553e-02,
        1.0315e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02, 4.6376e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0956e-02, 4.9356e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8350e-02,
        0.0000e+00, 0.0000e+00, 1.2050e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8788e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1826e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2458e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.4211e-02, 3.3095e-02, 4.4767e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3560e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1513e-02, 3.3207e-02, 2.1682e-02,
        2.1030e-01, 2.1682e-02, 0.0000e+00, 1.3209e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.6971e-01, 4.1302e-02, 9.9262e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4,
        8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 8,
        8, 8, 8, 8, 8, 8, 8, 5, 7, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7,
        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
        8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 4, 7, 7, 4, 8, 8, 8,
        8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([ 8.,  6.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,  3.,  5.,
         6.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8., -1., -1., -1., -1.,  3.,
         6.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8., -1., -1., -1.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8., -1., -1.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  6.,
         8.,  8.,  3.,  8.,  8.,  5.,  6.,  6.,  8.,  8.,  8.,  8.,  8., -1.,
        -1., -1.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  3.,  3.,  3.,  3.,
         6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8., -1., -1., -1., -1., -1.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,
        -1., -1., -1., -1., -1.,  6.,  8.,  8.,  8., -1., -1.,  8.,  3.,  8.,
         8.,  8.,  8.,  8.,  8.,  8., -1.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8., -1., -1., -1.,
        -1., -1., -1.,  3.,  8.,  6., -1., -1., -1., -1., -1.,  8.,  8.,  8.,
         8., -1., -1., -1., -1., -1., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,
         8.,  8.,  8., -1., -1.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8., -1.,
         3.,  5.,  5.,  6.,  8.,  8.,  8.,  8.]), 'best match scores': tensor([0.9997, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.3900, 1.0000,
        0.9999, 0.9776, 0.0000, 0.9924, 0.9479, 0.9992, 1.0000, 0.9143, 1.0000,
        0.9839, 1.0000, 0.2889, 1.0000, 0.2597, 0.0000, 0.0000, 0.0000, 0.0000,
        0.7386, 1.0000, 0.9777, 0.9999, 1.0000, 0.2559, 0.9999, 0.8512, 1.0000,
        0.9981, 0.3247, 0.9481, 0.9899, 0.9999, 1.0000, 0.9999, 0.9747, 1.0000,
        1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0526, 0.9998, 1.0000, 1.0000,
        0.5374, 1.0000, 1.0000, 0.4884, 0.4062, 0.9986, 0.0000, 0.0000, 0.5192,
        0.8323, 1.0000, 1.0000, 0.4808, 0.9553, 0.9998, 1.0000, 1.0000, 1.0000,
        1.0000, 0.5587, 0.1318, 0.6175, 1.0000, 1.0000, 0.2978, 1.0000, 0.0612,
        1.0000, 0.0786, 0.0000, 0.0000, 0.0000, 0.8701, 0.0597, 1.0000, 0.7590,
        1.0000, 0.2257, 1.0000, 0.1031, 0.9946, 1.0000, 1.0000, 1.0000, 1.0000,
        0.9980, 1.0000, 0.9991, 0.5257, 1.0000, 1.0000, 0.4224, 0.7452, 0.1359,
        0.5267, 0.1113, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.4972, 0.6369, 1.0000, 1.0000, 0.9999, 0.6374, 0.9992, 0.9944, 0.9811,
        1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.3010,
        1.0000, 1.0000, 1.0000, 0.9997, 0.9578, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 1.0000, 0.1086, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9983, 0.7441, 0.9993, 0.0000, 0.0730,
        1.0000, 0.7448, 0.0944, 0.2741, 1.0000, 0.9666, 0.9113, 0.0000, 0.0000,
        0.0000, 0.0000, 0.9994, 1.0000, 0.7328, 1.0000, 0.9998, 0.9063, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9964, 1.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.2658, 0.9111, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000,
        0.8422, 0.0627, 0.1236, 0.9998, 0.9996, 0.7728, 0.0000, 0.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.9997, 1.0000, 0.1086, 0.9017, 0.0000, 1.0000,
        0.4346, 0.9806, 1.0000, 0.9999, 1.0000, 0.6905, 0.9343]), 'num_pos': 232}
2020-12-11 17:41:57,645 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.469828
2020-12-12 00:19:38,187 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 00:19:38,187 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 00:19:38,188 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 00:19:48,343 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 00:19:48,344 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 00:19:48,345 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000002
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 00:19:48,348 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 2e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 00:19:50,341 maskrcnn_benchmark INFO: reloading weigts from bbox_best_r1.pth
2020-12-12 00:20:03,936 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-12 00:20:03,936 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-12 00:20:03,936 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-12 00:20:03,937 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-12 00:20:04,130 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-12 00:20:29,029 maskrcnn_benchmark.trainer INFO: Start training
2020-12-12 00:21:48,331 maskrcnn_benchmark.trainer INFO: eta: 1:37:46  iter: 20  loss: 19.6936 (21.7848)  loss_classifier: 4.4588 (6.3326)  loss_box_reg: 3.0180 (3.2367)  loss_objectness: 10.4540 (10.6199)  loss_rpn_box_reg: 1.5859 (1.5956)  time: 3.8357 (3.9639)  data: 0.2403 (0.2640)  lr: 0.000000  max mem: 1313
2020-12-12 00:23:05,290 maskrcnn_benchmark.trainer INFO: eta: 1:35:03  iter: 40  loss: 20.3334 (21.8965)  loss_classifier: 6.0761 (6.6197)  loss_box_reg: 2.3963 (2.8492)  loss_objectness: 11.0422 (10.8591)  loss_rpn_box_reg: 1.3412 (1.5684)  time: 3.8484 (3.9063)  data: 0.2390 (0.2537)  lr: 0.000000  max mem: 1313
2020-12-12 00:24:22,088 maskrcnn_benchmark.trainer INFO: eta: 1:33:13  iter: 60  loss: 22.1312 (22.7889)  loss_classifier: 5.5088 (7.2890)  loss_box_reg: 3.1410 (2.9580)  loss_objectness: 10.5715 (10.9385)  loss_rpn_box_reg: 1.6129 (1.6035)  time: 3.8368 (3.8842)  data: 0.2375 (0.2492)  lr: 0.000000  max mem: 1313
2020-12-12 00:25:38,874 maskrcnn_benchmark.trainer INFO: eta: 1:31:39  iter: 80  loss: 21.0093 (22.8425)  loss_classifier: 4.7132 (7.3203)  loss_box_reg: 2.2455 (2.9073)  loss_objectness: 10.9452 (10.9823)  loss_rpn_box_reg: 1.5142 (1.6327)  time: 3.8413 (3.8730)  data: 0.2315 (0.2455)  lr: 0.000000  max mem: 1313
2020-12-12 00:26:55,758 maskrcnn_benchmark.trainer INFO: eta: 1:30:14  iter: 100  loss: 20.6217 (22.5952)  loss_classifier: 5.2022 (7.1565)  loss_box_reg: 2.4537 (2.8656)  loss_objectness: 11.0636 (10.9529)  loss_rpn_box_reg: 1.5854 (1.6202)  time: 3.8355 (3.8672)  data: 0.2337 (0.2439)  lr: 0.000000  max mem: 1313
2020-12-12 00:26:55,760 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 00:26:57,077 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(148 images).
2020-12-12 00:30:43,150 maskrcnn_benchmark.inference INFO: Total run time: 0:03:46.072938 (1.5275198543393933 s / img per device, on 1 devices)
2020-12-12 00:30:43,151 maskrcnn_benchmark.inference INFO: Model inference time: 0:03:28.712332 (1.4102184579179093 s / img per device, on 1 devices)
2020-12-12 00:30:43,151 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 00:30:58,810 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 00:30:58,810 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([3.0657e-01, 3.0658e-02, 2.1682e-02, 5.5006e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.9861e-02, 8.7513e-02, 4.6860e-02, 2.8752e-02, 2.1075e-02, 1.6495e-02,
        5.6893e-03, 0.0000e+00, 0.0000e+00, 6.5288e-02, 2.1084e-02, 9.8640e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.3801e-02, 0.0000e+00, 0.0000e+00, 1.8743e-02, 3.3173e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.2043e-01, 1.0021e-01, 5.0568e-02, 4.7967e-02, 1.9101e-02,
        2.1384e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.9377e-02, 3.3003e-02,
        1.7714e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1526e-01, 1.3789e-01,
        7.3793e-02, 3.6968e-02, 2.0852e-02, 3.9880e-03, 1.1032e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3771e-01, 6.1927e-02,
        2.1682e-02, 3.6324e-02, 2.0980e-02, 4.0464e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.6598e-02, 1.8781e-02,
        1.5874e-02, 2.7533e-02, 6.4814e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7713e-02, 3.2977e-02,
        0.0000e+00, 3.2977e-02, 1.2769e-02, 0.0000e+00, 3.2977e-02, 0.0000e+00,
        1.4617e-01, 6.6532e-02, 5.5124e-02, 3.6842e-02, 2.0852e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3570e-01, 4.8928e-02, 2.1682e-02,
        1.2354e-01, 5.0102e-02, 0.0000e+00, 1.9543e-02, 1.2309e-02, 7.6657e-03,
        3.0699e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5428e-02, 6.8310e-02, 5.2716e-02,
        2.1695e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.4339e-02, 4.8578e-02, 9.5883e-03, 7.2538e-03, 3.4811e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7773e-02,
        3.3711e-02, 0.0000e+00, 7.4643e-02, 3.2977e-02, 0.0000e+00, 7.9212e-02,
        3.3645e-02, 0.0000e+00, 1.6289e-01, 3.2139e-02, 0.0000e+00, 3.1960e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.0860e-02, 3.2977e-02, 0.0000e+00, 2.1495e-02,
        2.2258e-02, 1.3782e-02, 0.0000e+00, 2.4064e-02, 1.2907e-02, 1.2174e-02,
        5.8647e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2977e-02, 2.2280e-02, 0.0000e+00, 5.1546e-02, 4.2194e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.8136e-01, 7.5726e-02, 6.4743e-02, 2.0234e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.5008e-02, 1.1676e-02, 4.5318e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6257e-02,
        3.2977e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4938e-02,
        3.2096e-02, 0.0000e+00, 9.1532e-02, 2.6046e-02, 3.4572e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.5416e-02, 8.4189e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8544e-02, 3.1593e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 5.1207e-02, 2.2925e-02, 1.3068e-02, 9.4496e-03, 9.2533e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2139e-02, 0.0000e+00,
        3.2977e-02, 2.8398e-02, 0.0000e+00, 1.0085e-01, 6.8747e-02, 5.0192e-02,
        9.5782e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3520e-01, 4.7139e-02, 0.0000e+00, 4.7674e-02, 0.0000e+00, 0.0000e+00,
        1.5898e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1560e-02, 2.2861e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.9832e-02, 6.8722e-02, 2.1682e-02, 3.5157e-02, 2.0881e-02, 1.0973e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.1749e-02, 0.0000e+00, 0.0000e+00, 6.9257e-02,
        6.4003e-02, 2.0477e-02, 1.7293e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 6.4910e-03, 0.0000e+00, 8.7894e-02,
        8.5684e-02, 8.0626e-02, 5.2047e-02, 5.1009e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.2151e-02, 6.5998e-02, 5.9994e-02, 3.5502e-02,
        2.1101e-02, 1.7444e-02, 1.2103e-02, 0.0000e+00, 0.0000e+00, 1.3396e-01,
        5.8137e-02, 2.9874e-02, 2.9090e-02, 2.2410e-02, 1.9230e-02, 1.7663e-02,
        1.1873e-02, 1.0113e-02, 6.3086e-03, 3.3088e-03, 4.8945e-02, 8.5852e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.1530e-02, 0.0000e+00, 0.0000e+00, 4.7139e-02, 0.0000e+00,
        0.0000e+00, 8.0029e-02, 2.9945e-02, 2.6169e-02, 1.5874e-02, 8.1135e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.5135e-02, 0.0000e+00, 0.0000e+00, 2.4234e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7183e-02,
        0.0000e+00, 0.0000e+00, 8.4526e-02, 1.5874e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.4430e-02, 3.1749e-02, 0.0000e+00, 2.4436e-01, 3.2139e-02,
        2.4952e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6705e-02, 2.1682e-02, 1.2676e-02,
        3.2977e-02, 2.6930e-05, 0.0000e+00, 3.0148e-02, 0.0000e+00, 0.0000e+00,
        1.0726e-01, 2.5513e-02, 1.2474e-02, 5.5006e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3059e-01, 7.9283e-02, 4.5322e-02,
        3.2977e-02, 1.4665e-02, 0.0000e+00, 1.0789e-02, 2.1766e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 2.9573e-02, 2.8801e-02, 2.6481e-02, 2.5957e-02, 1.8296e-02,
        1.5415e-02, 1.0111e-02, 7.1158e-03, 0.0000e+00, 0.0000e+00, 3.7334e-02,
        1.8896e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7594e-02, 9.2336e-02,
        7.0983e-02, 3.7737e-02, 2.5344e-02, 1.6384e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.3193e-02, 2.2162e-02, 1.5727e-02, 4.9960e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5173e-01, 1.0612e-01,
        0.0000e+00, 5.8047e-02, 1.5874e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6187e-01, 8.8703e-02, 4.9405e-02, 1.8054e-02, 3.2139e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02, 2.9293e-02, 0.0000e+00,
        2.6077e-01, 6.1857e-02, 1.1977e-02, 6.5873e-02, 3.3084e-02, 9.8640e-03,
        6.1973e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.9223e-02, 2.5157e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8250e-02,
        3.2977e-02, 0.0000e+00, 3.4083e-02, 0.0000e+00, 5.7177e-02, 5.1706e-02,
        4.5764e-02, 6.5366e-03, 5.9717e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.3711e-02, 0.0000e+00, 0.0000e+00, 5.7354e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2977e-02, 0.0000e+00, 0.0000e+00, 6.9893e-02, 5.1806e-02, 4.5801e-02,
        4.2667e-02, 6.7477e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7878e-03, 3.1593e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2977e-02, 0.0000e+00, 0.0000e+00, 1.5263e-01, 5.0590e-02, 6.4814e-03,
        1.7940e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.6835e-02, 8.2544e-02, 3.1025e-02, 1.7714e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5821e-02, 1.6038e-02,
        0.0000e+00, 1.0564e-01, 5.0478e-02, 3.9607e-02, 3.8628e-02, 1.6732e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1593e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.2139e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 0.0000e+00, 0.0000e+00, 8.6653e-02, 6.8346e-02, 2.9505e-02,
        1.5927e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5265e-02, 3.0478e-02, 0.0000e+00, 3.2977e-02, 2.1721e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5532e-01, 3.2977e-02, 0.0000e+00,
        5.6669e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8113e-02, 6.6889e-03, 5.1742e-03,
        4.8662e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8347e-02,
        2.0195e-02, 0.0000e+00, 1.6576e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2969e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.9452e-02, 3.5608e-02, 0.0000e+00, 7.5449e-02,
        0.0000e+00, 3.2139e-02, 2.2623e-02, 8.3561e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 2.8153e-02, 2.5625e-02, 2.0107e-02, 7.5474e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0460e-01,
        4.0854e-02, 2.2087e-02, 9.7633e-02, 8.0277e-02, 2.2323e-02, 4.1932e-02,
        0.0000e+00, 0.0000e+00, 1.2808e-01, 5.8996e-02, 4.6594e-02, 3.5426e-02,
        2.0951e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9485e-02,
        2.1682e-02, 5.2306e-03, 1.8054e-02, 1.5668e-01, 3.2977e-02, 0.0000e+00,
        8.2908e-02, 5.5611e-02, 3.2977e-02, 3.2139e-02, 2.0924e-02, 1.6543e-02,
        1.4402e-02, 1.0119e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00, 1.0867e-01,
        3.0617e-02, 0.0000e+00, 8.8029e-02, 3.9534e-02, 0.0000e+00, 2.9320e-01,
        2.3020e-01, 7.5912e-02, 5.9916e-02, 5.7203e-02, 1.7033e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.9190e-02, 3.1749e-02, 0.0000e+00, 7.4345e-03,
        6.8862e-03, 2.0021e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.1039e-02, 3.2139e-02, 0.0000e+00, 3.2977e-02,
        4.7605e-03, 0.0000e+00, 2.1183e-02, 1.4903e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7512e-02,
        0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 1, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7,
        4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 4, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 7, 7, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 7, 7, 4]), 'best match labels': tensor([ 3.,  8.,  8., -1., -1., -1., -1.,  3.,  8.,  8.,  8.,  8.,  3.,  3.,
         8.,  8.,  8.,  3.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,  8.,  3.,  8.,  8.,  3.,
         5.,  5.,  5.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8., -1.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  3.,  3.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  5.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  3.,
         3.,  8.,  8.,  8.,  3.,  3.,  8.,  3.,  3.,  8.,  3.,  3.,  3.,  8.,
         3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8., -1.,
         8., -1., -1., -1., -1., -1.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,  8., -1.,  3.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  3.,  3.,  8.,  8.,  8.,  8., -1.,  8.,
         8.,  3.,  8.,  3.,  3.,  5.,  6.,  8.,  8.,  8.,  3.,  3.,  3.,  3.,
         8.,  8.,  8.,  8.,  8., -1., -1., -1.,  8., -1., -1.,  8.,  8.,  8.,
         3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         3.,  3.,  3.,  3.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8., -1.,  8.,  3.,  8.,  3.,  3.,  6.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  3.,  8.,  8.,  8.,  3.,  3.,  8.,  8.,  8.,  5.,  8.,  6.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  3.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  3.,  3.,  6.,  8.,  8.,  8.,
         8.,  3.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  6.,  6.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  3.,  6., -1., -1., -1., -1.,  8.,  3.,  3.,
         8.,  8., -1.,  8., -1., -1.,  3.,  3.,  3.,  3.,  3.,  8.,  8.,  8.,
         8.,  8.,  8.,  8., -1., -1.,  3.,  3.,  3.,  3.,  6.,  8.,  8.,  8.,
         8.,  8., -1.,  8.,  3.,  3.,  3.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8., -1.,  8.,  8., -1., -1.,  3.,  6.,  6.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  3.,  3.,  5.,  6.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8., -1.,  8., -1., -1., -1., -1.,  3.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  6.,  8.,
         8.,  8.,  8.,  8.,  3.,  8.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  5.,  8.,  6.,  3.,  8.,  8.,  3.,  8.,
         3.,  8.,  8.,  8., -1.,  8., -1., -1., -1., -1.,  3.,  3.,  3.,  3.,
         6., -1., -1.,  3.,  8.,  8.,  8.,  8.,  8.,  8., -1.,  3.,  3.,  3.,
         3.,  3.,  3.,  5.,  8.,  5.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  5.,  5.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  6.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  3.,  3.,  5.,  5.,  8.,  6.,  8.,  8.,
         8., -1.,  8., -1., -1.,  3.,  3.,  3.,  3.,  6.,  8.,  8.,  8.,  8.,
         8.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,
         8.,  8., -1.,  3.,  3.,  8.,  8.,  8., -1., -1.,  3.,  3.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,
         3.,  5.,  6.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  5.,  5.,
         5.,  5.,  8.,  5.,  6.,  8.,  8.,  3.,  5.,  6.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  3.,  8.,  8.,  3.,  3.,  3.,  3.,
         8.,  8.,  8.,  8.,  3.,  8.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  3.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  3.,  8.,  3.,  3.,  8.,  6.,  8.,  8.,  8.,  3.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8., -1., -1., -1.,  8.,  8.,  8.,
         8.,  8.,  8.,  8.]), 'best match scores': tensor([0.9714, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9887, 1.0000,
        0.9991, 0.0853, 1.0000, 0.2749, 0.9996, 1.0000, 0.2061, 0.4926, 1.0000,
        0.9986, 0.9998, 1.0000, 0.0547, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,
        1.0000, 1.0000, 0.1119, 0.9549, 0.4477, 1.0000, 0.8313, 0.8522, 1.0000,
        1.0000, 0.9994, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9975, 0.9801,
        1.0000, 0.1060, 0.9926, 0.6732, 1.0000, 0.9940, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.0823, 1.0000, 1.0000, 0.9999, 0.9893,
        1.0000, 0.0639, 0.9994, 0.9998, 0.0000, 1.0000, 0.7919, 0.9434, 0.9999,
        0.4162, 0.9975, 1.0000, 1.0000, 1.0000, 0.2568, 1.0000, 0.9995, 0.0926,
        1.0000, 0.1829, 1.0000, 1.0000, 0.0743, 0.1005, 1.0000, 1.0000, 0.7669,
        1.0000, 0.0515, 1.0000, 1.0000, 0.9997, 0.4805, 1.0000, 1.0000, 1.0000,
        1.0000, 0.9999, 1.0000, 1.0000, 0.0903, 0.9684, 1.0000, 0.0793, 1.0000,
        1.0000, 0.8065, 1.0000, 1.0000, 1.0000, 1.0000, 0.9675, 0.9919, 1.0000,
        1.0000, 0.5623, 0.2323, 1.0000, 0.9902, 1.0000, 1.0000, 0.3825, 0.9805,
        1.0000, 1.0000, 0.9996, 0.9880, 0.7893, 0.8500, 0.0564, 0.9999, 1.0000,
        1.0000, 1.0000, 1.0000, 0.0742, 0.9999, 0.9999, 0.3560, 0.0933, 1.0000,
        1.0000, 0.9996, 0.9999, 0.9999, 1.0000, 0.9765, 1.0000, 1.0000, 0.1997,
        0.3848, 0.9997, 0.9970, 0.3743, 0.9888, 0.6478, 1.0000, 0.9999, 1.0000,
        1.0000, 0.9992, 1.0000, 1.0000, 1.0000, 0.9997, 0.9997, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.4202, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.9957, 0.5173, 1.0000, 1.0000, 0.9576, 0.9832,
        1.0000, 1.0000, 1.0000, 0.9923, 0.9996, 0.9508, 0.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.9998, 0.9999, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 0.9998, 0.9999, 0.8698, 0.1095, 0.7563, 1.0000, 0.5279,
        0.0737, 0.1243, 0.0000, 0.9790, 0.0000, 0.2588, 1.0000, 1.0000, 0.9998,
        0.9999, 0.9996, 0.0708, 1.0000, 0.9495, 1.0000, 0.8744, 1.0000, 1.0000,
        1.0000, 0.9851, 0.0000, 1.0000, 0.9528, 0.9947, 0.9997, 1.0000, 1.0000,
        0.7747, 0.9998, 0.9412, 0.0651, 0.9861, 1.0000, 1.0000, 0.9967, 0.9886,
        1.0000, 0.0659, 0.1735, 0.7004, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000,
        0.0000, 0.0000, 0.7665, 1.0000, 1.0000, 0.9383, 1.0000, 0.9282, 0.9998,
        0.9999, 1.0000, 0.0617, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,
        0.9829, 0.9393, 1.0000, 0.9234, 0.9881, 1.0000, 0.5717, 0.2452, 0.9969,
        0.0839, 0.3268, 0.0789, 1.0000, 1.0000, 1.0000, 0.9951, 0.5315, 0.9333,
        0.7912, 1.0000, 1.0000, 0.9950, 0.9997, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9995,
        0.0000, 1.0000, 1.0000, 1.0000, 0.9739, 0.9998, 1.0000, 1.0000, 0.9995,
        0.0962, 0.5331, 0.9996, 1.0000, 1.0000, 1.0000, 0.9720, 0.1121, 1.0000,
        0.6065, 0.7708, 0.2586, 0.8516, 1.0000, 0.8841, 1.0000, 0.9997, 0.9994,
        0.9930, 1.0000, 0.3193, 0.1632, 1.0000, 0.9999, 0.2846, 0.9993, 1.0000,
        0.4190, 0.9993, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.5891, 1.0000, 1.0000, 0.9970, 0.9997, 0.3882, 1.0000, 1.0000, 0.9999,
        0.2338, 0.9511, 0.9996, 0.4991, 1.0000, 1.0000, 0.9893, 0.9997, 0.3005,
        1.0000, 1.0000, 0.2592, 1.0000, 1.0000, 0.3429, 1.0000, 1.0000, 0.0588,
        1.0000, 0.9995, 0.9998, 0.9938, 1.0000, 1.0000, 0.9981, 1.0000, 0.9981,
        0.9347, 1.0000, 0.5096, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000,
        1.0000, 0.1051, 0.9858, 0.0000, 1.0000, 0.0000, 0.0000, 0.9998, 1.0000,
        0.9973, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 0.9964, 1.0000,
        1.0000, 0.0000, 0.0000, 0.2151, 0.7200, 1.0000, 1.0000, 0.7409, 1.0000,
        0.9994, 1.0000, 0.9995, 1.0000, 0.0000, 1.0000, 0.8120, 0.0736, 0.9991,
        1.0000, 0.8037, 0.8240, 0.9264, 0.4435, 1.0000, 1.0000, 0.5003, 1.0000,
        1.0000, 1.0000, 0.9983, 1.0000, 0.9966, 1.0000, 0.9906, 0.9998, 1.0000,
        0.0983, 0.9897, 0.1976, 1.0000, 0.9568, 1.0000, 0.9026, 0.9982, 1.0000,
        1.0000, 1.0000, 1.0000, 0.9553, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 0.0594, 1.0000, 1.0000, 0.6647, 1.0000, 0.9998, 1.0000,
        1.0000, 1.0000, 1.0000, 0.6755, 0.9988, 0.0000, 1.0000, 0.9890, 0.0000,
        0.0000, 1.0000, 1.0000, 0.9997, 1.0000, 1.0000, 0.9992, 1.0000, 0.0712,
        1.0000, 0.3311, 1.0000, 1.0000, 0.6251, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.1015, 1.0000, 0.9998, 1.0000, 0.9866, 0.0700, 1.0000, 0.6990,
        1.0000, 0.9942, 0.0566, 1.0000, 0.9794, 0.1350, 0.9927, 1.0000, 1.0000,
        0.4916, 1.0000, 0.9998, 1.0000, 0.0869, 0.6690, 0.9995, 0.0000, 1.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.2174, 1.0000, 0.6681, 1.0000,
        1.0000, 1.0000, 0.9992, 0.9997, 1.0000, 1.0000, 1.0000, 1.0000, 0.9775,
        1.0000, 0.6166, 0.6109, 0.0758, 0.3557, 1.0000, 0.5676, 0.7651, 0.9999,
        0.0873, 1.0000, 0.9998, 1.0000, 0.1319, 1.0000, 1.0000, 0.6297, 0.9998,
        1.0000, 0.0643, 0.4721, 0.9257, 0.0712, 1.0000, 1.0000, 0.8975, 1.0000,
        0.9972, 0.9858, 1.0000, 1.0000, 0.0998, 1.0000, 1.0000, 0.0000, 1.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9995, 1.0000, 1.0000, 1.0000,
        0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9982, 0.1621,
        0.0000, 0.3076, 1.0000, 0.1947, 1.0000, 1.0000, 0.9436, 0.3825, 1.0000,
        0.9736, 0.7007, 1.0000, 1.0000, 1.0000, 1.0000, 0.3347, 0.9966, 0.9998,
        0.9996, 1.0000, 0.9936, 0.9951, 1.0000, 0.6989, 0.0609, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.9963, 1.0000, 0.4313, 1.0000, 0.9421, 0.3977,
        0.9895, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 1.0000, 0.9971, 0.9989,
        0.1224, 0.8629, 0.7843, 1.0000, 1.0000, 1.0000, 1.0000, 0.0554, 0.2128,
        0.5167, 0.2320, 0.9962, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000,
        0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9995, 0.1517,
        1.0000, 1.0000, 1.0000, 1.0000, 0.8466, 0.9853, 1.0000, 0.3943, 0.9938,
        1.0000, 1.0000, 0.6520, 0.9641, 1.0000, 1.0000, 1.0000, 1.0000, 0.7655,
        0.0000, 0.2612, 1.0000, 0.9887, 1.0000, 0.9579, 0.0000, 0.0000, 0.9642,
        0.8824, 0.9999, 0.9998, 1.0000, 0.8271, 1.0000, 0.9999, 1.0000, 1.0000,
        1.0000, 0.9694, 1.0000, 1.0000, 1.0000, 0.9991, 1.0000, 1.0000, 0.3670,
        0.1119, 0.8783, 0.9999, 1.0000, 1.0000, 1.0000, 0.9997, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.8858, 1.0000, 1.0000, 1.0000, 0.9997, 1.0000,
        1.0000, 1.0000, 0.9990, 0.9998, 0.0946, 0.6374, 1.0000, 0.9999, 0.1654,
        1.0000, 1.0000, 0.9995, 1.0000, 0.6794, 1.0000, 0.9973, 1.0000, 1.0000,
        0.9994, 0.9654, 0.8940, 0.8285, 1.0000, 1.0000, 0.9994, 0.9985, 1.0000,
        0.1115, 1.0000, 0.0714, 0.9910, 0.9268, 0.7597, 1.0000, 0.9998, 1.0000,
        0.9995, 1.0000, 1.0000, 1.0000, 0.1309, 1.0000, 0.9998, 1.0000, 1.0000,
        0.2920, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9888, 0.1015,
        0.3863, 0.0503, 1.0000, 0.9990, 0.9993, 1.0000, 0.9980, 1.0000, 1.0000,
        0.7763, 1.0000, 0.9999, 1.0000, 1.0000, 0.9175, 1.0000, 0.9973, 1.0000,
        0.8045, 1.0000, 1.0000, 1.0000, 0.1971, 0.0552, 0.9999, 0.9931, 0.3106,
        0.9999, 0.9999, 1.0000, 0.1870, 1.0000, 0.9989, 0.9983, 1.0000, 0.9258,
        1.0000, 1.0000, 0.4090, 1.0000, 0.7887, 0.1610, 1.0000, 0.9999, 1.0000,
        0.9992, 1.0000, 1.0000, 1.0000, 1.0000, 0.9909, 1.0000, 1.0000, 1.0000,
        0.9998, 1.0000, 0.9879, 0.9990, 0.9977, 1.0000, 0.7880, 0.0000, 0.0000,
        0.0000, 0.2690, 0.3227, 1.0000, 0.9265, 0.9980, 1.0000, 1.0000]), 'num_pos': 872}
2020-12-12 00:30:58,998 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-12 00:30:59,001 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-12 00:31:03,455 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-12 00:32:21,429 maskrcnn_benchmark.trainer INFO: eta: 2:16:32  iter: 120  loss: 20.6177 (22.4064)  loss_classifier: 5.2722 (6.9910)  loss_box_reg: 2.6054 (2.8507)  loss_objectness: 11.0403 (10.9723)  loss_rpn_box_reg: 1.5502 (1.5924)  time: 3.8707 (5.9366)  data: 0.2390 (2.3078)  lr: 0.000000  max mem: 1313
2020-12-12 00:33:38,732 maskrcnn_benchmark.trainer INFO: eta: 2:07:51  iter: 140  loss: 21.1094 (22.5248)  loss_classifier: 5.0842 (6.9977)  loss_box_reg: 3.2405 (2.9118)  loss_objectness: 10.9367 (11.0165)  loss_rpn_box_reg: 1.5571 (1.5988)  time: 3.8410 (5.6407)  data: 0.2378 (2.0128)  lr: 0.000000  max mem: 1313
2020-12-12 00:34:56,090 maskrcnn_benchmark.trainer INFO: eta: 2:01:01  iter: 160  loss: 19.6606 (22.1999)  loss_classifier: 5.0434 (6.8111)  loss_box_reg: 2.0054 (2.8360)  loss_objectness: 10.5270 (10.9847)  loss_rpn_box_reg: 1.3059 (1.5681)  time: 3.8360 (5.4191)  data: 0.2280 (1.7912)  lr: 0.000000  max mem: 1313
2020-12-12 00:36:14,248 maskrcnn_benchmark.trainer INFO: eta: 1:55:31  iter: 180  loss: 19.6598 (21.9683)  loss_classifier: 4.0922 (6.6396)  loss_box_reg: 2.1889 (2.8031)  loss_objectness: 10.8237 (10.9771)  loss_rpn_box_reg: 1.2212 (1.5485)  time: 3.8555 (5.2512)  data: 0.2382 (1.6197)  lr: 0.000000  max mem: 1313
2020-12-12 00:37:31,621 maskrcnn_benchmark.trainer INFO: eta: 1:50:46  iter: 200  loss: 20.4306 (22.0528)  loss_classifier: 5.2948 (6.7092)  loss_box_reg: 3.2334 (2.8103)  loss_objectness: 11.1287 (10.9763)  loss_rpn_box_reg: 1.5331 (1.5571)  time: 3.8374 (5.1129)  data: 0.2313 (1.4812)  lr: 0.000000  max mem: 1313
2020-12-12 00:37:31,623 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 00:37:31,714 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(148 images).
2020-12-12 00:40:00,587 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 00:40:00,587 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 00:40:00,587 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 00:40:06,627 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 00:40:06,628 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 00:40:06,628 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.0000005
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1500
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 00:40:06,632 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 5e-07
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1500
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 00:40:08,429 maskrcnn_benchmark INFO: reloading weigts from _best_acc_r3.pth
2020-12-12 00:40:13,853 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-12 00:40:13,854 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-12 00:40:13,854 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-12 00:40:13,854 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-12 00:40:14,041 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-12 00:40:38,141 maskrcnn_benchmark.trainer INFO: Start training
2020-12-12 00:41:55,180 maskrcnn_benchmark.trainer INFO: eta: 1:35:00  iter: 20  loss: 19.3092 (22.0197)  loss_classifier: 4.6186 (6.5205)  loss_box_reg: 3.0070 (3.0312)  loss_objectness: 11.0305 (10.9027)  loss_rpn_box_reg: 1.5287 (1.5653)  time: 3.8340 (3.8515)  data: 0.2344 (0.2431)  lr: 0.000000  max mem: 1313
2020-12-12 00:43:11,980 maskrcnn_benchmark.trainer INFO: eta: 1:33:34  iter: 40  loss: 20.9679 (21.5326)  loss_classifier: 5.4656 (6.2452)  loss_box_reg: 2.1787 (2.7521)  loss_objectness: 11.0661 (11.0395)  loss_rpn_box_reg: 1.5111 (1.4958)  time: 3.8344 (3.8458)  data: 0.2352 (0.2431)  lr: 0.000000  max mem: 1313
2020-12-12 00:44:29,195 maskrcnn_benchmark.trainer INFO: eta: 1:32:25  iter: 60  loss: 18.9217 (21.5933)  loss_classifier: 4.2787 (6.3385)  loss_box_reg: 1.5436 (2.5670)  loss_objectness: 11.1814 (11.1365)  loss_rpn_box_reg: 1.4451 (1.5513)  time: 3.8534 (3.8508)  data: 0.2401 (0.2460)  lr: 0.000000  max mem: 1313
2020-12-12 00:45:48,517 maskrcnn_benchmark.trainer INFO: eta: 1:31:49  iter: 80  loss: 17.9826 (21.3866)  loss_classifier: 4.0081 (6.2979)  loss_box_reg: 1.5295 (2.4170)  loss_objectness: 11.0148 (11.1533)  loss_rpn_box_reg: 1.3674 (1.5184)  time: 3.9490 (3.8796)  data: 0.2396 (0.2478)  lr: 0.000000  max mem: 1313
2020-12-12 00:47:08,245 maskrcnn_benchmark.trainer INFO: eta: 1:31:01  iter: 100  loss: 18.1089 (20.9558)  loss_classifier: 3.7372 (5.9556)  loss_box_reg: 1.9667 (2.3272)  loss_objectness: 10.9514 (11.1230)  loss_rpn_box_reg: 1.5680 (1.5500)  time: 3.9247 (3.9010)  data: 0.2475 (0.2511)  lr: 0.000000  max mem: 1313
2020-12-12 00:47:08,247 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 00:47:08,373 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 00:47:14,619 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.245246 (1.5613116025924683 s / img per device, on 1 devices)
2020-12-12 00:47:14,619 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.657527 (1.4143818616867065 s / img per device, on 1 devices)
2020-12-12 00:47:14,619 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 00:47:15,056 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 00:47:15,056 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0243, 0.0093, 0.0016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0156,
        0.0052, 0.0017, 0.0011, 0.0000, 0.0000, 0.0000, 0.0111, 0.0100, 0.0036,
        0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0222, 0.0188, 0.0150, 0.0037,
        0.0029, 0.0004, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([6., 8., 8., 8., 8., 3., 8., 8., 8., 8., 8., 8., 8., 3., 8., 8., 3., 8.,
        3., 8., 8., 8., 8., 3., 3., 8., 8., 8., 8., 8.]), 'best match scores': tensor([0.9960, 0.9959, 0.3900, 0.9367, 0.0851, 0.5716, 0.9738, 1.0000, 1.0000,
        1.0000, 0.0932, 0.9954, 0.1393, 0.3163, 1.0000, 0.9986, 0.9959, 0.9889,
        0.9999, 0.9692, 1.0000, 0.5089, 0.5189, 0.9421, 0.9842, 1.0000, 0.9820,
        0.9905, 0.9837, 0.9999]), 'num_pos': 30}
2020-12-12 00:47:15,098 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-12 00:47:15,101 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-12 00:47:19,615 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-12 00:48:38,784 maskrcnn_benchmark.trainer INFO: eta: 1:32:07  iter: 120  loss: 18.6731 (20.7943)  loss_classifier: 3.5874 (5.8121)  loss_box_reg: 2.0268 (2.2748)  loss_objectness: 11.2504 (11.1706)  loss_rpn_box_reg: 1.5429 (1.5368)  time: 3.8788 (4.0053)  data: 0.2399 (0.3447)  lr: 0.000000  max mem: 1313
2020-12-12 00:49:57,287 maskrcnn_benchmark.trainer INFO: eta: 1:30:31  iter: 140  loss: 18.5600 (20.5660)  loss_classifier: 3.7193 (5.6769)  loss_box_reg: 1.8674 (2.2126)  loss_objectness: 10.7419 (11.1196)  loss_rpn_box_reg: 1.6098 (1.5570)  time: 3.8454 (3.9938)  data: 0.2374 (0.3303)  lr: 0.000000  max mem: 1313
2020-12-12 00:51:16,551 maskrcnn_benchmark.trainer INFO: eta: 1:29:06  iter: 160  loss: 17.5951 (20.1557)  loss_classifier: 3.3185 (5.3823)  loss_box_reg: 1.6518 (2.1495)  loss_objectness: 10.9062 (11.0902)  loss_rpn_box_reg: 1.4222 (1.5336)  time: 3.8543 (3.9900)  data: 0.2460 (0.3202)  lr: 0.000000  max mem: 1313
2020-12-12 00:52:36,098 maskrcnn_benchmark.trainer INFO: eta: 1:27:44  iter: 180  loss: 18.7002 (20.1237)  loss_classifier: 4.2729 (5.3668)  loss_box_reg: 1.6412 (2.1255)  loss_objectness: 11.0596 (11.1051)  loss_rpn_box_reg: 1.3439 (1.5263)  time: 3.9885 (3.9886)  data: 0.2339 (0.3108)  lr: 0.000000  max mem: 1313
2020-12-12 00:53:53,786 maskrcnn_benchmark.trainer INFO: eta: 1:26:11  iter: 200  loss: 16.3486 (19.8694)  loss_classifier: 2.3818 (5.2019)  loss_box_reg: 1.2547 (2.0514)  loss_objectness: 11.2507 (11.1088)  loss_rpn_box_reg: 1.4500 (1.5072)  time: 3.8523 (3.9782)  data: 0.2339 (0.3039)  lr: 0.000000  max mem: 1313
2020-12-12 00:53:53,788 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 00:53:53,799 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 00:53:59,900 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.099821 (1.5249553322792053 s / img per device, on 1 devices)
2020-12-12 00:53:59,900 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.663780 (1.4159449338912964 s / img per device, on 1 devices)
2020-12-12 00:53:59,900 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 00:54:00,344 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 00:54:00,344 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0254, 0.0021, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0017,
        0.0016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0142, 0.0111, 0.0100,
        0.0049, 0.0015, 0.0015, 0.0000, 0.0000, 0.0033, 0.0019, 0.0015, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([3., 2., 8., 3., 3., 2., 3., 8., 8., 8., 8., 8., 2., 8., 8., 6., 3., 8.,
        3., 2., 2., 8., 2., 8., 8., 8., 8., 8., 2., 8.]), 'best match scores': tensor([1.0000, 1.0000, 0.4321, 1.0000, 0.9805, 0.9999, 1.0000, 0.9508, 1.0000,
        0.9966, 0.1672, 1.0000, 0.9916, 0.3366, 0.1652, 1.0000, 0.1953, 1.0000,
        0.9052, 0.9980, 0.7634, 0.4762, 0.1440, 0.1340, 0.0973, 0.9763, 1.0000,
        0.9293, 0.6352, 0.9995]), 'num_pos': 30}
2020-12-12 00:54:00,353 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-12 00:55:17,329 maskrcnn_benchmark.trainer INFO: eta: 1:25:15  iter: 220  loss: 16.9123 (19.6336)  loss_classifier: 2.8290 (5.0473)  loss_box_reg: 1.2429 (1.9848)  loss_objectness: 10.8018 (11.1012)  loss_rpn_box_reg: 1.4726 (1.5002)  time: 3.8495 (3.9963)  data: 0.2363 (0.3278)  lr: 0.000000  max mem: 1313
2020-12-12 00:56:34,313 maskrcnn_benchmark.trainer INFO: eta: 1:23:39  iter: 240  loss: 16.5972 (19.4641)  loss_classifier: 2.9046 (4.9290)  loss_box_reg: 1.1958 (1.9428)  loss_objectness: 10.8323 (11.0967)  loss_rpn_box_reg: 1.3421 (1.4956)  time: 3.8396 (3.9840)  data: 0.2361 (0.3203)  lr: 0.000000  max mem: 1313
2020-12-12 00:57:52,116 maskrcnn_benchmark.trainer INFO: eta: 1:22:11  iter: 260  loss: 17.8610 (19.4511)  loss_classifier: 3.3869 (4.9335)  loss_box_reg: 1.4305 (1.9024)  loss_objectness: 10.7824 (11.0883)  loss_rpn_box_reg: 1.8839 (1.5269)  time: 3.8768 (3.9768)  data: 0.2378 (0.3146)  lr: 0.000000  max mem: 1313
2020-12-12 00:59:09,099 maskrcnn_benchmark.trainer INFO: eta: 1:20:40  iter: 280  loss: 15.6312 (19.2991)  loss_classifier: 2.2280 (4.8472)  loss_box_reg: 1.1690 (1.8650)  loss_objectness: 10.7545 (11.0715)  loss_rpn_box_reg: 1.2338 (1.5153)  time: 3.8476 (3.9677)  data: 0.2387 (0.3093)  lr: 0.000000  max mem: 1313
2020-12-12 01:00:26,330 maskrcnn_benchmark.trainer INFO: eta: 1:19:12  iter: 300  loss: 15.8511 (19.1570)  loss_classifier: 2.7219 (4.7588)  loss_box_reg: 1.0873 (1.8198)  loss_objectness: 10.8433 (11.0571)  loss_rpn_box_reg: 1.5411 (1.5212)  time: 3.8581 (3.9606)  data: 0.2396 (0.3048)  lr: 0.000000  max mem: 1313
2020-12-12 01:00:26,332 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 01:00:26,343 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 01:00:32,428 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.085148 (1.5212870836257935 s / img per device, on 1 devices)
2020-12-12 01:00:32,428 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.665430 (1.4163574576377869 s / img per device, on 1 devices)
2020-12-12 01:00:32,429 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 01:00:32,856 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 01:00:32,856 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0109, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0129,
        0.0036, 0.0036, 0.0020, 0.0000, 0.0000, 0.0000, 0.0019, 0.0017, 0.0016,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0017, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([3., 3., 3., 4., 4., 2., 4., 8., 7., 6., 7., 8., 8., 8., 8., 2., 8., 2.,
        3., 2., 7., 4., 6., 3., 4., 6., 8., 8., 8., 8.]), 'best match scores': tensor([1.0000, 1.0000, 1.0000, 0.1012, 0.9597, 0.9980, 0.9954, 0.1152, 0.9587,
        1.0000, 0.9988, 0.9613, 1.0000, 1.0000, 0.2560, 0.7427, 0.9997, 0.2079,
        1.0000, 1.0000, 0.5963, 0.0863, 1.0000, 1.0000, 0.9786, 1.0000, 1.0000,
        0.9276, 1.0000, 0.9926]), 'num_pos': 30}
2020-12-12 01:00:32,866 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-12 01:01:50,100 maskrcnn_benchmark.trainer INFO: eta: 1:18:10  iter: 320  loss: 15.6974 (18.9560)  loss_classifier: 2.1268 (4.6080)  loss_box_reg: 1.0245 (1.7761)  loss_objectness: 10.9156 (11.0477)  loss_rpn_box_reg: 1.5186 (1.5241)  time: 3.8582 (3.9748)  data: 0.2463 (0.3217)  lr: 0.000000  max mem: 1313
2020-12-12 01:03:06,913 maskrcnn_benchmark.trainer INFO: eta: 1:16:41  iter: 340  loss: 16.3005 (18.8610)  loss_classifier: 2.1829 (4.5296)  loss_box_reg: 1.2752 (1.7488)  loss_objectness: 10.8563 (11.0498)  loss_rpn_box_reg: 1.6011 (1.5328)  time: 3.8379 (3.9670)  data: 0.2353 (0.3167)  lr: 0.000000  max mem: 1313
2020-12-12 01:04:23,928 maskrcnn_benchmark.trainer INFO: eta: 1:15:14  iter: 360  loss: 15.3159 (18.6887)  loss_classifier: 1.8387 (4.4053)  loss_box_reg: 0.9507 (1.7076)  loss_objectness: 10.7543 (11.0520)  loss_rpn_box_reg: 1.3797 (1.5237)  time: 3.8475 (3.9605)  data: 0.2391 (0.3124)  lr: 0.000000  max mem: 1313
2020-12-12 01:05:40,924 maskrcnn_benchmark.trainer INFO: eta: 1:13:49  iter: 380  loss: 15.8136 (18.5741)  loss_classifier: 1.8519 (4.3176)  loss_box_reg: 1.0873 (1.6817)  loss_objectness: 10.9177 (11.0576)  loss_rpn_box_reg: 1.2318 (1.5171)  time: 3.8489 (3.9547)  data: 0.2370 (0.3085)  lr: 0.000000  max mem: 1313
2020-12-12 01:06:58,444 maskrcnn_benchmark.trainer INFO: eta: 1:12:25  iter: 400  loss: 15.3212 (18.4561)  loss_classifier: 1.7404 (4.2163)  loss_box_reg: 1.0291 (1.6562)  loss_objectness: 11.2585 (11.0681)  loss_rpn_box_reg: 1.4312 (1.5155)  time: 3.8566 (3.9507)  data: 0.2356 (0.3051)  lr: 0.000000  max mem: 1313
2020-12-12 01:06:58,446 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 01:06:58,458 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 01:07:04,572 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.113830 (1.5284574031829834 s / img per device, on 1 devices)
2020-12-12 01:07:04,572 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.672853 (1.4182132482528687 s / img per device, on 1 devices)
2020-12-12 01:07:04,572 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 01:07:05,004 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 01:07:05,004 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0115, 0.0080, 0.0016, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0487,
        0.0098, 0.0037, 0.0016, 0.0000, 0.0000, 0.0000, 0.0199, 0.0019, 0.0016,
        0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0154, 0.0036, 0.0016, 0.0015,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([4., 7., 7., 7., 7., 2., 7., 2., 7., 7., 7., 8., 7., 2., 7., 7., 8., 2.,
        7., 7., 7., 7., 7., 8., 8., 7., 8., 8., 7., 7.]), 'best match scores': tensor([1.0000, 0.9146, 1.0000, 0.0617, 1.0000, 1.0000, 0.8092, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.2284, 1.0000, 0.1713, 0.9285, 0.2744,
        1.0000, 1.0000, 1.0000, 0.7095, 1.0000, 0.9989, 0.0761, 0.9984, 0.9989,
        0.2076, 1.0000, 1.0000]), 'num_pos': 30}
2020-12-12 01:07:05,013 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-12 01:08:21,824 maskrcnn_benchmark.trainer INFO: eta: 1:11:18  iter: 420  loss: 15.2760 (18.3618)  loss_classifier: 1.8121 (4.1427)  loss_box_reg: 1.0064 (1.6307)  loss_objectness: 11.1384 (11.0663)  loss_rpn_box_reg: 1.5777 (1.5221)  time: 3.8257 (3.9611)  data: 0.2316 (0.3174)  lr: 0.000000  max mem: 1313
2020-12-12 01:09:38,504 maskrcnn_benchmark.trainer INFO: eta: 1:09:52  iter: 440  loss: 15.2927 (18.2524)  loss_classifier: 1.7415 (4.0548)  loss_box_reg: 0.9178 (1.6082)  loss_objectness: 10.9339 (11.0657)  loss_rpn_box_reg: 1.4290 (1.5237)  time: 3.8354 (3.9554)  data: 0.2342 (0.3137)  lr: 0.000000  max mem: 1313
2020-12-12 01:10:55,066 maskrcnn_benchmark.trainer INFO: eta: 1:08:27  iter: 460  loss: 14.8740 (18.1104)  loss_classifier: 1.5743 (3.9698)  loss_box_reg: 0.8691 (1.5808)  loss_objectness: 10.5964 (11.0481)  loss_rpn_box_reg: 0.9785 (1.5116)  time: 3.8280 (3.9498)  data: 0.2289 (0.3103)  lr: 0.000000  max mem: 1313
2020-12-12 01:12:11,539 maskrcnn_benchmark.trainer INFO: eta: 1:07:03  iter: 480  loss: 14.2918 (17.9864)  loss_classifier: 1.2195 (3.8731)  loss_box_reg: 0.8355 (1.5546)  loss_objectness: 11.0387 (11.0539)  loss_rpn_box_reg: 1.2824 (1.5048)  time: 3.8179 (3.9446)  data: 0.2297 (0.3069)  lr: 0.000000  max mem: 1313
2020-12-12 01:13:28,090 maskrcnn_benchmark.trainer INFO: eta: 1:05:39  iter: 500  loss: 15.0090 (17.9063)  loss_classifier: 2.0543 (3.8121)  loss_box_reg: 1.0926 (1.5386)  loss_objectness: 10.7708 (11.0467)  loss_rpn_box_reg: 1.3546 (1.5088)  time: 3.8215 (3.9399)  data: 0.2349 (0.3040)  lr: 0.000000  max mem: 1313
2020-12-12 01:13:28,093 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 01:13:28,103 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 01:13:34,145 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.042410 (1.510602593421936 s / img per device, on 1 devices)
2020-12-12 01:13:34,146 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.627933 (1.4069831371307373 s / img per device, on 1 devices)
2020-12-12 01:13:34,146 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 01:13:34,566 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 01:13:34,566 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0117, 0.0036, 0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0208,
        0.0192, 0.0027, 0.0018, 0.0009, 0.0000, 0.0000, 0.0072, 0.0055, 0.0020,
        0.0017, 0.0015, 0.0000, 0.0000, 0.0000, 0.0221, 0.0170, 0.0075, 0.0037,
        0.0017, 0.0015, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 8., 7., 1., 7., 1., 7.,
        7., 7., 7., 7., 7., 1., 8., 7., 7., 7., 7., 7.]), 'best match scores': tensor([0.9738, 1.0000, 0.9861, 0.9980, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000,
        1.0000, 0.1520, 1.0000, 1.0000, 1.0000, 0.6563, 0.9974, 0.9573, 1.0000,
        1.0000, 1.0000, 0.3132, 1.0000, 1.0000, 0.8710, 0.5249, 0.9988, 0.2752,
        0.7703, 1.0000, 1.0000]), 'num_pos': 30}
2020-12-12 01:13:34,575 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.100000
2020-12-12 01:13:34,578 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-12 01:13:38,171 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-12 01:14:54,954 maskrcnn_benchmark.trainer INFO: eta: 1:04:36  iter: 520  loss: 15.2743 (17.8297)  loss_classifier: 1.6568 (3.7426)  loss_box_reg: 1.0369 (1.5237)  loss_objectness: 11.0153 (11.0511)  loss_rpn_box_reg: 1.4757 (1.5123)  time: 3.8280 (3.9554)  data: 0.2304 (0.3210)  lr: 0.000000  max mem: 1313
2020-12-12 01:16:11,704 maskrcnn_benchmark.trainer INFO: eta: 1:03:12  iter: 540  loss: 14.4696 (17.7252)  loss_classifier: 1.5394 (3.6668)  loss_box_reg: 0.9475 (1.5099)  loss_objectness: 10.6505 (11.0336)  loss_rpn_box_reg: 1.5109 (1.5150)  time: 3.8293 (3.9510)  data: 0.2339 (0.3179)  lr: 0.000000  max mem: 1313
2020-12-12 01:17:28,277 maskrcnn_benchmark.trainer INFO: eta: 1:01:49  iter: 560  loss: 15.1845 (17.6574)  loss_classifier: 1.6563 (3.6072)  loss_box_reg: 0.9791 (1.5005)  loss_objectness: 10.7290 (11.0314)  loss_rpn_box_reg: 1.4389 (1.5183)  time: 3.8276 (3.9467)  data: 0.2296 (0.3149)  lr: 0.000000  max mem: 1313
2020-12-12 01:18:44,654 maskrcnn_benchmark.trainer INFO: eta: 1:00:26  iter: 580  loss: 14.9690 (17.5782)  loss_classifier: 1.5232 (3.5397)  loss_box_reg: 1.0730 (1.4900)  loss_objectness: 11.0730 (11.0354)  loss_rpn_box_reg: 1.3060 (1.5131)  time: 3.8171 (3.9422)  data: 0.2280 (0.3119)  lr: 0.000000  max mem: 1313
2020-12-12 01:20:01,485 maskrcnn_benchmark.trainer INFO: eta: 0:59:05  iter: 600  loss: 14.8907 (17.4965)  loss_classifier: 1.5443 (3.4771)  loss_box_reg: 0.9848 (1.4750)  loss_objectness: 10.6791 (11.0304)  loss_rpn_box_reg: 1.4098 (1.5139)  time: 3.8406 (3.9389)  data: 0.2350 (0.3094)  lr: 0.000000  max mem: 1313
2020-12-12 01:20:01,487 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 01:20:01,498 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 01:20:07,579 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.080678 (1.52016943693161 s / img per device, on 1 devices)
2020-12-12 01:20:07,579 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.666487 (1.4166216254234314 s / img per device, on 1 devices)
2020-12-12 01:20:07,579 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 01:20:08,008 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 01:20:08,008 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0037, 0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0210,
        0.0097, 0.0039, 0.0027, 0.0024, 0.0000, 0.0000, 0.0267, 0.0198, 0.0020,
        0.0019, 0.0018, 0.0000, 0.0000, 0.0000, 0.0170, 0.0020, 0.0016, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([4., 4., 7., 7., 7., 7., 7., 7., 1., 7., 7., 7., 8., 7., 1., 7., 1., 2.,
        7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 1.]), 'best match scores': tensor([0.9809, 0.9987, 0.2769, 1.0000, 0.0814, 1.0000, 0.9991, 0.9941, 0.9998,
        1.0000, 0.9996, 1.0000, 0.9825, 0.9976, 0.8604, 0.0631, 0.9999, 0.4846,
        1.0000, 1.0000, 1.0000, 0.2262, 1.0000, 1.0000, 0.9713, 0.9329, 0.0938,
        1.0000, 0.9995, 0.9999]), 'num_pos': 30}
2020-12-12 01:20:08,017 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.133333
2020-12-12 01:20:08,019 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-12 01:20:12,035 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-12 01:21:28,900 maskrcnn_benchmark.trainer INFO: eta: 0:57:58  iter: 620  loss: 14.4559 (17.4115)  loss_classifier: 1.4447 (3.4152)  loss_box_reg: 0.9266 (1.4611)  loss_objectness: 10.3788 (11.0205)  loss_rpn_box_reg: 1.5105 (1.5147)  time: 3.8341 (3.9528)  data: 0.2304 (0.3241)  lr: 0.000000  max mem: 1313
2020-12-12 01:22:45,389 maskrcnn_benchmark.trainer INFO: eta: 0:56:35  iter: 640  loss: 15.0902 (17.3527)  loss_classifier: 1.6044 (3.3638)  loss_box_reg: 1.1018 (1.4518)  loss_objectness: 10.6448 (11.0196)  loss_rpn_box_reg: 1.4331 (1.5176)  time: 3.8238 (3.9488)  data: 0.2271 (0.3211)  lr: 0.000000  max mem: 1313
2020-12-12 01:24:01,964 maskrcnn_benchmark.trainer INFO: eta: 0:55:13  iter: 660  loss: 15.3158 (17.3008)  loss_classifier: 1.5064 (3.3139)  loss_box_reg: 0.8659 (1.4389)  loss_objectness: 11.2686 (11.0271)  loss_rpn_box_reg: 1.5002 (1.5209)  time: 3.8239 (3.9452)  data: 0.2305 (0.3184)  lr: 0.000000  max mem: 1313
2020-12-12 01:25:18,732 maskrcnn_benchmark.trainer INFO: eta: 0:53:52  iter: 680  loss: 15.5077 (17.2468)  loss_classifier: 1.6516 (3.2703)  loss_box_reg: 1.0718 (1.4305)  loss_objectness: 11.0173 (11.0214)  loss_rpn_box_reg: 1.5659 (1.5245)  time: 3.8351 (3.9420)  data: 0.2316 (0.3159)  lr: 0.000000  max mem: 1313
2020-12-12 01:26:35,435 maskrcnn_benchmark.trainer INFO: eta: 0:52:31  iter: 700  loss: 14.5688 (17.2021)  loss_classifier: 1.5768 (3.2308)  loss_box_reg: 0.9374 (1.4215)  loss_objectness: 10.6844 (11.0165)  loss_rpn_box_reg: 1.7105 (1.5333)  time: 3.8315 (3.9390)  data: 0.2296 (0.3135)  lr: 0.000000  max mem: 1313
2020-12-12 01:26:35,437 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 01:26:35,448 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 01:26:41,516 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.068174 (1.5170435905456543 s / img per device, on 1 devices)
2020-12-12 01:26:41,516 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.651357 (1.4128392338752747 s / img per device, on 1 devices)
2020-12-12 01:26:41,517 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 01:26:41,940 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 01:26:41,940 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0199, 0.0118, 0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0186,
        0.0092, 0.0034, 0.0027, 0.0016, 0.0000, 0.0000, 0.0270, 0.0203, 0.0083,
        0.0080, 0.0033, 0.0013, 0.0000, 0.0000, 0.0148, 0.0060, 0.0041, 0.0017,
        0.0015, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([4., 2., 7., 7., 7., 7., 7., 7., 7., 8., 7., 7., 7., 7., 1., 7., 2., 2.,
        7., 7., 7., 7., 7., 1., 7., 7., 7., 7., 7., 7.]), 'best match scores': tensor([0.9878, 0.9854, 0.8467, 1.0000, 0.1739, 1.0000, 0.9994, 0.9999, 1.0000,
        0.9077, 1.0000, 1.0000, 1.0000, 0.9955, 0.9963, 1.0000, 0.1650, 0.9761,
        1.0000, 1.0000, 0.9516, 0.2989, 1.0000, 0.9987, 0.9241, 0.9063, 0.9983,
        0.9477, 1.0000, 1.0000]), 'num_pos': 30}
2020-12-12 01:26:41,950 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.066667
2020-12-12 01:27:58,634 maskrcnn_benchmark.trainer INFO: eta: 0:51:17  iter: 720  loss: 14.8823 (17.1392)  loss_classifier: 1.4838 (3.1822)  loss_box_reg: 0.9844 (1.4087)  loss_objectness: 10.5435 (11.0109)  loss_rpn_box_reg: 1.5788 (1.5374)  time: 3.8306 (3.9451)  data: 0.2322 (0.3204)  lr: 0.000000  max mem: 1313
2020-12-12 01:29:15,258 maskrcnn_benchmark.trainer INFO: eta: 0:49:55  iter: 740  loss: 13.8851 (17.0720)  loss_classifier: 1.3097 (3.1330)  loss_box_reg: 0.6808 (1.3931)  loss_objectness: 11.0650 (11.0205)  loss_rpn_box_reg: 0.8467 (1.5254)  time: 3.8330 (3.9420)  data: 0.2333 (0.3179)  lr: 0.000000  max mem: 1313
2020-12-12 01:30:31,789 maskrcnn_benchmark.trainer INFO: eta: 0:48:34  iter: 760  loss: 15.5634 (17.0395)  loss_classifier: 1.5914 (3.0967)  loss_box_reg: 0.9764 (1.3860)  loss_objectness: 10.9107 (11.0239)  loss_rpn_box_reg: 1.5790 (1.5329)  time: 3.8212 (3.9390)  data: 0.2283 (0.3157)  lr: 0.000000  max mem: 1313
2020-12-12 01:31:48,422 maskrcnn_benchmark.trainer INFO: eta: 0:47:14  iter: 780  loss: 14.5965 (16.9938)  loss_classifier: 1.6193 (3.0605)  loss_box_reg: 0.8532 (1.3784)  loss_objectness: 10.8446 (11.0189)  loss_rpn_box_reg: 1.5668 (1.5360)  time: 3.8313 (3.9362)  data: 0.2311 (0.3135)  lr: 0.000000  max mem: 1313
2020-12-12 01:33:04,991 maskrcnn_benchmark.trainer INFO: eta: 0:45:53  iter: 800  loss: 15.2428 (16.9585)  loss_classifier: 1.3578 (3.0231)  loss_box_reg: 1.0698 (1.3708)  loss_objectness: 11.0060 (11.0257)  loss_rpn_box_reg: 1.5038 (1.5389)  time: 3.8278 (3.9336)  data: 0.2335 (0.3115)  lr: 0.000000  max mem: 1313
2020-12-12 01:33:04,993 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 01:33:05,004 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 01:33:11,050 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.045901 (1.5114752054214478 s / img per device, on 1 devices)
2020-12-12 01:33:11,050 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.630110 (1.407527506351471 s / img per device, on 1 devices)
2020-12-12 01:33:11,050 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 01:33:11,470 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 01:33:11,470 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0219, 0.0098, 0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0164,
        0.0082, 0.0046, 0.0024, 0.0018, 0.0000, 0.0000, 0.0249, 0.0212, 0.0061,
        0.0018, 0.0015, 0.0000, 0.0000, 0.0000, 0.0276, 0.0140, 0.0020, 0.0016,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([7., 2., 7., 7., 7., 7., 7., 7., 1., 7., 7., 7., 8., 7., 7., 7., 1., 2.,
        7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 1.]), 'best match scores': tensor([1.0000, 0.6294, 0.9999, 1.0000, 0.9978, 1.0000, 1.0000, 0.9021, 0.8855,
        1.0000, 1.0000, 1.0000, 0.4713, 1.0000, 0.9996, 1.0000, 0.7362, 0.2777,
        1.0000, 1.0000, 1.0000, 0.9827, 1.0000, 0.9996, 0.8746, 0.7363, 1.0000,
        0.9287, 1.0000, 0.9451]), 'num_pos': 30}
2020-12-12 01:33:11,479 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.100000
2020-12-12 01:34:27,915 maskrcnn_benchmark.trainer INFO: eta: 0:44:38  iter: 820  loss: 14.5542 (16.9019)  loss_classifier: 1.3020 (2.9863)  loss_box_reg: 0.8189 (1.3599)  loss_objectness: 10.5571 (11.0218)  loss_rpn_box_reg: 1.3710 (1.5338)  time: 3.8239 (3.9387)  data: 0.2279 (0.3174)  lr: 0.000000  max mem: 1313
2020-12-12 01:35:44,670 maskrcnn_benchmark.trainer INFO: eta: 0:43:17  iter: 840  loss: 14.7481 (16.8603)  loss_classifier: 1.3714 (2.9520)  loss_box_reg: 0.9529 (1.3522)  loss_objectness: 10.9287 (11.0189)  loss_rpn_box_reg: 1.5572 (1.5372)  time: 3.8231 (3.9363)  data: 0.2279 (0.3154)  lr: 0.000000  max mem: 1313
2020-12-12 01:37:01,122 maskrcnn_benchmark.trainer INFO: eta: 0:41:57  iter: 860  loss: 13.6453 (16.7911)  loss_classifier: 1.0913 (2.9124)  loss_box_reg: 0.6044 (1.3378)  loss_objectness: 10.6266 (11.0100)  loss_rpn_box_reg: 1.1983 (1.5308)  time: 3.8140 (3.9337)  data: 0.2291 (0.3134)  lr: 0.000000  max mem: 1313
2020-12-12 01:38:17,414 maskrcnn_benchmark.trainer INFO: eta: 0:40:37  iter: 880  loss: 15.0686 (16.7573)  loss_classifier: 1.4559 (2.8810)  loss_box_reg: 1.0178 (1.3314)  loss_objectness: 10.9852 (11.0125)  loss_rpn_box_reg: 1.5970 (1.5324)  time: 3.8184 (3.9310)  data: 0.2280 (0.3115)  lr: 0.000000  max mem: 1313
2020-12-12 01:39:33,853 maskrcnn_benchmark.trainer INFO: eta: 0:39:17  iter: 900  loss: 13.9000 (16.7094)  loss_classifier: 1.0776 (2.8469)  loss_box_reg: 0.7142 (1.3206)  loss_objectness: 10.7166 (11.0110)  loss_rpn_box_reg: 1.3915 (1.5309)  time: 3.8186 (3.9286)  data: 0.2282 (0.3098)  lr: 0.000000  max mem: 1313
2020-12-12 01:39:33,855 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 01:39:33,865 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 01:39:39,894 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.028230 (1.507057547569275 s / img per device, on 1 devices)
2020-12-12 01:39:39,894 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.623533 (1.4058833718299866 s / img per device, on 1 devices)
2020-12-12 01:39:39,894 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 01:39:40,304 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 01:39:40,305 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0190, 0.0038, 0.0018, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0205,
        0.0076, 0.0029, 0.0018, 0.0000, 0.0000, 0.0000, 0.0101, 0.0020, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0110, 0.0089, 0.0035, 0.0015,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([7., 2., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 4., 4., 7.,
        7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.]), 'best match scores': tensor([1.0000, 0.8532, 0.0793, 0.9994, 1.0000, 1.0000, 0.6898, 1.0000, 1.0000,
        0.9895, 1.0000, 1.0000, 1.0000, 0.9867, 1.0000, 0.7477, 0.1261, 1.0000,
        1.0000, 1.0000, 1.0000, 0.1104, 1.0000, 1.0000, 0.9999, 0.4956, 0.9711,
        0.6405, 0.0552, 1.0000]), 'num_pos': 30}
2020-12-12 01:39:40,313 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-12 01:40:56,852 maskrcnn_benchmark.trainer INFO: eta: 0:38:01  iter: 920  loss: 14.7816 (16.6712)  loss_classifier: 1.3432 (2.8141)  loss_box_reg: 0.8871 (1.3110)  loss_objectness: 11.2618 (11.0171)  loss_rpn_box_reg: 1.5311 (1.5290)  time: 3.8224 (3.9334)  data: 0.2308 (0.3152)  lr: 0.000000  max mem: 1313
2020-12-12 01:42:13,175 maskrcnn_benchmark.trainer INFO: eta: 0:36:41  iter: 940  loss: 15.5949 (16.6381)  loss_classifier: 1.5237 (2.7842)  loss_box_reg: 1.1246 (1.3044)  loss_objectness: 11.2557 (11.0248)  loss_rpn_box_reg: 1.2296 (1.5247)  time: 3.8170 (3.9309)  data: 0.2282 (0.3133)  lr: 0.000000  max mem: 1313
2020-12-12 01:43:29,595 maskrcnn_benchmark.trainer INFO: eta: 0:35:21  iter: 960  loss: 14.4416 (16.6025)  loss_classifier: 1.2524 (2.7557)  loss_box_reg: 0.6782 (1.2975)  loss_objectness: 11.0889 (11.0265)  loss_rpn_box_reg: 1.5353 (1.5228)  time: 3.8161 (3.9286)  data: 0.2289 (0.3115)  lr: 0.000000  max mem: 1313
2020-12-12 01:44:46,078 maskrcnn_benchmark.trainer INFO: eta: 0:34:01  iter: 980  loss: 14.6301 (16.5691)  loss_classifier: 1.2361 (2.7278)  loss_box_reg: 0.7974 (1.2899)  loss_objectness: 10.8922 (11.0260)  loss_rpn_box_reg: 1.4995 (1.5253)  time: 3.8283 (3.9265)  data: 0.2249 (0.3099)  lr: 0.000000  max mem: 1313
2020-12-12 01:46:02,420 maskrcnn_benchmark.trainer INFO: eta: 0:32:42  iter: 1000  loss: 14.6291 (16.5324)  loss_classifier: 1.2825 (2.6997)  loss_box_reg: 0.7819 (1.2809)  loss_objectness: 10.7968 (11.0261)  loss_rpn_box_reg: 1.5911 (1.5257)  time: 3.8088 (3.9243)  data: 0.2244 (0.3083)  lr: 0.000000  max mem: 1313
2020-12-12 01:46:02,422 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 01:46:02,432 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 01:46:08,493 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.043904 (1.5109760165214539 s / img per device, on 1 devices)
2020-12-12 01:46:08,493 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.636127 (1.4090316891670227 s / img per device, on 1 devices)
2020-12-12 01:46:08,493 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 01:46:08,906 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 01:46:08,906 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0155, 0.0044, 0.0016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0236,
        0.0186, 0.0091, 0.0080, 0.0048, 0.0027, 0.0000, 0.0245, 0.0133, 0.0085,
        0.0027, 0.0018, 0.0015, 0.0000, 0.0000, 0.0303, 0.0200, 0.0178, 0.0025,
        0.0017, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([4., 2., 7., 7., 7., 7., 7., 7., 4., 7., 7., 7., 8., 7., 1., 7., 1., 2.,
        7., 7., 7., 7., 7., 1., 7., 7., 7., 7., 7., 7.]), 'best match scores': tensor([0.9996, 0.9552, 1.0000, 1.0000, 1.0000, 1.0000, 0.9912, 1.0000, 0.3431,
        0.2168, 1.0000, 1.0000, 0.4533, 0.9988, 0.8470, 0.1794, 0.1881, 0.5497,
        1.0000, 1.0000, 1.0000, 0.6282, 1.0000, 0.8835, 0.0772, 0.2146, 0.9012,
        0.9891, 0.9959, 1.0000]), 'num_pos': 30}
2020-12-12 01:46:08,915 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.100000
2020-12-12 01:47:25,305 maskrcnn_benchmark.trainer INFO: eta: 0:31:25  iter: 1020  loss: 13.6580 (16.4852)  loss_classifier: 0.9959 (2.6689)  loss_box_reg: 0.6808 (1.2701)  loss_objectness: 11.2968 (11.0291)  loss_rpn_box_reg: 0.9159 (1.5171)  time: 3.8097 (3.9286)  data: 0.2285 (0.3132)  lr: 0.000000  max mem: 1313
2020-12-12 01:48:41,756 maskrcnn_benchmark.trainer INFO: eta: 0:30:06  iter: 1040  loss: 13.9752 (16.4456)  loss_classifier: 1.2183 (2.6401)  loss_box_reg: 0.7094 (1.2617)  loss_objectness: 10.9668 (11.0289)  loss_rpn_box_reg: 1.3239 (1.5149)  time: 3.8225 (3.9265)  data: 0.2254 (0.3115)  lr: 0.000000  max mem: 1313
2020-12-12 01:49:58,015 maskrcnn_benchmark.trainer INFO: eta: 0:28:46  iter: 1060  loss: 14.9530 (16.4276)  loss_classifier: 1.2767 (2.6194)  loss_box_reg: 0.9495 (1.2590)  loss_objectness: 11.3103 (11.0306)  loss_rpn_box_reg: 1.6067 (1.5187)  time: 3.8111 (3.9244)  data: 0.2268 (0.3099)  lr: 0.000000  max mem: 1313
2020-12-12 01:51:14,621 maskrcnn_benchmark.trainer INFO: eta: 0:27:27  iter: 1080  loss: 14.8140 (16.4069)  loss_classifier: 1.1690 (2.5963)  loss_box_reg: 0.8026 (1.2534)  loss_objectness: 11.3379 (11.0401)  loss_rpn_box_reg: 1.3741 (1.5171)  time: 3.8221 (3.9227)  data: 0.2267 (0.3085)  lr: 0.000000  max mem: 1313
2020-12-12 01:52:31,245 maskrcnn_benchmark.trainer INFO: eta: 0:26:08  iter: 1100  loss: 13.9490 (16.3672)  loss_classifier: 1.1567 (2.5704)  loss_box_reg: 0.7550 (1.2454)  loss_objectness: 10.5275 (11.0329)  loss_rpn_box_reg: 1.5858 (1.5185)  time: 3.8319 (3.9210)  data: 0.2262 (0.3071)  lr: 0.000000  max mem: 1313
2020-12-12 01:52:31,247 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 01:52:31,257 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 01:52:37,304 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.047296 (1.5118240714073181 s / img per device, on 1 devices)
2020-12-12 01:52:37,304 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.638813 (1.4097031950950623 s / img per device, on 1 devices)
2020-12-12 01:52:37,305 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 01:52:37,716 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 01:52:37,716 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0052,
        0.0032, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0258, 0.0079, 0.0017,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0125, 0.0043, 0.0019, 0.0012,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([4., 4., 4., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 2., 2.,
        7., 7., 7., 7., 7., 4., 7., 7., 7., 7., 7., 7.]), 'best match scores': tensor([0.2963, 0.4892, 0.9428, 1.0000, 0.9944, 1.0000, 1.0000, 0.9995, 0.1544,
        0.1127, 0.9999, 0.9534, 0.9999, 0.7776, 1.0000, 1.0000, 0.5935, 0.9979,
        1.0000, 0.9955, 1.0000, 1.0000, 0.9883, 1.0000, 0.9553, 0.9956, 0.5697,
        0.1183, 1.0000, 0.9997]), 'num_pos': 30}
2020-12-12 01:52:37,725 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-12 01:53:54,255 maskrcnn_benchmark.trainer INFO: eta: 0:24:51  iter: 1120  loss: 14.0150 (16.3302)  loss_classifier: 1.1246 (2.5467)  loss_box_reg: 0.7260 (1.2387)  loss_objectness: 10.3474 (11.0276)  loss_rpn_box_reg: 1.2486 (1.5171)  time: 3.8225 (3.9251)  data: 0.2272 (0.3116)  lr: 0.000000  max mem: 1313
2020-12-12 01:55:10,377 maskrcnn_benchmark.trainer INFO: eta: 0:23:32  iter: 1140  loss: 13.9195 (16.2947)  loss_classifier: 1.0383 (2.5225)  loss_box_reg: 0.6726 (1.2315)  loss_objectness: 10.9557 (11.0286)  loss_rpn_box_reg: 1.5008 (1.5121)  time: 3.8079 (3.9230)  data: 0.2257 (0.3101)  lr: 0.000000  max mem: 1313
2020-12-12 01:56:26,613 maskrcnn_benchmark.trainer INFO: eta: 0:22:13  iter: 1160  loss: 14.1805 (16.2678)  loss_classifier: 0.9556 (2.5002)  loss_box_reg: 0.7691 (1.2259)  loss_objectness: 10.7188 (11.0269)  loss_rpn_box_reg: 1.5894 (1.5148)  time: 3.8121 (3.9211)  data: 0.2266 (0.3087)  lr: 0.000000  max mem: 1313
2020-12-12 01:57:43,109 maskrcnn_benchmark.trainer INFO: eta: 0:20:54  iter: 1180  loss: 15.0371 (16.2489)  loss_classifier: 1.1422 (2.4807)  loss_box_reg: 0.8780 (1.2217)  loss_objectness: 10.9930 (11.0289)  loss_rpn_box_reg: 1.5941 (1.5176)  time: 3.8290 (3.9195)  data: 0.2255 (0.3073)  lr: 0.000000  max mem: 1313
2020-12-12 01:58:59,339 maskrcnn_benchmark.trainer INFO: eta: 0:19:35  iter: 1200  loss: 14.1599 (16.2136)  loss_classifier: 1.2135 (2.4581)  loss_box_reg: 0.9125 (1.2146)  loss_objectness: 10.9995 (11.0287)  loss_rpn_box_reg: 1.2295 (1.5122)  time: 3.8100 (3.9177)  data: 0.2279 (0.3060)  lr: 0.000000  max mem: 1313
2020-12-12 01:58:59,341 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 01:58:59,373 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 01:59:05,414 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.041109 (1.5102772116661072 s / img per device, on 1 devices)
2020-12-12 01:59:05,415 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.634889 (1.408722162246704 s / img per device, on 1 devices)
2020-12-12 01:59:05,415 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 01:59:05,824 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 01:59:05,825 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0320, 0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0206,
        0.0087, 0.0085, 0.0027, 0.0023, 0.0016, 0.0000, 0.0263, 0.0079, 0.0034,
        0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0271, 0.0041, 0.0017, 0.0015,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([4., 2., 7., 7., 7., 7., 7., 7., 4., 7., 7., 7., 7., 7., 1., 4., 2., 2.,
        7., 7., 7., 7., 7., 1., 7., 7., 7., 7., 7., 7.]), 'best match scores': tensor([0.9996, 0.9647, 1.0000, 1.0000, 1.0000, 1.0000, 0.1596, 1.0000, 0.9009,
        0.9875, 0.8416, 1.0000, 1.0000, 0.2677, 0.2298, 0.1442, 0.8730, 0.9997,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.2287, 0.1284, 0.2211, 0.5000,
        0.9041, 1.0000, 1.0000]), 'num_pos': 30}
2020-12-12 01:59:05,833 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.066667
2020-12-12 02:00:22,348 maskrcnn_benchmark.trainer INFO: eta: 0:18:18  iter: 1220  loss: 14.3365 (16.1913)  loss_classifier: 1.1759 (2.4381)  loss_box_reg: 0.7443 (1.2101)  loss_objectness: 10.9707 (11.0316)  loss_rpn_box_reg: 1.3373 (1.5116)  time: 3.8198 (3.9215)  data: 0.2286 (0.3101)  lr: 0.000000  max mem: 1313
2020-12-12 02:01:38,555 maskrcnn_benchmark.trainer INFO: eta: 0:16:59  iter: 1240  loss: 14.0782 (16.1593)  loss_classifier: 0.9461 (2.4150)  loss_box_reg: 0.7739 (1.2040)  loss_objectness: 10.9261 (11.0324)  loss_rpn_box_reg: 1.0187 (1.5079)  time: 3.8024 (3.9197)  data: 0.2278 (0.3089)  lr: 0.000000  max mem: 1313
2020-12-12 02:02:54,818 maskrcnn_benchmark.trainer INFO: eta: 0:15:40  iter: 1260  loss: 13.9797 (16.1291)  loss_classifier: 1.1546 (2.3961)  loss_box_reg: 0.8450 (1.1981)  loss_objectness: 10.6344 (11.0283)  loss_rpn_box_reg: 1.4233 (1.5066)  time: 3.8126 (3.9180)  data: 0.2268 (0.3076)  lr: 0.000000  max mem: 1313
2020-12-12 02:04:11,299 maskrcnn_benchmark.trainer INFO: eta: 0:14:21  iter: 1280  loss: 15.4372 (16.1179)  loss_classifier: 1.3342 (2.3802)  loss_box_reg: 0.9352 (1.1957)  loss_objectness: 11.1113 (11.0322)  loss_rpn_box_reg: 1.6425 (1.5099)  time: 3.8272 (3.9165)  data: 0.2237 (0.3064)  lr: 0.000000  max mem: 1313
2020-12-12 02:05:27,521 maskrcnn_benchmark.trainer INFO: eta: 0:13:02  iter: 1300  loss: 14.0959 (16.0900)  loss_classifier: 0.9962 (2.3621)  loss_box_reg: 0.6523 (1.1891)  loss_objectness: 10.7266 (11.0305)  loss_rpn_box_reg: 1.2488 (1.5083)  time: 3.8087 (3.9149)  data: 0.2294 (0.3052)  lr: 0.000000  max mem: 1313
2020-12-12 02:05:27,522 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 02:05:27,534 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 02:05:33,586 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.051820 (1.5129549503326416 s / img per device, on 1 devices)
2020-12-12 02:05:33,586 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.606411 (1.4016028046607971 s / img per device, on 1 devices)
2020-12-12 02:05:33,586 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 02:05:34,020 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 02:05:34,020 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0175,
        0.0093, 0.0068, 0.0039, 0.0023, 0.0017, 0.0000, 0.0040, 0.0017, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0116, 0.0107, 0.0037, 0.0017,
        0.0015, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([4., 4., 7., 7., 7., 7., 7., 7., 4., 7., 7., 1., 7., 7., 7., 2., 2., 7.,
        4., 7., 7., 7., 7., 1., 7., 7., 7., 7., 7., 7.]), 'best match scores': tensor([0.6674, 0.9668, 1.0000, 1.0000, 1.0000, 1.0000, 0.0872, 1.0000, 0.1558,
        0.8955, 1.0000, 0.0786, 1.0000, 0.0793, 1.0000, 1.0000, 1.0000, 1.0000,
        0.9940, 1.0000, 1.0000, 1.0000, 0.9998, 0.0642, 0.9989, 0.0599, 0.0679,
        0.9455, 0.9999, 1.0000]), 'num_pos': 30}
2020-12-12 02:05:34,028 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.066667
2020-12-12 02:06:50,347 maskrcnn_benchmark.trainer INFO: eta: 0:11:45  iter: 1320  loss: 14.8412 (16.0778)  loss_classifier: 1.1398 (2.3464)  loss_box_reg: 0.7136 (1.1869)  loss_objectness: 11.1323 (11.0338)  loss_rpn_box_reg: 1.6548 (1.5108)  time: 3.8090 (3.9183)  data: 0.2364 (0.3092)  lr: 0.000000  max mem: 1313
2020-12-12 02:08:06,502 maskrcnn_benchmark.trainer INFO: eta: 0:10:26  iter: 1340  loss: 14.6118 (16.0570)  loss_classifier: 1.0462 (2.3277)  loss_box_reg: 0.8590 (1.1838)  loss_objectness: 10.9452 (11.0338)  loss_rpn_box_reg: 1.3822 (1.5117)  time: 3.8063 (3.9167)  data: 0.2247 (0.3079)  lr: 0.000000  max mem: 1313
2020-12-12 02:09:22,740 maskrcnn_benchmark.trainer INFO: eta: 0:09:08  iter: 1360  loss: 13.9651 (16.0268)  loss_classifier: 0.9673 (2.3084)  loss_box_reg: 0.6220 (1.1766)  loss_objectness: 10.7729 (11.0324)  loss_rpn_box_reg: 1.4815 (1.5094)  time: 3.8009 (3.9151)  data: 0.2342 (0.3069)  lr: 0.000000  max mem: 1313
2020-12-12 02:10:38,865 maskrcnn_benchmark.trainer INFO: eta: 0:07:49  iter: 1380  loss: 13.8160 (16.0016)  loss_classifier: 1.0268 (2.2912)  loss_box_reg: 0.7354 (1.1719)  loss_objectness: 10.8195 (11.0291)  loss_rpn_box_reg: 1.5042 (1.5094)  time: 3.8045 (3.9136)  data: 0.2276 (0.3057)  lr: 0.000000  max mem: 1313
2020-12-12 02:11:55,323 maskrcnn_benchmark.trainer INFO: eta: 0:06:31  iter: 1400  loss: 14.3321 (15.9827)  loss_classifier: 1.0579 (2.2746)  loss_box_reg: 0.7889 (1.1681)  loss_objectness: 10.6072 (11.0273)  loss_rpn_box_reg: 1.6620 (1.5127)  time: 3.8219 (3.9123)  data: 0.2322 (0.3047)  lr: 0.000000  max mem: 1313
2020-12-12 02:11:55,325 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 02:11:55,335 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 02:12:01,387 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.051721 (1.512930154800415 s / img per device, on 1 devices)
2020-12-12 02:12:01,388 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.646808 (1.411702036857605 s / img per device, on 1 devices)
2020-12-12 02:12:01,388 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 02:12:01,803 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 02:12:01,803 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0109,
        0.0068, 0.0018, 0.0000, 0.0000, 0.0000, 0.0000, 0.0262, 0.0080, 0.0017,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0159, 0.0049, 0.0021, 0.0016,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([4., 7., 7., 7., 7., 7., 7., 7., 4., 7., 7., 7., 7., 7., 7., 7., 2., 2.,
        7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 1.]), 'best match scores': tensor([0.9254, 1.0000, 1.0000, 1.0000, 0.0850, 1.0000, 1.0000, 0.1670, 0.1296,
        0.9999, 0.8924, 0.8672, 0.9996, 0.6267, 1.0000, 1.0000, 0.7905, 0.9985,
        1.0000, 0.9996, 1.0000, 1.0000, 0.9739, 0.1021, 0.9993, 0.2736, 1.0000,
        0.9997, 0.2472, 0.9865]), 'num_pos': 30}
2020-12-12 02:12:01,811 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.033333
2020-12-12 02:13:18,484 maskrcnn_benchmark.trainer INFO: eta: 0:05:13  iter: 1420  loss: 13.6958 (15.9590)  loss_classifier: 1.0813 (2.2578)  loss_box_reg: 0.6573 (1.1626)  loss_objectness: 10.8132 (11.0263)  loss_rpn_box_reg: 1.4392 (1.5124)  time: 3.8263 (3.9157)  data: 0.2264 (0.3083)  lr: 0.000000  max mem: 1313
2020-12-12 02:14:34,977 maskrcnn_benchmark.trainer INFO: eta: 0:03:54  iter: 1440  loss: 14.1184 (15.9372)  loss_classifier: 1.0564 (2.2410)  loss_box_reg: 0.7004 (1.1572)  loss_objectness: 10.6817 (11.0283)  loss_rpn_box_reg: 1.2784 (1.5107)  time: 3.8128 (3.9145)  data: 0.2341 (0.3074)  lr: 0.000000  max mem: 1313
2020-12-12 02:15:50,881 maskrcnn_benchmark.trainer INFO: eta: 0:02:36  iter: 1460  loss: 13.8819 (15.9061)  loss_classifier: 0.8414 (2.2227)  loss_box_reg: 0.6177 (1.1506)  loss_objectness: 10.6266 (11.0267)  loss_rpn_box_reg: 0.9557 (1.5061)  time: 3.7931 (3.9128)  data: 0.2183 (0.3062)  lr: 0.000000  max mem: 1313
2020-12-12 02:17:06,985 maskrcnn_benchmark.trainer INFO: eta: 0:01:18  iter: 1480  loss: 14.1759 (15.8862)  loss_classifier: 0.8869 (2.2066)  loss_box_reg: 0.7571 (1.1457)  loss_objectness: 10.9290 (11.0274)  loss_rpn_box_reg: 1.4496 (1.5065)  time: 3.7943 (3.9114)  data: 0.2262 (0.3051)  lr: 0.000000  max mem: 1313
2020-12-12 02:18:23,316 maskrcnn_benchmark.trainer INFO: eta: 0:00:00  iter: 1500  loss: 13.9023 (15.8692)  loss_classifier: 1.1169 (2.1933)  loss_box_reg: 0.7999 (1.1421)  loss_objectness: 10.9096 (11.0265)  loss_rpn_box_reg: 1.6088 (1.5073)  time: 3.8130 (3.9101)  data: 0.2144 (0.3039)  lr: 0.000000  max mem: 1313
2020-12-12 02:18:23,318 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 02:18:23,329 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 02:18:29,367 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.038286 (1.5095714330673218 s / img per device, on 1 devices)
2020-12-12 02:18:29,368 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.630813 (1.4077033400535583 s / img per device, on 1 devices)
2020-12-12 02:18:29,368 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 02:18:29,782 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 02:18:29,783 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0213, 0.0039, 0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0410,
        0.0226, 0.0080, 0.0076, 0.0053, 0.0026, 0.0017, 0.0270, 0.0040, 0.0039,
        0.0016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0314, 0.0174, 0.0036, 0.0020,
        0.0015, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([7., 7., 7., 7., 7., 7., 7., 7., 4., 7., 7., 7., 7., 2., 7., 4., 7., 2.,
        7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 1.]), 'best match scores': tensor([1.0000, 1.0000, 0.5499, 1.0000, 0.3328, 1.0000, 0.9557, 1.0000, 0.8237,
        0.1975, 1.0000, 1.0000, 1.0000, 0.1487, 0.0927, 0.9999, 1.0000, 0.1085,
        0.2280, 1.0000, 1.0000, 1.0000, 1.0000, 0.0763, 0.5263, 0.0543, 1.0000,
        0.9979, 0.9999, 0.1142]), 'num_pos': 30}
2020-12-12 02:18:29,792 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.033333
2020-12-12 02:18:29,797 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./final_mode_r3.pth
2020-12-12 02:18:30,987 maskrcnn_benchmark.trainer INFO: final model, saving model to: final_mode_r3
2020-12-12 02:18:31,002 maskrcnn_benchmark.trainer INFO: Total training time: 1:37:52.853203 (3.9152 s / it)
2020-12-12 02:18:35,719 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_test dataset(258 images).
2020-12-12 02:25:10,651 maskrcnn_benchmark.inference INFO: Total run time: 0:06:34.931671 (1.5307429123294445 s / img per device, on 1 devices)
2020-12-12 02:25:10,651 maskrcnn_benchmark.inference INFO: Model inference time: 0:06:03.060626 (1.4072117269501205 s / img per device, on 1 devices)
2020-12-12 02:25:10,708 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 02:25:38,811 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 02:25:38,811 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1176, 0.0351, 0.0000,  ..., 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([7, 7, 4,  ..., 2, 2, 2]), 'best match labels': tensor([7., 7., 7.,  ..., 7., 7., 7.]), 'best match scores': tensor([0.9634, 1.0000, 0.9815,  ..., 1.0000, 1.0000, 0.7500]), 'num_pos': 1516}
2020-12-12 02:25:38,835 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_test dataset(7 images).
2020-12-12 02:25:49,537 maskrcnn_benchmark.inference INFO: Total run time: 0:00:10.701985 (1.5288550172533308 s / img per device, on 1 devices)
2020-12-12 02:25:49,538 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:09.883914 (1.4119877474648612 s / img per device, on 1 devices)
2020-12-12 02:25:49,539 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 02:25:50,293 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 02:25:50,293 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0315, 0.0143, 0.0110, 0.0251, 0.0206, 0.0089, 0.0220, 0.0152, 0.0252,
        0.0041, 0.0316, 0.0186, 0.0032, 0.0232, 0.0072, 0.0256, 0.0165, 0.0082]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([2., 7., 4., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.]), 'best match scores': tensor([0.1438, 1.0000, 0.0610, 0.9999, 0.9996, 1.0000, 1.0000, 0.5234, 1.0000,
        1.0000, 0.9989, 1.0000, 1.0000, 1.0000, 1.0000, 0.3274, 1.0000, 0.9999]), 'num_pos': 18}
2020-12-12 02:25:50,300 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_test dataset(3 images).
2020-12-12 02:25:54,914 maskrcnn_benchmark.inference INFO: Total run time: 0:00:04.613494 (1.5378313859303792 s / img per device, on 1 devices)
2020-12-12 02:25:54,914 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:04.247136 (1.4157118797302246 s / img per device, on 1 devices)
2020-12-12 02:25:54,915 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 02:25:55,232 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 02:25:55,232 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0266, 0.0080, 0.0035, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0059,
        0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0368, 0.0315,
        0.0179, 0.0114, 0.0091, 0.0048, 0.0037, 0.0018, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1]), 'best match labels': tensor([7., 7., 7., 7., 7., 2., 8., 8., 4., 7., 7., 7., 7., 7., 7., 8., 7., 7.,
        8., 7., 7., 4., 2., 2., 2.]), 'best match scores': tensor([1.0000, 0.0817, 1.0000, 0.9999, 1.0000, 0.5856, 0.8599, 0.1014, 0.9992,
        0.9819, 0.9957, 0.1610, 0.9838, 0.7062, 0.7542, 0.9422, 0.9812, 0.9427,
        1.0000, 0.9995, 0.9445, 0.1153, 1.0000, 0.9999, 1.0000]), 'num_pos': 25}
2020-12-12 08:39:51,251 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 08:39:51,252 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 08:39:51,252 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 08:39:58,909 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 08:39:58,910 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 08:39:58,910 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.0000003
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1000
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 08:39:58,914 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 3e-07
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 08:40:00,747 maskrcnn_benchmark INFO: reloading weigts from final_mode_r3.pth
2020-12-12 08:40:13,505 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-12 08:40:13,505 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-12 08:40:13,506 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-12 08:40:13,506 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-12 08:40:13,671 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-12 08:40:36,040 maskrcnn_benchmark.trainer INFO: Start training
2020-12-12 08:41:53,609 maskrcnn_benchmark.trainer INFO: eta: 1:03:19  iter: 20  loss: 14.2401 (14.8248)  loss_classifier: 1.1446 (1.1871)  loss_box_reg: 0.8757 (0.9807)  loss_objectness: 10.9286 (11.1075)  loss_rpn_box_reg: 1.5250 (1.5495)  time: 3.7751 (3.8769)  data: 0.2116 (0.2260)  lr: 0.000000  max mem: 1313
2020-12-12 08:43:09,233 maskrcnn_benchmark.trainer INFO: eta: 1:01:16  iter: 40  loss: 14.7996 (14.8229)  loss_classifier: 1.1770 (1.1600)  loss_box_reg: 0.7893 (0.9455)  loss_objectness: 10.9310 (11.0985)  loss_rpn_box_reg: 1.3951 (1.6189)  time: 3.7670 (3.8296)  data: 0.2097 (0.2236)  lr: 0.000000  max mem: 1313
2020-12-12 08:44:24,729 maskrcnn_benchmark.trainer INFO: eta: 0:59:42  iter: 60  loss: 14.6122 (14.8328)  loss_classifier: 1.1249 (1.1388)  loss_box_reg: 0.8676 (0.9407)  loss_objectness: 11.1674 (11.1203)  loss_rpn_box_reg: 1.4323 (1.6330)  time: 3.7690 (3.8113)  data: 0.2151 (0.2201)  lr: 0.000000  max mem: 1313
2020-12-12 08:45:40,145 maskrcnn_benchmark.trainer INFO: eta: 0:58:17  iter: 80  loss: 14.3140 (14.7690)  loss_classifier: 0.9259 (1.1201)  loss_box_reg: 0.6739 (0.9217)  loss_objectness: 11.2234 (11.1008)  loss_rpn_box_reg: 1.3840 (1.6264)  time: 3.7692 (3.8012)  data: 0.2104 (0.2180)  lr: 0.000000  max mem: 1313
2020-12-12 08:46:55,530 maskrcnn_benchmark.trainer INFO: eta: 0:56:55  iter: 100  loss: 14.1413 (14.6517)  loss_classifier: 0.9325 (1.1063)  loss_box_reg: 0.6967 (0.9021)  loss_objectness: 10.5964 (11.0584)  loss_rpn_box_reg: 1.5015 (1.5849)  time: 3.7670 (3.7948)  data: 0.2097 (0.2165)  lr: 0.000000  max mem: 1313
2020-12-12 08:46:55,532 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 08:46:55,577 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 08:47:01,589 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.011395 (1.5028486847877502 s / img per device, on 1 devices)
2020-12-12 08:47:01,589 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.608286 (1.4020715951919556 s / img per device, on 1 devices)
2020-12-12 08:47:01,589 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 08:47:02,049 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 08:47:02,049 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0114, 0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0294,
        0.0223, 0.0079, 0.0055, 0.0027, 0.0017, 0.0000, 0.0264, 0.0079, 0.0017,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0187, 0.0146, 0.0037, 0.0020,
        0.0015, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([7., 7., 7., 7., 7., 7., 7., 7., 4., 7., 7., 7., 7., 7., 1., 7., 2., 2.,
        7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 1.]), 'best match scores': tensor([1.0000, 1.0000, 1.0000, 0.2287, 1.0000, 1.0000, 0.1203, 0.9106, 0.7616,
        0.1157, 0.9999, 0.5242, 1.0000, 0.0606, 0.4487, 1.0000, 0.1325, 0.8772,
        0.1319, 1.0000, 1.0000, 0.9998, 1.0000, 0.1972, 0.3903, 1.0000, 0.8074,
        0.9958, 0.9996, 0.3245]), 'num_pos': 30}
2020-12-12 08:47:02,094 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.066667
2020-12-12 08:47:02,098 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-12 08:47:02,543 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-12 08:48:18,371 maskrcnn_benchmark.trainer INFO: eta: 0:56:30  iter: 120  loss: 14.7049 (14.6632)  loss_classifier: 0.9961 (1.1130)  loss_box_reg: 0.7759 (0.8997)  loss_objectness: 10.8208 (11.0590)  loss_rpn_box_reg: 1.6486 (1.5916)  time: 3.7899 (3.8527)  data: 0.2134 (0.2761)  lr: 0.000000  max mem: 1313
2020-12-12 08:49:33,831 maskrcnn_benchmark.trainer INFO: eta: 0:55:03  iter: 140  loss: 14.3884 (14.6571)  loss_classifier: 1.0079 (1.0987)  loss_box_reg: 0.7080 (0.8881)  loss_objectness: 10.8958 (11.0920)  loss_rpn_box_reg: 1.4754 (1.5783)  time: 3.7669 (3.8413)  data: 0.2111 (0.2669)  lr: 0.000000  max mem: 1313
2020-12-12 08:50:49,451 maskrcnn_benchmark.trainer INFO: eta: 0:53:40  iter: 160  loss: 15.0208 (14.6910)  loss_classifier: 0.9806 (1.0906)  loss_box_reg: 0.8477 (0.8909)  loss_objectness: 11.3452 (11.1367)  loss_rpn_box_reg: 1.5324 (1.5728)  time: 3.7727 (3.8338)  data: 0.2132 (0.2602)  lr: 0.000000  max mem: 1313
2020-12-12 08:52:05,032 maskrcnn_benchmark.trainer INFO: eta: 0:52:18  iter: 180  loss: 14.5431 (14.6882)  loss_classifier: 1.0094 (1.0990)  loss_box_reg: 0.8630 (0.8960)  loss_objectness: 11.0845 (11.1206)  loss_rpn_box_reg: 1.4157 (1.5726)  time: 3.7825 (3.8277)  data: 0.2139 (0.2549)  lr: 0.000000  max mem: 1313
2020-12-12 08:53:20,605 maskrcnn_benchmark.trainer INFO: eta: 0:50:58  iter: 200  loss: 13.7842 (14.6420)  loss_classifier: 0.9459 (1.0929)  loss_box_reg: 0.6420 (0.8930)  loss_objectness: 10.8271 (11.0911)  loss_rpn_box_reg: 1.0505 (1.5650)  time: 3.7746 (3.8228)  data: 0.2148 (0.2509)  lr: 0.000000  max mem: 1313
2020-12-12 08:53:20,607 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 08:53:20,617 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 08:53:26,611 maskrcnn_benchmark.inference INFO: Total run time: 0:00:05.994222 (1.498555600643158 s / img per device, on 1 devices)
2020-12-12 08:53:26,612 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.611142 (1.4027855396270752 s / img per device, on 1 devices)
2020-12-12 08:53:26,612 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 08:53:27,008 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 08:53:27,008 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0247, 0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0081,
        0.0061, 0.0027, 0.0017, 0.0004, 0.0000, 0.0000, 0.0265, 0.0079, 0.0020,
        0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0110, 0.0092, 0.0031, 0.0017,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([4., 4., 7., 7., 7., 7., 7., 7., 4., 7., 7., 7., 7., 7., 1., 4., 2., 2.,
        7., 7., 7., 7., 7., 4., 7., 7., 7., 7., 7., 7.]), 'best match scores': tensor([0.1645, 0.8035, 1.0000, 1.0000, 1.0000, 1.0000, 0.4868, 1.0000, 0.1976,
        0.0909, 0.9980, 1.0000, 1.0000, 0.9751, 0.0533, 0.9960, 0.0846, 0.7823,
        1.0000, 1.0000, 1.0000, 0.9993, 0.9922, 1.0000, 0.1306, 0.9993, 0.9992,
        0.9769, 0.1863, 0.9875]), 'num_pos': 30}
2020-12-12 08:53:27,017 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.033333
2020-12-12 08:54:42,882 maskrcnn_benchmark.trainer INFO: eta: 0:50:02  iter: 220  loss: 13.7050 (14.5592)  loss_classifier: 0.9559 (1.0792)  loss_box_reg: 0.6425 (0.8694)  loss_objectness: 11.0362 (11.0793)  loss_rpn_box_reg: 1.0653 (1.5313)  time: 3.7814 (3.8492)  data: 0.2161 (0.2768)  lr: 0.000000  max mem: 1313
2020-12-12 08:55:58,451 maskrcnn_benchmark.trainer INFO: eta: 0:48:40  iter: 240  loss: 13.6821 (14.5332)  loss_classifier: 0.9188 (1.0702)  loss_box_reg: 0.6010 (0.8543)  loss_objectness: 10.8001 (11.0769)  loss_rpn_box_reg: 1.5723 (1.5318)  time: 3.7705 (3.8433)  data: 0.2107 (0.2713)  lr: 0.000000  max mem: 1313
2020-12-12 08:57:13,876 maskrcnn_benchmark.trainer INFO: eta: 0:47:19  iter: 260  loss: 13.5181 (14.5204)  loss_classifier: 0.8338 (1.0651)  loss_box_reg: 0.6148 (0.8516)  loss_objectness: 10.7824 (11.0813)  loss_rpn_box_reg: 1.2838 (1.5225)  time: 3.7680 (3.8378)  data: 0.2134 (0.2667)  lr: 0.000000  max mem: 1313
2020-12-12 08:58:29,367 maskrcnn_benchmark.trainer INFO: eta: 0:45:59  iter: 280  loss: 14.4304 (14.5204)  loss_classifier: 0.9571 (1.0667)  loss_box_reg: 0.5660 (0.8509)  loss_objectness: 11.1179 (11.0850)  loss_rpn_box_reg: 1.3172 (1.5179)  time: 3.7687 (3.8333)  data: 0.2120 (0.2628)  lr: 0.000000  max mem: 1313
2020-12-12 08:59:44,893 maskrcnn_benchmark.trainer INFO: eta: 0:44:40  iter: 300  loss: 14.1276 (14.5257)  loss_classifier: 0.9401 (1.0694)  loss_box_reg: 0.6981 (0.8536)  loss_objectness: 11.2360 (11.0926)  loss_rpn_box_reg: 1.1293 (1.5101)  time: 3.7766 (3.8295)  data: 0.2120 (0.2595)  lr: 0.000000  max mem: 1313
2020-12-12 08:59:44,895 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 08:59:44,904 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 08:59:50,890 maskrcnn_benchmark.inference INFO: Total run time: 0:00:05.985446 (1.4963616132736206 s / img per device, on 1 devices)
2020-12-12 08:59:50,890 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.600857 (1.4002143740653992 s / img per device, on 1 devices)
2020-12-12 08:59:50,890 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 08:59:51,287 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 08:59:51,287 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0233, 0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0396,
        0.0224, 0.0106, 0.0078, 0.0048, 0.0023, 0.0017, 0.0259, 0.0079, 0.0017,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0129, 0.0123, 0.0037, 0.0020,
        0.0015, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([7., 2., 7., 7., 7., 7., 7., 7., 4., 7., 7., 1., 7., 2., 7., 7., 2., 2.,
        7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 1.]), 'best match scores': tensor([1.0000, 0.3763, 1.0000, 0.3474, 1.0000, 1.0000, 0.2445, 0.9785, 0.8605,
        0.2290, 0.9999, 0.7549, 1.0000, 0.8857, 0.1478, 1.0000, 0.1908, 0.8968,
        0.3011, 1.0000, 1.0000, 0.9998, 1.0000, 0.8758, 0.9999, 1.0000, 0.0838,
        0.9987, 0.9994, 0.6149]), 'num_pos': 30}
2020-12-12 08:59:51,295 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.066667
2020-12-12 09:01:06,821 maskrcnn_benchmark.trainer INFO: eta: 0:43:35  iter: 320  loss: 14.1436 (14.5002)  loss_classifier: 0.8085 (1.0607)  loss_box_reg: 0.7383 (0.8488)  loss_objectness: 11.0578 (11.0961)  loss_rpn_box_reg: 0.8459 (1.4947)  time: 3.7762 (3.8462)  data: 0.2124 (0.2766)  lr: 0.000000  max mem: 1313
2020-12-12 09:02:22,365 maskrcnn_benchmark.trainer INFO: eta: 0:42:15  iter: 340  loss: 14.4362 (14.4918)  loss_classifier: 0.9598 (1.0562)  loss_box_reg: 0.7346 (0.8472)  loss_objectness: 10.9931 (11.0866)  loss_rpn_box_reg: 1.5396 (1.5018)  time: 3.7687 (3.8421)  data: 0.2146 (0.2728)  lr: 0.000000  max mem: 1313
2020-12-12 09:03:37,831 maskrcnn_benchmark.trainer INFO: eta: 0:40:56  iter: 360  loss: 13.3092 (14.4491)  loss_classifier: 0.7995 (1.0452)  loss_box_reg: 0.5998 (0.8399)  loss_objectness: 10.3989 (11.0581)  loss_rpn_box_reg: 1.5911 (1.5058)  time: 3.7702 (3.8383)  data: 0.2105 (0.2695)  lr: 0.000000  max mem: 1313
2020-12-12 09:04:53,244 maskrcnn_benchmark.trainer INFO: eta: 0:39:37  iter: 380  loss: 13.2909 (14.4214)  loss_classifier: 0.7973 (1.0418)  loss_box_reg: 0.5075 (0.8333)  loss_objectness: 10.7867 (11.0497)  loss_rpn_box_reg: 1.2424 (1.4966)  time: 3.7719 (3.8347)  data: 0.2067 (0.2663)  lr: 0.000000  max mem: 1313
2020-12-12 09:06:08,787 maskrcnn_benchmark.trainer INFO: eta: 0:38:19  iter: 400  loss: 13.3312 (14.4137)  loss_classifier: 0.8426 (1.0362)  loss_box_reg: 0.7486 (0.8303)  loss_objectness: 11.0677 (11.0545)  loss_rpn_box_reg: 1.2419 (1.4927)  time: 3.7767 (3.8318)  data: 0.2134 (0.2637)  lr: 0.000000  max mem: 1313
2020-12-12 09:06:08,789 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 09:06:08,798 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 09:06:14,784 maskrcnn_benchmark.inference INFO: Total run time: 0:00:05.985246 (1.496311604976654 s / img per device, on 1 devices)
2020-12-12 09:06:14,784 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.596532 (1.3991329073905945 s / img per device, on 1 devices)
2020-12-12 09:06:14,784 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 09:06:15,174 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 09:06:15,174 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0210, 0.0018, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0284,
        0.0106, 0.0048, 0.0027, 0.0017, 0.0009, 0.0000, 0.0251, 0.0079, 0.0020,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0123, 0.0020, 0.0016, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([4., 2., 7., 7., 7., 7., 7., 7., 4., 7., 7., 7., 7., 2., 1., 7., 2., 2.,
        7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 1.]), 'best match scores': tensor([0.9595, 0.0814, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.7349, 0.8322,
        0.0504, 0.4077, 0.9074, 1.0000, 0.7801, 0.3494, 1.0000, 0.4492, 0.9757,
        0.0599, 0.9977, 1.0000, 0.9844, 1.0000, 0.9897, 0.9994, 0.2577, 0.1654,
        0.9646, 0.9949, 0.2010]), 'num_pos': 30}
2020-12-12 09:06:15,182 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.066667
2020-12-12 09:07:30,735 maskrcnn_benchmark.trainer INFO: eta: 0:37:09  iter: 420  loss: 14.1920 (14.4295)  loss_classifier: 1.0498 (1.0390)  loss_box_reg: 0.7295 (0.8347)  loss_objectness: 11.4263 (11.0632)  loss_rpn_box_reg: 1.5320 (1.4926)  time: 3.7784 (3.8445)  data: 0.2133 (0.2765)  lr: 0.000000  max mem: 1313
2020-12-12 09:08:46,254 maskrcnn_benchmark.trainer INFO: eta: 0:35:51  iter: 440  loss: 13.5934 (14.4105)  loss_classifier: 0.9221 (1.0344)  loss_box_reg: 0.6807 (0.8325)  loss_objectness: 10.8431 (11.0519)  loss_rpn_box_reg: 1.4924 (1.4918)  time: 3.7745 (3.8414)  data: 0.2108 (0.2736)  lr: 0.000000  max mem: 1313
2020-12-12 09:10:01,860 maskrcnn_benchmark.trainer INFO: eta: 0:34:32  iter: 460  loss: 13.9472 (14.4018)  loss_classifier: 1.0349 (1.0388)  loss_box_reg: 0.7447 (0.8334)  loss_objectness: 10.6579 (11.0393)  loss_rpn_box_reg: 1.4661 (1.4903)  time: 3.7779 (3.8387)  data: 0.2130 (0.2710)  lr: 0.000000  max mem: 1313
2020-12-12 09:11:20,869 maskrcnn_benchmark.trainer INFO: eta: 0:33:18  iter: 480  loss: 14.1403 (14.3943)  loss_classifier: 0.8382 (1.0359)  loss_box_reg: 0.7015 (0.8329)  loss_objectness: 11.1513 (11.0391)  loss_rpn_box_reg: 1.2964 (1.4865)  time: 3.8406 (3.8434)  data: 0.2244 (0.2704)  lr: 0.000000  max mem: 1313
2020-12-12 09:12:40,145 maskrcnn_benchmark.trainer INFO: eta: 0:32:04  iter: 500  loss: 14.8713 (14.4056)  loss_classifier: 0.9550 (1.0364)  loss_box_reg: 0.7945 (0.8323)  loss_objectness: 10.9046 (11.0460)  loss_rpn_box_reg: 1.4997 (1.4908)  time: 3.9651 (3.8482)  data: 0.2341 (0.2695)  lr: 0.000000  max mem: 1313
2020-12-12 09:12:40,147 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 09:12:40,158 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 09:12:46,622 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.463004 (1.6157509684562683 s / img per device, on 1 devices)
2020-12-12 09:12:46,622 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:06.038167 (1.5095417499542236 s / img per device, on 1 devices)
2020-12-12 09:12:46,622 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 09:12:47,052 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 09:12:47,052 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0032, 0.0018, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0138,
        0.0053, 0.0030, 0.0027, 0.0017, 0.0000, 0.0000, 0.0249, 0.0246, 0.0074,
        0.0021, 0.0020, 0.0000, 0.0000, 0.0000, 0.0080, 0.0078, 0.0037, 0.0020,
        0.0016, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([7., 4., 4., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 4., 1., 7., 7., 2.,
        7., 7., 7., 7., 2., 7., 7., 7., 7., 7., 7., 1.]), 'best match scores': tensor([1.0000, 0.7349, 0.9779, 1.0000, 0.9998, 1.0000, 1.0000, 0.7522, 0.9735,
        0.5808, 0.1739, 0.9992, 0.9998, 0.9386, 0.1517, 1.0000, 0.0511, 0.9959,
        0.9849, 1.0000, 1.0000, 0.9294, 0.8163, 0.2453, 0.9993, 0.9874, 0.9484,
        0.8303, 0.0941, 0.0696]), 'num_pos': 30}
2020-12-12 09:12:47,061 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.066667
2020-12-12 09:14:06,530 maskrcnn_benchmark.trainer INFO: eta: 0:30:55  iter: 520  loss: 14.4075 (14.4027)  loss_classifier: 0.8499 (1.0347)  loss_box_reg: 0.8427 (0.8357)  loss_objectness: 10.9379 (11.0438)  loss_rpn_box_reg: 1.4079 (1.4885)  time: 3.9417 (3.8663)  data: 0.2273 (0.2814)  lr: 0.000000  max mem: 1313
2020-12-12 09:15:24,779 maskrcnn_benchmark.trainer INFO: eta: 0:29:39  iter: 540  loss: 14.0087 (14.3971)  loss_classifier: 0.9512 (1.0319)  loss_box_reg: 0.7285 (0.8358)  loss_objectness: 10.7750 (11.0390)  loss_rpn_box_reg: 1.5249 (1.4905)  time: 3.8961 (3.8680)  data: 0.2215 (0.2794)  lr: 0.000000  max mem: 1313
2020-12-12 09:16:43,189 maskrcnn_benchmark.trainer INFO: eta: 0:28:22  iter: 560  loss: 13.8252 (14.3761)  loss_classifier: 0.8012 (1.0233)  loss_box_reg: 0.5999 (0.8289)  loss_objectness: 10.7280 (11.0331)  loss_rpn_box_reg: 1.5326 (1.4908)  time: 3.8651 (3.8699)  data: 0.2335 (0.2778)  lr: 0.000000  max mem: 1313
2020-12-12 09:18:01,369 maskrcnn_benchmark.trainer INFO: eta: 0:27:05  iter: 580  loss: 14.1407 (14.3693)  loss_classifier: 0.8860 (1.0237)  loss_box_reg: 0.7595 (0.8287)  loss_objectness: 10.7350 (11.0237)  loss_rpn_box_reg: 1.5176 (1.4933)  time: 3.8456 (3.8712)  data: 0.2200 (0.2760)  lr: 0.000000  max mem: 1313
2020-12-12 09:19:04,526 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 09:19:04,526 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 09:19:04,526 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 09:19:06,604 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 09:19:06,604 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 09:19:06,604 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.0000001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1000
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 09:19:06,605 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 1e-07
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 09:19:08,126 maskrcnn_benchmark INFO: reloading weigts from final_mode_r3.pth
2020-12-12 09:19:10,127 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-12 09:19:10,128 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-12 09:19:10,128 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-12 09:19:10,128 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-12 09:19:10,128 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-12 09:19:10,128 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-12 09:19:10,129 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-12 09:19:10,129 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-12 09:19:10,129 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-12 09:19:10,129 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-12 09:19:10,296 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-12 09:19:10,708 maskrcnn_benchmark.trainer INFO: Start training
2020-12-12 09:19:36,306 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 09:19:36,306 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 09:19:36,306 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 09:19:38,322 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 09:19:38,322 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 09:19:38,322 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.0000001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1000
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 09:19:38,323 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 1e-07
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 09:19:39,846 maskrcnn_benchmark INFO: reloading weigts from final_mode_r3.pth
2020-12-12 09:19:41,865 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-12 09:19:41,866 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-12 09:19:41,866 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-12 09:19:41,866 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-12 09:19:41,866 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-12 09:19:41,866 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-12 09:19:41,867 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-12 09:19:41,867 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-12 09:19:41,867 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-12 09:19:41,867 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-12 09:19:41,867 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-12 09:19:41,867 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-12 09:19:41,867 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-12 09:19:41,868 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-12 09:19:42,033 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-12 09:19:42,446 maskrcnn_benchmark.trainer INFO: Start training
2020-12-12 09:21:01,052 maskrcnn_benchmark.trainer INFO: eta: 1:04:11  iter: 20  loss: 12.9926 (13.2641)  loss_classifier: 0.9483 (0.9855)  loss_box_reg: 0.7534 (0.8987)  loss_objectness: 9.9918 (10.0084)  loss_rpn_box_reg: 1.1267 (1.3715)  time: 3.8596 (3.9302)  data: 0.2227 (0.2290)  lr: 0.000000  max mem: 1424
2020-12-12 09:22:20,312 maskrcnn_benchmark.trainer INFO: eta: 1:03:08  iter: 40  loss: 9.0167 (11.1822)  loss_classifier: 0.9834 (0.9915)  loss_box_reg: 0.6772 (0.8291)  loss_objectness: 5.6683 (8.0392)  loss_rpn_box_reg: 1.2971 (1.3224)  time: 3.8546 (3.9466)  data: 0.2289 (0.2360)  lr: 0.000000  max mem: 1424
2020-12-12 09:23:36,879 maskrcnn_benchmark.trainer INFO: eta: 1:01:12  iter: 60  loss: 4.7961 (9.2487)  loss_classifier: 0.6994 (0.9322)  loss_box_reg: 0.5326 (0.7564)  loss_objectness: 2.5162 (6.2174)  loss_rpn_box_reg: 1.2294 (1.3427)  time: 3.8300 (3.9072)  data: 0.2135 (0.2290)  lr: 0.000000  max mem: 1424
2020-12-12 09:24:53,589 maskrcnn_benchmark.trainer INFO: eta: 0:59:38  iter: 80  loss: 3.3292 (7.8508)  loss_classifier: 0.6506 (0.8900)  loss_box_reg: 0.5543 (0.7033)  loss_objectness: 0.7960 (4.9339)  loss_rpn_box_reg: 1.1213 (1.3236)  time: 3.8331 (3.8893)  data: 0.2121 (0.2246)  lr: 0.000000  max mem: 1424
2020-12-12 09:26:10,428 maskrcnn_benchmark.trainer INFO: eta: 0:58:11  iter: 100  loss: 3.0963 (7.0566)  loss_classifier: 0.8253 (0.8857)  loss_box_reg: 0.5415 (0.6907)  loss_objectness: 0.5596 (4.1303)  loss_rpn_box_reg: 1.3258 (1.3499)  time: 3.8442 (3.8798)  data: 0.2107 (0.2221)  lr: 0.000000  max mem: 1424
2020-12-12 09:26:10,430 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 09:26:10,440 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 09:26:16,531 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.090836 (1.5227090716362 s / img per device, on 1 devices)
2020-12-12 09:26:16,531 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.635654 (1.4089136123657227 s / img per device, on 1 devices)
2020-12-12 09:26:16,532 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 09:26:16,937 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 09:26:16,938 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0027, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0035,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0276, 0.0153, 0.0096,
        0.0084, 0.0000, 0.0000, 0.0000, 0.0000, 0.0067, 0.0017, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1., -1., -1., -1.,  7.,  2.,  4.,  4.,  4.,  4.,  4.,  4.,  7.,
         7.,  2.,  4.,  2.,  7.,  7.,  7.,  7.,  8.,  7.,  7.,  7.,  7.,  7.,
         7.,  7.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1500, 0.9685, 0.9976, 1.0000,
        1.0000, 1.0000, 0.3280, 0.1091, 1.0000, 0.4062, 0.2463, 0.1403, 0.9926,
        1.0000, 1.0000, 1.0000, 1.0000, 0.3184, 0.9097, 0.2024, 1.0000, 0.2975,
        0.4785, 0.6313, 0.9872]), 'num_pos': 30}
2020-12-12 09:26:16,946 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-12 09:26:16,949 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-12 09:26:21,174 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-12 09:27:38,019 maskrcnn_benchmark.trainer INFO: eta: 0:58:07  iter: 120  loss: 3.3851 (6.5097)  loss_classifier: 0.7229 (0.8719)  loss_box_reg: 0.5888 (0.6781)  loss_objectness: 0.8984 (3.6083)  loss_rpn_box_reg: 1.1846 (1.3515)  time: 3.8306 (3.9631)  data: 0.2115 (0.3104)  lr: 0.000000  max mem: 1424
2020-12-12 09:28:54,872 maskrcnn_benchmark.trainer INFO: eta: 0:56:33  iter: 140  loss: 2.9098 (6.0083)  loss_classifier: 0.6134 (0.8463)  loss_box_reg: 0.5346 (0.6548)  loss_objectness: 0.4515 (3.1951)  loss_rpn_box_reg: 0.9803 (1.3120)  time: 3.8434 (3.9459)  data: 0.2136 (0.2970)  lr: 0.000000  max mem: 1424
2020-12-12 09:30:11,541 maskrcnn_benchmark.trainer INFO: eta: 0:55:02  iter: 160  loss: 2.7362 (5.6337)  loss_classifier: 0.6822 (0.8311)  loss_box_reg: 0.5085 (0.6348)  loss_objectness: 0.6159 (2.8833)  loss_rpn_box_reg: 1.1032 (1.2845)  time: 3.8332 (3.9318)  data: 0.2054 (0.2856)  lr: 0.000000  max mem: 1424
2020-12-12 09:31:28,315 maskrcnn_benchmark.trainer INFO: eta: 0:53:35  iter: 180  loss: 2.6399 (5.3416)  loss_classifier: 0.7141 (0.8205)  loss_box_reg: 0.4874 (0.6227)  loss_objectness: 0.4605 (2.6354)  loss_rpn_box_reg: 1.0521 (1.2630)  time: 3.8398 (3.9215)  data: 0.2071 (0.2771)  lr: 0.000000  max mem: 1424
2020-12-12 09:32:45,238 maskrcnn_benchmark.trainer INFO: eta: 0:52:11  iter: 200  loss: 2.8690 (5.1148)  loss_classifier: 0.6956 (0.8127)  loss_box_reg: 0.4842 (0.6174)  loss_objectness: 0.3912 (2.4283)  loss_rpn_box_reg: 1.1535 (1.2563)  time: 3.8420 (3.9139)  data: 0.2149 (0.2710)  lr: 0.000000  max mem: 1424
2020-12-12 09:32:45,240 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 09:32:45,250 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 09:32:51,338 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.087191 (1.5217977166175842 s / img per device, on 1 devices)
2020-12-12 09:32:51,338 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.634450 (1.4086124300956726 s / img per device, on 1 devices)
2020-12-12 09:32:51,338 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 09:32:51,747 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 09:32:51,747 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0187, 0.0102, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0314,
        0.0138, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0017, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0276, 0.0245, 0.0026, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1.,  7., -1.,  7., -1.,  2.,  4.,  2.,  1.,  2.,  2.,  7.,  2.,
         4.,  2.,  2.,  4.,  7.,  7.,  7.,  7.,  7.,  7.,  4.,  7.,  1.,  7.,
         7.,  7.]), 'best match scores': tensor([0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.1415, 0.0594, 0.9992,
        0.3354, 0.9988, 1.0000, 1.0000, 0.9987, 0.9122, 0.9952, 0.9999, 1.0000,
        1.0000, 0.9997, 0.6190, 0.9912, 1.0000, 0.9995, 1.0000, 0.9991, 0.0733,
        0.5975, 0.0685, 0.7961]), 'num_pos': 30}
2020-12-12 09:32:51,755 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.066667
2020-12-12 09:32:51,758 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-12 09:32:56,071 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-12 09:34:13,188 maskrcnn_benchmark.trainer INFO: eta: 0:51:27  iter: 220  loss: 2.9950 (4.9402)  loss_classifier: 0.7688 (0.8117)  loss_box_reg: 0.5570 (0.6165)  loss_objectness: 0.5313 (2.2657)  loss_rpn_box_reg: 1.0920 (1.2463)  time: 3.8406 (3.9579)  data: 0.2122 (0.3160)  lr: 0.000000  max mem: 1424
2020-12-12 09:35:30,062 maskrcnn_benchmark.trainer INFO: eta: 0:50:00  iter: 240  loss: 2.7128 (4.7880)  loss_classifier: 0.6812 (0.8019)  loss_box_reg: 0.5869 (0.6131)  loss_objectness: 0.4093 (2.1295)  loss_rpn_box_reg: 1.1116 (1.2435)  time: 3.8386 (3.9484)  data: 0.2080 (0.3073)  lr: 0.000000  max mem: 1424
2020-12-12 09:36:47,234 maskrcnn_benchmark.trainer INFO: eta: 0:48:36  iter: 260  loss: 2.3151 (4.6255)  loss_classifier: 0.5784 (0.7903)  loss_box_reg: 0.4171 (0.6018)  loss_objectness: 0.3777 (2.0052)  loss_rpn_box_reg: 0.9792 (1.2282)  time: 3.8472 (3.9415)  data: 0.2093 (0.3001)  lr: 0.000000  max mem: 1424
2020-12-12 09:38:03,988 maskrcnn_benchmark.trainer INFO: eta: 0:47:12  iter: 280  loss: 2.5057 (4.4782)  loss_classifier: 0.6679 (0.7783)  loss_box_reg: 0.4740 (0.5933)  loss_objectness: 0.2724 (1.8922)  loss_rpn_box_reg: 1.0312 (1.2144)  time: 3.8363 (3.9341)  data: 0.2142 (0.2939)  lr: 0.000000  max mem: 1424
2020-12-12 09:39:20,674 maskrcnn_benchmark.trainer INFO: eta: 0:45:49  iter: 300  loss: 2.5817 (4.3750)  loss_classifier: 0.6229 (0.7698)  loss_box_reg: 0.4529 (0.5897)  loss_objectness: 0.4248 (1.8055)  loss_rpn_box_reg: 1.0670 (1.2100)  time: 3.8289 (3.9274)  data: 0.2100 (0.2883)  lr: 0.000000  max mem: 1424
2020-12-12 09:39:20,676 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 09:39:20,686 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 09:39:26,741 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.055443 (1.5138607621192932 s / img per device, on 1 devices)
2020-12-12 09:39:26,742 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.612315 (1.4030787348747253 s / img per device, on 1 devices)
2020-12-12 09:39:26,742 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 09:39:27,144 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 09:39:27,144 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0061,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0207, 0.0067, 0.0017,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0161, 0.0066, 0.0020, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1., -1.,  1.,  2.,  7.,  7.,  8., -1., -1., -1., -1., -1.,  7.,
         7.,  2.,  2.,  4.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  4.,  7.,  7.,
         8.,  7.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0666, 0.4307, 1.0000, 0.9213, 0.9689, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.4350, 0.9965, 0.9815,
        0.4716, 1.0000, 0.2309, 0.8431, 0.7966, 1.0000, 0.9960, 0.9688, 0.3113,
        1.0000, 0.1473, 0.9989]), 'num_pos': 30}
2020-12-12 09:39:27,152 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.033333
2020-12-12 09:40:43,921 maskrcnn_benchmark.trainer INFO: eta: 0:44:40  iter: 320  loss: 2.5707 (4.2795)  loss_classifier: 0.6296 (0.7635)  loss_box_reg: 0.5383 (0.5864)  loss_objectness: 0.4994 (1.7266)  loss_rpn_box_reg: 1.0666 (1.2030)  time: 3.8332 (3.9421)  data: 0.2073 (0.3036)  lr: 0.000000  max mem: 1424
2020-12-12 09:42:00,667 maskrcnn_benchmark.trainer INFO: eta: 0:43:17  iter: 340  loss: 2.4308 (4.2124)  loss_classifier: 0.5478 (0.7598)  loss_box_reg: 0.4549 (0.5862)  loss_objectness: 0.4414 (1.6610)  loss_rpn_box_reg: 1.1674 (1.2053)  time: 3.8376 (3.9359)  data: 0.2094 (0.2981)  lr: 0.000000  max mem: 1424
2020-12-12 09:43:17,408 maskrcnn_benchmark.trainer INFO: eta: 0:41:55  iter: 360  loss: 1.9791 (4.1000)  loss_classifier: 0.4645 (0.7492)  loss_box_reg: 0.3395 (0.5768)  loss_objectness: 0.3559 (1.5921)  loss_rpn_box_reg: 0.8309 (1.1820)  time: 3.8320 (3.9304)  data: 0.2122 (0.2934)  lr: 0.000000  max mem: 1424
2020-12-12 09:44:34,182 maskrcnn_benchmark.trainer INFO: eta: 0:40:33  iter: 380  loss: 2.4563 (4.0309)  loss_classifier: 0.5558 (0.7424)  loss_box_reg: 0.4464 (0.5735)  loss_objectness: 0.4416 (1.5359)  loss_rpn_box_reg: 1.1588 (1.1791)  time: 3.8384 (3.9256)  data: 0.2128 (0.2891)  lr: 0.000000  max mem: 1424
2020-12-12 09:45:51,361 maskrcnn_benchmark.trainer INFO: eta: 0:39:13  iter: 400  loss: 2.4201 (3.9746)  loss_classifier: 0.7073 (0.7404)  loss_box_reg: 0.5275 (0.5727)  loss_objectness: 0.3682 (1.4842)  loss_rpn_box_reg: 1.1261 (1.1773)  time: 3.8579 (3.9223)  data: 0.2153 (0.2855)  lr: 0.000000  max mem: 1424
2020-12-12 09:45:51,363 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 09:45:51,373 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 09:45:57,433 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.059893 (1.5149732828140259 s / img per device, on 1 devices)
2020-12-12 09:45:57,434 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.616218 (1.404054582118988 s / img per device, on 1 devices)
2020-12-12 09:45:57,434 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 09:45:57,842 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 09:45:57,842 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0269, 0.0040, 0.0016, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0099,
        0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0155, 0.0038, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0025, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([2., 7., 7., 4., 7., 2., 7., 1., 4., 7., 2., 7., 7., 7., 7., 2., 7., 7.,
        4., 7., 7., 8., 8., 7., 7., 7., 7., 7., 8., 1.]), 'best match scores': tensor([0.5672, 1.0000, 1.0000, 0.9984, 1.0000, 0.9788, 0.9999, 0.6874, 1.0000,
        0.7440, 0.8409, 0.9770, 0.9993, 0.9999, 0.9975, 0.6851, 0.1030, 0.1502,
        0.1331, 1.0000, 0.9999, 0.3576, 0.8520, 1.0000, 0.1787, 1.0000, 0.9665,
        0.9553, 0.0669, 0.9980]), 'num_pos': 30}
2020-12-12 09:45:57,850 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.066667
2020-12-12 09:47:15,232 maskrcnn_benchmark.trainer INFO: eta: 0:38:02  iter: 420  loss: 2.1817 (3.9100)  loss_classifier: 0.5040 (0.7324)  loss_box_reg: 0.4878 (0.5707)  loss_objectness: 0.3513 (1.4369)  loss_rpn_box_reg: 1.1120 (1.1699)  time: 3.8524 (3.9352)  data: 0.2123 (0.2977)  lr: 0.000000  max mem: 1424
2020-12-12 09:48:32,231 maskrcnn_benchmark.trainer INFO: eta: 0:36:41  iter: 440  loss: 2.2781 (3.8667)  loss_classifier: 0.5772 (0.7280)  loss_box_reg: 0.4153 (0.5705)  loss_objectness: 0.2983 (1.3962)  loss_rpn_box_reg: 1.0347 (1.1720)  time: 3.8482 (3.9313)  data: 0.2152 (0.2940)  lr: 0.000000  max mem: 1424
2020-12-12 09:49:49,127 maskrcnn_benchmark.trainer INFO: eta: 0:35:20  iter: 460  loss: 2.2768 (3.8139)  loss_classifier: 0.6229 (0.7229)  loss_box_reg: 0.6145 (0.5707)  loss_objectness: 0.2897 (1.3534)  loss_rpn_box_reg: 0.9666 (1.1669)  time: 3.8412 (3.9276)  data: 0.2122 (0.2905)  lr: 0.000000  max mem: 1424
2020-12-12 09:51:05,893 maskrcnn_benchmark.trainer INFO: eta: 0:34:00  iter: 480  loss: 2.7116 (3.7690)  loss_classifier: 0.5615 (0.7171)  loss_box_reg: 0.5215 (0.5697)  loss_objectness: 0.4635 (1.3184)  loss_rpn_box_reg: 0.9569 (1.1639)  time: 3.8366 (3.9238)  data: 0.2099 (0.2872)  lr: 0.000000  max mem: 1424
2020-12-12 09:52:22,621 maskrcnn_benchmark.trainer INFO: eta: 0:32:40  iter: 500  loss: 2.1630 (3.7128)  loss_classifier: 0.5042 (0.7110)  loss_box_reg: 0.4395 (0.5657)  loss_objectness: 0.3395 (1.2841)  loss_rpn_box_reg: 0.7779 (1.1520)  time: 3.8345 (3.9203)  data: 0.2079 (0.2842)  lr: 0.000000  max mem: 1424
2020-12-12 09:52:22,623 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 09:52:22,633 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 09:52:28,715 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.081277 (1.5203193426132202 s / img per device, on 1 devices)
2020-12-12 09:52:28,715 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.627300 (1.4068248867988586 s / img per device, on 1 devices)
2020-12-12 09:52:28,715 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 09:52:29,125 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 09:52:29,125 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0080,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0266, 0.0251, 0.0016,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0042, 0.0025, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1., -1., -1., -1.,  1.,  2.,  2.,  7.,  1.,  2.,  2.,  4.,  7.,
         7., -1.,  7.,  2., -1.,  7., -1.,  1.,  7.,  2.,  7.,  7.,  7.,  4.,
         7.,  1.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1308, 0.9724, 0.9998, 0.0823,
        1.0000, 0.1193, 0.5061, 0.9544, 0.0972, 0.6167, 0.0000, 0.5971, 1.0000,
        0.0000, 0.9918, 0.0000, 0.3402, 0.8508, 0.7328, 0.9994, 0.1724, 0.5453,
        0.9956, 0.0525, 0.1348]), 'num_pos': 30}
2020-12-12 09:52:29,133 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.133333
2020-12-12 09:52:29,136 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-12 09:52:33,326 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-12 09:53:50,249 maskrcnn_benchmark.trainer INFO: eta: 0:31:30  iter: 520  loss: 2.1361 (3.6646)  loss_classifier: 0.4973 (0.7032)  loss_box_reg: 0.4160 (0.5619)  loss_objectness: 0.2950 (1.2520)  loss_rpn_box_reg: 0.9540 (1.1475)  time: 3.8468 (3.9381)  data: 0.2148 (0.3022)  lr: 0.000000  max mem: 1424
2020-12-12 09:55:07,189 maskrcnn_benchmark.trainer INFO: eta: 0:30:09  iter: 540  loss: 2.9791 (3.6415)  loss_classifier: 0.6195 (0.7013)  loss_box_reg: 0.6008 (0.5631)  loss_objectness: 0.4852 (1.2266)  loss_rpn_box_reg: 1.2231 (1.1505)  time: 3.8456 (3.9347)  data: 0.2170 (0.2990)  lr: 0.000000  max mem: 1424
2020-12-12 09:56:24,082 maskrcnn_benchmark.trainer INFO: eta: 0:28:49  iter: 560  loss: 2.7425 (3.6115)  loss_classifier: 0.5895 (0.6987)  loss_box_reg: 0.5411 (0.5630)  loss_objectness: 0.5021 (1.2005)  loss_rpn_box_reg: 1.0409 (1.1493)  time: 3.8446 (3.9315)  data: 0.2134 (0.2960)  lr: 0.000000  max mem: 1424
2020-12-12 09:57:40,936 maskrcnn_benchmark.trainer INFO: eta: 0:27:29  iter: 580  loss: 2.9353 (3.5812)  loss_classifier: 0.5201 (0.6937)  loss_box_reg: 0.5412 (0.5627)  loss_objectness: 0.5423 (1.1776)  loss_rpn_box_reg: 1.1148 (1.1473)  time: 3.8431 (3.9284)  data: 0.2112 (0.2931)  lr: 0.000000  max mem: 1424
2020-12-12 09:58:57,783 maskrcnn_benchmark.trainer INFO: eta: 0:26:10  iter: 600  loss: 2.2870 (3.5360)  loss_classifier: 0.4486 (0.6878)  loss_box_reg: 0.4258 (0.5582)  loss_objectness: 0.2954 (1.1506)  loss_rpn_box_reg: 0.9867 (1.1393)  time: 3.8453 (3.9256)  data: 0.2155 (0.2905)  lr: 0.000000  max mem: 1424
2020-12-12 09:58:57,785 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 09:58:57,795 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 09:59:03,872 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.077093 (1.5192732214927673 s / img per device, on 1 devices)
2020-12-12 09:59:03,872 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.621300 (1.4053248763084412 s / img per device, on 1 devices)
2020-12-12 09:59:03,873 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 09:59:04,279 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 09:59:04,280 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0118, 0.0113, 0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0435,
        0.0240, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0072, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0023, 0.0018, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1.,  7.,  7., -1., -1.,  7.,  2.,  2., -1., -1.,  4.,  7.,  2.,  7.,
         7., -1., -1., -1., -1.,  7., -1.,  1.,  2.,  2.,  4.,  4.,  7.,  4.,
         7.,  1.]), 'best match scores': tensor([0.0000, 0.9883, 1.0000, 0.0000, 0.0000, 0.6953, 0.9848, 0.9988, 0.0000,
        0.0000, 0.1073, 0.9999, 0.9971, 0.9983, 0.9102, 0.0000, 0.0000, 0.0000,
        0.0000, 1.0000, 0.0000, 0.9999, 1.0000, 0.4651, 0.9979, 0.5664, 0.7843,
        0.3580, 0.9935, 0.1348]), 'num_pos': 30}
2020-12-12 09:59:04,288 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.066667
2020-12-12 10:00:21,125 maskrcnn_benchmark.trainer INFO: eta: 0:24:54  iter: 620  loss: 1.9095 (3.5001)  loss_classifier: 0.4737 (0.6818)  loss_box_reg: 0.3708 (0.5536)  loss_objectness: 0.3314 (1.1271)  loss_rpn_box_reg: 0.9576 (1.1376)  time: 3.8431 (3.9333)  data: 0.2128 (0.2985)  lr: 0.000000  max mem: 1424
2020-12-12 10:01:37,944 maskrcnn_benchmark.trainer INFO: eta: 0:23:34  iter: 640  loss: 1.9235 (3.4586)  loss_classifier: 0.4569 (0.6759)  loss_box_reg: 0.4724 (0.5504)  loss_objectness: 0.2943 (1.1040)  loss_rpn_box_reg: 0.8764 (1.1282)  time: 3.8365 (3.9305)  data: 0.2158 (0.2958)  lr: 0.000000  max mem: 1424
2020-12-12 10:02:55,156 maskrcnn_benchmark.trainer INFO: eta: 0:22:15  iter: 660  loss: 2.4447 (3.4353)  loss_classifier: 0.5160 (0.6722)  loss_box_reg: 0.4952 (0.5499)  loss_objectness: 0.3951 (1.0852)  loss_rpn_box_reg: 1.0765 (1.1281)  time: 3.8437 (3.9283)  data: 0.2127 (0.2933)  lr: 0.000000  max mem: 1424
2020-12-12 10:04:11,918 maskrcnn_benchmark.trainer INFO: eta: 0:20:56  iter: 680  loss: 2.3073 (3.4012)  loss_classifier: 0.4075 (0.6661)  loss_box_reg: 0.4977 (0.5478)  loss_objectness: 0.3487 (1.0652)  loss_rpn_box_reg: 0.9598 (1.1221)  time: 3.8398 (3.9257)  data: 0.2118 (0.2909)  lr: 0.000000  max mem: 1424
2020-12-12 10:05:28,659 maskrcnn_benchmark.trainer INFO: eta: 0:19:36  iter: 700  loss: 1.9608 (3.3753)  loss_classifier: 0.4657 (0.6623)  loss_box_reg: 0.4258 (0.5471)  loss_objectness: 0.2944 (1.0475)  loss_rpn_box_reg: 0.8250 (1.1184)  time: 3.8363 (3.9232)  data: 0.2077 (0.2885)  lr: 0.000000  max mem: 1424
2020-12-12 10:05:28,661 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 10:05:28,671 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 10:05:34,719 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.047689 (1.5119223594665527 s / img per device, on 1 devices)
2020-12-12 10:05:34,719 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.606246 (1.4015613794326782 s / img per device, on 1 devices)
2020-12-12 10:05:34,719 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 10:05:35,120 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 10:05:35,121 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0155, 0.0068, 0.0034, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0058, 0.0023, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0181, 0.0020, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1.,  7.,  7., -1., -1.,  2., -1.,  2.,  2.,  4.,  4.,  7.,  7.,  7.,
         7., -1., -1.,  7., -1.,  1.,  7.,  2.,  8.,  1.,  2.,  4.,  4.,  7.,
         8.,  7.]), 'best match scores': tensor([0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.8464, 0.0000, 0.1307, 1.0000,
        0.6352, 0.2953, 0.9999, 1.0000, 0.0666, 0.0510, 0.0000, 0.0000, 0.9998,
        0.0000, 0.8524, 0.3158, 1.0000, 0.9948, 0.8502, 0.0700, 0.9504, 0.9997,
        1.0000, 1.0000, 1.0000]), 'num_pos': 30}
2020-12-12 10:05:35,129 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.066667
2020-12-12 10:06:51,852 maskrcnn_benchmark.trainer INFO: eta: 0:18:20  iter: 720  loss: 2.1257 (3.3451)  loss_classifier: 0.4644 (0.6587)  loss_box_reg: 0.5281 (0.5465)  loss_objectness: 0.2326 (1.0275)  loss_rpn_box_reg: 0.8527 (1.1125)  time: 3.8334 (3.9297)  data: 0.2100 (0.2953)  lr: 0.000000  max mem: 1424
2020-12-12 10:08:08,645 maskrcnn_benchmark.trainer INFO: eta: 0:17:01  iter: 740  loss: 2.4645 (3.3299)  loss_classifier: 0.5076 (0.6553)  loss_box_reg: 0.6628 (0.5493)  loss_objectness: 0.3090 (1.0132)  loss_rpn_box_reg: 0.9862 (1.1120)  time: 3.8365 (3.9273)  data: 0.2083 (0.2930)  lr: 0.000000  max mem: 1424
2020-12-12 10:09:25,411 maskrcnn_benchmark.trainer INFO: eta: 0:15:41  iter: 760  loss: 2.1315 (3.3029)  loss_classifier: 0.4407 (0.6501)  loss_box_reg: 0.4566 (0.5471)  loss_objectness: 0.3416 (0.9965)  loss_rpn_box_reg: 0.9281 (1.1092)  time: 3.8373 (3.9250)  data: 0.2103 (0.2909)  lr: 0.000000  max mem: 1424
2020-12-12 10:10:42,083 maskrcnn_benchmark.trainer INFO: eta: 0:14:22  iter: 780  loss: 2.0322 (3.2752)  loss_classifier: 0.4415 (0.6460)  loss_box_reg: 0.4105 (0.5442)  loss_objectness: 0.2868 (0.9805)  loss_rpn_box_reg: 0.8647 (1.1045)  time: 3.8313 (3.9226)  data: 0.2109 (0.2888)  lr: 0.000000  max mem: 1424
2020-12-12 10:11:58,894 maskrcnn_benchmark.trainer INFO: eta: 0:13:04  iter: 800  loss: 2.3064 (3.2584)  loss_classifier: 0.5710 (0.6438)  loss_box_reg: 0.5534 (0.5448)  loss_objectness: 0.2856 (0.9670)  loss_rpn_box_reg: 0.9671 (1.1028)  time: 3.8389 (3.9206)  data: 0.2127 (0.2869)  lr: 0.000000  max mem: 1424
2020-12-12 10:11:58,896 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 10:11:58,906 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 10:12:05,026 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.119412 (1.5298530459403992 s / img per device, on 1 devices)
2020-12-12 10:12:05,026 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.660089 (1.415022373199463 s / img per device, on 1 devices)
2020-12-12 10:12:05,026 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 10:12:05,432 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 10:12:05,433 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0227, 0.0137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0021, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0059, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([ 1.,  1.,  7.,  7.,  2.,  2.,  7.,  7.,  2.,  2.,  2.,  4.,  7.,  7.,
         7., -1., -1., -1.,  1.,  4.,  2.,  4.,  4.,  4.,  4.,  4.,  7.,  7.,
         2.,  7.]), 'best match scores': tensor([0.0525, 0.2156, 1.0000, 0.9237, 1.0000, 0.0687, 0.5592, 0.9918, 0.8126,
        1.0000, 1.0000, 0.0764, 0.9808, 0.9876, 1.0000, 0.0000, 0.0000, 0.0000,
        0.9848, 0.9996, 0.2595, 0.9356, 0.9040, 0.9979, 0.9966, 0.1877, 1.0000,
        0.7372, 0.8765, 1.0000]), 'num_pos': 30}
2020-12-12 10:12:05,441 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.100000
2020-12-12 10:15:17,740 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 10:15:17,740 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 10:15:17,741 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 10:15:19,746 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 10:15:19,746 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 10:15:19,746 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.0000001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1000
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 10:15:19,747 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 1e-07
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 10:15:21,270 maskrcnn_benchmark INFO: reloading weigts from _best_acc_r3.pth
2020-12-12 10:15:23,307 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-12 10:15:23,307 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-12 10:15:23,308 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-12 10:15:23,308 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-12 10:15:23,308 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-12 10:15:23,308 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-12 10:15:23,473 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-12 10:15:23,887 maskrcnn_benchmark.trainer INFO: Start training
2020-12-12 10:16:39,904 maskrcnn_benchmark.trainer INFO: eta: 1:02:04  iter: 20  loss: 2.6538 (3.1244)  loss_classifier: 0.5357 (0.6462)  loss_box_reg: 0.4987 (0.5738)  loss_objectness: 0.5355 (0.6815)  loss_rpn_box_reg: 1.1166 (1.2230)  time: 3.7942 (3.8007)  data: 0.1999 (0.2054)  lr: 0.000000  max mem: 1318
2020-12-12 10:17:55,711 maskrcnn_benchmark.trainer INFO: eta: 1:00:43  iter: 40  loss: 2.2453 (2.8829)  loss_classifier: 0.6119 (0.6184)  loss_box_reg: 0.4654 (0.5459)  loss_objectness: 0.3308 (0.5586)  loss_rpn_box_reg: 1.0366 (1.1600)  time: 3.7911 (3.7955)  data: 0.2013 (0.2041)  lr: 0.000000  max mem: 1318
2020-12-12 10:19:11,628 maskrcnn_benchmark.trainer INFO: eta: 0:59:27  iter: 60  loss: 2.6063 (2.7904)  loss_classifier: 0.5862 (0.6070)  loss_box_reg: 0.5751 (0.5245)  loss_objectness: 0.3462 (0.5440)  loss_rpn_box_reg: 1.0280 (1.1149)  time: 3.7925 (3.7957)  data: 0.2029 (0.2046)  lr: 0.000000  max mem: 1318
2020-12-12 10:20:27,567 maskrcnn_benchmark.trainer INFO: eta: 0:58:12  iter: 80  loss: 2.3857 (2.7463)  loss_classifier: 0.6202 (0.6110)  loss_box_reg: 0.5501 (0.5333)  loss_objectness: 0.2569 (0.5036)  loss_rpn_box_reg: 1.0140 (1.0984)  time: 3.7944 (3.7960)  data: 0.2021 (0.2045)  lr: 0.000000  max mem: 1318
2020-12-12 10:21:43,514 maskrcnn_benchmark.trainer INFO: eta: 0:56:56  iter: 100  loss: 2.4261 (2.6997)  loss_classifier: 0.5436 (0.6022)  loss_box_reg: 0.5377 (0.5356)  loss_objectness: 0.4069 (0.4995)  loss_rpn_box_reg: 0.9234 (1.0624)  time: 3.7997 (3.7962)  data: 0.2048 (0.2044)  lr: 0.000000  max mem: 1318
2020-12-12 10:21:43,516 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 10:21:43,526 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 10:21:49,545 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.018748 (1.5046868920326233 s / img per device, on 1 devices)
2020-12-12 10:21:49,545 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.609077 (1.402269184589386 s / img per device, on 1 devices)
2020-12-12 10:21:49,546 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 10:21:49,951 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 10:21:49,951 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0211,
        0.0027, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0084, 0.0020, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1., -1.,  1.,  1.,  2.,  2.,  4.,  7.,  7.,
         7., -1., -1., -1., -1., -1.,  2.,  7.,  7.,  7.,  2.,  2.,  4.,  7.,
         7.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1157, 0.9977,
        0.9985, 1.0000, 0.9936, 0.3246, 0.2539, 0.8087, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.9639, 0.8993, 0.8007, 0.0526, 0.6732, 1.0000, 0.8638,
        0.7819, 1.0000, 1.0000]), 'num_pos': 30}
2020-12-12 10:21:49,959 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.066667
2020-12-12 10:21:49,962 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-12 10:21:53,623 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-12 10:23:09,635 maskrcnn_benchmark.trainer INFO: eta: 0:56:55  iter: 120  loss: 2.3526 (2.6927)  loss_classifier: 0.6641 (0.6065)  loss_box_reg: 0.5923 (0.5452)  loss_objectness: 0.2282 (0.4822)  loss_rpn_box_reg: 0.9902 (1.0588)  time: 3.7936 (3.8812)  data: 0.2023 (0.2895)  lr: 0.000000  max mem: 1318
2020-12-12 10:24:25,536 maskrcnn_benchmark.trainer INFO: eta: 0:55:27  iter: 140  loss: 2.2678 (2.6432)  loss_classifier: 0.6100 (0.6081)  loss_box_reg: 0.4558 (0.5360)  loss_objectness: 0.2566 (0.4618)  loss_rpn_box_reg: 0.9476 (1.0373)  time: 3.7929 (3.8689)  data: 0.1997 (0.2772)  lr: 0.000000  max mem: 1318
2020-12-12 10:25:46,739 maskrcnn_benchmark.trainer INFO: eta: 0:54:29  iter: 160  loss: 2.2535 (2.6021)  loss_classifier: 0.5102 (0.6010)  loss_box_reg: 0.4129 (0.5291)  loss_objectness: 0.3095 (0.4503)  loss_rpn_box_reg: 0.9722 (1.0217)  time: 4.1128 (3.8928)  data: 0.2213 (0.2744)  lr: 0.000000  max mem: 1318
2020-12-12 10:27:11,235 maskrcnn_benchmark.trainer INFO: eta: 0:53:42  iter: 180  loss: 2.4088 (2.5933)  loss_classifier: 0.5893 (0.6055)  loss_box_reg: 0.5076 (0.5287)  loss_objectness: 0.2585 (0.4439)  loss_rpn_box_reg: 1.0605 (1.0151)  time: 4.2698 (3.9297)  data: 0.2710 (0.2734)  lr: 0.000000  max mem: 1318
2020-12-12 10:28:35,126 maskrcnn_benchmark.trainer INFO: eta: 0:52:44  iter: 200  loss: 2.4469 (2.5788)  loss_classifier: 0.6067 (0.6008)  loss_box_reg: 0.5306 (0.5278)  loss_objectness: 0.2820 (0.4374)  loss_rpn_box_reg: 0.9815 (1.0127)  time: 4.2702 (3.9562)  data: 0.2644 (0.2723)  lr: 0.000000  max mem: 1318
2020-12-12 10:28:35,128 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 10:28:35,140 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 10:28:41,682 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.541908 (1.6354770064353943 s / img per device, on 1 devices)
2020-12-12 10:28:41,682 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:06.069304 (1.5173258781433105 s / img per device, on 1 devices)
2020-12-12 10:28:41,682 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 10:28:42,120 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 10:28:42,120 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0097, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0120, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1., -1., -1.,  7.,  1.,  2.,  7., -1., -1.,  2.,  2.,  2.,  7.,
         7., -1., -1., -1., -1.,  7., -1., -1.,  2., -1., -1., -1.,  2.,  4.,
         7.,  7.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.8865, 1.0000, 0.9998, 0.0000,
        0.0000, 1.0000, 0.1087, 1.0000, 0.1939, 0.9856, 0.0000, 0.0000, 0.0000,
        0.0000, 0.9939, 0.0000, 0.0000, 0.0744, 0.0000, 0.0000, 0.0000, 0.9800,
        0.0674, 0.9990, 0.9981]), 'num_pos': 30}
2020-12-12 10:28:42,129 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.033333
2020-12-12 10:30:00,652 maskrcnn_benchmark.trainer INFO: eta: 0:51:48  iter: 220  loss: 2.5187 (2.5886)  loss_classifier: 0.5222 (0.5983)  loss_box_reg: 0.5087 (0.5320)  loss_objectness: 0.3270 (0.4360)  loss_rpn_box_reg: 1.0833 (1.0223)  time: 3.8680 (3.9853)  data: 0.2244 (0.2999)  lr: 0.000000  max mem: 1318
2020-12-12 10:31:16,622 maskrcnn_benchmark.trainer INFO: eta: 0:50:16  iter: 240  loss: 2.7137 (2.5881)  loss_classifier: 0.4995 (0.5960)  loss_box_reg: 0.5605 (0.5343)  loss_objectness: 0.2813 (0.4337)  loss_rpn_box_reg: 0.9835 (1.0241)  time: 3.7953 (3.9697)  data: 0.2010 (0.2919)  lr: 0.000000  max mem: 1318
2020-12-12 10:32:32,612 maskrcnn_benchmark.trainer INFO: eta: 0:48:47  iter: 260  loss: 2.9755 (2.5986)  loss_classifier: 0.5112 (0.5933)  loss_box_reg: 0.5758 (0.5333)  loss_objectness: 0.2936 (0.4386)  loss_rpn_box_reg: 1.0159 (1.0334)  time: 3.7956 (3.9566)  data: 0.2041 (0.2852)  lr: 0.000000  max mem: 1318
2020-12-12 10:33:48,529 maskrcnn_benchmark.trainer INFO: eta: 0:47:20  iter: 280  loss: 2.1813 (2.5789)  loss_classifier: 0.5127 (0.5883)  loss_box_reg: 0.4208 (0.5262)  loss_objectness: 0.2422 (0.4372)  loss_rpn_box_reg: 0.9548 (1.0272)  time: 3.7949 (3.9451)  data: 0.2038 (0.2795)  lr: 0.000000  max mem: 1318
2020-12-12 10:35:04,459 maskrcnn_benchmark.trainer INFO: eta: 0:45:54  iter: 300  loss: 2.3962 (2.5708)  loss_classifier: 0.5019 (0.5849)  loss_box_reg: 0.5081 (0.5236)  loss_objectness: 0.4461 (0.4373)  loss_rpn_box_reg: 0.9451 (1.0250)  time: 3.7964 (3.9352)  data: 0.2025 (0.2744)  lr: 0.000000  max mem: 1318
2020-12-12 10:35:04,461 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 10:35:04,471 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 10:35:10,504 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.032866 (1.508216381072998 s / img per device, on 1 devices)
2020-12-12 10:35:10,504 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.618572 (1.4046430587768555 s / img per device, on 1 devices)
2020-12-12 10:35:10,505 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 10:35:10,914 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 10:35:10,914 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0249, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0087, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1.,  2.,  2.,  7.,  4.,  4., -1., -1., -1., -1., -1., -1., -1.,
         7.,  1.,  2.,  2.,  2.,  2.,  7.,  7.]), 'best match scores': tensor([0.0000, 0.0000, 1.0000, 1.0000, 0.0770, 0.1257, 0.2415, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8103, 0.1414, 0.0746, 0.5271,
        0.1510, 0.9999, 0.5633, 0.1052]), 'num_pos': 22}
2020-12-12 10:35:10,921 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.045455
2020-12-12 10:36:26,882 maskrcnn_benchmark.trainer INFO: eta: 0:44:43  iter: 320  loss: 2.1056 (2.5673)  loss_classifier: 0.5062 (0.5833)  loss_box_reg: 0.4817 (0.5217)  loss_objectness: 0.2914 (0.4387)  loss_rpn_box_reg: 0.9169 (1.0236)  time: 3.7978 (3.9469)  data: 0.2025 (0.2904)  lr: 0.000000  max mem: 1318
2020-12-12 10:37:42,762 maskrcnn_benchmark.trainer INFO: eta: 0:43:18  iter: 340  loss: 2.3154 (2.5643)  loss_classifier: 0.6077 (0.5823)  loss_box_reg: 0.4657 (0.5204)  loss_objectness: 0.3206 (0.4380)  loss_rpn_box_reg: 0.8176 (1.0235)  time: 3.7927 (3.9379)  data: 0.2009 (0.2852)  lr: 0.000000  max mem: 1318
2020-12-12 10:38:58,796 maskrcnn_benchmark.trainer INFO: eta: 0:41:55  iter: 360  loss: 2.5977 (2.5789)  loss_classifier: 0.5874 (0.5864)  loss_box_reg: 0.5485 (0.5250)  loss_objectness: 0.3660 (0.4394)  loss_rpn_box_reg: 1.0064 (1.0282)  time: 3.8015 (3.9303)  data: 0.2048 (0.2808)  lr: 0.000000  max mem: 1318
2020-12-12 10:40:14,801 maskrcnn_benchmark.trainer INFO: eta: 0:40:32  iter: 380  loss: 2.6523 (2.5880)  loss_classifier: 0.6515 (0.5894)  loss_box_reg: 0.6052 (0.5267)  loss_objectness: 0.3014 (0.4421)  loss_rpn_box_reg: 1.0470 (1.0297)  time: 3.8024 (3.9235)  data: 0.2072 (0.2769)  lr: 0.000000  max mem: 1318
2020-12-12 10:41:30,710 maskrcnn_benchmark.trainer INFO: eta: 0:39:10  iter: 400  loss: 2.3438 (2.5748)  loss_classifier: 0.4684 (0.5848)  loss_box_reg: 0.4844 (0.5247)  loss_objectness: 0.3458 (0.4410)  loss_rpn_box_reg: 0.9257 (1.0243)  time: 3.7959 (3.9171)  data: 0.2059 (0.2732)  lr: 0.000000  max mem: 1318
2020-12-12 10:41:30,712 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 10:41:30,722 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 10:41:36,757 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.035160 (1.5087899565696716 s / img per device, on 1 devices)
2020-12-12 10:41:36,757 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.622665 (1.4056662321090698 s / img per device, on 1 devices)
2020-12-12 10:41:36,758 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 10:41:37,163 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 10:41:37,163 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0241, 0.0028, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0095, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1., -1., -1.,  1.,  1.,  2.,  7., -1., -1., -1.,  1.,  2.,  4.,
         7., -1., -1.,  7., -1.,  7., -1., -1., -1., -1., -1.,  2.,  2.,  4.,
         7.,  1.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.9826, 0.8863, 0.6351, 0.3740, 0.0000,
        0.0000, 0.0000, 0.0847, 1.0000, 0.0974, 0.9769, 0.0000, 0.0000, 0.2516,
        0.0000, 0.3453, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3792, 0.0840,
        0.1533, 0.8992, 0.1277]), 'num_pos': 30}
2020-12-12 10:41:37,171 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.133333
2020-12-12 10:41:37,174 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-12 10:41:41,099 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-12 10:42:57,216 maskrcnn_benchmark.trainer INFO: eta: 0:38:03  iter: 420  loss: 2.1925 (2.5610)  loss_classifier: 0.5765 (0.5832)  loss_box_reg: 0.5253 (0.5222)  loss_objectness: 0.2870 (0.4382)  loss_rpn_box_reg: 0.8273 (1.0173)  time: 3.7928 (3.9365)  data: 0.2036 (0.2952)  lr: 0.000000  max mem: 1318
2020-12-12 10:44:13,301 maskrcnn_benchmark.trainer INFO: eta: 0:36:41  iter: 440  loss: 2.1569 (2.5538)  loss_classifier: 0.5089 (0.5844)  loss_box_reg: 0.4716 (0.5208)  loss_objectness: 0.2425 (0.4337)  loss_rpn_box_reg: 1.0109 (1.0150)  time: 3.8049 (3.9305)  data: 0.2045 (0.2913)  lr: 0.000000  max mem: 1318
2020-12-12 10:45:29,690 maskrcnn_benchmark.trainer INFO: eta: 0:35:19  iter: 460  loss: 2.5042 (2.5551)  loss_classifier: 0.5910 (0.5838)  loss_box_reg: 0.5316 (0.5225)  loss_objectness: 0.3073 (0.4334)  loss_rpn_box_reg: 0.9243 (1.0154)  time: 3.8053 (3.9257)  data: 0.2056 (0.2876)  lr: 0.000000  max mem: 1318
2020-12-12 10:46:45,670 maskrcnn_benchmark.trainer INFO: eta: 0:33:58  iter: 480  loss: 2.2997 (2.5606)  loss_classifier: 0.6558 (0.5857)  loss_box_reg: 0.5297 (0.5234)  loss_objectness: 0.4084 (0.4354)  loss_rpn_box_reg: 0.9333 (1.0161)  time: 3.8004 (3.9204)  data: 0.2023 (0.2841)  lr: 0.000000  max mem: 1318
2020-12-12 10:48:01,569 maskrcnn_benchmark.trainer INFO: eta: 0:32:37  iter: 500  loss: 2.5007 (2.5640)  loss_classifier: 0.5832 (0.5884)  loss_box_reg: 0.5134 (0.5256)  loss_objectness: 0.3149 (0.4344)  loss_rpn_box_reg: 0.9186 (1.0155)  time: 3.7955 (3.9154)  data: 0.2028 (0.2809)  lr: 0.000000  max mem: 1318
2020-12-12 10:48:01,571 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 10:48:01,582 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 10:48:07,583 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.001524 (1.5003811120986938 s / img per device, on 1 devices)
2020-12-12 10:48:07,584 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.604002 (1.4010006189346313 s / img per device, on 1 devices)
2020-12-12 10:48:07,584 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 10:48:07,983 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 10:48:07,983 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0018, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0270, 0.0053, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1., -1., -1., -1.,  7.,  2.,  7., -1., -1., -1.,  1.,  2.,  2.,
         7., -1., -1., -1.,  2.,  2.,  7.,  7.,  7.,  7.,  2.,  2.,  4.,  4.,
         7.,  7.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5859, 0.9941, 0.9436, 0.0000,
        0.0000, 0.0000, 0.9887, 0.9999, 0.4791, 0.1641, 0.0000, 0.0000, 0.0000,
        1.0000, 0.0695, 0.1949, 0.9798, 0.1083, 0.5554, 0.7072, 0.1879, 0.9906,
        0.9778, 0.6662, 0.8156]), 'num_pos': 30}
2020-12-12 10:48:07,991 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.033333
2020-12-12 10:49:23,883 maskrcnn_benchmark.trainer INFO: eta: 0:31:23  iter: 520  loss: 2.4654 (2.5622)  loss_classifier: 0.6307 (0.5905)  loss_box_reg: 0.5453 (0.5273)  loss_objectness: 0.2464 (0.4321)  loss_rpn_box_reg: 0.7901 (1.0123)  time: 3.7878 (3.9231)  data: 0.2039 (0.2903)  lr: 0.000000  max mem: 1318
2020-12-12 10:50:39,639 maskrcnn_benchmark.trainer INFO: eta: 0:30:02  iter: 540  loss: 2.3494 (2.5569)  loss_classifier: 0.4774 (0.5884)  loss_box_reg: 0.4739 (0.5256)  loss_objectness: 0.3201 (0.4322)  loss_rpn_box_reg: 0.9650 (1.0107)  time: 3.7876 (3.9181)  data: 0.1989 (0.2869)  lr: 0.000000  max mem: 1318
2020-12-12 10:51:55,472 maskrcnn_benchmark.trainer INFO: eta: 0:28:41  iter: 560  loss: 2.5838 (2.5624)  loss_classifier: 0.6005 (0.5898)  loss_box_reg: 0.5114 (0.5276)  loss_objectness: 0.3594 (0.4316)  loss_rpn_box_reg: 1.0525 (1.0135)  time: 3.7934 (3.9135)  data: 0.2004 (0.2839)  lr: 0.000000  max mem: 1318
2020-12-12 10:53:11,321 maskrcnn_benchmark.trainer INFO: eta: 0:27:21  iter: 580  loss: 2.3717 (2.5584)  loss_classifier: 0.6399 (0.5904)  loss_box_reg: 0.5444 (0.5278)  loss_objectness: 0.2490 (0.4280)  loss_rpn_box_reg: 0.9164 (1.0122)  time: 3.7898 (3.9094)  data: 0.2049 (0.2811)  lr: 0.000000  max mem: 1318
2020-12-12 10:54:27,172 maskrcnn_benchmark.trainer INFO: eta: 0:26:02  iter: 600  loss: 2.2215 (2.5470)  loss_classifier: 0.5477 (0.5899)  loss_box_reg: 0.4231 (0.5253)  loss_objectness: 0.2728 (0.4248)  loss_rpn_box_reg: 0.8337 (1.0070)  time: 3.7899 (3.9055)  data: 0.2027 (0.2786)  lr: 0.000000  max mem: 1318
2020-12-12 10:54:27,174 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 10:54:27,184 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 10:54:33,175 maskrcnn_benchmark.inference INFO: Total run time: 0:00:05.990931 (1.497732698917389 s / img per device, on 1 devices)
2020-12-12 10:54:33,175 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.594594 (1.3986485600471497 s / img per device, on 1 devices)
2020-12-12 10:54:33,176 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 10:54:33,575 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 10:54:33,575 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0037, 0.0026, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1., -1., -1., -1.,  7.,  1.,  2.,  1.,  2.,  2.,  4.,  4.,  7.,
         7., -1., -1.,  7., -1.,  2.,  7.,  4.,  7., -1.,  1.,  2.,  2.,  4.,
         7.,  7.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6973, 0.9999, 0.1633, 1.0000,
        0.1053, 1.0000, 0.9953, 0.9550, 0.9888, 0.9999, 0.0000, 0.0000, 0.3882,
        0.0000, 0.1051, 0.2744, 1.0000, 0.4506, 0.0000, 0.9883, 0.0851, 1.0000,
        1.0000, 0.8359, 1.0000]), 'num_pos': 30}
2020-12-12 10:54:33,583 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.100000
2020-12-12 10:55:49,431 maskrcnn_benchmark.trainer INFO: eta: 0:24:46  iter: 620  loss: 1.9408 (2.5394)  loss_classifier: 0.4882 (0.5888)  loss_box_reg: 0.4584 (0.5236)  loss_objectness: 0.2755 (0.4239)  loss_rpn_box_reg: 0.8371 (1.0031)  time: 3.7921 (3.9122)  data: 0.2046 (0.2865)  lr: 0.000000  max mem: 1318
2020-12-12 10:57:05,231 maskrcnn_benchmark.trainer INFO: eta: 0:23:27  iter: 640  loss: 2.6206 (2.5433)  loss_classifier: 0.6300 (0.5918)  loss_box_reg: 0.5563 (0.5253)  loss_objectness: 0.2955 (0.4237)  loss_rpn_box_reg: 1.0061 (1.0025)  time: 3.7835 (3.9083)  data: 0.1986 (0.2838)  lr: 0.000000  max mem: 1318
2020-12-12 10:58:20,999 maskrcnn_benchmark.trainer INFO: eta: 0:22:07  iter: 660  loss: 2.3793 (2.5433)  loss_classifier: 0.6216 (0.5921)  loss_box_reg: 0.5274 (0.5256)  loss_objectness: 0.3490 (0.4239)  loss_rpn_box_reg: 0.9011 (1.0017)  time: 3.7894 (3.9047)  data: 0.1973 (0.2812)  lr: 0.000000  max mem: 1318
2020-12-12 10:59:36,826 maskrcnn_benchmark.trainer INFO: eta: 0:20:48  iter: 680  loss: 2.7303 (2.5493)  loss_classifier: 0.5765 (0.5928)  loss_box_reg: 0.6519 (0.5274)  loss_objectness: 0.3758 (0.4249)  loss_rpn_box_reg: 0.9911 (1.0042)  time: 3.7893 (3.9014)  data: 0.2007 (0.2789)  lr: 0.000000  max mem: 1318
2020-12-12 11:00:52,620 maskrcnn_benchmark.trainer INFO: eta: 0:19:29  iter: 700  loss: 2.1532 (2.5508)  loss_classifier: 0.5385 (0.5925)  loss_box_reg: 0.5129 (0.5271)  loss_objectness: 0.2832 (0.4258)  loss_rpn_box_reg: 0.9154 (1.0054)  time: 3.7897 (3.8982)  data: 0.1985 (0.2766)  lr: 0.000000  max mem: 1318
2020-12-12 11:00:52,622 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 11:00:52,633 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 11:00:58,629 maskrcnn_benchmark.inference INFO: Total run time: 0:00:05.996436 (1.499108910560608 s / img per device, on 1 devices)
2020-12-12 11:00:58,630 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.598535 (1.3996336460113525 s / img per device, on 1 devices)
2020-12-12 11:00:58,630 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 11:00:59,028 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 11:00:59,028 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0119, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0231,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0017, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0152, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1.,  7., -1., -1., -1.,  2.,  7.,  2.,  2.,  6.,  7.,  7.,  7.,
         7., -1., -1., -1.,  1.,  2.,  7.,  7.,  7., -1., -1.,  1.,  2.,  4.,
         7.,  7.]), 'best match scores': tensor([0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9997, 0.9330,
        1.0000, 0.3086, 0.9914, 0.2520, 0.9301, 0.6791, 0.0000, 0.0000, 0.0000,
        0.1124, 0.9997, 0.9992, 0.9986, 1.0000, 0.0000, 0.0000, 0.8295, 0.9999,
        1.0000, 0.5102, 0.3266]), 'num_pos': 30}
2020-12-12 11:00:59,036 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.066667
2020-12-12 11:02:14,800 maskrcnn_benchmark.trainer INFO: eta: 0:18:13  iter: 720  loss: 1.9335 (2.5437)  loss_classifier: 0.5591 (0.5921)  loss_box_reg: 0.4266 (0.5253)  loss_objectness: 0.2252 (0.4252)  loss_rpn_box_reg: 0.7745 (1.0011)  time: 3.7824 (3.9040)  data: 0.2005 (0.2835)  lr: 0.000000  max mem: 1318
2020-12-12 11:03:30,912 maskrcnn_benchmark.trainer INFO: eta: 0:16:54  iter: 740  loss: 1.8907 (2.5336)  loss_classifier: 0.4830 (0.5896)  loss_box_reg: 0.3409 (0.5228)  loss_objectness: 0.2382 (0.4234)  loss_rpn_box_reg: 0.8437 (0.9978)  time: 3.7985 (3.9014)  data: 0.2042 (0.2814)  lr: 0.000000  max mem: 1318
2020-12-12 11:04:47,028 maskrcnn_benchmark.trainer INFO: eta: 0:15:35  iter: 760  loss: 2.6333 (2.5351)  loss_classifier: 0.6195 (0.5911)  loss_box_reg: 0.5783 (0.5235)  loss_objectness: 0.2687 (0.4226)  loss_rpn_box_reg: 0.9603 (0.9979)  time: 3.8061 (3.8989)  data: 0.2070 (0.2795)  lr: 0.000000  max mem: 1318
2020-12-12 11:06:03,107 maskrcnn_benchmark.trainer INFO: eta: 0:14:17  iter: 780  loss: 1.8790 (2.5270)  loss_classifier: 0.4977 (0.5897)  loss_box_reg: 0.3090 (0.5211)  loss_objectness: 0.2539 (0.4213)  loss_rpn_box_reg: 0.8431 (0.9949)  time: 3.8011 (3.8964)  data: 0.2063 (0.2776)  lr: 0.000000  max mem: 1318
2020-12-12 11:07:19,149 maskrcnn_benchmark.trainer INFO: eta: 0:12:58  iter: 800  loss: 1.9917 (2.5176)  loss_classifier: 0.4923 (0.5881)  loss_box_reg: 0.3807 (0.5184)  loss_objectness: 0.2815 (0.4205)  loss_rpn_box_reg: 0.8031 (0.9906)  time: 3.8006 (3.8941)  data: 0.2076 (0.2759)  lr: 0.000000  max mem: 1318
2020-12-12 11:07:19,151 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 11:07:19,161 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 11:07:25,195 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.034139 (1.5085347890853882 s / img per device, on 1 devices)
2020-12-12 11:07:25,195 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.615788 (1.403946876525879 s / img per device, on 1 devices)
2020-12-12 11:07:25,196 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 11:07:25,603 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 11:07:25,604 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0356, 0.0052, 0.0016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0086, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([ 2.,  7.,  7.,  2.,  2.,  2.,  7.,  8., -1., -1.,  1.,  2.,  4.,  7.,
         7., -1., -1.,  7., -1., -1.,  1.,  4.,  4.,  1.,  2.,  2.,  2.,  2.,
         4.,  8.]), 'best match scores': tensor([0.9992, 0.6592, 1.0000, 0.1621, 0.1817, 0.1255, 1.0000, 0.9833, 0.0000,
        0.0000, 0.9996, 0.9876, 0.9185, 0.9971, 0.0986, 0.0000, 0.0000, 0.2451,
        0.0000, 0.0000, 0.9999, 0.9527, 0.9984, 0.9997, 0.4842, 1.0000, 0.9999,
        1.0000, 0.4198, 0.1461]), 'num_pos': 30}
2020-12-12 11:07:25,612 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.100000
2020-12-12 11:08:41,647 maskrcnn_benchmark.trainer INFO: eta: 0:11:41  iter: 820  loss: 1.9211 (2.5056)  loss_classifier: 0.5256 (0.5870)  loss_box_reg: 0.3599 (0.5154)  loss_objectness: 0.2302 (0.4177)  loss_rpn_box_reg: 0.8273 (0.9855)  time: 3.7990 (3.8997)  data: 0.2087 (0.2822)  lr: 0.000000  max mem: 1318
2020-12-12 11:09:57,582 maskrcnn_benchmark.trainer INFO: eta: 0:10:23  iter: 840  loss: 1.8551 (2.5067)  loss_classifier: 0.5392 (0.5880)  loss_box_reg: 0.3532 (0.5153)  loss_objectness: 0.2719 (0.4180)  loss_rpn_box_reg: 0.8320 (0.9854)  time: 3.7985 (3.8973)  data: 0.2034 (0.2803)  lr: 0.000000  max mem: 1318
2020-12-12 11:11:13,578 maskrcnn_benchmark.trainer INFO: eta: 0:09:05  iter: 860  loss: 2.3631 (2.5092)  loss_classifier: 0.4923 (0.5870)  loss_box_reg: 0.5239 (0.5165)  loss_objectness: 0.2999 (0.4184)  loss_rpn_box_reg: 0.9589 (0.9874)  time: 3.7987 (3.8950)  data: 0.2050 (0.2786)  lr: 0.000000  max mem: 1318
2020-12-12 11:12:29,596 maskrcnn_benchmark.trainer INFO: eta: 0:07:47  iter: 880  loss: 2.3073 (2.5069)  loss_classifier: 0.5662 (0.5868)  loss_box_reg: 0.5964 (0.5173)  loss_objectness: 0.2878 (0.4173)  loss_rpn_box_reg: 0.9165 (0.9854)  time: 3.7990 (3.8928)  data: 0.2048 (0.2770)  lr: 0.000000  max mem: 1318
2020-12-12 11:16:45,733 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 11:16:45,733 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='draw_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 11:16:45,733 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 11:16:48,192 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 11:16:48,192 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 11:16:48,193 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.0000001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1000
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 11:16:48,195 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 1e-07
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 11:16:49,722 maskrcnn_benchmark INFO: reloading weigts from _best_acc_r3.pth
2020-12-12 11:36:15,419 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 11:36:15,419 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 11:36:15,419 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 11:36:17,422 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 11:36:17,422 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 11:36:17,423 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.0000001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1000
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 11:36:17,424 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.0005
    FG_IOU_THRESHOLD: 0.05
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 1e-07
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 11:36:18,942 maskrcnn_benchmark INFO: reloading weigts from _best_acc_r3.pth
2020-12-12 11:36:20,912 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-12 11:36:20,913 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-12 11:36:20,913 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-12 11:36:20,913 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-12 11:36:20,913 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-12 11:36:20,914 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-12 11:36:21,079 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-12 11:36:21,489 maskrcnn_benchmark.trainer INFO: Start training
2020-12-12 11:37:41,257 maskrcnn_benchmark.trainer INFO: eta: 1:05:08  iter: 20  loss: 11.6614 (11.3964)  loss_classifier: 0.6588 (0.6737)  loss_box_reg: 0.4596 (0.5672)  loss_objectness: 4.4630 (4.4120)  loss_rpn_box_reg: 5.6680 (5.7435)  time: 4.0117 (3.9882)  data: 0.2107 (0.2205)  lr: 0.000000  max mem: 1317
2020-12-12 11:38:58,022 maskrcnn_benchmark.trainer INFO: eta: 1:02:36  iter: 40  loss: 10.0972 (10.5540)  loss_classifier: 0.4846 (0.5826)  loss_box_reg: 0.3355 (0.4882)  loss_objectness: 3.6525 (4.0558)  loss_rpn_box_reg: 5.2203 (5.4274)  time: 3.8376 (3.9133)  data: 0.2136 (0.2182)  lr: 0.000000  max mem: 1317
2020-12-12 11:40:14,955 maskrcnn_benchmark.trainer INFO: eta: 1:00:57  iter: 60  loss: 9.7850 (10.2947)  loss_classifier: 0.5690 (0.5975)  loss_box_reg: 0.4696 (0.5213)  loss_objectness: 3.4047 (3.8228)  loss_rpn_box_reg: 5.0807 (5.3531)  time: 3.8462 (3.8911)  data: 0.2113 (0.2174)  lr: 0.000000  max mem: 1317
2020-12-12 11:41:31,829 maskrcnn_benchmark.trainer INFO: eta: 0:59:28  iter: 80  loss: 9.3300 (9.9972)  loss_classifier: 0.5162 (0.5893)  loss_box_reg: 0.4064 (0.5032)  loss_objectness: 2.8525 (3.5818)  loss_rpn_box_reg: 5.3781 (5.3229)  time: 3.8424 (3.8792)  data: 0.2162 (0.2170)  lr: 0.000000  max mem: 1317
2020-12-12 11:42:48,879 maskrcnn_benchmark.trainer INFO: eta: 0:58:06  iter: 100  loss: 8.8843 (9.7424)  loss_classifier: 0.5584 (0.5852)  loss_box_reg: 0.3972 (0.4924)  loss_objectness: 2.5463 (3.3678)  loss_rpn_box_reg: 5.0794 (5.2970)  time: 3.8471 (3.8739)  data: 0.2161 (0.2169)  lr: 0.000000  max mem: 1317
2020-12-12 11:42:48,881 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 11:42:48,892 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 11:42:55,000 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.107603 (1.526900827884674 s / img per device, on 1 devices)
2020-12-12 11:42:55,000 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.660658 (1.415164589881897 s / img per device, on 1 devices)
2020-12-12 11:42:55,001 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 11:42:55,428 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 11:42:55,428 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0017,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0172, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1., -1., -1.,  2.,  2.,  2.,  7.,  2.,  4.,  7.,  7.,  8.,  8.,
         1., -1., -1.,  7., -1.,  1.,  2.,  2.,  8., -1.,  1.,  2.,  2.,  4.,
         4.,  7.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.9988, 0.1534, 0.9997, 1.0000, 0.7536,
        0.9991, 0.6571, 0.4349, 0.5581, 0.2284, 0.2286, 0.0000, 0.0000, 0.0970,
        0.0000, 0.3527, 1.0000, 0.7622, 0.5077, 0.0000, 0.0813, 0.9567, 0.9974,
        0.8689, 0.9233, 0.9998]), 'num_pos': 30}
2020-12-12 11:42:55,436 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.100000
2020-12-12 11:42:55,439 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-12 11:42:59,412 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-12 11:44:42,066 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 11:44:42,066 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 11:44:42,066 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 11:44:44,276 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 11:44:44,276 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 11:44:44,276 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.0000001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1000
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 11:44:44,277 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 5e-05
    FG_IOU_THRESHOLD: 0.01
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 1e-07
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 11:44:46,008 maskrcnn_benchmark INFO: reloading weigts from _best_acc_r3.pth
2020-12-12 11:44:48,230 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-12 11:44:48,230 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-12 11:44:48,231 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-12 11:44:48,231 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-12 11:44:48,231 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-12 11:44:48,231 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-12 11:44:48,401 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-12 11:44:48,854 maskrcnn_benchmark.trainer INFO: Start training
2020-12-12 11:46:05,878 maskrcnn_benchmark.trainer INFO: eta: 1:02:54  iter: 20  loss: 8.9772 (8.8310)  loss_classifier: 0.4502 (0.5229)  loss_box_reg: 0.3455 (0.4132)  loss_objectness: 2.2901 (2.3113)  loss_rpn_box_reg: 5.6811 (5.5836)  time: 3.8410 (3.8511)  data: 0.2232 (0.2222)  lr: 0.000000  max mem: 1317
2020-12-12 11:47:23,073 maskrcnn_benchmark.trainer INFO: eta: 1:01:41  iter: 40  loss: 8.3601 (8.7043)  loss_classifier: 0.6254 (0.5733)  loss_box_reg: 0.5623 (0.4976)  loss_objectness: 2.1152 (2.2029)  loss_rpn_box_reg: 5.3076 (5.4304)  time: 3.8513 (3.8554)  data: 0.2191 (0.2221)  lr: 0.000000  max mem: 1317
2020-12-12 11:48:40,000 maskrcnn_benchmark.trainer INFO: eta: 1:00:21  iter: 60  loss: 8.4748 (8.6480)  loss_classifier: 0.5679 (0.5813)  loss_box_reg: 0.5861 (0.5291)  loss_objectness: 1.9757 (2.1275)  loss_rpn_box_reg: 5.2041 (5.4101)  time: 3.8473 (3.8524)  data: 0.2150 (0.2206)  lr: 0.000000  max mem: 1317
2020-12-12 11:49:56,816 maskrcnn_benchmark.trainer INFO: eta: 0:59:01  iter: 80  loss: 8.3656 (8.5662)  loss_classifier: 0.5044 (0.5750)  loss_box_reg: 0.5199 (0.5314)  loss_objectness: 1.8926 (2.0709)  loss_rpn_box_reg: 5.4144 (5.3888)  time: 3.8368 (3.8495)  data: 0.2200 (0.2211)  lr: 0.000000  max mem: 1317
2020-12-12 11:51:13,586 maskrcnn_benchmark.trainer INFO: eta: 0:57:42  iter: 100  loss: 8.1447 (8.4744)  loss_classifier: 0.5480 (0.5822)  loss_box_reg: 0.4650 (0.5220)  loss_objectness: 1.8534 (2.0270)  loss_rpn_box_reg: 5.0447 (5.3432)  time: 3.8403 (3.8473)  data: 0.2165 (0.2204)  lr: 0.000000  max mem: 1317
2020-12-12 11:51:13,588 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 11:51:13,599 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 11:51:19,712 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.113029 (1.5282572507858276 s / img per device, on 1 devices)
2020-12-12 11:51:19,713 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.660136 (1.4150338768959045 s / img per device, on 1 devices)
2020-12-12 11:51:19,713 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 11:51:20,128 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 11:51:20,128 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0208,
        0.0056, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1., -1.,  1.,  1.,  1.,  4.,  7.,  7.,  7.,  1.,  1.,  4.,  6.,
         7., -1., -1., -1.,  1.,  1.,  2.,  2.,  2.,  2.,  2.,  7.,  7.,  7.,
         8.,  8.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0918, 0.9934, 0.7439, 1.0000, 0.9999, 0.9996,
        0.9277, 1.0000, 0.9992, 0.9993, 0.5152, 0.1472, 0.0000, 0.0000, 0.0000,
        0.0621, 0.9974, 0.9802, 1.0000, 1.0000, 0.9334, 0.9906, 1.0000, 0.8785,
        0.9765, 0.2778, 0.6119]), 'num_pos': 30}
2020-12-12 11:51:20,135 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.233333
2020-12-12 11:51:20,137 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-12 11:51:23,870 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-12 11:52:40,818 maskrcnn_benchmark.trainer INFO: eta: 0:57:41  iter: 120  loss: 7.8442 (8.4024)  loss_classifier: 0.4578 (0.5775)  loss_box_reg: 0.2989 (0.5035)  loss_objectness: 1.7840 (1.9837)  loss_rpn_box_reg: 5.1272 (5.3378)  time: 3.8428 (3.9330)  data: 0.2205 (0.3064)  lr: 0.000000  max mem: 1317
2020-12-12 11:53:57,629 maskrcnn_benchmark.trainer INFO: eta: 0:56:11  iter: 140  loss: 7.7233 (8.2970)  loss_classifier: 0.4376 (0.5638)  loss_box_reg: 0.3080 (0.4877)  loss_objectness: 1.6997 (1.9435)  loss_rpn_box_reg: 4.9935 (5.3020)  time: 3.8368 (3.9198)  data: 0.2280 (0.2954)  lr: 0.000000  max mem: 1317
2020-12-12 11:55:14,586 maskrcnn_benchmark.trainer INFO: eta: 0:54:45  iter: 160  loss: 7.9990 (8.2290)  loss_classifier: 0.5614 (0.5633)  loss_box_reg: 0.5087 (0.4915)  loss_objectness: 1.6535 (1.9020)  loss_rpn_box_reg: 5.0319 (5.2722)  time: 3.8485 (3.9108)  data: 0.2221 (0.2863)  lr: 0.000000  max mem: 1317
2020-12-12 11:56:31,509 maskrcnn_benchmark.trainer INFO: eta: 0:53:20  iter: 180  loss: 8.4604 (8.2344)  loss_classifier: 0.5983 (0.5686)  loss_box_reg: 0.5817 (0.5069)  loss_objectness: 1.6430 (1.8737)  loss_rpn_box_reg: 5.4826 (5.2852)  time: 3.8448 (3.9036)  data: 0.2268 (0.2796)  lr: 0.000000  max mem: 1317
2020-12-12 11:57:48,535 maskrcnn_benchmark.trainer INFO: eta: 0:51:58  iter: 200  loss: 8.2565 (8.2414)  loss_classifier: 0.7141 (0.5829)  loss_box_reg: 0.6215 (0.5165)  loss_objectness: 1.6140 (1.8499)  loss_rpn_box_reg: 5.3774 (5.2921)  time: 3.8482 (3.8984)  data: 0.2150 (0.2734)  lr: 0.000000  max mem: 1317
2020-12-12 11:57:48,537 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 11:57:48,548 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 11:57:54,644 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.096385 (1.5240961909294128 s / img per device, on 1 devices)
2020-12-12 11:57:54,645 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.651816 (1.412954032421112 s / img per device, on 1 devices)
2020-12-12 11:57:54,645 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 11:57:55,075 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 11:57:55,076 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0425, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0099,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1.,  7., -1., -1.,  1.,  7.,  7.,  1.,  7.,  2.,  4.,  7.,  7.,
         8., -1., -1., -1.,  1.,  2.,  2.,  2.,  7., -1.,  1.,  2.,  4.,  7.,
         7.,  7.]), 'best match scores': tensor([0.0000, 0.0000, 0.9989, 0.0000, 0.0000, 0.9743, 0.1183, 1.0000, 1.0000,
        0.2638, 0.9720, 0.8649, 0.1055, 0.4954, 0.8220, 0.0000, 0.0000, 0.0000,
        0.7513, 0.8878, 1.0000, 0.9997, 0.1001, 0.0000, 0.7710, 0.0512, 0.9989,
        0.7607, 0.3827, 0.5191]), 'num_pos': 30}
2020-12-12 11:57:55,084 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.133333
2020-12-12 11:59:12,513 maskrcnn_benchmark.trainer INFO: eta: 0:51:02  iter: 220  loss: 8.1322 (8.2132)  loss_classifier: 0.4867 (0.5824)  loss_box_reg: 0.3752 (0.5104)  loss_objectness: 1.5978 (1.8256)  loss_rpn_box_reg: 5.1844 (5.2948)  time: 3.8587 (3.9257)  data: 0.2197 (0.2989)  lr: 0.000000  max mem: 1317
2020-12-12 12:00:29,374 maskrcnn_benchmark.trainer INFO: eta: 0:49:38  iter: 240  loss: 7.7387 (8.1731)  loss_classifier: 0.6202 (0.5833)  loss_box_reg: 0.5225 (0.5131)  loss_objectness: 1.4540 (1.7960)  loss_rpn_box_reg: 5.1816 (5.2806)  time: 3.8428 (3.9188)  data: 0.2256 (0.2929)  lr: 0.000000  max mem: 1317
2020-12-12 12:01:46,437 maskrcnn_benchmark.trainer INFO: eta: 0:48:16  iter: 260  loss: 7.9961 (8.1615)  loss_classifier: 0.5298 (0.5810)  loss_box_reg: 0.4855 (0.5119)  loss_objectness: 1.5143 (1.7772)  loss_rpn_box_reg: 5.3169 (5.2915)  time: 3.8514 (3.9138)  data: 0.2139 (0.2872)  lr: 0.000000  max mem: 1317
2020-12-12 12:03:03,343 maskrcnn_benchmark.trainer INFO: eta: 0:46:54  iter: 280  loss: 7.7308 (8.1244)  loss_classifier: 0.5426 (0.5816)  loss_box_reg: 0.4335 (0.5065)  loss_objectness: 1.4860 (1.7563)  loss_rpn_box_reg: 5.1430 (5.2799)  time: 3.8374 (3.9089)  data: 0.2216 (0.2826)  lr: 0.000000  max mem: 1317
2020-12-12 12:04:20,251 maskrcnn_benchmark.trainer INFO: eta: 0:45:33  iter: 300  loss: 7.7945 (8.1100)  loss_classifier: 0.6501 (0.5873)  loss_box_reg: 0.5522 (0.5092)  loss_objectness: 1.4634 (1.7358)  loss_rpn_box_reg: 5.1677 (5.2776)  time: 3.8399 (3.9046)  data: 0.2214 (0.2788)  lr: 0.000000  max mem: 1317
2020-12-12 12:04:20,253 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 12:04:20,264 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 12:04:26,348 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.083146 (1.520786464214325 s / img per device, on 1 devices)
2020-12-12 12:04:26,348 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.622185 (1.4055461883544922 s / img per device, on 1 devices)
2020-12-12 12:04:26,348 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 12:04:26,779 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 12:04:26,779 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1., -1., -1.,  1.,  2.,  4.,  7.,  1.,  1.,  2.,  2.,  4.,  7.,
         8., -1., -1., -1.,  1.,  1.,  2.,  2.,  2., -1.,  1.,  1.,  2.,  2.,
         4.,  7.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.2469, 1.0000, 1.0000, 1.0000, 0.9856,
        0.1045, 1.0000, 0.7741, 0.2822, 0.8945, 0.9799, 0.0000, 0.0000, 0.0000,
        1.0000, 0.8514, 1.0000, 0.0696, 0.0721, 0.0000, 0.5719, 0.3452, 0.5194,
        0.6562, 0.0777, 0.3437]), 'num_pos': 30}
2020-12-12 12:04:26,787 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.233333
2020-12-12 12:06:36,839 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 12:06:36,839 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 12:06:36,840 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 12:06:39,046 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 12:06:39,046 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 12:06:39,047 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000004
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1000
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 12:06:39,048 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 5e-05
    FG_IOU_THRESHOLD: 0.005
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 4e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 12:06:40,754 maskrcnn_benchmark INFO: reloading weigts from _best_acc_r3.pth
2020-12-12 12:06:42,962 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-12 12:06:42,962 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-12 12:06:42,963 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-12 12:06:42,963 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-12 12:06:42,963 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-12 12:06:42,963 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-12 12:06:42,963 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-12 12:06:42,963 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-12 12:06:42,964 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-12 12:06:42,964 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-12 12:06:42,964 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-12 12:06:42,964 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-12 12:06:42,964 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-12 12:06:42,964 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-12 12:06:43,137 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-12 12:06:43,589 maskrcnn_benchmark.trainer INFO: Start training
2020-12-12 12:08:01,284 maskrcnn_benchmark.trainer INFO: eta: 1:03:26  iter: 20  loss: 8.3191 (7.9984)  loss_classifier: 0.4662 (0.4755)  loss_box_reg: 0.2449 (0.3356)  loss_objectness: 1.8262 (1.8126)  loss_rpn_box_reg: 5.6718 (5.3747)  time: 3.8700 (3.8846)  data: 0.2151 (0.2241)  lr: 0.000000  max mem: 1424
2020-12-12 12:09:19,076 maskrcnn_benchmark.trainer INFO: eta: 1:02:11  iter: 40  loss: 8.1800 (8.1472)  loss_classifier: 0.6704 (0.5752)  loss_box_reg: 0.5636 (0.4680)  loss_objectness: 1.7401 (1.7676)  loss_rpn_box_reg: 5.3232 (5.3365)  time: 3.8909 (3.8871)  data: 0.2205 (0.2225)  lr: 0.000000  max mem: 1424
2020-12-12 12:10:36,874 maskrcnn_benchmark.trainer INFO: eta: 1:00:54  iter: 60  loss: 7.8973 (8.0928)  loss_classifier: 0.5526 (0.5682)  loss_box_reg: 0.4418 (0.4793)  loss_objectness: 1.7333 (1.7569)  loss_rpn_box_reg: 5.1217 (5.2883)  time: 3.8903 (3.8880)  data: 0.2212 (0.2223)  lr: 0.000000  max mem: 1424
2020-12-12 12:11:54,791 maskrcnn_benchmark.trainer INFO: eta: 0:59:38  iter: 80  loss: 8.2524 (8.0840)  loss_classifier: 0.4490 (0.5631)  loss_box_reg: 0.4792 (0.4809)  loss_objectness: 1.6794 (1.7431)  loss_rpn_box_reg: 5.3874 (5.2970)  time: 3.8893 (3.8900)  data: 0.2193 (0.2217)  lr: 0.000000  max mem: 1424
2020-12-12 12:13:12,652 maskrcnn_benchmark.trainer INFO: eta: 0:58:21  iter: 100  loss: 8.0419 (8.0604)  loss_classifier: 0.6897 (0.5815)  loss_box_reg: 0.5445 (0.5044)  loss_objectness: 1.6286 (1.7246)  loss_rpn_box_reg: 4.9317 (5.2499)  time: 3.8910 (3.8906)  data: 0.2179 (0.2213)  lr: 0.000000  max mem: 1424
2020-12-12 12:13:12,654 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 12:13:12,674 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(1 images).
2020-12-12 12:13:14,247 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.573138 (1.5731377601623535 s / img per device, on 1 devices)
2020-12-12 12:13:14,247 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.419499 (1.4194989204406738 s / img per device, on 1 devices)
2020-12-12 12:13:14,248 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 12:13:14,348 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 12:13:14,348 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0261, 0.0200]), 'gt_labels': tensor([8, 8]), 'best match labels': tensor([7., 7.]), 'best match scores': tensor([1.0000, 0.9999]), 'num_pos': 2}
2020-12-12 12:13:14,353 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-12 12:13:14,356 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-12 12:13:18,610 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-12 12:14:33,497 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 12:14:33,497 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 12:14:33,497 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 12:14:35,734 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 12:14:35,734 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 12:14:35,734 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000004
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1000
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 12:14:35,735 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 5e-05
    FG_IOU_THRESHOLD: 0.005
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 4e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 12:14:37,454 maskrcnn_benchmark INFO: reloading weigts from _best_acc_r3.pth
2020-12-12 12:14:39,732 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-12 12:14:39,732 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-12 12:14:39,732 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-12 12:14:39,732 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-12 12:14:39,732 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-12 12:14:39,732 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-12 12:14:39,733 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-12 12:14:39,733 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-12 12:14:39,733 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-12 12:14:39,733 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-12 12:14:39,733 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-12 12:14:39,733 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-12 12:14:39,734 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-12 12:14:39,734 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-12 12:14:39,907 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-12 12:14:40,362 maskrcnn_benchmark.trainer INFO: Start training
2020-12-12 12:15:58,281 maskrcnn_benchmark.trainer INFO: eta: 1:03:37  iter: 20  loss: 8.2438 (8.3049)  loss_classifier: 0.4537 (0.5844)  loss_box_reg: 0.2989 (0.4934)  loss_objectness: 1.6493 (1.6754)  loss_rpn_box_reg: 5.5541 (5.5516)  time: 3.8859 (3.8959)  data: 0.2191 (0.2252)  lr: 0.000000  max mem: 1424
2020-12-12 12:17:15,887 maskrcnn_benchmark.trainer INFO: eta: 1:02:12  iter: 40  loss: 8.0316 (8.1475)  loss_classifier: 0.5377 (0.5690)  loss_box_reg: 0.5121 (0.4638)  loss_objectness: 1.6931 (1.6819)  loss_rpn_box_reg: 5.2595 (5.4328)  time: 3.8804 (3.8881)  data: 0.2200 (0.2234)  lr: 0.000000  max mem: 1424
2020-12-12 12:18:33,508 maskrcnn_benchmark.trainer INFO: eta: 1:00:52  iter: 60  loss: 8.2935 (8.2017)  loss_classifier: 0.5076 (0.5689)  loss_box_reg: 0.5782 (0.5136)  loss_objectness: 1.6815 (1.6832)  loss_rpn_box_reg: 5.3165 (5.4361)  time: 3.8865 (3.8857)  data: 0.2178 (0.2223)  lr: 0.000000  max mem: 1424
2020-12-12 12:19:51,181 maskrcnn_benchmark.trainer INFO: eta: 0:59:34  iter: 80  loss: 8.0812 (8.1257)  loss_classifier: 0.5368 (0.5706)  loss_box_reg: 0.5245 (0.5154)  loss_objectness: 1.5847 (1.6543)  loss_rpn_box_reg: 5.1957 (5.3854)  time: 3.8792 (3.8852)  data: 0.2145 (0.2211)  lr: 0.000000  max mem: 1424
2020-12-12 12:21:08,855 maskrcnn_benchmark.trainer INFO: eta: 0:58:16  iter: 100  loss: 8.1156 (8.0799)  loss_classifier: 0.5065 (0.5548)  loss_box_reg: 0.4431 (0.5002)  loss_objectness: 1.5511 (1.6367)  loss_rpn_box_reg: 5.3862 (5.3882)  time: 3.8811 (3.8849)  data: 0.2140 (0.2205)  lr: 0.000000  max mem: 1424
2020-12-12 12:22:26,679 maskrcnn_benchmark.trainer INFO: eta: 0:56:59  iter: 120  loss: 8.3037 (8.1251)  loss_classifier: 0.5398 (0.5543)  loss_box_reg: 0.5770 (0.5118)  loss_objectness: 1.5174 (1.6266)  loss_rpn_box_reg: 5.7464 (5.4324)  time: 3.8870 (3.8860)  data: 0.2170 (0.2205)  lr: 0.000000  max mem: 1424
2020-12-12 12:23:44,343 maskrcnn_benchmark.trainer INFO: eta: 0:55:41  iter: 140  loss: 7.7097 (8.0497)  loss_classifier: 0.5469 (0.5539)  loss_box_reg: 0.5027 (0.5107)  loss_objectness: 1.4824 (1.6111)  loss_rpn_box_reg: 5.0909 (5.3740)  time: 3.8857 (3.8856)  data: 0.2210 (0.2209)  lr: 0.000000  max mem: 1424
2020-12-12 12:25:02,091 maskrcnn_benchmark.trainer INFO: eta: 0:54:24  iter: 160  loss: 8.0963 (8.0346)  loss_classifier: 0.5200 (0.5465)  loss_box_reg: 0.3122 (0.4947)  loss_objectness: 1.6132 (1.6065)  loss_rpn_box_reg: 5.7179 (5.3870)  time: 3.8843 (3.8858)  data: 0.2191 (0.2210)  lr: 0.000000  max mem: 1424
2020-12-12 12:25:02,093 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 12:25:03,013 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(148 images).
2020-12-12 12:28:48,896 maskrcnn_benchmark.inference INFO: Total run time: 0:03:45.883286 (1.5262384205251127 s / img per device, on 1 devices)
2020-12-12 12:28:48,897 maskrcnn_benchmark.inference INFO: Model inference time: 0:03:28.692258 (1.4100828251323185 s / img per device, on 1 devices)
2020-12-12 12:28:48,897 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 12:29:04,791 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 12:29:04,791 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([3.8669e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.5340e-02, 4.9025e-02, 1.8044e-02, 1.5198e-02, 4.6119e-06, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6901e-02, 1.0193e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.2313e-02, 1.6361e-03, 0.0000e+00, 0.0000e+00, 3.3173e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.4752e-02, 2.0472e-02, 1.8957e-03, 1.6091e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2484e-01, 9.2663e-02,
        3.7403e-02, 1.5954e-02, 1.4896e-02, 1.1072e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 5.8999e-04, 0.0000e+00, 0.0000e+00, 1.1765e-01, 8.7965e-02,
        1.6455e-02, 1.4867e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3255e-01, 1.0618e-01,
        2.1682e-02, 9.6014e-02, 3.9268e-02, 3.8573e-02, 2.4200e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0954e-03, 0.0000e+00,
        0.0000e+00, 1.3369e-01, 0.0000e+00, 0.0000e+00, 1.9838e-01, 7.5236e-02,
        2.0852e-02, 2.5620e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5146e-02, 1.3024e-02, 0.0000e+00,
        1.8876e-01, 9.9174e-02, 3.2977e-02, 7.2666e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.7918e-03, 0.0000e+00, 0.0000e+00, 1.8173e-08, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9855e-01, 3.2139e-02, 1.5349e-02, 9.3508e-03, 3.7120e-03, 3.4811e-03,
        5.5439e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0786e-01,
        0.0000e+00, 0.0000e+00, 1.2415e-01, 7.0874e-02, 2.3771e-02, 4.7139e-02,
        0.0000e+00, 0.0000e+00, 1.3854e-01, 1.2178e-01, 1.1873e-01, 3.6996e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.3968e-03, 6.9872e-03, 0.0000e+00, 3.0271e-01,
        1.5560e-02, 0.0000e+00, 0.0000e+00, 3.0575e-02, 1.1056e-02, 6.7477e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9825e-01, 0.0000e+00, 0.0000e+00, 3.5431e-02, 1.5874e-02, 6.0982e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.6760e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6632e-02,
        3.2977e-02, 1.6543e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3496e-02,
        2.4894e-03, 0.0000e+00, 1.6210e-04, 7.7509e-06, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.8108e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9260e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.3621e-02, 9.0914e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1624e-03, 0.0000e+00,
        3.4315e-01, 2.1682e-02, 1.2997e-02, 2.1993e-02, 1.8674e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.7261e-02, 3.2977e-02, 3.1124e-03, 3.9811e-03, 0.0000e+00, 0.0000e+00,
        4.4351e-02, 3.3896e-02, 2.1567e-02, 1.5282e-02, 9.8867e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.4065e-02, 3.1749e-02, 2.1682e-02, 6.4459e-02, 1.5556e-02, 6.7146e-03,
        5.8569e-03, 5.1440e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.0152e-02, 6.0018e-02, 1.7300e-02, 2.6708e-02,
        1.1941e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.8592e-02, 2.3336e-02, 0.0000e+00, 2.3183e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.4461e-01, 1.8001e-02, 1.6287e-07, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7143e-02,
        4.8456e-02, 3.3139e-02, 2.3084e-02, 2.0436e-02, 1.4995e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2331e-02, 1.8248e-03,
        1.0116e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.1924e-02, 4.3760e-02, 3.0693e-02, 2.9341e-01, 3.4602e-02,
        0.0000e+00, 2.1914e-01, 7.1018e-02, 2.9606e-02, 2.0068e-02, 1.7180e-02,
        8.7407e-03, 3.4811e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.9879e-02, 3.6518e-02, 2.3677e-02, 5.9527e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.5940e-01, 3.1395e-02, 2.5800e-02, 1.6614e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2544e-01,
        8.3580e-03, 0.0000e+00, 3.2139e-02, 1.5874e-02, 6.9711e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.7171e-02, 3.5685e-02, 1.0625e-02, 9.8721e-02, 5.5027e-02,
        3.2139e-02, 2.2852e-02, 1.6483e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.4470e-02, 3.8761e-03, 0.0000e+00,
        3.2977e-02, 0.0000e+00, 0.0000e+00, 7.7722e-02, 5.8700e-02, 1.8523e-02,
        5.3911e-02, 4.7060e-02, 7.2535e-03, 4.5318e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7490e-04, 2.0180e-02, 0.0000e+00,
        2.8102e-07, 0.0000e+00, 0.0000e+00, 4.8108e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3330e-01, 4.0153e-02, 2.1266e-02, 6.5446e-03, 4.5564e-03, 3.1410e-03,
        3.0877e-03, 3.0334e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0504e-02,
        3.7187e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.1583e-02, 6.3487e-02,
        6.2883e-03, 4.7385e-03, 1.7512e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.2241e-02, 1.8269e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4159e-01, 0.0000e+00,
        0.0000e+00, 3.2139e-02, 2.5520e-02, 2.2936e-02, 6.4412e-03, 3.7147e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7528e-01, 2.7199e-02, 2.6757e-02, 2.7092e-02, 3.2139e-02, 2.1924e-02,
        1.8991e-02, 3.2690e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9895e-02, 2.8450e-02, 3.3741e-04,
        3.4371e-02, 5.5200e-03, 0.0000e+00, 4.7345e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 2.8227e-02, 2.2623e-02, 1.5874e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1111e-02,
        0.0000e+00, 0.0000e+00, 2.2939e-01, 3.6407e-02, 3.4764e-02, 3.0116e-02,
        1.1140e-02, 7.8854e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.4329e-02, 9.0476e-05, 0.0000e+00, 3.2139e-02, 1.0633e-02,
        6.5042e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2521e-02, 3.0993e-04, 0.0000e+00,
        4.2642e-02, 2.1682e-02, 0.0000e+00, 3.2977e-02, 9.8593e-04, 0.0000e+00,
        1.3947e-01, 4.9807e-02, 4.7257e-02, 6.1886e-03, 5.7203e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0794e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.4814e-03, 3.9022e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.1332e-01, 8.1232e-02, 6.6564e-02, 3.9970e-02, 3.1233e-02,
        1.2648e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6301e-01, 6.8114e-02,
        1.6849e-02, 5.9364e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.3314e-02, 2.0385e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.0933e-02, 7.6019e-03, 0.0000e+00, 4.3045e-02, 3.1234e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0592e-01, 6.2638e-02, 2.1682e-02, 4.5541e-02, 3.8907e-02, 0.0000e+00,
        3.2139e-02, 1.9951e-02, 0.0000e+00, 2.3997e-01, 4.7139e-02, 3.5139e-08,
        4.8066e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.6809e-02, 2.2003e-02, 1.5874e-02, 2.6302e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1120e-01,
        3.2339e-02, 2.1682e-02, 8.1551e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3899e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.2146e-02, 4.3732e-02, 1.8567e-02, 1.2026e-03,
        0.0000e+00, 4.0737e-02, 3.7448e-02, 8.8395e-03, 7.9571e-03, 6.8807e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.1359e-01, 8.6714e-02, 2.2241e-02, 1.5101e-02, 8.5945e-03, 3.1436e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6248e-06,
        0.0000e+00, 0.0000e+00, 6.8487e-02, 1.1750e-02, 9.3543e-03, 3.2877e-02,
        0.0000e+00, 0.0000e+00, 1.2147e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0568e-02,
        4.9464e-04, 0.0000e+00, 2.2932e-02, 4.8841e-02, 4.1761e-02, 0.0000e+00,
        6.2938e-02, 5.2423e-02, 3.2977e-02, 8.5299e-02, 1.4348e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.2281e-02, 4.6297e-02, 3.2666e-02, 1.1914e-01,
        8.6750e-02, 3.8930e-02, 6.8297e-02, 3.7516e-02, 1.9798e-05, 3.3255e-02,
        2.8398e-02, 1.1623e-02, 4.7653e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2105e-06, 0.0000e+00, 0.0000e+00, 2.2761e-02,
        1.1179e-02, 2.0021e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1449e-01,
        2.0395e-02, 0.0000e+00, 3.4018e-01, 3.3363e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5765e-02,
        1.2446e-02, 0.0000e+00]), 'gt_labels': tensor([7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 1, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7,
        4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 4, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 7, 7, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 7, 7, 4]), 'best match labels': tensor([ 7.,  7.,  8.,  2.,  2.,  4.,  4.,  4.,  7.,  7.,  7.,  7.,  1.,  2.,
         7.,  4.,  7.,  8.,  8.,  2.,  2.,  2.,  2.,  7.,  7.,  7.,  7.,  7.,
         8.,  4.,  7.,  2.,  2.,  7.,  2.,  2.,  2.,  2.,  2.,  2.,  1.,  2.,
         4.,  1.,  1.,  1.,  7.,  8.,  4.,  2.,  7.,  8.,  7.,  7.,  7.,  7.,
         7.,  8.,  1.,  2.,  1.,  4.,  2.,  7.,  1.,  4.,  7.,  2.,  2.,  2.,
         2.,  8.,  4.,  4.,  7.,  7.,  2.,  2.,  7.,  2.,  7.,  1.,  2.,  7.,
         7.,  7.,  8.,  7.,  7.,  7.,  7.,  2.,  2.,  2.,  2.,  2.,  7.,  7.,
         7.,  8.,  4.,  7.,  7.,  8.,  8.,  7.,  4.,  7.,  2.,  2.,  8.,  2.,
         2.,  2.,  2.,  5.,  7.,  2.,  8.,  7.,  4.,  7.,  2.,  4.,  2.,  2.,
         7.,  7.,  7.,  7.,  7.,  8.,  7.,  7.,  7.,  2.,  2.,  2.,  2.,  4.,
         7.,  7.,  2.,  7.,  2.,  4.,  1.,  2.,  7.,  2.,  2.,  4.,  7.,  2.,
         4.,  2.,  8.,  8.,  7.,  7.,  7.,  7.,  8.,  4.,  2.,  7.,  7.,  2.,
         2.,  4.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  2.,  7.,  1.,  7.,  8.,
         7.,  2.,  4.,  2.,  2.,  7.,  2.,  2.,  2.,  7.,  7.,  2.,  7.,  7.,
         1.,  7.,  7.,  7.,  7.,  7.,  8.,  8.,  8.,  7.,  2.,  2.,  7.,  2.,
         4.,  7.,  7.,  7.,  8.,  7.,  7.,  7.,  2.,  2.,  2.,  2.,  2.,  4.,
         7.,  7.,  7.,  4.,  7.,  4.,  7.,  7.,  8.,  7.,  2.,  7.,  2.,  1.,
         2.,  2.,  4.,  7.,  7.,  7.,  7.,  7.,  8., -1.,  2., -1., -1.,  1.,
         2.,  2.,  4.,  7.,  2.,  2.,  2.,  4.,  2.,  6.,  7.,  7.,  8.,  2.,
         2.,  2.,  2.,  2.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  2.,  1.,  1.,
         4.,  1.,  2.,  2.,  2.,  4.,  6.,  4.,  2.,  7.,  2.,  8.,  1.,  8.,
         6.,  7.,  7.,  7.,  2.,  7.,  7.,  2.,  7.,  2.,  2.,  2.,  2.,  4.,
         7.,  7.,  7.,  8.,  1.,  2.,  7.,  1.,  2.,  1.,  2.,  2.,  2.,  4.,
         2.,  7.,  2.,  7.,  7.,  7.,  7., -1.,  1., -1., -1.,  2.,  4.,  2.,
         7.,  7.,  7.,  2.,  4., -1., -1., -1.,  1.,  2.,  2.,  4.,  7.,  7.,
         7.,  4.,  7.,  7.,  7.,  7.,  7.,  8.,  7.,  8.,  2.,  2.,  2.,  2.,
         2.,  2.,  7.,  7.,  7.,  8.,  2.,  2.,  2.,  7.,  4.,  8.,  8.,  8.,
         2.,  7.,  7.,  2.,  7.,  2.,  2.,  7.,  7.,  1.,  7.,  2.,  7.,  7.,
         8.,  7.,  2.,  8.,  4.,  7.,  2., -1.,  2.,  1.,  1.,  2.,  2.,  4.,
         7.,  8.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  8.,  2.,  7.,
         2.,  8.,  4.,  7.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  7.,  8.,  4.,
         2.,  7.,  7.,  7.,  7.,  7.,  2.,  7.,  7.,  7.,  8.,  2.,  7.,  8.,
         7.,  7.,  7.,  7.,  7.,  7.,  2.,  2.,  2.,  4.,  7.,  4.,  4.,  7.,
         4.,  6.,  1.,  8.,  2.,  7.,  2.,  7.,  7.,  2.,  2.,  4.,  4.,  7.,
         7.,  7.,  7.,  7.,  7.,  7.,  2.,  7.,  7.,  2.,  7.,  7.,  8.,  2.,
         4.,  4.,  1.,  4.,  5.,  7.,  7.,  7.,  7.,  7.,  8.,  7.,  2.,  2.,
         2.,  2.,  7.,  7.,  7.,  2.,  7.,  2.,  7.,  2.,  2.,  7.,  7.,  8.,
         8.,  7.,  4.,  7.,  7.,  2.,  7.,  2.,  2.,  4.,  4.,  7.,  2.,  7.,
         7.,  7.,  7.,  4.,  7.,  2.,  7.,  1.,  2.,  7.,  7.,  7.,  7.,  7.,
         7.,  1.,  7.,  2.,  7.,  7.,  2.,  7.,  7., -1.,  1.,  2.,  2.,  2.,
         2.,  4.,  7.,  8.,  4.,  7.,  2.,  2.,  2.,  2.,  2.,  7.,  7.,  7.,
         7.,  7.,  2.,  7.,  2.,  2.,  7.,  1.,  2.,  2.,  2.,  7.,  6.,  8.,
         2.,  8.,  2.,  7.,  7.,  7.,  7.,  8.,  8.,  8.,  8.,  8.,  8.,  7.,
         2.,  7.,  7.,  2.,  4.,  7.,  8.,  8.,  4.,  8.,  7.,  2.,  7.,  2.,
         7.,  2.,  4.,  7.,  2., -1., -1., -1., -1., -1.,  1.,  2.,  4.,  7.,
         7.,  8.,  2.,  8.,  2.,  2.,  2.,  2.,  4.,  7.,  7.,  7.,  7.,  2.,
         8.,  7.,  2.,  7.,  2.,  7.,  7.,  2.,  2.,  4.,  2.,  1.,  1.,  2.,
         2.,  4.,  7.,  7.,  8.,  2.,  1.,  1.,  1.,  1.,  2.,  2.,  4.,  7.,
         7.,  1.,  2.,  2.,  7.,  2.,  3.,  4.,  7.,  7.,  7.,  8.,  2.,  8.,
         1.,  1.,  2.,  2.,  2.,  7.,  2.,  4.,  4.,  7.,  4.,  7.,  2.,  7.,
         4.,  1.,  8.,  4.,  4.,  1.,  7.,  7.,  2.,  2.,  2.,  2.,  2.,  2.,
         2.,  7.,  7.,  1.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  4.,  7.,  4.,
         2.,  2.,  4.,  4.,  7.,  4.,  7.,  7.,  1.,  4.,  7.,  7.,  2.,  2.,
         2.,  2.,  2.,  2.,  7.,  7.,  8., -1., -1.,  1.,  1.,  2.,  2.,  2.,
         7.,  4.,  7.,  2.,  7.,  4.,  7.,  2.,  2.,  2.,  7.,  4.,  7.,  7.,
         7.,  7.,  7.,  8.,  1.,  7.,  6.,  7.,  7.,  2.,  7.,  7.,  7.,  2.,
         2.,  8.,  8.,  8.,  8.,  2.,  4.,  7.,  8.,  7., -1., -1.,  7., -1.,
        -1., -1., -1., -1.,  1.,  8.,  2.,  2.,  4.,  7.,  7.,  7.,  4.,  4.,
         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  7.,  2.,  4.,  7.,  4.,  2.,
         2.,  1.,  2.,  2.,  1.,  7.,  7.,  2.,  2.,  4.,  8.,  4.,  7.,  7.,
         8.,  7.,  2.,  7.,  8.,  7.,  8.,  2.,  2.,  2.,  4.,  7.,  8.,  2.,
         7.,  2.,  2.,  7.,  8.,  7.,  2.,  2.,  2.,  2.,  2.,  4.,  7.,  4.,
         7.,  1.,  7.,  2.]), 'best match scores': tensor([0.9929, 0.3948, 0.9899, 0.0578, 0.1752, 0.2001, 0.3794, 0.3098, 0.0873,
        0.9999, 0.9999, 0.8868, 0.2648, 1.0000, 0.9999, 0.9980, 0.9984, 0.1771,
        0.1348, 0.7800, 0.4636, 0.2021, 1.0000, 1.0000, 0.1440, 0.9998, 0.9947,
        1.0000, 0.1104, 1.0000, 0.9983, 0.9998, 1.0000, 1.0000, 0.0644, 1.0000,
        0.9349, 0.1419, 0.2118, 0.1447, 0.2144, 0.9170, 1.0000, 0.6896, 0.1311,
        0.0580, 1.0000, 0.9561, 0.9764, 0.9998, 0.4526, 0.1058, 0.1127, 1.0000,
        0.9983, 0.9684, 0.8101, 1.0000, 0.0789, 0.2828, 0.1927, 0.8032, 0.9963,
        0.9889, 0.0894, 1.0000, 0.3822, 0.9999, 1.0000, 0.7693, 0.0663, 0.1408,
        0.9515, 0.8100, 0.0519, 0.9718, 0.9989, 0.8225, 0.2354, 0.1293, 0.0520,
        0.9509, 1.0000, 0.9927, 0.9937, 1.0000, 0.6890, 0.6259, 0.9859, 0.9822,
        0.7016, 1.0000, 0.4185, 0.9901, 0.9104, 0.0677, 0.8576, 0.7669, 0.0651,
        0.6227, 0.8084, 1.0000, 0.4005, 0.9747, 0.0642, 0.7786, 1.0000, 0.9423,
        0.1831, 1.0000, 1.0000, 1.0000, 0.9988, 0.2812, 0.9999, 0.9456, 1.0000,
        0.9477, 0.9985, 0.6311, 0.9977, 0.0742, 0.2036, 1.0000, 0.0556, 1.0000,
        0.1011, 0.9993, 1.0000, 0.2361, 0.9165, 0.9598, 0.1263, 0.2075, 0.9232,
        1.0000, 1.0000, 0.9989, 1.0000, 0.9335, 0.9990, 0.7546, 0.9437, 0.9511,
        0.8606, 1.0000, 0.9986, 0.9998, 0.4454, 0.9902, 0.3712, 1.0000, 0.7615,
        0.0851, 1.0000, 0.0888, 0.2280, 0.9996, 0.8751, 0.1179, 0.8307, 0.4512,
        0.9962, 0.7118, 1.0000, 0.1026, 0.9316, 0.9426, 0.1828, 0.1920, 0.9878,
        0.0891, 0.1234, 1.0000, 0.9992, 0.9952, 0.0811, 0.6420, 0.2921, 0.3788,
        0.4647, 0.9192, 0.6626, 1.0000, 0.9991, 1.0000, 0.9935, 0.9997, 0.2444,
        0.6434, 0.7906, 1.0000, 0.5410, 0.0901, 0.7609, 0.9623, 0.9875, 1.0000,
        1.0000, 0.9986, 0.6864, 0.8302, 0.9997, 0.9955, 0.9975, 0.3884, 0.0894,
        0.9999, 0.8015, 0.0606, 0.9664, 0.9997, 1.0000, 0.7031, 0.2305, 0.8038,
        1.0000, 0.9998, 0.9987, 0.6292, 1.0000, 0.1213, 0.8579, 0.4506, 0.0920,
        0.9994, 1.0000, 0.9928, 1.0000, 1.0000, 1.0000, 0.8830, 0.9994, 1.0000,
        0.1609, 0.9999, 1.0000, 0.9950, 0.9998, 1.0000, 0.9087, 1.0000, 0.9109,
        0.9974, 0.1422, 0.9954, 0.1184, 0.0000, 1.0000, 0.0000, 0.0000, 0.9593,
        0.7931, 1.0000, 0.1520, 1.0000, 1.0000, 0.9230, 0.8813, 0.9605, 1.0000,
        1.0000, 0.1396, 0.0780, 0.1107, 0.1874, 0.9956, 0.1479, 1.0000, 1.0000,
        1.0000, 0.9826, 1.0000, 0.9951, 1.0000, 0.5212, 1.0000, 0.0691, 0.6059,
        1.0000, 0.9999, 0.1792, 0.0538, 0.9972, 0.1316, 1.0000, 0.9966, 0.9046,
        1.0000, 0.1461, 0.9991, 1.0000, 0.2022, 0.1384, 0.3929, 0.9997, 0.9298,
        0.7318, 0.6055, 1.0000, 1.0000, 0.4535, 0.3796, 0.9922, 0.8662, 1.0000,
        0.0872, 0.9943, 0.9983, 0.0762, 0.9995, 0.1456, 0.9939, 0.9980, 0.1263,
        0.2207, 0.1704, 0.9986, 0.9484, 0.9991, 0.9910, 1.0000, 0.9992, 1.0000,
        0.1698, 1.0000, 0.2355, 0.9328, 0.8425, 0.0000, 0.1723, 0.0000, 0.0000,
        1.0000, 0.4728, 0.0568, 0.2249, 0.9998, 0.9660, 1.0000, 0.7827, 0.0000,
        0.0000, 0.0000, 0.7576, 0.1071, 0.1070, 0.1849, 0.0795, 1.0000, 0.1220,
        0.9998, 0.9752, 1.0000, 0.9996, 0.2691, 0.6906, 0.7862, 0.7714, 0.2119,
        0.4401, 0.9960, 0.9989, 1.0000, 0.9969, 0.8854, 0.4618, 0.0516, 0.9523,
        0.1589, 0.9845, 0.2499, 0.9999, 0.0699, 1.0000, 0.0855, 0.9602, 1.0000,
        0.9995, 0.9871, 0.9950, 0.9845, 0.9815, 0.9747, 1.0000, 0.9047, 0.8573,
        0.1279, 0.0701, 0.1717, 0.2017, 1.0000, 0.8298, 0.6715, 0.0776, 0.0730,
        0.9432, 1.0000, 0.7464, 0.0000, 0.8013, 0.9997, 0.9998, 0.9861, 0.1405,
        0.9105, 1.0000, 0.0816, 0.9922, 0.9991, 0.9889, 0.1948, 0.9990, 1.0000,
        1.0000, 0.1072, 0.9492, 0.0673, 0.2129, 0.3806, 0.6850, 0.2390, 0.9896,
        0.9960, 0.0749, 1.0000, 0.9994, 0.5872, 1.0000, 0.9999, 0.1703, 1.0000,
        0.1720, 0.9972, 0.1291, 0.9998, 0.1018, 0.9982, 0.1474, 0.8564, 1.0000,
        0.9998, 0.1975, 0.9898, 0.5445, 1.0000, 1.0000, 0.1544, 0.0620, 1.0000,
        0.9992, 1.0000, 0.9813, 1.0000, 1.0000, 0.7991, 0.0919, 0.9601, 1.0000,
        0.7492, 1.0000, 0.8693, 0.9081, 0.3850, 0.7121, 0.9637, 0.0891, 0.9999,
        0.7754, 0.3757, 0.9940, 0.0633, 0.2560, 0.9586, 0.9681, 0.9983, 1.0000,
        0.2972, 1.0000, 0.0796, 1.0000, 0.9748, 1.0000, 0.9983, 0.6812, 1.0000,
        0.9017, 1.0000, 0.9746, 1.0000, 0.1208, 0.9927, 0.1905, 0.9984, 0.7550,
        1.0000, 1.0000, 0.2852, 1.0000, 0.0942, 0.9998, 0.9999, 0.4236, 1.0000,
        0.9995, 0.1285, 1.0000, 1.0000, 0.2780, 0.6041, 0.7976, 0.0902, 0.8879,
        0.0778, 1.0000, 0.9961, 0.1370, 0.9969, 1.0000, 0.1106, 0.9923, 1.0000,
        0.2908, 0.9223, 1.0000, 1.0000, 0.9960, 0.1309, 0.1151, 1.0000, 1.0000,
        1.0000, 0.1660, 1.0000, 1.0000, 1.0000, 0.9965, 0.6947, 0.9972, 0.0543,
        0.7381, 0.1271, 1.0000, 1.0000, 0.2606, 1.0000, 0.9848, 0.9395, 0.0820,
        0.9893, 0.9970, 0.9804, 1.0000, 0.8522, 0.8551, 0.0000, 0.9858, 0.9508,
        1.0000, 1.0000, 0.9773, 0.2043, 0.8609, 0.9998, 0.1299, 0.4705, 0.3218,
        1.0000, 0.3786, 0.9996, 0.9999, 0.8392, 1.0000, 1.0000, 0.9964, 0.2112,
        0.9991, 0.9811, 1.0000, 0.9981, 0.9140, 0.0748, 0.2801, 0.9999, 1.0000,
        0.9953, 1.0000, 0.6487, 1.0000, 0.9668, 1.0000, 0.4794, 1.0000, 1.0000,
        1.0000, 0.8706, 0.7562, 0.6560, 0.9772, 0.9880, 1.0000, 1.0000, 0.8701,
        1.0000, 0.9581, 0.9998, 1.0000, 0.2678, 0.9730, 0.9470, 1.0000, 1.0000,
        0.9083, 1.0000, 0.2060, 1.0000, 0.1254, 0.9978, 0.7221, 0.1486, 0.9992,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9867, 0.3573, 1.0000, 0.3706,
        0.9413, 0.0523, 1.0000, 0.4730, 1.0000, 0.9834, 0.1507, 0.9977, 0.3003,
        0.8804, 1.0000, 0.9817, 0.9980, 0.1071, 0.2264, 0.0811, 0.9993, 0.7081,
        0.0824, 0.2880, 1.0000, 0.8179, 0.9983, 0.5229, 0.4849, 0.8163, 0.8632,
        0.9993, 0.2926, 1.0000, 1.0000, 0.7361, 0.0913, 0.5230, 0.9976, 0.5358,
        0.3847, 0.9994, 0.2467, 0.7727, 0.1780, 0.9996, 0.4508, 0.9867, 1.0000,
        0.9732, 0.9752, 0.1720, 0.6172, 0.5510, 1.0000, 0.3828, 0.5771, 0.1658,
        1.0000, 0.0559, 0.4823, 1.0000, 0.8356, 0.9998, 1.0000, 0.9266, 1.0000,
        0.8387, 0.6214, 1.0000, 1.0000, 0.2009, 0.2199, 1.0000, 1.0000, 0.9805,
        0.8318, 0.8744, 0.9985, 1.0000, 0.9993, 0.5146, 0.9954, 0.9990, 1.0000,
        0.2469, 1.0000, 0.9977, 1.0000, 0.8934, 1.0000, 0.9019, 0.9920, 1.0000,
        0.1382, 1.0000, 0.3140, 0.5076, 0.1981, 0.5490, 0.5831, 1.0000, 1.0000,
        0.9931, 1.0000, 1.0000, 0.9997, 0.9671, 1.0000, 0.8653, 0.9836, 1.0000,
        0.4660, 0.9966, 0.9935, 0.1883, 0.6838, 1.0000, 0.1978, 0.9983, 0.9214,
        0.1266, 0.9724, 0.0000, 0.0000, 0.1712, 0.9998, 0.8231, 0.1351, 1.0000,
        1.0000, 0.9650, 0.7804, 0.1693, 0.9559, 0.9816, 0.4759, 0.1037, 0.9453,
        0.9994, 0.9701, 0.4389, 1.0000, 0.2719, 0.9980, 0.9153, 0.9999, 1.0000,
        0.3351, 0.9962, 0.9167, 1.0000, 0.0541, 1.0000, 1.0000, 0.9734, 0.8374,
        0.9502, 0.1845, 1.0000, 0.9731, 0.9963, 0.0767, 0.9961, 0.9006, 0.9997,
        0.1901, 0.9996, 0.0000, 0.0000, 0.9590, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.9982, 0.1279, 1.0000, 1.0000, 0.8035, 0.9769, 1.0000, 0.1096,
        0.6582, 0.8748, 0.6449, 0.5942, 0.9938, 0.6941, 0.4887, 0.8312, 0.9497,
        0.1399, 0.7564, 0.7121, 0.2936, 1.0000, 1.0000, 0.9969, 0.8022, 0.9436,
        1.0000, 0.9990, 0.8123, 0.9931, 1.0000, 1.0000, 0.9045, 0.6398, 0.0736,
        0.9997, 0.1366, 0.0831, 0.3583, 0.9448, 0.1688, 0.9963, 0.2192, 0.8860,
        0.2800, 0.1015, 0.9746, 0.3672, 0.9679, 0.8291, 0.9654, 0.9970, 0.9526,
        0.2470, 0.6837, 0.5183, 0.9999, 1.0000, 0.9999, 0.9442, 1.0000, 1.0000,
        1.0000, 0.9749, 1.0000, 1.0000, 0.8550, 0.3482, 0.9929, 0.9999]), 'num_pos': 872}
2020-12-12 12:29:04,904 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.297018
2020-12-12 12:29:04,906 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-12 12:29:09,180 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-12 12:30:27,433 maskrcnn_benchmark.trainer INFO: eta: 1:11:54  iter: 180  loss: 7.7995 (8.0326)  loss_classifier: 0.5965 (0.5526)  loss_box_reg: 0.5568 (0.5057)  loss_objectness: 1.4935 (1.5956)  loss_rpn_box_reg: 5.1079 (5.3787)  time: 3.8984 (5.2615)  data: 0.2239 (1.5946)  lr: 0.000000  max mem: 1424
2020-12-12 12:31:44,888 maskrcnn_benchmark.trainer INFO: eta: 1:08:18  iter: 200  loss: 7.4623 (7.9887)  loss_classifier: 0.4414 (0.5534)  loss_box_reg: 0.4619 (0.5025)  loss_objectness: 1.4912 (1.5832)  loss_rpn_box_reg: 5.0411 (5.3496)  time: 3.8727 (5.1226)  data: 0.2142 (1.4570)  lr: 0.000000  max mem: 1424
2020-12-12 12:33:03,619 maskrcnn_benchmark.trainer INFO: eta: 1:05:11  iter: 220  loss: 7.7277 (7.9755)  loss_classifier: 0.5357 (0.5568)  loss_box_reg: 0.5037 (0.5079)  loss_objectness: 1.5415 (1.5757)  loss_rpn_box_reg: 5.1656 (5.3350)  time: 3.9238 (5.0148)  data: 0.2271 (1.3456)  lr: 0.000000  max mem: 1424
2020-12-12 12:34:25,165 maskrcnn_benchmark.trainer INFO: eta: 1:02:31  iter: 240  loss: 7.8377 (7.9706)  loss_classifier: 0.5387 (0.5556)  loss_box_reg: 0.5054 (0.5118)  loss_objectness: 1.5066 (1.5735)  loss_rpn_box_reg: 5.1266 (5.3296)  time: 4.0685 (4.9367)  data: 0.2441 (1.2538)  lr: 0.000000  max mem: 1424
2020-12-12 12:35:43,403 maskrcnn_benchmark.trainer INFO: eta: 0:59:54  iter: 260  loss: 7.9261 (7.9782)  loss_classifier: 0.5621 (0.5552)  loss_box_reg: 0.5605 (0.5106)  loss_objectness: 1.4894 (1.5705)  loss_rpn_box_reg: 5.5280 (5.3419)  time: 3.8720 (4.8578)  data: 0.2335 (1.1753)  lr: 0.000000  max mem: 1424
2020-12-12 12:37:01,140 maskrcnn_benchmark.trainer INFO: eta: 0:57:27  iter: 280  loss: 7.8881 (7.9598)  loss_classifier: 0.5182 (0.5524)  loss_box_reg: 0.5757 (0.5143)  loss_objectness: 1.4760 (1.5629)  loss_rpn_box_reg: 5.2614 (5.3302)  time: 3.8852 (4.7885)  data: 0.2189 (1.1071)  lr: 0.000000  max mem: 1424
2020-12-12 12:38:18,572 maskrcnn_benchmark.trainer INFO: eta: 0:55:09  iter: 300  loss: 8.0476 (7.9601)  loss_classifier: 0.4993 (0.5515)  loss_box_reg: 0.4487 (0.5118)  loss_objectness: 1.4745 (1.5596)  loss_rpn_box_reg: 5.4916 (5.3372)  time: 3.8711 (4.7274)  data: 0.2212 (1.0480)  lr: 0.000000  max mem: 1424
2020-12-12 12:39:36,332 maskrcnn_benchmark.trainer INFO: eta: 0:52:58  iter: 320  loss: 7.2660 (7.9241)  loss_classifier: 0.5089 (0.5509)  loss_box_reg: 0.2648 (0.5056)  loss_objectness: 1.4521 (1.5544)  loss_rpn_box_reg: 4.9946 (5.3131)  time: 3.8861 (4.6749)  data: 0.2238 (0.9968)  lr: 0.000000  max mem: 1424
2020-12-12 12:39:36,334 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 12:39:36,411 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(148 images).
2020-12-12 12:43:20,901 maskrcnn_benchmark.inference INFO: Total run time: 0:03:44.490051 (1.5168246675182033 s / img per device, on 1 devices)
2020-12-12 12:43:20,902 maskrcnn_benchmark.inference INFO: Model inference time: 0:03:29.029300 (1.4123601381843154 s / img per device, on 1 devices)
2020-12-12 12:43:20,902 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 12:43:36,812 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 12:43:36,813 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([3.2977e-02, 0.0000e+00, 0.0000e+00, 1.5097e-02, 1.1951e-02, 3.7807e-06,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9036e-02, 1.8044e-02, 2.9709e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2467e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6083e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8002e-02, 8.3297e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.9875e-02, 3.9849e-02, 2.1005e-02, 4.2926e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4256e-01, 1.9678e-02,
        1.7714e-02, 4.7650e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.2977e-02, 2.1682e-02, 0.0000e+00, 5.5110e-03, 0.0000e+00,
        0.0000e+00, 9.9961e-02, 9.5648e-02, 2.1002e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0116e-02, 8.5174e-02,
        2.1682e-02, 9.0299e-02, 4.0827e-02, 2.1526e-02, 7.3999e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4056e-02, 4.6515e-03,
        0.0000e+00, 9.9421e-03, 2.0304e-03, 9.0680e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.6100e-02, 8.4312e-02,
        0.0000e+00, 4.0629e-02, 2.1337e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.0852e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7000e-02, 2.7216e-02, 0.0000e+00,
        1.6496e-01, 1.0068e-01, 2.2888e-02, 3.1593e-03, 2.9653e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2977e-02, 0.0000e+00, 0.0000e+00, 5.6887e-02, 3.9671e-02, 2.8526e-03,
        6.0256e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.9802e-02, 1.8946e-02, 1.7104e-02, 1.6310e-02, 7.0389e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8932e-02,
        4.7375e-02, 0.0000e+00, 5.8123e-02, 2.4613e-02, 6.6624e-04, 2.0296e-01,
        0.0000e+00, 0.0000e+00, 6.6919e-02, 2.0963e-04, 0.0000e+00, 2.1486e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.4599e-02, 0.0000e+00, 0.0000e+00, 2.1495e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7477e-03, 1.4168e-06, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.0336e-02, 2.9282e-05, 0.0000e+00, 3.8408e-02, 3.2212e-02, 2.7972e-02,
        1.0133e-02, 1.7736e-03, 1.2857e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.1902e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4023e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1490e-02,
        4.5125e-02, 2.1131e-02, 1.5664e-01, 2.1682e-02, 0.0000e+00, 3.5669e-02,
        7.1262e-05, 3.1533e-05, 6.7644e-02, 1.1565e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.1624e-02, 2.3553e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2139e-02, 1.5874e-02,
        3.2977e-02, 2.1682e-02, 1.7310e-02, 1.1171e-01, 4.8635e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0388e-01, 6.1333e-02, 1.0153e-02, 1.7438e-01, 1.2503e-01, 0.0000e+00,
        5.2728e-02, 2.7473e-02, 1.5047e-02, 1.2723e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5119e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7598e-01, 7.4606e-02, 5.2307e-02, 1.1999e-01, 6.7345e-02, 2.0873e-02,
        1.1488e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1919e-01, 2.1682e-02, 7.4605e-03, 2.1620e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 3.0122e-02, 1.4191e-03, 1.3658e-12,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2268e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5516e-02,
        2.3582e-02, 1.9380e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3525e-01, 6.4323e-02,
        2.8705e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.5356e-02, 5.8262e-02, 2.1682e-02, 2.0757e-01, 4.3437e-02,
        0.0000e+00, 6.4149e-02, 2.8026e-02, 2.6379e-02, 1.6143e-02, 1.0193e-02,
        1.6090e-03, 1.5495e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9156e-02, 2.0298e-02, 2.5804e-03, 5.7234e-02, 5.5269e-02, 3.0695e-02,
        2.6716e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2180e-01, 1.2003e-01, 8.0583e-02, 3.4044e-02, 1.3034e-02, 3.4833e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0257e-01,
        3.6652e-02, 2.7590e-02, 3.8358e-02, 3.8024e-02, 2.5875e-02, 1.5874e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.1749e-02, 2.7544e-03, 0.0000e+00, 3.2139e-02, 2.2508e-02,
        2.2480e-02, 1.8815e-02, 1.5874e-02, 3.4811e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2476e-01, 4.4969e-02, 2.8420e-03,
        1.6204e-02, 5.7531e-03, 0.0000e+00, 6.7900e-02, 5.0793e-02, 2.1682e-02,
        4.2947e-02, 1.8194e-02, 1.4689e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.2933e-02, 3.2977e-02, 0.0000e+00, 5.2122e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 2.8841e-02, 9.6225e-03, 5.6232e-03, 4.3746e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8833e-02,
        5.8835e-02, 3.4157e-02, 5.4870e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5301e-01, 8.6347e-02,
        8.0022e-02, 1.9947e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.2213e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2077e-01, 2.0373e-01,
        2.2682e-03, 1.7144e-01, 3.2286e-02, 1.5874e-02, 1.2699e-02, 1.1714e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.3075e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6351e-02, 1.5874e-02,
        1.1783e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8652e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 2.1388e-02, 1.0508e-02, 5.7659e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5746e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1508e-02, 4.0805e-02,
        3.1058e-02, 9.8390e-03, 6.9790e-03, 5.8647e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.3817e-01, 4.6985e-03, 0.0000e+00, 1.0626e-01, 6.1792e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2977e-02, 2.6645e-02, 2.1682e-02, 2.7782e-01, 2.2089e-02, 1.5349e-02,
        8.5750e-03, 5.1076e-03, 1.3951e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.0412e-02, 2.9985e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.8713e-02, 1.8474e-02, 4.8617e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.6415e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3552e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.0091e-02, 1.3658e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.6697e-02, 3.2139e-02, 1.5874e-02, 4.3752e-02, 1.9996e-02, 1.3790e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.6409e-02, 5.6037e-02, 3.2977e-02, 5.4068e-02, 3.7642e-02, 0.0000e+00,
        3.2877e-03, 0.0000e+00, 0.0000e+00, 1.1740e-01, 6.4084e-02, 0.0000e+00,
        6.8581e-02, 1.5281e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0633e-01, 6.0117e-02, 2.6302e-03, 2.2169e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2820e-02,
        3.5719e-02, 2.1682e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8956e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.8230e-02, 2.8804e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.9513e-02, 1.8220e-02, 1.6366e-02, 1.3251e-02, 4.5925e-04,
        1.0843e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.3250e-02, 7.2055e-02, 6.1775e-02, 2.3220e-02, 2.8237e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6550e-02,
        3.2015e-02, 8.4090e-05, 4.4743e-02, 4.3440e-02, 0.0000e+00, 5.0173e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8115e-03,
        0.0000e+00, 0.0000e+00, 2.8214e-02, 5.9715e-03, 0.0000e+00, 0.0000e+00,
        1.3459e-01, 7.0157e-02, 3.0043e-02, 4.5408e-02, 3.2139e-02, 3.4811e-03,
        6.2489e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.4331e-01, 9.6969e-02, 0.0000e+00, 7.1825e-02,
        1.0614e-03, 1.4418e-07, 1.0678e-03, 0.0000e+00, 0.0000e+00, 1.8891e-02,
        1.5970e-03, 1.0925e-04, 1.7639e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.0551e-02, 3.2366e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.9713e-02, 0.0000e+00, 0.0000e+00, 1.1900e-01,
        3.3423e-02, 3.2977e-02, 8.9161e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9201e-01,
        6.2901e-03, 0.0000e+00]), 'gt_labels': tensor([7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 1, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7,
        4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 4, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 7, 7, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 7, 7, 4]), 'best match labels': tensor([ 7.,  7.,  8.,  2.,  7.,  4.,  2.,  7.,  7.,  7.,  7.,  2.,  1.,  2.,
         2.,  2.,  4.,  7.,  7.,  8.,  1.,  2.,  2.,  2.,  4.,  7.,  7.,  7.,
         7.,  7.,  7.,  7.,  2.,  7.,  1.,  1.,  1.,  7.,  1.,  2.,  2.,  7.,
         7.,  2.,  2.,  7.,  4.,  7.,  7.,  7.,  7.,  7.,  2.,  2.,  7.,  2.,
         2.,  2.,  2.,  7.,  7.,  1.,  7.,  7.,  7.,  7.,  2.,  2.,  2.,  4.,
         2.,  2.,  4.,  4.,  7.,  2.,  7.,  2.,  2.,  2.,  8.,  7.,  2.,  2.,
         2.,  2.,  4.,  7.,  8.,  2.,  7.,  2.,  2.,  2.,  7.,  7.,  1.,  7.,
         2.,  7.,  8.,  2.,  2.,  8.,  7.,  2.,  7.,  7.,  2.,  2.,  2.,  2.,
         2.,  2.,  2.,  2.,  7.,  8.,  2.,  7.,  4.,  7.,  2.,  2.,  2.,  2.,
         4.,  7.,  7.,  7.,  7.,  2.,  7.,  2.,  8.,  2.,  2.,  7.,  2.,  4.,
         7.,  7.,  2.,  1.,  1.,  2.,  1.,  1.,  2.,  2.,  4.,  4.,  7.,  2.,
         7.,  8.,  7.,  7.,  2.,  4.,  2.,  7.,  7.,  7.,  7.,  1.,  7.,  8.,
         2.,  2.,  4.,  5.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  2.,  4.,  5.,
         7.,  2.,  2.,  2.,  2.,  2.,  7.,  2.,  7.,  7.,  7.,  1.,  7.,  2.,
         7.,  2.,  7.,  7.,  8.,  8.,  1.,  7.,  8.,  8., -1., -1.,  2.,  1.,
         2.,  4.,  4.,  7.,  7.,  7.,  7.,  7., -1., -1., -1.,  1.,  2.,  2.,
         4.,  7.,  7.,  8.,  7.,  7.,  7.,  7.,  8.,  2.,  2.,  2.,  7.,  7.,
         2.,  2.,  2.,  2.,  2.,  2.,  7.,  7.,  7.,  7., -1., -1.,  7., -1.,
         1.,  2.,  7.,  8., -1.,  1.,  1.,  2.,  2.,  2.,  7.,  7.,  8., -1.,
        -1., -1., -1., -1., -1., -1., -1.,  2.,  4.,  7.,  2.,  7.,  4.,  2.,
         1.,  1.,  2.,  4.,  4.,  7.,  8.,  2.,  2.,  7.,  4.,  8.,  7.,  7.,
         2.,  2.,  7.,  2.,  7.,  2.,  6.,  7.,  7.,  1.,  2.,  2.,  4.,  4.,
         7.,  7.,  7.,  7.,  2.,  7.,  7.,  7.,  2.,  2.,  2.,  2.,  2.,  2.,
         4.,  7.,  2.,  2.,  4.,  7.,  8.,  2., -1.,  2.,  2.,  2.,  2.,  2.,
         2.,  7.,  2.,  4.,  7., -1., -1., -1.,  1.,  2.,  2.,  7.,  7.,  1.,
         2.,  7.,  2.,  2.,  4.,  4.,  7.,  7.,  7.,  2.,  4.,  2.,  2.,  7.,
         2.,  7.,  7.,  7.,  7.,  8.,  6.,  7.,  7.,  2.,  7.,  8.,  7.,  8.,
         2.,  7.,  7.,  7.,  8.,  7.,  2.,  4.,  8.,  2.,  4.,  7.,  2.,  2.,
         2.,  7.,  8.,  1.,  4.,  2.,  2.,  2.,  2.,  2.,  1.,  4.,  4.,  4.,
         8.,  2.,  7.,  7.,  1.,  2.,  7.,  1.,  7.,  7.,  7.,  2.,  7.,  2.,
         7.,  2.,  4.,  7.,  7.,  7.,  2.,  2.,  2.,  7.,  7.,  7.,  8.,  8.,
         7.,  2.,  4.,  7.,  4.,  7.,  1.,  2.,  7.,  7.,  7.,  2.,  8.,  7.,
         2.,  2.,  2.,  1.,  7.,  4.,  7.,  7.,  1.,  7.,  2.,  2.,  2.,  7.,
         1.,  8.,  8.,  7.,  2.,  5.,  8.,  7.,  2., -1.,  1.,  2.,  2.,  8.,
         4.,  4.,  7.,  7.,  2.,  4.,  2.,  4.,  2.,  2.,  4.,  4.,  7.,  8.,
         2.,  4.,  7.,  2.,  2.,  2.,  7.,  2.,  4.,  8.,  8.,  7.,  7.,  7.,
         7.,  4.,  8.,  8.,  2.,  2.,  7.,  1.,  1.,  1.,  2.,  2.,  4.,  8.,
         4.,  8.,  7.,  1.,  7.,  7.,  4.,  7.,  2.,  2.,  7.,  7.,  7.,  7.,
         7.,  7.,  2.,  4.,  6.,  7.,  7.,  1.,  2.,  1.,  2.,  2.,  4.,  6.,
         7.,  7.,  7.,  7.,  1.,  8.,  2.,  4.,  8., -1.,  1.,  1.,  2.,  2.,
         2.,  2.,  4.,  4.,  2.,  7.,  2.,  7.,  2.,  2.,  2.,  2.,  4.,  7.,
         7.,  2.,  4.,  7.,  1.,  1.,  1.,  7.,  1.,  7.,  7.,  7.,  2.,  7.,
         7.,  7.,  7.,  2.,  1.,  7.,  2.,  2.,  7.,  7.,  7.,  8.,  8.,  8.,
         7.,  7.,  7.,  8.,  4.,  7.,  1.,  4.,  1.,  7.,  2.,  7.,  6.,  7.,
         2.,  7.,  7.,  8.,  7., -1., -1., -1., -1.,  1.,  2.,  2.,  2.,  2.,
         2.,  8.,  2.,  7.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  4.,  2.,
         2.,  2.,  2.,  2.,  2.,  7.,  2.,  8.,  7.,  7.,  7.,  1.,  1.,  1.,
         1.,  2.,  7.,  1.,  7.,  7.,  1.,  1.,  1.,  2.,  2.,  4.,  4.,  4.,
         7.,  1.,  2.,  7.,  2.,  2.,  2.,  2.,  4.,  4.,  7.,  8.,  2.,  7.,
         7.,  1.,  2.,  7.,  2.,  7.,  2.,  2.,  7.,  7.,  1.,  4.,  7.,  2.,
         4.,  7.,  7.,  8.,  8.,  7.,  7.,  2.,  2.,  2.,  2.,  4.,  4.,  7.,
         7.,  2.,  7.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  7.,  8.,  1.,  7.,
         2.,  2.,  4.,  1.,  4.,  7.,  7.,  8.,  7.,  7.,  4.,  7.,  1.,  2.,
         2.,  2.,  2.,  2.,  2.,  4.,  7.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,
         2.,  7.,  7.,  2.,  7.,  7.,  8.,  8.,  1.,  2.,  4.,  7.,  2.,  7.,
         7.,  2.,  2.,  2.,  1.,  2.,  4.,  2.,  6.,  7.,  7.,  7.,  7.,  2.,
         7.,  2.,  8.,  8.,  8.,  2.,  7.,  4.,  1.,  7., -1., -1.,  1.,  1.,
         1.,  2.,  2.,  4.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  4.,  4.,
         7.,  1.,  4.,  1.,  1.,  1.,  1.,  2.,  2.,  2.,  7.,  7.,  4.,  7.,
         7.,  7.,  2.,  2.,  2.,  7.,  2.,  2.,  2.,  2.,  4.,  7.,  2.,  8.,
         7.,  2.,  7.,  2.,  7.,  2.,  2.,  2.,  2.,  4.,  6.,  7.,  7.,  7.,
         2.,  2.,  4.,  2.,  7.,  2., -1.,  1.,  2.,  2.,  7.,  2.,  2.,  2.,
         7.,  1.,  2.,  7.]), 'best match scores': tensor([1.0000, 1.0000, 0.7164, 1.0000, 0.4056, 0.6586, 0.1475, 0.9995, 1.0000,
        0.9384, 0.9919, 0.9918, 0.1488, 0.9999, 0.1242, 1.0000, 0.9991, 0.9955,
        0.4612, 0.9954, 0.3288, 0.9586, 0.2411, 0.2013, 1.0000, 1.0000, 1.0000,
        1.0000, 0.9990, 0.8571, 0.0855, 0.2126, 0.9809, 0.1690, 0.9985, 0.9868,
        0.9509, 0.9997, 0.9686, 0.9573, 0.9755, 0.7861, 0.9999, 0.9979, 1.0000,
        0.9966, 0.9861, 0.9593, 0.7078, 1.0000, 0.9996, 0.9995, 0.8585, 0.9983,
        1.0000, 0.1184, 0.2478, 0.0620, 0.9999, 1.0000, 0.8634, 1.0000, 1.0000,
        0.0824, 1.0000, 0.3669, 0.9889, 0.5859, 0.6612, 0.9941, 0.9998, 0.9995,
        0.0653, 0.3387, 0.2928, 0.8866, 0.9998, 0.5038, 0.6113, 1.0000, 0.2911,
        0.4754, 0.9991, 0.2095, 1.0000, 0.7865, 0.3925, 0.9467, 0.5682, 0.9951,
        0.9891, 0.9999, 0.8967, 0.4762, 1.0000, 0.0652, 0.9996, 0.4919, 0.9673,
        0.3123, 0.6133, 0.9995, 0.3351, 0.1167, 0.9998, 0.9764, 0.2674, 0.9922,
        0.0807, 1.0000, 1.0000, 0.9382, 0.2814, 1.0000, 0.9994, 0.9887, 0.9686,
        0.9995, 0.3693, 1.0000, 0.8967, 0.2659, 0.8338, 0.8467, 0.1445, 0.2998,
        1.0000, 1.0000, 1.0000, 0.3898, 0.1773, 0.2776, 0.7924, 0.7607, 0.9984,
        0.1095, 0.3333, 1.0000, 0.9904, 0.2469, 0.9998, 0.1467, 0.9999, 0.2491,
        0.9788, 0.9918, 0.9999, 0.9887, 1.0000, 0.3914, 0.9998, 1.0000, 0.9620,
        0.7417, 0.8581, 0.1397, 0.6692, 0.9710, 0.9113, 0.9722, 0.0510, 0.4025,
        0.2157, 0.9947, 1.0000, 0.9995, 0.9710, 0.0640, 0.7883, 0.4366, 0.9908,
        0.1451, 0.9997, 0.0702, 0.5480, 0.9995, 0.9998, 0.9916, 0.9956, 1.0000,
        0.7860, 0.1767, 0.1549, 1.0000, 0.6053, 0.5345, 1.0000, 0.5734, 0.2514,
        0.9975, 0.9995, 0.9934, 0.4026, 0.0882, 0.0559, 0.2121, 0.3795, 0.8200,
        1.0000, 1.0000, 0.9996, 0.9537, 0.0508, 0.2118, 0.5109, 0.9877, 0.0000,
        0.0000, 0.9980, 0.0990, 0.9989, 0.9997, 0.9526, 1.0000, 0.9991, 0.9336,
        1.0000, 0.9940, 0.0000, 0.0000, 0.0000, 0.8370, 1.0000, 0.1973, 0.9969,
        0.9465, 1.0000, 1.0000, 0.9692, 0.9616, 0.8964, 0.5842, 1.0000, 0.9869,
        1.0000, 1.0000, 0.9862, 0.9989, 1.0000, 0.9999, 0.9999, 1.0000, 0.2457,
        0.9784, 0.9157, 0.8060, 0.9949, 0.9999, 0.0000, 0.0000, 0.9728, 0.0000,
        0.9996, 0.0502, 0.9938, 0.9998, 0.0000, 0.9334, 0.3349, 0.8825, 1.0000,
        0.2518, 0.9324, 0.9877, 0.9523, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.9701, 0.7374, 1.0000, 1.0000, 0.9903, 0.9885,
        0.6092, 0.9783, 0.4666, 0.2651, 0.6334, 1.0000, 0.9991, 0.9999, 0.6046,
        1.0000, 0.3311, 0.9977, 0.2361, 0.7264, 0.9371, 1.0000, 0.9011, 1.0000,
        0.1113, 1.0000, 0.0902, 1.0000, 1.0000, 1.0000, 0.5589, 0.3319, 1.0000,
        0.0576, 0.9989, 1.0000, 0.9236, 0.3645, 0.2157, 0.9988, 1.0000, 0.9972,
        0.9995, 0.0929, 0.4647, 0.6511, 0.0732, 0.9980, 0.9929, 1.0000, 1.0000,
        0.3234, 0.9808, 0.9826, 0.9437, 0.0908, 1.0000, 0.0000, 0.3931, 0.0557,
        0.0750, 0.9691, 0.9895, 0.6969, 0.7896, 0.1732, 1.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.1816, 0.9920, 0.0757, 0.0691, 1.0000, 0.7315, 1.0000,
        0.7620, 1.0000, 0.2363, 0.9998, 0.1149, 0.9737, 1.0000, 0.2780, 0.8050,
        0.9963, 0.7657, 1.0000, 0.9680, 0.0624, 0.9914, 1.0000, 0.9082, 0.1949,
        0.0754, 1.0000, 0.0865, 1.0000, 1.0000, 0.0882, 1.0000, 1.0000, 0.9351,
        0.9990, 0.4626, 0.9968, 0.7084, 0.9977, 1.0000, 0.5318, 0.7763, 0.1974,
        0.5260, 0.9995, 1.0000, 0.3442, 0.9993, 0.4991, 0.9033, 0.8352, 0.2190,
        1.0000, 0.9997, 0.9977, 0.8549, 0.9866, 0.1715, 0.7866, 1.0000, 0.8108,
        0.7467, 0.7439, 0.9997, 1.0000, 0.9962, 0.9800, 0.0952, 0.9993, 0.1601,
        0.9991, 0.9991, 0.9998, 0.0529, 0.9834, 0.9998, 1.0000, 0.1274, 0.9912,
        0.9848, 1.0000, 0.8447, 1.0000, 0.3117, 1.0000, 0.1647, 0.1675, 1.0000,
        0.2486, 1.0000, 0.9653, 0.9774, 0.9945, 1.0000, 0.8383, 1.0000, 0.9928,
        0.0505, 0.6957, 0.9493, 0.0872, 1.0000, 0.2724, 0.0914, 1.0000, 1.0000,
        0.8243, 1.0000, 1.0000, 0.9619, 0.9996, 0.9529, 0.0526, 0.2217, 1.0000,
        0.0630, 0.9888, 0.0578, 0.9970, 0.4458, 0.8495, 0.9973, 0.9998, 0.2417,
        0.7611, 1.0000, 0.7073, 0.0000, 1.0000, 0.8007, 1.0000, 1.0000, 0.9931,
        0.9924, 1.0000, 1.0000, 1.0000, 0.9709, 0.5377, 1.0000, 1.0000, 0.8901,
        0.8629, 0.6555, 1.0000, 0.7656, 0.8875, 0.8633, 0.9999, 0.9152, 0.9924,
        0.9743, 1.0000, 0.9999, 0.0574, 0.3062, 0.9999, 0.9980, 1.0000, 0.5008,
        1.0000, 0.2670, 0.4595, 0.7894, 0.7966, 1.0000, 0.0533, 0.1565, 0.0530,
        0.9995, 0.2604, 0.9141, 0.3788, 0.9981, 0.4349, 0.8164, 0.1570, 1.0000,
        1.0000, 0.9984, 1.0000, 0.4616, 0.7128, 0.1941, 0.0584, 0.9612, 0.9983,
        0.6410, 0.9911, 0.9797, 0.9962, 0.9084, 0.9959, 0.9966, 1.0000, 0.2421,
        0.2145, 0.9491, 1.0000, 0.9757, 0.0525, 0.9724, 1.0000, 0.7705, 0.1192,
        0.0778, 0.0763, 0.9213, 0.9570, 0.6172, 0.2229, 0.0000, 0.0667, 0.9499,
        0.0668, 0.9604, 0.9698, 1.0000, 0.8467, 0.9998, 0.0971, 0.2715, 0.9998,
        0.4670, 0.3735, 1.0000, 0.1018, 0.9895, 0.8478, 1.0000, 0.9425, 0.8756,
        0.7224, 0.1003, 0.6793, 1.0000, 0.9954, 0.9857, 0.9451, 0.6725, 0.0517,
        0.6183, 1.0000, 0.8569, 1.0000, 0.9972, 0.6634, 0.1427, 0.9919, 1.0000,
        1.0000, 0.9618, 0.8393, 1.0000, 0.9999, 0.3356, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6222, 1.0000, 0.7230, 0.9966, 1.0000, 1.0000, 0.5660, 0.3594,
        1.0000, 0.0751, 1.0000, 0.4679, 0.8370, 1.0000, 0.9998, 0.1464, 0.8498,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0613, 1.0000, 0.3708, 0.0697, 1.0000,
        0.8223, 0.7553, 0.9990, 0.9803, 0.0816, 0.9911, 0.8009, 1.0000, 1.0000,
        1.0000, 1.0000, 0.9739, 0.9997, 0.0571, 0.1667, 0.4094, 0.0843, 1.0000,
        0.6390, 0.2548, 0.8046, 0.3561, 1.0000, 1.0000, 0.3567, 0.9999, 0.1845,
        0.6909, 0.9994, 0.7805, 1.0000, 0.9999, 0.9991, 1.0000, 0.8380, 0.1713,
        0.9993, 0.6847, 0.9912, 0.1108, 0.9981, 0.0741, 1.0000, 0.0665, 0.2527,
        0.1828, 0.8448, 0.9443, 0.9939, 0.9994, 0.9759, 0.4211, 0.9657, 0.0555,
        0.1252, 0.9439, 0.9981, 0.5849, 0.2866, 0.2542, 1.0000, 0.9996, 0.5076,
        0.8061, 0.8594, 1.0000, 0.9653, 1.0000, 0.9547, 0.8454, 0.9137, 0.8642,
        0.9749, 0.1081, 0.9999, 0.9999, 1.0000, 0.9579, 0.9952, 0.1032, 0.0509,
        0.9993, 0.4661, 0.5333, 0.5579, 0.6231, 0.0734, 0.8181, 1.0000, 1.0000,
        0.0655, 0.1456, 0.1950, 0.9074, 0.9997, 0.7836, 0.4984, 1.0000, 0.9116,
        1.0000, 0.9808, 0.9909, 1.0000, 0.0935, 1.0000, 0.5961, 1.0000, 1.0000,
        1.0000, 1.0000, 0.9990, 0.9196, 0.3239, 1.0000, 0.1697, 0.7055, 1.0000,
        0.9904, 0.4472, 0.9671, 0.1454, 0.3524, 0.9664, 0.9975, 1.0000, 0.7207,
        0.8076, 1.0000, 1.0000, 0.5642, 1.0000, 0.1845, 0.7480, 0.8294, 0.8199,
        1.0000, 0.5586, 0.3851, 0.9949, 1.0000, 0.9298, 1.0000, 1.0000, 1.0000,
        0.3675, 0.4141, 0.9954, 1.0000, 0.9962, 0.1252, 0.9996, 0.0522, 0.9999,
        0.0906, 0.9997, 0.4242, 1.0000, 1.0000, 0.9992, 1.0000, 0.7647, 0.6526,
        0.9771, 0.9967, 0.0000, 0.0000, 1.0000, 0.8960, 0.6162, 1.0000, 0.2911,
        0.8875, 0.4602, 0.6423, 1.0000, 0.7429, 0.3781, 1.0000, 0.4659, 0.8246,
        0.9899, 0.9970, 0.9477, 0.1030, 0.9726, 0.4583, 0.4300, 0.6429, 0.9999,
        1.0000, 0.9996, 0.1962, 0.2686, 0.9844, 1.0000, 1.0000, 0.1604, 1.0000,
        1.0000, 0.1374, 0.9998, 0.9999, 0.9845, 0.3581, 0.9996, 0.0822, 0.9954,
        0.0675, 0.3233, 0.1933, 0.9711, 1.0000, 1.0000, 0.7028, 0.3338, 0.0629,
        0.1148, 0.9987, 0.2628, 0.0544, 0.9996, 0.4340, 0.3910, 1.0000, 0.9210,
        0.9784, 0.9999, 1.0000, 0.9997, 0.8116, 0.0000, 0.1325, 0.9936, 0.9810,
        0.9972, 0.1863, 1.0000, 1.0000, 0.9872, 0.4142, 1.0000, 0.6452]), 'num_pos': 872}
2020-12-12 12:43:36,925 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.313073
2020-12-12 12:43:36,927 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-12 12:43:41,433 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-12 12:44:58,947 maskrcnn_benchmark.trainer INFO: eta: 0:58:50  iter: 340  loss: 8.0195 (7.9312)  loss_classifier: 0.3991 (0.5512)  loss_box_reg: 0.4011 (0.5042)  loss_objectness: 1.5366 (1.5530)  loss_rpn_box_reg: 5.3756 (5.3228)  time: 3.8742 (5.3488)  data: 0.2212 (1.6722)  lr: 0.000000  max mem: 1424
2020-12-12 12:46:16,376 maskrcnn_benchmark.trainer INFO: eta: 0:56:10  iter: 360  loss: 7.4843 (7.9097)  loss_classifier: 0.4941 (0.5513)  loss_box_reg: 0.4549 (0.5030)  loss_objectness: 1.4555 (1.5474)  loss_rpn_box_reg: 5.0631 (5.3080)  time: 3.8698 (5.2667)  data: 0.2216 (1.5915)  lr: 0.000000  max mem: 1424
2020-12-12 12:47:33,905 maskrcnn_benchmark.trainer INFO: eta: 0:53:39  iter: 380  loss: 7.4384 (7.8925)  loss_classifier: 0.4447 (0.5490)  loss_box_reg: 0.5847 (0.5057)  loss_objectness: 1.4724 (1.5425)  loss_rpn_box_reg: 5.1649 (5.2953)  time: 3.8742 (5.1935)  data: 0.2205 (1.5194)  lr: 0.000000  max mem: 1424
2020-12-12 12:48:51,219 maskrcnn_benchmark.trainer INFO: eta: 0:51:16  iter: 400  loss: 7.1939 (7.8693)  loss_classifier: 0.5065 (0.5486)  loss_box_reg: 0.2946 (0.5019)  loss_objectness: 1.3867 (1.5355)  loss_rpn_box_reg: 4.8952 (5.2833)  time: 3.8653 (5.1271)  data: 0.2132 (1.4542)  lr: 0.000000  max mem: 1424
2020-12-12 12:50:09,219 maskrcnn_benchmark.trainer INFO: eta: 0:48:59  iter: 420  loss: 7.3638 (7.8547)  loss_classifier: 0.5495 (0.5514)  loss_box_reg: 0.4670 (0.5056)  loss_objectness: 1.4246 (1.5307)  loss_rpn_box_reg: 4.8375 (5.2670)  time: 3.8834 (5.0687)  data: 0.2192 (1.3955)  lr: 0.000000  max mem: 1424
2020-12-12 12:51:26,771 maskrcnn_benchmark.trainer INFO: eta: 0:46:48  iter: 440  loss: 7.5374 (7.8366)  loss_classifier: 0.6087 (0.5541)  loss_box_reg: 0.5852 (0.5093)  loss_objectness: 1.3946 (1.5253)  loss_rpn_box_reg: 4.7752 (5.2480)  time: 3.8795 (5.0146)  data: 0.2100 (1.3418)  lr: 0.000000  max mem: 1424
2020-12-12 12:52:44,057 maskrcnn_benchmark.trainer INFO: eta: 0:44:40  iter: 460  loss: 7.0622 (7.8130)  loss_classifier: 0.3726 (0.5495)  loss_box_reg: 0.3827 (0.5060)  loss_objectness: 1.4148 (1.5219)  loss_rpn_box_reg: 4.7867 (5.2356)  time: 3.8567 (4.9645)  data: 0.2154 (1.2929)  lr: 0.000000  max mem: 1424
2020-12-12 12:54:01,387 maskrcnn_benchmark.trainer INFO: eta: 0:42:37  iter: 480  loss: 7.5183 (7.8023)  loss_classifier: 0.5078 (0.5498)  loss_box_reg: 0.5867 (0.5091)  loss_objectness: 1.4756 (1.5188)  loss_rpn_box_reg: 4.9008 (5.2246)  time: 3.8647 (4.9188)  data: 0.2211 (1.2482)  lr: 0.000000  max mem: 1424
2020-12-12 12:54:01,389 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 12:54:01,458 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(148 images).
2020-12-12 12:57:45,599 maskrcnn_benchmark.inference INFO: Total run time: 0:03:44.141147 (1.5144672103830286 s / img per device, on 1 devices)
2020-12-12 12:57:45,599 maskrcnn_benchmark.inference INFO: Model inference time: 0:03:28.739870 (1.410404529120471 s / img per device, on 1 devices)
2020-12-12 12:57:45,600 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 12:58:01,575 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 12:58:01,575 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([3.2977e-02, 1.5304e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2654e-01, 1.7345e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6021e-02, 5.3918e-06, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9843e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.0958e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5870e-01, 1.5863e-01,
        3.8229e-02, 3.3179e-02, 9.4180e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.9887e-02, 3.4873e-02, 0.0000e+00, 1.8452e-01, 1.9912e-03,
        0.0000e+00, 2.0852e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00,
        0.0000e+00, 1.7983e-01, 5.8060e-02, 5.3317e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2139e-02, 0.0000e+00,
        0.0000e+00, 3.6556e-02, 3.5553e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.6575e-02, 2.1158e-02, 0.0000e+00, 3.9984e-03, 3.5674e-05,
        8.2890e-02, 3.8641e-02, 2.4141e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2870e-02, 1.3336e-02, 1.0982e-03,
        2.8426e-01, 1.1658e-01, 2.8139e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0675e-02, 7.6673e-02, 1.8321e-02,
        1.5710e-03, 1.2768e-03, 3.1165e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2696e-01, 4.3835e-02, 2.8053e-02, 2.2436e-02, 1.1467e-02, 8.2390e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8402e-02,
        0.0000e+00, 0.0000e+00, 7.6791e-02, 4.8321e-02, 0.0000e+00, 4.7139e-02,
        3.2977e-02, 7.6202e-04, 1.0413e-03, 6.1842e-06, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.8840e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.3609e-02, 2.2067e-02, 4.5131e-03, 6.5335e-02, 3.0854e-02, 1.1474e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.3122e-05, 0.0000e+00, 0.0000e+00, 3.1207e-01, 5.4172e-02, 2.4164e-02,
        2.1603e-02, 2.8100e-03, 1.1396e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1028e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6636e-02,
        3.2977e-02, 0.0000e+00, 3.3749e-02, 8.2961e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9018e-02,
        4.6178e-02, 0.0000e+00, 7.2472e-02, 2.4889e-02, 2.8221e-03, 9.3636e-02,
        3.3745e-02, 0.0000e+00, 3.2348e-02, 4.2537e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3945e-02, 0.0000e+00,
        4.8458e-02, 3.2977e-02, 0.0000e+00, 9.0437e-02, 1.2396e-02, 1.1212e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4393e-01, 5.0519e-02, 0.0000e+00, 1.3946e-01, 5.7289e-02, 2.6556e-02,
        6.2971e-02, 6.2943e-02, 1.2849e-02, 6.1448e-03, 5.7592e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1274e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5179e-01, 6.9426e-02, 6.1237e-02, 6.4495e-02, 6.1766e-02, 3.2139e-02,
        2.3798e-02, 1.0991e-02, 6.6303e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.8982e-02, 2.2751e-02, 0.0000e+00, 1.3761e-08,
        1.0711e-08, 6.5010e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.9492e-02, 2.4049e-02, 2.1682e-02, 6.7320e-02,
        4.9849e-02, 1.6769e-02, 6.3807e-03, 4.8406e-03, 4.6011e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.7584e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8490e-02,
        4.0369e-02, 2.1581e-02, 1.9173e-02, 1.3449e-02, 1.1579e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5852e-03, 6.0329e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.1530e-02, 3.8753e-02, 0.0000e+00, 4.0916e-02, 0.0000e+00,
        0.0000e+00, 3.2139e-02, 2.4661e-02, 1.7474e-02, 1.7390e-02, 1.4050e-02,
        7.2633e-03, 6.8580e-03, 2.0348e-03, 9.9006e-04, 0.0000e+00, 0.0000e+00,
        1.3607e-01, 0.0000e+00, 0.0000e+00, 9.6572e-02, 9.6003e-02, 7.9976e-02,
        1.6965e-02, 2.9772e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.3719e-02, 2.8390e-02, 8.1831e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8055e-02,
        3.0544e-02, 4.8471e-03, 4.5294e-02, 3.6201e-02, 2.9003e-02, 2.4942e-02,
        1.5874e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.1749e-02, 5.5354e-03, 0.0000e+00, 5.4970e-02, 3.4679e-02,
        1.5874e-02, 1.0539e-02, 9.4847e-03, 2.9219e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5526e-02, 3.4770e-03, 0.0000e+00,
        1.1420e-01, 3.7570e-02, 2.7426e-02, 6.1728e-02, 3.2977e-02, 2.8728e-02,
        4.6013e-02, 8.4207e-03, 5.8092e-03, 4.8157e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6173e-02, 0.0000e+00, 0.0000e+00,
        5.5382e-02, 3.2977e-02, 1.1720e-02, 8.2709e-03, 5.9814e-03, 4.5222e-03,
        3.8890e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 1.0758e-02, 8.6630e-03, 8.0393e-03, 4.3914e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6978e-02,
        3.2139e-02, 5.5254e-03, 3.4222e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5950e-01, 1.3946e-01,
        1.0370e-01, 4.6830e-02, 2.2432e-02, 2.0265e-02, 2.9029e-03, 0.0000e+00,
        0.0000e+00, 3.8865e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7519e-02, 8.7223e-04,
        0.0000e+00, 5.6421e-02, 3.9714e-02, 1.4858e-02, 6.3500e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5641e-02, 0.0000e+00, 0.0000e+00, 1.8743e-02, 5.1195e-02, 2.4999e-02,
        1.0756e-02, 5.3677e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5662e-07, 0.0000e+00, 0.0000e+00,
        5.7474e-02, 0.0000e+00, 0.0000e+00, 1.0604e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.6569e-02, 1.2689e-02, 7.4836e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7147e-02,
        1.1415e-05, 0.0000e+00, 7.4237e-03, 0.0000e+00, 5.7431e-02, 5.0357e-02,
        4.8343e-02, 3.1421e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1565e-01, 3.7637e-02, 3.4765e-02, 3.5045e-02, 1.6189e-02,
        1.5874e-02, 1.2107e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.5349e-01, 3.1815e-02, 0.0000e+00, 4.3224e-02, 2.1682e-02, 1.6543e-02,
        4.2959e-02, 1.2037e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9006e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3001e-01, 8.2999e-02, 4.9502e-02, 0.0000e+00, 7.2756e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.6707e-02, 3.4805e-05, 1.0135e-06, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4318e-01, 4.6712e-02,
        2.5535e-04, 2.5388e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.9304e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.7910e-01, 2.8549e-02, 3.9720e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.5793e-02, 1.2617e-02, 0.0000e+00, 1.0791e-01, 9.5232e-02, 4.3583e-03,
        7.0807e-04, 5.7609e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9203e-01, 4.7784e-02, 2.8804e-02, 4.8297e-02, 4.2190e-02, 0.0000e+00,
        1.0607e-01, 0.0000e+00, 0.0000e+00, 1.2588e-01, 8.2108e-02, 4.7139e-02,
        3.2939e-02, 1.0118e-02, 7.9570e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8099e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 1.5874e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4703e-01,
        3.6564e-02, 1.5442e-02, 1.2700e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2969e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.1831e-02, 4.2366e-02, 2.1682e-02, 0.0000e+00,
        0.0000e+00, 3.2139e-02, 1.9618e-02, 8.4288e-03, 8.4208e-03, 3.8222e-03,
        1.0465e-03, 6.4942e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.6523e-02, 2.2380e-02, 9.1279e-03, 1.2244e-10, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4683e-02,
        5.4462e-02, 3.3216e-02, 3.9712e-02, 6.1178e-03, 0.0000e+00, 1.1432e-01,
        7.3232e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4440e-02,
        8.1900e-02, 1.4787e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2383e-01, 7.5185e-02, 4.8031e-02, 8.1095e-02, 2.9766e-02, 1.9326e-02,
        9.1353e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4210e-01, 4.3669e-02, 0.0000e+00, 8.9125e-02,
        6.0440e-02, 5.4205e-02, 8.1619e-02, 4.5179e-02, 6.9539e-05, 4.7963e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1572e-02, 9.5063e-03, 4.7939e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.0529e-01, 3.2139e-02, 0.0000e+00, 4.7582e-02,
        2.1682e-02, 4.2072e-03, 7.9060e-02, 6.9545e-02, 3.4659e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2998e-02,
        4.5034e-02, 0.0000e+00]), 'gt_labels': tensor([7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 1, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7,
        4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 4, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 7, 7, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 7, 7, 4]), 'best match labels': tensor([ 7.,  7.,  7., -1., -1., -1., -1., -1.,  2.,  2.,  2.,  4.,  4.,  1.,
         1.,  2.,  2.,  2.,  2.,  1.,  7.,  2.,  2.,  2.,  4.,  4.,  7.,  7.,
         7.,  8.,  4.,  7.,  7.,  7.,  1.,  1.,  1.,  2.,  2.,  2.,  4.,  7.,
         7.,  2.,  2.,  2.,  7.,  2.,  7.,  7.,  8.,  8.,  2.,  7.,  4.,  1.,
         7.,  7.,  7.,  8.,  1.,  7.,  2.,  2.,  2.,  7.,  7., -1., -1., -1.,
        -1.,  2.,  2.,  2.,  4.,  2.,  8.,  2.,  8.,  2.,  2.,  2.,  2.,  2.,
         4.,  8.,  7.,  8.,  8.,  7.,  8.,  2.,  4.,  7.,  7.,  7.,  1.,  7.,
         7.,  7.,  4.,  7.,  7.,  8.,  7.,  7.,  4.,  2.,  2.,  2.,  7.,  2.,
         2.,  8.,  8.,  8.,  7.,  2.,  1.,  7.,  4.,  7.,  2.,  2.,  2.,  2.,
         2.,  4.,  7.,  7.,  7.,  7.,  4.,  7.,  7.,  7.,  7.,  2.,  7.,  7.,
         7.,  7.,  2.,  1.,  2.,  1.,  1.,  2.,  2.,  2.,  2.,  7.,  4.,  7.,
         2.,  7.,  8.,  7.,  7.,  2.,  7.,  2.,  4.,  7.,  2.,  2.,  7.,  2.,
         2.,  2.,  2.,  2.,  7.,  7.,  7.,  7.,  4.,  2.,  7.,  7.,  7.,  2.,
         2.,  2.,  2.,  2.,  7.,  2.,  7.,  2.,  7.,  7.,  4.,  2.,  7.,  1.,
         7.,  7.,  8.,  8.,  7.,  7.,  1.,  8.,  8.,  7., -1., -1., -1.,  1.,
        -1., -1.,  2.,  4.,  7.,  8.,  2.,  2.,  1.,  1.,  1.,  2.,  7.,  2.,
         7.,  7.,  7.,  8.,  4.,  8.,  7.,  1.,  2.,  7.,  2.,  7.,  2.,  1.,
         2.,  2.,  2.,  2.,  2.,  7.,  7.,  1.,  8., -1., -1., -1., -1.,  1.,
         1.,  2.,  2.,  7.,  1.,  1.,  1.,  2.,  2.,  2.,  2.,  7.,  7., -1.,
         1.,  1.,  1.,  1.,  2.,  2.,  2.,  7.,  2.,  4.,  8.,  2.,  1.,  2.,
         2.,  2.,  2.,  4.,  4.,  4.,  7.,  2.,  1.,  7.,  7.,  4.,  2.,  2.,
         7.,  2.,  7.,  7.,  2.,  6.,  2.,  7.,  2.,  2.,  2.,  2.,  2.,  4.,
         7.,  7.,  7.,  1.,  1.,  7.,  7.,  7.,  4.,  2.,  2.,  2.,  4.,  2.,
         4.,  2.,  2.,  1.,  7.,  2.,  7.,  1.,  2.,  1.,  2.,  2.,  2.,  7.,
         7.,  1.,  7.,  7.,  7.,  1.,  2., -1.,  2.,  7.,  1.,  2.,  2.,  7.,
         2., -1., -1., -1., -1.,  2.,  2.,  7.,  7.,  2.,  2.,  2.,  2.,  7.,
         7.,  7.,  2.,  7.,  7.,  2.,  4.,  4.,  2.,  5.,  7.,  8.,  8.,  8.,
         4.,  8.,  7.,  7.,  7.,  8.,  2.,  8.,  7.,  2.,  2.,  7.,  2.,  2.,
         7.,  7.,  7.,  7.,  8.,  8.,  1.,  1.,  7.,  4.,  2.,  4.,  7.,  7.,
         8.,  2.,  2.,  2.,  7.,  2.,  4.,  5.,  7.,  7.,  7.,  2.,  7.,  1.,
         2.,  2.,  4.,  7.,  7.,  2.,  2.,  2.,  4.,  7.,  1.,  7.,  1.,  1.,
         7.,  7.,  2.,  2.,  1.,  7.,  7.,  7.,  7.,  7.,  8.,  2.,  2.,  4.,
         1.,  8.,  1.,  2.,  1.,  4.,  4.,  7.,  2.,  7.,  4.,  2.,  2.,  7.,
         4.,  8.,  1.,  7.,  1.,  8.,  2.,  7.,  2.,  8.,  4.,  7.,  7.,  7.,
         7.,  7.,  7.,  2.,  2.,  4.,  2.,  7.,  1.,  2.,  7.,  2.,  4.,  4.,
         1.,  1.,  2.,  4.,  4.,  7.,  1.,  7.,  8.,  8.,  8.,  7.,  1.,  2.,
         7.,  2.,  1.,  2.,  7.,  2.,  7.,  2.,  2.,  4.,  4.,  4.,  2.,  4.,
         7.,  7.,  8.,  1.,  7.,  1.,  1.,  2.,  2.,  2.,  2.,  2.,  7.,  7.,
         7.,  4.,  7.,  4.,  7.,  4.,  7.,  2.,  1.,  2.,  2.,  2.,  7.,  7.,
         7.,  7.,  8.,  7.,  2.,  7.,  2.,  7.,  1.,  1.,  2.,  2.,  2.,  2.,
         4.,  7.,  8.,  4.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  4.,
         7.,  8.,  7.,  7.,  2.,  2.,  7.,  7.,  2.,  7.,  7.,  2.,  7.,  7.,
         7.,  2.,  1.,  7.,  7.,  3.,  2.,  2.,  2.,  2.,  2.,  4.,  7.,  8.,
         8.,  2.,  2.,  7.,  8.,  8.,  7.,  8.,  4.,  1.,  2.,  2.,  2.,  4.,
         4.,  7.,  7.,  2.,  7., -1.,  2.,  2.,  2.,  2.,  2.,  2.,  7.,  2.,
         7.,  1.,  7.,  7.,  2.,  2.,  2.,  2.,  4.,  4.,  7.,  7.,  8.,  2.,
         2.,  1.,  2.,  4.,  2.,  7.,  7.,  8.,  7.,  2.,  7.,  2.,  2.,  2.,
         2.,  4.,  4.,  4.,  6.,  7.,  7.,  2.,  2.,  2.,  2.,  2.,  4.,  4.,
         8.,  7.,  1.,  2.,  2.,  2.,  7.,  2.,  2.,  2.,  4.,  7.,  7.,  2.,
         7.,  4.,  7.,  1.,  1.,  2.,  7.,  1.,  7.,  1.,  1.,  2.,  4.,  2.,
         8.,  1.,  2.,  4.,  7.,  4.,  2.,  1.,  2.,  7.,  7.,  7.,  2.,  7.,
         7.,  7.,  4.,  2.,  2.,  2.,  2.,  2.,  4.,  7.,  7.,  2.,  2.,  4.,
         1.,  1.,  1.,  1.,  2.,  4.,  4.,  7.,  8.,  2.,  1.,  7.,  1.,  1.,
         2.,  1.,  2.,  2.,  2.,  4.,  7., -1.,  1.,  1.,  1.,  7.,  2.,  2.,
         2.,  4.,  7.,  2.,  1.,  7.,  7.,  1.,  2.,  7.,  7.,  7.,  7.,  8.,
         7.,  7.,  2.,  2.,  7.,  2.,  4.,  4.,  6.,  7.,  7.,  7.,  7.,  2.,
         1.,  2.,  1.,  7.,  8.,  8.,  2.,  1.,  7.,  4.,  1.,  2.,  2.,  4.,
         4.,  4.,  4.,  6.,  7.,  7.,  2.,  7.,  8.,  4.,  7.,  7.,  4.,  4.,
         1.,  1.,  4.,  1.,  2.,  2.,  2.,  2.,  4.,  7.,  7.,  7.,  7.,  2.,
         7.,  7.,  2.,  1.,  1.,  7.,  7.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,
         2.,  4.,  1.,  2.,  1.,  2.,  4.,  4.,  4.,  7.,  7.,  7.,  8.,  8.,
         7.,  7.,  7.,  7.,  4.,  7.,  7.,  2.,  4.,  7.,  7.,  7.,  7.,  8.,
         2.,  2.,  4.,  7.]), 'best match scores': tensor([1.0000, 0.6391, 0.2548, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5155,
        1.0000, 1.0000, 0.2769, 0.0695, 0.9266, 0.9979, 0.9981, 0.3125, 0.9347,
        0.9892, 0.0667, 0.9998, 1.0000, 0.4800, 1.0000, 0.4944, 0.3903, 0.9866,
        0.9272, 1.0000, 0.1252, 0.9998, 1.0000, 0.2969, 0.9817, 0.9957, 0.0665,
        0.9998, 0.9806, 0.9500, 0.9888, 1.0000, 1.0000, 1.0000, 0.8549, 0.4162,
        1.0000, 1.0000, 0.9999, 0.9430, 0.5955, 0.0637, 0.9381, 1.0000, 1.0000,
        0.3686, 0.9985, 1.0000, 1.0000, 0.5430, 1.0000, 0.9995, 0.9996, 1.0000,
        0.9995, 0.9914, 0.9568, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,
        1.0000, 0.8419, 0.4307, 1.0000, 1.0000, 0.9921, 1.0000, 0.0605, 1.0000,
        0.2096, 0.8709, 1.0000, 0.9999, 1.0000, 0.2132, 0.1826, 0.9990, 0.9999,
        0.0823, 1.0000, 0.9986, 0.8066, 0.6635, 0.8982, 0.9991, 0.8901, 0.5741,
        0.9992, 0.1393, 0.6861, 1.0000, 0.2723, 1.0000, 0.4342, 0.2863, 0.9972,
        0.3162, 0.8606, 0.6894, 0.9927, 0.9961, 0.1187, 0.9765, 0.5478, 0.0973,
        0.2009, 0.9496, 0.9996, 1.0000, 0.9783, 0.1127, 0.0803, 0.0567, 0.7565,
        0.8346, 0.9993, 1.0000, 0.2868, 0.0700, 0.2622, 0.8572, 0.0626, 0.4514,
        0.9952, 0.9899, 0.2924, 1.0000, 0.7255, 1.0000, 0.9758, 0.5081, 0.0888,
        0.9239, 0.9751, 0.9999, 1.0000, 0.9488, 0.9985, 0.1810, 0.9050, 1.0000,
        0.0966, 0.9999, 1.0000, 0.1486, 1.0000, 1.0000, 0.9994, 0.5494, 0.1142,
        0.9276, 0.4952, 1.0000, 0.9802, 1.0000, 0.6959, 0.0675, 1.0000, 0.0512,
        0.9860, 0.4808, 0.0570, 0.7661, 0.9855, 0.9999, 0.2221, 0.9982, 0.9926,
        1.0000, 1.0000, 0.0965, 0.5439, 0.2363, 0.9885, 0.9961, 0.9772, 1.0000,
        1.0000, 0.0609, 1.0000, 0.0766, 0.0706, 0.9571, 0.9999, 0.0594, 0.5413,
        1.0000, 0.9809, 1.0000, 0.9963, 0.9279, 0.4535, 0.9985, 1.0000, 0.0000,
        0.0000, 0.0000, 0.9644, 0.0000, 0.0000, 0.7271, 0.3171, 1.0000, 1.0000,
        0.0972, 0.9909, 0.7408, 1.0000, 0.9770, 0.7182, 0.0575, 0.1690, 0.8756,
        1.0000, 0.9709, 1.0000, 1.0000, 0.9989, 0.0631, 0.3561, 0.9994, 0.9975,
        0.5485, 0.9975, 0.5406, 0.9084, 1.0000, 1.0000, 0.0827, 0.9479, 0.9997,
        0.9739, 0.9980, 0.6535, 0.5280, 0.0000, 0.0000, 0.0000, 0.0000, 0.2025,
        0.9956, 0.9290, 0.6323, 0.9991, 0.9973, 0.6943, 0.9850, 0.9996, 1.0000,
        0.0607, 0.2015, 0.1987, 1.0000, 0.0000, 0.9999, 0.1197, 0.2601, 0.9996,
        0.9998, 0.3175, 1.0000, 0.9653, 1.0000, 1.0000, 0.9290, 1.0000, 0.4438,
        0.1868, 1.0000, 0.9771, 0.9854, 0.9932, 1.0000, 0.9800, 0.8061, 0.1512,
        0.2198, 1.0000, 0.0760, 0.9988, 0.1427, 0.9827, 1.0000, 0.9996, 0.7551,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9904, 0.9867,
        0.3781, 0.0543, 0.2107, 0.1756, 0.9996, 0.1155, 0.5149, 0.0686, 1.0000,
        0.9464, 1.0000, 1.0000, 0.0520, 0.9847, 0.3767, 0.5905, 0.9938, 0.9977,
        0.9997, 0.0875, 0.9999, 0.2909, 0.0986, 1.0000, 0.9972, 0.1897, 0.9972,
        1.0000, 1.0000, 0.8468, 0.0754, 0.5606, 0.9989, 0.2302, 0.9954, 0.9456,
        0.0532, 0.0000, 0.9996, 0.6970, 1.0000, 1.0000, 0.8895, 0.1105, 0.7809,
        0.0000, 0.0000, 0.0000, 0.0000, 0.9632, 1.0000, 0.8582, 0.9746, 0.4547,
        0.9853, 1.0000, 0.3030, 1.0000, 0.0683, 0.6060, 0.9925, 0.7343, 0.8864,
        0.9845, 0.9821, 0.9892, 1.0000, 0.7344, 0.9995, 0.9342, 0.9954, 1.0000,
        0.9677, 0.8555, 0.2280, 1.0000, 0.6483, 1.0000, 0.0576, 0.7692, 0.9999,
        0.0955, 1.0000, 0.3215, 0.9826, 0.9994, 1.0000, 0.7296, 0.0599, 0.1657,
        0.2144, 0.1382, 0.2489, 0.2867, 0.8552, 0.1908, 0.9996, 0.2231, 0.9358,
        0.2300, 0.9729, 0.9294, 1.0000, 0.0863, 0.9792, 0.3755, 1.0000, 0.9978,
        0.9941, 0.9989, 1.0000, 0.0691, 0.9991, 0.1822, 1.0000, 1.0000, 0.9979,
        0.9072, 1.0000, 0.2892, 0.0926, 0.2921, 0.9886, 1.0000, 0.9925, 1.0000,
        0.9999, 1.0000, 1.0000, 0.4881, 0.9883, 1.0000, 0.0769, 0.9562, 0.9897,
        0.9997, 0.9456, 0.1586, 0.4891, 1.0000, 0.9921, 0.9993, 0.9907, 0.4370,
        0.1052, 0.1936, 0.9994, 0.2456, 0.9999, 0.0501, 0.8233, 0.0716, 1.0000,
        0.2470, 0.2475, 1.0000, 1.0000, 0.9610, 0.8452, 0.0779, 0.8736, 0.4591,
        0.9644, 1.0000, 0.9971, 0.4286, 0.1055, 0.3604, 0.0621, 0.7931, 0.9999,
        0.9998, 0.8887, 0.5591, 1.0000, 0.8404, 0.1949, 0.2314, 0.8775, 0.2630,
        0.9274, 0.1488, 0.7059, 0.9742, 1.0000, 0.9208, 0.9995, 0.0770, 0.5481,
        1.0000, 0.7551, 0.9941, 0.9997, 0.9976, 0.3348, 1.0000, 1.0000, 0.0626,
        0.1091, 0.4300, 0.9981, 0.9990, 0.1206, 1.0000, 0.0550, 0.4124, 1.0000,
        1.0000, 1.0000, 0.9812, 0.9977, 0.9943, 0.1939, 0.9996, 0.0741, 0.8286,
        0.9653, 0.1747, 1.0000, 0.6333, 0.9617, 0.9999, 0.8625, 0.4821, 1.0000,
        1.0000, 0.1019, 1.0000, 0.9412, 0.6346, 0.6785, 1.0000, 0.9995, 0.8881,
        0.8657, 0.4776, 0.7318, 0.9002, 0.9873, 1.0000, 0.8452, 1.0000, 0.0974,
        0.7878, 0.9430, 0.9954, 0.9993, 0.0569, 1.0000, 0.0968, 0.5369, 0.4302,
        1.0000, 1.0000, 0.3003, 0.1005, 0.0575, 1.0000, 1.0000, 1.0000, 0.9999,
        0.0581, 0.2701, 1.0000, 0.0986, 0.9950, 0.7237, 1.0000, 0.9994, 0.9620,
        0.5747, 1.0000, 0.3200, 1.0000, 0.4122, 0.0656, 0.9998, 0.1303, 1.0000,
        0.9999, 0.9612, 1.0000, 1.0000, 0.0650, 1.0000, 0.2997, 1.0000, 0.9807,
        0.9976, 0.2603, 1.0000, 1.0000, 0.9808, 0.6824, 1.0000, 0.2478, 0.8471,
        1.0000, 1.0000, 0.9999, 0.9963, 0.5523, 0.9676, 0.2020, 1.0000, 0.9973,
        0.3286, 0.9179, 0.9971, 1.0000, 1.0000, 1.0000, 0.1140, 0.9998, 0.9432,
        0.0000, 0.9990, 0.9683, 0.1012, 1.0000, 1.0000, 0.5992, 0.1714, 1.0000,
        0.9804, 0.9165, 1.0000, 0.1027, 0.9949, 0.0838, 0.9874, 0.5436, 0.1865,
        0.2526, 0.8971, 0.9997, 0.9991, 0.0577, 1.0000, 0.0798, 0.1751, 0.0633,
        0.9972, 0.0893, 0.5686, 0.9202, 1.0000, 0.0886, 1.0000, 0.9992, 0.4070,
        0.7813, 1.0000, 0.9918, 1.0000, 0.3228, 1.0000, 1.0000, 0.0643, 0.9891,
        0.9773, 0.0713, 1.0000, 0.1490, 1.0000, 0.8616, 0.8200, 0.9979, 0.7793,
        0.9981, 0.9661, 0.9998, 1.0000, 0.4117, 0.9561, 0.9990, 0.9998, 0.1014,
        0.9981, 0.9330, 0.9929, 0.2372, 0.9975, 0.9884, 0.8692, 0.9296, 0.5780,
        0.2170, 1.0000, 0.9996, 0.0741, 1.0000, 1.0000, 0.3494, 0.9999, 0.9502,
        0.9545, 0.0577, 0.2528, 0.7360, 0.9866, 0.3388, 0.9990, 0.9997, 0.2614,
        0.4985, 0.7190, 1.0000, 0.3627, 1.0000, 0.1343, 0.4598, 1.0000, 0.1737,
        0.0524, 1.0000, 0.3188, 0.3307, 0.0872, 0.9472, 1.0000, 1.0000, 1.0000,
        1.0000, 0.6216, 0.9686, 0.1096, 0.9992, 0.9999, 1.0000, 0.7707, 0.4669,
        0.1218, 0.8887, 1.0000, 0.0775, 1.0000, 0.9661, 0.3352, 0.9981, 0.2628,
        0.9284, 0.6648, 0.0000, 0.9973, 0.1124, 1.0000, 0.2555, 0.9376, 1.0000,
        0.4707, 0.8049, 0.9986, 1.0000, 0.9951, 0.1693, 0.9999, 0.5954, 1.0000,
        0.9290, 0.3955, 1.0000, 0.8686, 0.1029, 0.9474, 0.9705, 0.9999, 1.0000,
        0.9842, 0.9978, 0.9972, 0.9716, 1.0000, 0.9968, 1.0000, 0.8739, 0.2349,
        0.9219, 0.1883, 1.0000, 0.9539, 0.6209, 0.7483, 0.2064, 0.0963, 0.0570,
        0.2098, 0.7377, 0.8049, 1.0000, 1.0000, 1.0000, 0.5622, 0.6198, 0.0570,
        1.0000, 0.9623, 1.0000, 1.0000, 0.9997, 0.0775, 0.9756, 0.9864, 0.6988,
        1.0000, 1.0000, 0.0878, 0.3978, 0.9964, 0.6972, 0.8318, 0.3700, 0.1612,
        0.8066, 0.0824, 0.7995, 0.2921, 1.0000, 0.9996, 0.9895, 0.8026, 0.8227,
        0.9999, 0.9998, 0.2632, 1.0000, 0.4652, 1.0000, 0.1587, 0.2928, 0.1230,
        0.3766, 0.9025, 1.0000, 0.9996, 0.8263, 0.9074, 0.7937, 0.4643, 0.2739,
        0.8735, 0.1598, 0.6401, 0.1720, 0.6747, 0.9963, 0.0514, 0.6808, 0.8795,
        1.0000, 0.3101, 0.9997, 1.0000, 0.9970, 0.0531, 0.8645, 0.9552, 0.1072,
        0.9198, 1.0000, 0.6689, 0.9999, 0.9677, 0.9999, 1.0000, 0.4100]), 'num_pos': 872}
2020-12-12 12:58:01,686 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.268349
2020-12-12 12:59:19,551 maskrcnn_benchmark.trainer INFO: eta: 0:44:39  iter: 500  loss: 7.7928 (7.7969)  loss_classifier: 0.4761 (0.5480)  loss_box_reg: 0.3044 (0.5051)  loss_objectness: 1.4641 (1.5168)  loss_rpn_box_reg: 5.3623 (5.2270)  time: 3.8915 (5.3584)  data: 0.2209 (1.6879)  lr: 0.000000  max mem: 1424
2020-12-12 13:00:36,953 maskrcnn_benchmark.trainer INFO: eta: 0:42:24  iter: 520  loss: 7.2638 (7.7862)  loss_classifier: 0.4598 (0.5475)  loss_box_reg: 0.4905 (0.5045)  loss_objectness: 1.4080 (1.5130)  loss_rpn_box_reg: 5.1832 (5.2212)  time: 3.8605 (5.3011)  data: 0.2137 (1.6314)  lr: 0.000000  max mem: 1424
2020-12-12 13:01:54,025 maskrcnn_benchmark.trainer INFO: eta: 0:40:13  iter: 540  loss: 7.3496 (7.7663)  loss_classifier: 0.5319 (0.5468)  loss_box_reg: 0.4118 (0.5032)  loss_objectness: 1.3997 (1.5083)  loss_rpn_box_reg: 4.9083 (5.2079)  time: 3.8533 (5.2475)  data: 0.2074 (1.5788)  lr: 0.000000  max mem: 1424
2020-12-12 13:03:11,305 maskrcnn_benchmark.trainer INFO: eta: 0:38:07  iter: 560  loss: 7.1338 (7.7506)  loss_classifier: 0.4005 (0.5433)  loss_box_reg: 0.2072 (0.4979)  loss_objectness: 1.4114 (1.5062)  loss_rpn_box_reg: 5.0375 (5.2032)  time: 3.8662 (5.1981)  data: 0.2127 (1.5300)  lr: 0.000000  max mem: 1424
2020-12-12 13:04:28,782 maskrcnn_benchmark.trainer INFO: eta: 0:36:04  iter: 580  loss: 7.3905 (7.7320)  loss_classifier: 0.4451 (0.5416)  loss_box_reg: 0.3195 (0.4951)  loss_objectness: 1.4033 (1.5029)  loss_rpn_box_reg: 4.8588 (5.1924)  time: 3.8737 (5.1524)  data: 0.2177 (1.4848)  lr: 0.000000  max mem: 1424
2020-12-12 13:05:46,519 maskrcnn_benchmark.trainer INFO: eta: 0:34:04  iter: 600  loss: 8.0312 (7.7387)  loss_classifier: 0.5023 (0.5427)  loss_box_reg: 0.6227 (0.4970)  loss_objectness: 1.4355 (1.5009)  loss_rpn_box_reg: 5.4007 (5.1981)  time: 3.8834 (5.1103)  data: 0.2158 (1.4426)  lr: 0.000000  max mem: 1424
2020-12-12 13:07:04,169 maskrcnn_benchmark.trainer INFO: eta: 0:32:06  iter: 620  loss: 7.7335 (7.7359)  loss_classifier: 0.5421 (0.5438)  loss_box_reg: 0.5540 (0.4991)  loss_objectness: 1.3766 (1.4975)  loss_rpn_box_reg: 4.9206 (5.1955)  time: 3.8822 (5.0707)  data: 0.2215 (1.4033)  lr: 0.000000  max mem: 1424
2020-12-12 13:08:21,785 maskrcnn_benchmark.trainer INFO: eta: 0:30:12  iter: 640  loss: 7.4740 (7.7265)  loss_classifier: 0.4673 (0.5415)  loss_box_reg: 0.5170 (0.4975)  loss_objectness: 1.4186 (1.4952)  loss_rpn_box_reg: 5.0983 (5.1922)  time: 3.8834 (5.0335)  data: 0.2223 (1.3665)  lr: 0.000000  max mem: 1424
2020-12-12 13:08:21,787 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 13:08:21,861 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(148 images).
2020-12-12 13:12:06,107 maskrcnn_benchmark.inference INFO: Total run time: 0:03:44.245081 (1.5151694674749632 s / img per device, on 1 devices)
2020-12-12 13:12:06,107 maskrcnn_benchmark.inference INFO: Model inference time: 0:03:28.772882 (1.4106275793668386 s / img per device, on 1 devices)
2020-12-12 13:12:06,107 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 13:12:22,043 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 13:12:22,044 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([7.2014e-02, 3.8917e-02, 0.0000e+00, 4.5904e-02, 3.6247e-02, 5.5006e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0840e-01, 3.3025e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6100e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5307e-03, 0.0000e+00, 0.0000e+00, 6.0227e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.1521e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5249e-01, 1.4768e-01,
        3.4562e-02, 2.6585e-02, 2.2138e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1203e-02, 4.8480e-03, 0.0000e+00, 8.4641e-02, 0.0000e+00,
        0.0000e+00, 1.5601e-01, 3.7298e-02, 3.4027e-02, 1.7812e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4113e-01, 4.9384e-02,
        2.1334e-04, 6.9380e-02, 5.6264e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6633e-03, 0.0000e+00,
        0.0000e+00, 7.0571e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3139e-01, 1.0592e-01,
        1.8552e-03, 4.2524e-02, 1.0143e-02, 0.0000e+00, 2.8203e-02, 4.7058e-05,
        7.9349e-02, 6.0557e-02, 5.5365e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4229e-01, 4.2882e-02, 6.6128e-03,
        6.8890e-02, 3.1856e-02, 0.0000e+00, 3.1593e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8439e-01, 1.1011e-01, 2.9947e-02, 1.0440e-01, 9.9652e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 1.6197e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5389e-02,
        4.2932e-03, 0.0000e+00, 8.4656e-02, 0.0000e+00, 0.0000e+00, 1.0152e-01,
        4.4130e-02, 3.7236e-03, 1.5307e-01, 1.0266e-04, 0.0000e+00, 3.0277e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2604e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1749e-02, 1.0465e-02, 0.0000e+00, 5.1903e-02, 2.4514e-02, 1.3819e-02,
        6.7477e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3771e-05, 0.0000e+00, 0.0000e+00, 1.7369e-01, 5.7761e-02, 1.2366e-02,
        4.5733e-03, 2.7254e-03, 3.7118e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.4343e-02, 7.8288e-02, 2.4505e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1609e-01,
        0.0000e+00, 0.0000e+00, 1.1948e-02, 6.6487e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1690e-01,
        4.3878e-02, 2.9327e-02, 5.6844e-05, 0.0000e+00, 0.0000e+00, 7.0179e-02,
        2.8804e-02, 0.0000e+00, 2.3341e-02, 1.4040e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.2694e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2499e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.6578e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0565e-02, 2.4732e-02,
        1.1218e-01, 4.9833e-02, 1.2997e-02, 4.6360e-02, 1.0193e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.4182e-02, 6.8796e-03, 0.0000e+00, 1.0029e-01, 6.9958e-02, 6.9791e-02,
        6.6298e-02, 3.5979e-02, 1.8356e-02, 1.3382e-02, 1.2723e-02, 2.1855e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.9770e-02, 2.2647e-02, 2.2270e-02, 4.7620e-02, 3.4637e-02, 2.1266e-02,
        1.9468e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4015e-01, 6.6283e-02, 8.2829e-03, 1.4210e-01,
        4.9896e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0954e-01, 6.3083e-02, 2.7625e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2343e-02,
        1.9720e-02, 9.8761e-03, 2.3864e-03, 2.2143e-03, 1.1171e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.7416e-02, 3.2977e-02, 0.0000e+00, 1.4807e-01, 3.2977e-02,
        0.0000e+00, 7.3070e-02, 4.1843e-02, 2.2771e-02, 8.7859e-03, 9.4046e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.7890e-02, 2.0888e-02, 2.1717e-04, 1.1981e-02, 1.0950e-02, 4.6955e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.9189e-02, 2.6263e-02, 2.5976e-02, 2.2055e-02, 1.7097e-02, 7.4801e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6494e-02,
        1.0279e-02, 0.0000e+00, 5.7481e-02, 3.2139e-02, 2.6415e-02, 1.5939e-02,
        2.3834e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.9995e-02, 2.4641e-02, 0.0000e+00, 6.8670e-02, 1.9093e-02,
        1.7108e-02, 1.5891e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1632e-01, 3.8112e-02, 0.0000e+00,
        9.5036e-02, 3.7858e-02, 3.1940e-02, 5.0269e-02, 1.8211e-04, 0.0000e+00,
        1.7917e-02, 1.0581e-02, 5.5006e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7262e-02, 2.1136e-01, 0.0000e+00,
        9.1739e-02, 6.4507e-02, 3.2977e-02, 3.9258e-02, 3.9901e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.6591e-02, 1.2623e-02, 3.9677e-03, 8.7982e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0073e-01,
        1.9584e-02, 1.8068e-02, 3.9671e-03, 6.1983e-06, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4229e-02, 7.2745e-02,
        3.3912e-02, 7.6350e-03, 1.9598e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.7828e-02, 3.6498e-02, 9.2291e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4037e-01, 1.0707e-01,
        7.4911e-06, 1.1393e-01, 5.3826e-02, 4.9772e-02, 1.4218e-02, 3.4470e-03,
        3.3449e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.9671e-02, 3.2977e-02, 0.0000e+00, 0.0000e+00, 2.1058e-01, 4.0561e-02,
        3.9783e-02, 4.6413e-03, 2.0240e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02, 2.8538e-06, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 3.1730e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1227e-01,
        1.0127e-02, 8.4017e-04, 4.3481e-03, 0.0000e+00, 4.3903e-02, 3.6325e-02,
        3.3845e-02, 8.0409e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.2753e-02, 7.4328e-02, 7.2323e-02, 1.6630e-01, 6.9696e-02,
        1.5630e-02, 5.5857e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5542e-02, 0.0000e+00, 0.0000e+00,
        6.9243e-02, 1.0016e-02, 9.0224e-03, 6.4274e-02, 2.1682e-02, 0.0000e+00,
        9.9953e-02, 4.6960e-02, 1.0818e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7586e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.4724e-02, 3.8003e-02, 0.0000e+00, 0.0000e+00, 6.9595e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.8599e-02, 2.0148e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0772e-02, 0.0000e+00,
        0.0000e+00, 6.4550e-02, 1.7123e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5344e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.2365e-02, 5.7433e-04, 1.4377e-06, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.4139e-02, 1.5513e-02, 5.9659e-04, 8.1838e-02, 8.0580e-02, 7.8890e-02,
        5.4183e-02, 3.4280e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1130e-01, 4.7270e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.4303e-02, 0.0000e+00, 0.0000e+00, 1.2670e-01, 3.2977e-02, 2.2501e-02,
        5.4205e-02, 4.4802e-02, 5.5480e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0469e-03, 1.3043e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0323e-02,
        6.4673e-03, 0.0000e+00, 1.6576e-02, 1.6293e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2969e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.7473e-01, 9.5211e-02, 3.5160e-02, 0.0000e+00,
        0.0000e+00, 3.2139e-02, 1.6742e-02, 1.0707e-02, 6.8578e-03, 3.2851e-03,
        1.2392e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.1308e-02, 1.5659e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2119e-02,
        2.2688e-05, 0.0000e+00, 3.4766e-01, 5.5159e-02, 0.0000e+00, 2.0596e-04,
        0.0000e+00, 0.0000e+00, 7.0865e-03, 1.1680e-04, 1.5060e-06, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7810e-01,
        6.0213e-02, 1.2350e-02, 0.0000e+00, 3.4459e-01, 1.2083e-01, 6.7890e-07,
        1.0013e-01, 5.1033e-02, 3.5851e-02, 7.6648e-02, 3.5109e-02, 3.1819e-02,
        1.8546e-02, 1.5787e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2957e-01, 6.8130e-02, 2.8106e-03, 4.7139e-02,
        0.0000e+00, 0.0000e+00, 1.3666e-01, 2.7122e-02, 2.5302e-02, 8.0964e-02,
        7.4011e-02, 2.0852e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.5988e-02, 8.4980e-03, 0.0000e+00, 3.3873e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.6985e-02, 1.0366e-01, 4.9283e-02, 3.7193e-02,
        1.9938e-02, 0.0000e+00, 2.1442e-01, 3.7256e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9962e-02,
        0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 1, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7,
        4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 4, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 7, 7, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 7, 7, 4]), 'best match labels': tensor([ 8.,  7.,  7.,  4.,  4.,  4.,  7.,  7.,  7.,  2.,  8.,  7.,  2.,  2.,
         4.,  6.,  1.,  7.,  8.,  8.,  2.,  1.,  1.,  2.,  2.,  2.,  2.,  4.,
         7.,  7.,  7.,  2.,  7.,  7.,  1.,  2.,  2.,  2.,  6.,  7.,  7.,  7.,
         7., -1.,  1.,  2.,  4.,  4.,  4.,  7.,  7.,  7.,  7.,  7.,  7.,  2.,
         4.,  2.,  7.,  8.,  1.,  8.,  2.,  2.,  7.,  7.,  2.,  1.,  2.,  2.,
         2.,  2.,  2.,  2.,  2.,  7.,  2.,  8.,  7.,  2.,  2.,  2.,  7.,  4.,
         7.,  7.,  7.,  7.,  7.,  7.,  7.,  2.,  2.,  4.,  7.,  7.,  7.,  7.,
         8.,  8.,  2.,  1.,  8.,  7.,  7.,  7.,  4.,  2.,  2.,  2.,  2.,  2.,
         4.,  7.,  2.,  8.,  1.,  2.,  2.,  7.,  4.,  7.,  2.,  2.,  2.,  2.,
         2.,  4.,  2.,  2.,  4.,  8.,  1.,  1.,  7.,  2.,  4.,  7.,  7.,  7.,
         7.,  2.,  7.,  7.,  2.,  2.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  7.,
         7.,  8.,  2.,  7.,  1.,  7.,  7.,  4.,  2.,  7.,  7.,  2.,  8.,  2.,
         2.,  2.,  2.,  4.,  4.,  7.,  7.,  7.,  2.,  7.,  4.,  7.,  7.,  7.,
         7.,  2.,  2.,  4.,  2.,  6.,  2.,  7.,  7.,  7.,  2.,  2.,  7.,  1.,
         7.,  7.,  7.,  8.,  8.,  1.,  1.,  1.,  8.,  8.,  2.,  2.,  7.,  2.,
         2.,  4.,  7.,  2.,  7.,  7.,  7.,  7.,  2.,  2.,  2.,  2.,  2.,  7.,
         7.,  7.,  7.,  4.,  4.,  7.,  8.,  7.,  7.,  8.,  2.,  4.,  2.,  2.,
         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  4., -1., -1., -1., -1.,  2.,
         1.,  2.,  2.,  2., -1., -1., -1.,  1.,  7.,  2.,  2.,  2.,  7., -1.,
         1.,  1.,  2.,  2.,  2.,  2.,  7.,  7.,  2.,  2.,  7.,  2.,  7.,  4.,
         4.,  4.,  4.,  4.,  2.,  4.,  7.,  4.,  7.,  1.,  2.,  1.,  8.,  7.,
         4.,  2.,  2.,  2.,  7.,  7.,  7.,  7.,  7., -1.,  1.,  1.,  2.,  2.,
         2.,  7.,  7.,  7.,  2.,  7.,  2.,  7.,  2.,  4.,  4.,  4.,  7.,  4.,
         4.,  1.,  7.,  8.,  7.,  7.,  2.,  1.,  2.,  2.,  7.,  2.,  4.,  7.,
         7.,  7.,  7.,  7.,  7., -1.,  1.,  2.,  2.,  2.,  2.,  4.,  7.,  8.,
         2.,  2.,  2.,  7.,  7.,  2.,  4.,  7.,  7.,  7.,  7.,  7.,  7.,  2.,
         2.,  7.,  7.,  7.,  1.,  7.,  4.,  7.,  7.,  8.,  8.,  8.,  8.,  8.,
         8.,  7.,  7.,  7.,  8.,  7.,  7.,  2.,  7.,  1.,  7.,  4.,  2.,  7.,
         7.,  7.,  8.,  8.,  2.,  2.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,
         2.,  4.,  4.,  5.,  7.,  7.,  1.,  1.,  2.,  7.,  1.,  7.,  7.,  2.,
         7.,  8.,  1.,  7.,  2.,  2.,  4.,  7.,  7.,  8.,  4.,  7.,  1.,  8.,
         2.,  7.,  2.,  2.,  7.,  7.,  4.,  7.,  7.,  7.,  7.,  7.,  8.,  1.,
         7.,  8.,  2.,  2.,  7.,  8.,  2.,  1.,  7.,  4.,  2.,  4.,  4.,  7.,
         7.,  8.,  7.,  2.,  7.,  2.,  2.,  7.,  2.,  7.,  4.,  7.,  7.,  7.,
         7.,  7.,  8.,  2.,  2.,  1.,  2.,  2.,  2.,  4.,  7.,  4.,  4.,  2.,
         7.,  1.,  4.,  2.,  2.,  7.,  7.,  7.,  7.,  7.,  7.,  8.,  2.,  1.,
         7.,  7.,  8.,  7.,  8.,  1.,  7.,  4.,  7.,  4.,  4.,  4.,  8.,  7.,
         7.,  8.,  1.,  7.,  2.,  1.,  1.,  2.,  2.,  4.,  7.,  7.,  7.,  8.,
         7.,  7.,  8.,  7.,  2.,  7.,  4.,  7.,  2.,  7.,  7.,  7.,  7.,  7.,
         8.,  1.,  2.,  2.,  2.,  7.,  2.,  4.,  7., -1., -1.,  2.,  2.,  2.,
         2.,  6.,  7.,  8.,  2.,  7.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,
         7.,  1.,  2.,  2.,  1.,  1.,  7.,  7.,  7.,  7.,  7.,  1.,  7.,  7.,
         8.,  2.,  7.,  7.,  7.,  8.,  7.,  4.,  4.,  7.,  8.,  8.,  8.,  8.,
         7.,  2.,  7.,  7.,  7.,  8.,  7.,  8.,  2.,  8.,  4.,  4.,  7.,  4.,
         7.,  7.,  2.,  8.,  8.,  1.,  1.,  2.,  2.,  2.,  2.,  7.,  4.,  4.,
         8.,  4.,  7.,  7.,  2.,  2.,  2.,  4.,  4.,  8.,  2.,  8.,  8.,  2.,
         2.,  2.,  2.,  2.,  2.,  2.,  2.,  7.,  7.,  1.,  7.,  4.,  4.,  7.,
         7.,  7.,  7.,  8.,  8.,  8.,  2.,  2.,  2.,  2.,  2.,  7.,  2.,  4.,
         7.,  1.,  1.,  1.,  2.,  2.,  2.,  7.,  2.,  2.,  7.,  8.,  2.,  1.,
         7.,  2.,  2.,  2.,  1.,  2.,  7.,  7.,  4.,  1.,  2.,  2.,  7.,  7.,
         7.,  7.,  7.,  4.,  7.,  1.,  7.,  2.,  2.,  2.,  2.,  2.,  2.,  4.,
         7.,  7.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  7.,  8.,  1.,  1.,
         2.,  2.,  2.,  4.,  4.,  4.,  4.,  7.,  7.,  7.,  8.,  8.,  2.,  2.,
         2.,  2.,  4.,  2.,  7.,  8.,  8.,  2.,  2.,  2.,  2.,  7.,  2.,  2.,
         7.,  7.,  7.,  2.,  2.,  4.,  7.,  1.,  2.,  2.,  2.,  2.,  4.,  7.,
         7.,  2.,  2.,  2.,  1.,  7.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  4.,
         7.,  8.,  8.,  7.,  8.,  7.,  7.,  7.,  7.,  1.,  8.,  8.,  2.,  2.,
         7.,  2.,  4.,  4.,  7.,  1.,  2.,  2.,  7.,  1.,  1.,  7.,  4.,  4.,
         7.,  2.,  7.,  4.,  4.,  2.,  2.,  7.,  7.,  7.,  1.,  8.,  4.,  2.,
         2.,  7.,  8.,  7.,  7.,  2.,  7.,  2.,  4.,  4.,  4.,  8.,  4.,  6.,
         8.,  4.,  1.,  2.,  8.,  4.,  4.,  6.,  7.,  7.,  7.,  7.,  7.,  8.,
         7.,  1.,  4.,  8.,  4.,  7., -1.,  7., -1.,  2.,  1.,  2.,  2.,  2.,
         7.,  4.,  7.,  7.]), 'best match scores': tensor([0.6201, 1.0000, 1.0000, 0.9889, 1.0000, 0.9660, 0.9966, 0.7196, 0.9992,
        1.0000, 1.0000, 0.0501, 0.9045, 0.8736, 0.9284, 0.8890, 1.0000, 0.9956,
        0.2728, 0.9960, 0.9912, 0.7876, 0.9743, 0.2318, 1.0000, 0.6310, 0.9997,
        0.9229, 1.0000, 1.0000, 0.0604, 0.9936, 0.4383, 0.9991, 0.9981, 0.9994,
        0.9968, 0.6989, 0.9998, 0.9933, 0.9953, 0.9696, 0.2717, 0.0000, 0.9676,
        0.0989, 0.5342, 0.6038, 0.9964, 0.7214, 0.9916, 0.9619, 0.0807, 0.9993,
        0.9999, 0.0729, 0.9029, 0.9908, 1.0000, 0.9882, 0.9995, 0.9998, 0.3010,
        0.9939, 0.2099, 1.0000, 1.0000, 0.0553, 0.3493, 0.9758, 0.8867, 0.1607,
        0.9968, 0.3354, 0.3943, 0.9954, 0.8524, 0.5139, 0.9886, 0.1515, 1.0000,
        1.0000, 1.0000, 0.9839, 0.7298, 0.9990, 0.6371, 0.5180, 0.9958, 0.9895,
        0.9982, 0.9996, 0.8923, 0.9401, 0.0832, 1.0000, 0.1077, 1.0000, 0.0533,
        1.0000, 0.4627, 0.0606, 0.2111, 0.9871, 0.3786, 0.6918, 1.0000, 0.1234,
        1.0000, 0.5940, 0.9464, 0.5977, 0.6284, 0.9968, 0.2798, 0.1914, 0.6134,
        1.0000, 0.1017, 0.9591, 0.8432, 0.5273, 1.0000, 0.9212, 0.9939, 0.2639,
        0.0812, 0.9983, 0.0680, 0.9990, 0.1274, 0.8532, 0.9999, 0.7899, 0.7031,
        0.0951, 0.2072, 0.0508, 0.9953, 0.9971, 1.0000, 0.9626, 0.7266, 0.9990,
        0.1127, 1.0000, 0.9985, 0.0521, 1.0000, 0.9999, 1.0000, 0.9991, 1.0000,
        0.8505, 1.0000, 0.9416, 0.9993, 0.3827, 0.9863, 0.4393, 0.9914, 0.9999,
        1.0000, 0.9926, 0.2225, 1.0000, 0.1698, 0.9998, 1.0000, 0.8443, 0.9929,
        0.1697, 0.9988, 1.0000, 0.9972, 0.1474, 0.7576, 0.9965, 0.0904, 0.3212,
        0.9999, 0.0833, 0.9362, 1.0000, 0.1006, 0.1875, 0.1978, 0.9999, 0.9992,
        0.9962, 0.9911, 0.4021, 0.1413, 0.1950, 0.1442, 0.8531, 0.9990, 0.9874,
        0.8534, 0.9550, 0.9974, 0.4273, 0.2631, 0.9993, 0.7710, 0.9961, 0.3074,
        0.3476, 0.2352, 0.9714, 0.9772, 0.9784, 0.9516, 0.9325, 1.0000, 1.0000,
        0.9969, 0.1469, 0.3662, 1.0000, 0.1916, 1.0000, 0.9952, 0.6379, 0.2471,
        0.0625, 0.9997, 0.3941, 1.0000, 0.9880, 0.4292, 1.0000, 1.0000, 0.7013,
        1.0000, 0.9997, 0.9965, 0.9997, 0.0943, 0.2780, 0.8690, 0.3460, 0.9996,
        1.0000, 0.6128, 0.5431, 0.9915, 0.0000, 0.0000, 0.0000, 0.0000, 0.9714,
        0.9879, 0.3771, 0.9968, 0.4648, 0.0000, 0.0000, 0.0000, 0.9999, 0.9606,
        0.0940, 1.0000, 0.9982, 0.9970, 0.0000, 0.9973, 1.0000, 0.3781, 0.6270,
        0.9708, 0.9999, 0.0931, 1.0000, 0.9997, 0.9937, 1.0000, 0.1656, 1.0000,
        0.9982, 0.6364, 0.7875, 1.0000, 0.2414, 0.2562, 0.9997, 0.0839, 0.9999,
        0.9036, 0.1299, 0.3858, 0.9999, 0.9615, 0.9591, 1.0000, 0.1652, 1.0000,
        0.9930, 1.0000, 0.3878, 1.0000, 0.9980, 0.8960, 0.0000, 0.6269, 0.0950,
        0.2497, 1.0000, 0.0753, 1.0000, 0.2727, 0.9996, 0.6511, 1.0000, 0.9925,
        1.0000, 0.9993, 0.8880, 0.9993, 0.9780, 0.1680, 0.9965, 1.0000, 0.9994,
        0.9933, 0.6436, 0.9902, 1.0000, 0.3247, 0.4924, 1.0000, 1.0000, 0.1805,
        0.9541, 1.0000, 1.0000, 0.2585, 0.9998, 0.3530, 0.7312, 0.4945, 0.0000,
        0.0596, 0.3385, 0.1990, 0.9085, 0.5048, 0.5026, 0.1188, 0.9999, 0.6159,
        0.9948, 0.1170, 0.7563, 0.7482, 0.1299, 0.7827, 0.8376, 0.3596, 0.9850,
        1.0000, 0.1417, 0.9910, 0.2314, 0.4669, 0.5042, 0.9704, 1.0000, 0.8165,
        0.9869, 0.2679, 0.9872, 0.1768, 0.9999, 0.2524, 0.1819, 0.9558, 0.6028,
        0.9998, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 0.9384, 1.0000, 0.9953,
        0.9520, 0.9589, 0.0850, 0.0642, 0.9986, 0.9981, 0.1723, 0.3110, 0.9831,
        0.9900, 0.9559, 0.5156, 0.4001, 0.7773, 0.8131, 1.0000, 0.0601, 1.0000,
        0.5949, 0.6444, 0.1159, 0.1141, 0.4470, 0.0629, 0.7027, 0.0539, 0.9999,
        0.8336, 0.0959, 0.7116, 0.9998, 0.9992, 0.9699, 1.0000, 0.7070, 0.1972,
        1.0000, 0.6179, 0.9979, 0.0515, 0.9998, 1.0000, 0.7779, 1.0000, 1.0000,
        1.0000, 0.9902, 0.8515, 0.9998, 1.0000, 0.9994, 0.6387, 0.5459, 0.9900,
        0.3468, 1.0000, 1.0000, 1.0000, 0.3950, 1.0000, 0.1478, 0.9851, 0.9975,
        0.1374, 0.9908, 0.9946, 0.9999, 0.9980, 1.0000, 0.7313, 1.0000, 0.9941,
        0.9999, 1.0000, 0.9649, 0.6347, 1.0000, 1.0000, 0.1279, 1.0000, 0.1995,
        0.0736, 1.0000, 1.0000, 0.9984, 0.1120, 1.0000, 1.0000, 0.9522, 0.3923,
        0.3786, 1.0000, 0.2777, 0.0790, 0.9999, 1.0000, 0.9866, 0.2218, 0.0946,
        0.9981, 1.0000, 0.9221, 1.0000, 1.0000, 0.0565, 0.9770, 0.0770, 1.0000,
        1.0000, 0.8877, 0.0561, 0.9999, 0.9999, 0.1251, 0.4188, 0.5837, 1.0000,
        0.8005, 0.1787, 0.5702, 1.0000, 0.2762, 1.0000, 0.0619, 0.9903, 0.9985,
        0.5322, 1.0000, 1.0000, 0.9810, 1.0000, 0.9693, 0.2203, 0.9766, 0.9359,
        0.9113, 0.9233, 0.6282, 1.0000, 1.0000, 0.9998, 1.0000, 0.2939, 0.9990,
        0.1350, 0.0632, 1.0000, 0.2408, 0.9999, 0.9230, 0.9865, 0.2969, 0.8486,
        0.7002, 1.0000, 0.2998, 1.0000, 0.9530, 0.8443, 0.9973, 0.9771, 1.0000,
        0.9290, 0.9947, 0.6263, 0.4180, 0.9772, 0.6768, 0.0000, 0.0000, 1.0000,
        1.0000, 0.5069, 0.6504, 1.0000, 0.9906, 0.9745, 0.9978, 0.0932, 1.0000,
        0.9984, 0.9985, 0.1023, 0.9999, 0.1263, 0.7379, 0.9910, 0.8199, 0.1362,
        0.9976, 0.9997, 1.0000, 0.9819, 0.7636, 0.7167, 1.0000, 0.9969, 0.9988,
        0.1049, 0.9985, 0.1668, 0.8488, 0.9998, 0.4847, 0.4282, 0.9765, 0.9980,
        0.6161, 0.1988, 1.0000, 0.6201, 0.9992, 0.9743, 0.0545, 0.4263, 1.0000,
        1.0000, 0.4320, 0.1666, 0.9547, 0.9999, 0.1106, 0.6437, 0.9996, 0.9598,
        0.9892, 1.0000, 0.9825, 0.9576, 0.9601, 0.0954, 0.9999, 0.1914, 0.9599,
        0.9231, 0.1545, 0.9879, 0.9743, 0.1854, 0.9058, 0.9978, 1.0000, 0.1674,
        0.9865, 1.0000, 0.5361, 0.5307, 0.9546, 0.9999, 0.9480, 0.9937, 0.1959,
        0.9999, 0.3024, 0.5428, 0.6471, 0.5966, 0.9909, 0.9660, 0.8824, 0.9877,
        0.9038, 1.0000, 1.0000, 0.9987, 0.0672, 0.9997, 0.2624, 1.0000, 0.1005,
        1.0000, 0.0648, 0.9872, 0.7643, 0.1068, 0.3941, 0.9999, 0.2025, 0.0659,
        0.9984, 0.9981, 0.9341, 0.8433, 0.9760, 1.0000, 0.0542, 0.9525, 0.2794,
        0.5256, 0.7997, 0.4768, 0.9592, 1.0000, 1.0000, 0.9985, 0.9998, 0.9990,
        0.9703, 0.6033, 0.9999, 0.4840, 0.2809, 0.9876, 0.0892, 0.9996, 0.4711,
        0.6487, 0.7191, 0.1779, 0.5814, 1.0000, 0.2994, 0.9626, 1.0000, 0.4865,
        1.0000, 0.1680, 1.0000, 0.4531, 0.9989, 0.9946, 0.1356, 0.9702, 1.0000,
        1.0000, 0.3572, 0.9983, 0.1043, 0.9712, 0.3718, 0.5324, 1.0000, 0.9999,
        1.0000, 0.9972, 1.0000, 0.1749, 0.5379, 0.0882, 1.0000, 0.7883, 0.9992,
        0.9967, 0.2825, 0.9390, 0.8923, 1.0000, 1.0000, 0.9998, 0.9980, 0.2735,
        0.7173, 0.8207, 0.9996, 0.1105, 0.5207, 0.9902, 1.0000, 1.0000, 0.2157,
        0.0857, 0.8159, 1.0000, 0.7963, 0.0693, 1.0000, 0.9953, 0.7396, 1.0000,
        0.9972, 0.3317, 0.9965, 0.1741, 0.0518, 1.0000, 1.0000, 0.6237, 1.0000,
        0.9996, 1.0000, 0.9925, 0.9129, 0.9818, 0.9986, 1.0000, 0.9991, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9969, 0.8883, 1.0000, 1.0000,
        0.9985, 0.9886, 1.0000, 0.9999, 0.9111, 0.0661, 0.9915, 0.9993, 0.4034,
        0.8080, 0.5891, 1.0000, 1.0000, 1.0000, 0.1997, 0.1218, 0.9941, 0.9999,
        1.0000, 0.7558, 0.9967, 1.0000, 0.9337, 0.9998, 0.0824, 0.1846, 0.0994,
        1.0000, 1.0000, 0.5554, 0.9694, 1.0000, 1.0000, 1.0000, 0.8584, 0.3885,
        0.5284, 0.9984, 0.5752, 0.9931, 0.9997, 1.0000, 1.0000, 1.0000, 1.0000,
        0.0896, 1.0000, 0.2193, 1.0000, 0.9998, 0.9916, 0.2379, 0.0644, 0.9992,
        0.0971, 0.9989, 1.0000, 0.5734, 1.0000, 0.9225, 0.7813, 0.6869, 0.9784,
        0.8919, 0.9587, 0.0799, 0.9618, 0.8428, 0.9798, 0.0716, 0.7379, 0.9863,
        0.9856, 0.9932, 0.2910, 1.0000, 0.3145, 0.0000, 0.0652, 0.0000, 0.1106,
        0.9911, 1.0000, 0.3484, 1.0000, 0.2405, 0.0619, 0.9107, 0.1673]), 'num_pos': 872}
2020-12-12 13:12:22,156 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.282110
2020-12-12 13:13:39,960 maskrcnn_benchmark.trainer INFO: eta: 0:30:23  iter: 660  loss: 7.4078 (7.7193)  loss_classifier: 0.4977 (0.5419)  loss_box_reg: 0.5268 (0.4983)  loss_objectness: 1.3989 (1.4923)  loss_rpn_box_reg: 4.9829 (5.1868)  time: 3.8891 (5.3630)  data: 0.2190 (1.6960)  lr: 0.000000  max mem: 1424
2020-12-12 13:14:57,832 maskrcnn_benchmark.trainer INFO: eta: 0:28:22  iter: 680  loss: 7.3761 (7.7121)  loss_classifier: 0.5278 (0.5424)  loss_box_reg: 0.4744 (0.4987)  loss_objectness: 1.3889 (1.4899)  loss_rpn_box_reg: 4.9385 (5.1810)  time: 3.8822 (5.3198)  data: 0.2238 (1.6527)  lr: 0.000000  max mem: 1424
2020-12-12 13:16:15,491 maskrcnn_benchmark.trainer INFO: eta: 0:26:23  iter: 700  loss: 7.4737 (7.7071)  loss_classifier: 0.4233 (0.5408)  loss_box_reg: 0.4291 (0.4983)  loss_objectness: 1.3725 (1.4876)  loss_rpn_box_reg: 4.9753 (5.1804)  time: 3.8717 (5.2788)  data: 0.2133 (1.6117)  lr: 0.000000  max mem: 1424
2020-12-12 13:17:32,718 maskrcnn_benchmark.trainer INFO: eta: 0:24:27  iter: 720  loss: 7.2608 (7.6920)  loss_classifier: 0.4543 (0.5392)  loss_box_reg: 0.4475 (0.4983)  loss_objectness: 1.3613 (1.4841)  loss_rpn_box_reg: 4.8349 (5.1703)  time: 3.8595 (5.2394)  data: 0.2154 (1.5730)  lr: 0.000000  max mem: 1424
2020-12-12 13:18:49,865 maskrcnn_benchmark.trainer INFO: eta: 0:22:32  iter: 740  loss: 7.4102 (7.6768)  loss_classifier: 0.4572 (0.5371)  loss_box_reg: 0.5278 (0.4973)  loss_objectness: 1.3351 (1.4814)  loss_rpn_box_reg: 4.8063 (5.1609)  time: 3.8574 (5.2020)  data: 0.2147 (1.5363)  lr: 0.000000  max mem: 1424
2020-12-12 13:20:07,055 maskrcnn_benchmark.trainer INFO: eta: 0:20:40  iter: 760  loss: 7.3298 (7.6702)  loss_classifier: 0.4139 (0.5358)  loss_box_reg: 0.5548 (0.4986)  loss_objectness: 1.3965 (1.4791)  loss_rpn_box_reg: 4.9669 (5.1567)  time: 3.8562 (5.1667)  data: 0.2127 (1.5015)  lr: 0.000000  max mem: 1424
2020-12-12 13:21:24,324 maskrcnn_benchmark.trainer INFO: eta: 0:18:49  iter: 780  loss: 7.0984 (7.6581)  loss_classifier: 0.3738 (0.5338)  loss_box_reg: 0.4379 (0.4976)  loss_objectness: 1.4161 (1.4767)  loss_rpn_box_reg: 4.9607 (5.1500)  time: 3.8602 (5.1333)  data: 0.2096 (1.4684)  lr: 0.000000  max mem: 1424
2020-12-12 13:22:41,609 maskrcnn_benchmark.trainer INFO: eta: 0:17:00  iter: 800  loss: 7.2316 (7.6497)  loss_classifier: 0.4994 (0.5334)  loss_box_reg: 0.5473 (0.4980)  loss_objectness: 1.3429 (1.4737)  loss_rpn_box_reg: 4.8829 (5.1447)  time: 3.8617 (5.1016)  data: 0.2117 (1.4371)  lr: 0.000000  max mem: 1424
2020-12-12 13:22:41,611 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 13:22:41,681 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(148 images).
2020-12-12 13:26:24,775 maskrcnn_benchmark.inference INFO: Total run time: 0:03:43.093677 (1.507389709756181 s / img per device, on 1 devices)
2020-12-12 13:26:24,775 maskrcnn_benchmark.inference INFO: Model inference time: 0:03:28.399480 (1.408104592078441 s / img per device, on 1 devices)
2020-12-12 13:26:24,775 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 13:26:40,307 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 13:26:40,307 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([3.8789e-02, 3.3973e-02, 2.1682e-02, 4.9605e-02, 3.3709e-02, 8.1666e-03,
        4.6202e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3634e-01, 6.6473e-02, 2.2893e-02, 2.0529e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.1637e-02, 6.0138e-02, 4.5095e-02,
        1.8956e-02, 8.7492e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.3803e-02, 3.2977e-02, 0.0000e+00, 6.8612e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.3069e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8999e-01, 1.3921e-01,
        7.6954e-02, 2.2320e-02, 1.5326e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.9672e-02, 4.8173e-06, 0.0000e+00, 1.5435e-02, 3.7087e-03,
        1.6362e-03, 5.7957e-02, 4.7464e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2495e-01, 4.8238e-02,
        2.1682e-02, 3.7938e-02, 1.3775e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2716e-06, 0.0000e+00,
        0.0000e+00, 4.0976e-02, 2.9928e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8771e-02, 7.2692e-04,
        0.0000e+00, 1.5134e-01, 1.0736e-01, 3.3946e-02, 3.9394e-03, 0.0000e+00,
        3.4251e-02, 2.3293e-02, 1.9947e-02, 1.7123e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9446e-01, 0.0000e+00, 0.0000e+00,
        9.1543e-02, 5.0102e-02, 0.0000e+00, 1.8830e-02, 3.1593e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.6106e-03, 0.0000e+00, 0.0000e+00, 1.2547e-01, 6.6643e-03, 1.0692e-09,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8663e-02, 2.2917e-03, 1.2052e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8584e-01,
        7.1790e-02, 4.5784e-02, 1.4351e-01, 2.9582e-03, 0.0000e+00, 6.7476e-02,
        6.0114e-02, 0.0000e+00, 1.8948e-01, 0.0000e+00, 0.0000e+00, 2.8606e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9558e-01,
        2.5890e-02, 1.4410e-02, 8.5702e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.6681e-02, 2.9666e-05, 0.0000e+00, 6.6334e-02, 2.4817e-02, 1.2048e-02,
        1.1163e-02, 3.9431e-03, 1.8612e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.4087e-02, 3.4777e-02, 1.7461e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6698e-01,
        1.4041e-01, 3.8167e-02, 1.6065e-01, 1.4612e-02, 6.5477e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8685e-02,
        4.0956e-02, 2.1682e-02, 4.9749e-02, 1.4512e-03, 0.0000e+00, 4.1472e-02,
        5.4924e-03, 0.0000e+00, 3.0042e-01, 3.5375e-02, 1.7466e-02, 1.5874e-02,
        5.5404e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.2231e-03, 5.3174e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4296e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 5.6473e-02, 2.1272e-02, 9.4496e-03, 2.0504e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9235e-02, 0.0000e+00,
        1.0113e-02, 5.1059e-03, 5.8852e-05, 1.7073e-02, 1.3475e-02, 1.0735e-02,
        9.5782e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.6987e-02, 1.1074e-02, 0.0000e+00, 1.4722e-01, 2.9971e-02, 5.2761e-06,
        1.1193e-01, 7.1765e-02, 5.9560e-02, 1.3541e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.5021e-02, 5.2262e-02, 2.2415e-02, 7.8339e-02, 2.3248e-02, 1.5874e-02,
        5.8883e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.5967e-01, 4.0015e-02, 3.8790e-03, 2.1183e-02,
        2.0896e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00, 4.5566e-02,
        2.5416e-02, 1.2710e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.7944e-02, 1.5555e-02, 6.7485e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4973e-02,
        2.4297e-02, 1.9711e-02, 1.2958e-02, 8.9758e-03, 2.8708e-03, 2.1152e-03,
        1.0358e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7753e-02, 1.5861e-02,
        3.0597e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.7187e-01, 4.4558e-02, 2.1682e-02, 8.9490e-02, 8.3433e-02,
        4.5991e-02, 3.1817e-02, 1.8640e-02, 7.5832e-03, 9.4502e-04, 7.6639e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0254e-01, 2.3756e-02, 0.0000e+00, 1.7581e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6331e-01, 2.1330e-02, 1.9576e-02, 7.2594e-03, 4.2118e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1507e-02,
        3.8705e-02, 1.2205e-02, 3.2139e-02, 1.5874e-02, 6.4634e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.5707e-02, 3.4468e-02, 0.0000e+00, 4.4350e-02, 2.6532e-02,
        2.4940e-02, 2.4674e-02, 2.4576e-02, 2.2459e-02, 1.5874e-02, 1.5874e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.4859e-02, 2.6150e-02, 0.0000e+00, 1.1658e-01, 1.7134e-03, 0.0000e+00,
        1.6558e-02, 8.3405e-03, 7.3715e-03, 1.8647e-03, 8.5567e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6552e-02, 0.0000e+00,
        6.0340e-02, 1.9066e-02, 0.0000e+00, 1.7756e-02, 3.4275e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.5380e-02, 4.2980e-02, 2.8081e-02, 1.3192e-02, 1.3205e-03, 3.9406e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0095e-02,
        2.7307e-02, 1.8226e-02, 1.0880e-02, 9.0901e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7047e-01, 9.3582e-02,
        9.2526e-02, 9.0455e-02, 2.5839e-02, 1.7123e-02, 9.8988e-06, 0.0000e+00,
        0.0000e+00, 4.6740e-02, 3.8273e-02, 5.4275e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6669e-01, 1.2357e-01,
        1.1939e-01, 5.3110e-02, 2.4958e-02, 1.7906e-02, 1.5869e-02, 2.3227e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.2693e-02, 4.7797e-02, 4.3732e-02, 0.0000e+00, 1.3210e-01, 2.0595e-02,
        1.7632e-02, 2.1105e-03, 1.6078e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0349e-01, 0.0000e+00, 0.0000e+00,
        4.1514e-02, 5.8889e-05, 0.0000e+00, 6.4920e-02, 4.4773e-02, 2.5997e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9293e-01, 2.2990e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1308e-02,
        5.2037e-02, 0.0000e+00, 6.6513e-02, 0.0000e+00, 9.4960e-02, 7.5661e-02,
        7.2031e-02, 1.7634e-02, 5.9717e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.0312e-02, 4.6457e-02, 3.6486e-02, 1.8377e-01, 4.6271e-02,
        1.9869e-02, 7.5863e-03, 2.7058e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4140e-02, 2.1682e-02, 0.0000e+00, 1.1694e-01, 2.2958e-02, 1.6543e-02,
        5.6616e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.6307e-03, 5.1897e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.3746e-02, 1.0086e-05, 0.0000e+00, 9.7467e-02, 4.6516e-02, 6.4814e-03,
        2.9945e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.0259e-02, 2.8958e-02, 1.5089e-02, 5.0467e-04, 6.9817e-06,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3097e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.4058e-02, 3.0761e-02, 2.5590e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3932e-01, 1.1719e-01, 0.0000e+00, 8.4571e-02, 5.5873e-02, 5.1323e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2977e-02, 2.8804e-02, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 5.4696e-04, 0.0000e+00, 9.8480e-02, 6.4134e-02, 8.6205e-05,
        1.6393e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6621e-03, 4.6870e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.3820e-02, 3.2139e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8021e-02,
        3.2977e-02, 0.0000e+00, 9.3551e-02, 6.7684e-02, 1.5687e-02, 1.3819e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2464e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2654e-01, 6.5319e-02, 3.8994e-02, 3.2977e-02,
        0.0000e+00, 3.2139e-02, 1.6588e-02, 1.5886e-02, 1.2110e-02, 1.0670e-02,
        7.5061e-03, 3.8766e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.5144e-02, 2.9792e-02, 2.7155e-02, 1.8810e-02, 1.8670e-02, 3.7668e-03,
        2.6587e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8358e-02,
        5.3677e-04, 0.0000e+00, 1.7255e-01, 6.6671e-02, 5.1525e-02, 3.2977e-02,
        7.7546e-05, 0.0000e+00, 3.0777e-04, 1.8615e-04, 1.0347e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0781e-02,
        6.1174e-02, 4.7681e-02, 2.6854e-01, 1.9748e-01, 1.0509e-03, 0.0000e+00,
        5.2232e-02, 3.2977e-02, 1.9331e-02, 1.3820e-01, 9.0476e-02, 2.1779e-02,
        1.1572e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.5462e-02, 0.0000e+00, 0.0000e+00, 8.5493e-02,
        1.9114e-03, 1.9801e-04, 1.8120e-01, 6.3585e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.9558e-02, 1.0084e-02, 0.0000e+00, 6.3352e-02,
        2.4527e-02, 3.1588e-03, 2.0021e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.2292e-02, 3.4067e-02, 0.0000e+00, 4.6963e-02,
        4.0102e-02, 2.8556e-02, 3.4746e-02, 2.7170e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1463e-02,
        0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 1, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7,
        4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 4, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 7, 7, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 7, 7, 4]), 'best match labels': tensor([ 7.,  4.,  7.,  4.,  2.,  4.,  2.,  7.,  7.,  7.,  8.,  7.,  2.,  2.,
         6.,  1.,  7.,  7.,  8.,  8.,  2.,  7.,  1.,  7.,  1.,  7.,  7.,  7.,
         7.,  7.,  7.,  7.,  7.,  7., -1., -1., -1.,  1.,  1.,  2.,  2.,  2.,
         6.,  2.,  2.,  4.,  7.,  4.,  7.,  7.,  7.,  8.,  2.,  4.,  7.,  7.,
         7.,  8.,  2.,  8.,  1.,  8.,  7.,  7.,  1.,  7.,  7.,  2.,  2.,  2.,
         2.,  2.,  2.,  2.,  2.,  2.,  7.,  2.,  7.,  2.,  2.,  2.,  2.,  2.,
         4.,  7.,  7.,  7.,  1.,  2.,  7.,  2.,  2.,  2.,  2.,  4.,  7.,  7.,
         8.,  2.,  8.,  1.,  7.,  2.,  7.,  2.,  2.,  7.,  2.,  4.,  2.,  7.,
         7.,  2.,  4.,  8.,  7.,  8.,  7.,  8.,  4.,  7.,  2.,  2.,  2.,  2.,
         2.,  4.,  4.,  7.,  7.,  2.,  7.,  8.,  7.,  7.,  7.,  7.,  2.,  7.,
         7.,  7.,  2.,  7.,  2.,  2.,  2.,  2.,  2.,  2.,  4.,  7.,  7.,  1.,
         2.,  7.,  7.,  2.,  2.,  7.,  2.,  8.,  2.,  7.,  4.,  7.,  7.,  2.,
         2.,  2.,  4.,  4.,  7.,  7.,  7.,  7.,  2.,  4.,  4.,  2.,  2.,  7.,
         7.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  4.,  7.,  7.,  2.,  2.,  7.,
         7.,  2.,  2.,  7.,  8.,  1.,  1.,  7.,  8.,  8.,  1.,  2.,  2.,  2.,
         4.,  4.,  4.,  2.,  7.,  7.,  2.,  2.,  1.,  1.,  2.,  2.,  2.,  7.,
         7.,  7.,  1.,  8.,  4.,  7.,  7.,  2.,  2.,  8.,  2.,  2.,  2.,  2.,
         2.,  2.,  2.,  4.,  4.,  7.,  7.,  7.,  2.,  2.,  2.,  2.,  2.,  2.,
         2.,  7.,  7.,  7.,  1.,  1.,  2.,  2.,  7.,  2.,  2.,  7.,  7.,  2.,
         4.,  7.,  2.,  2.,  2.,  7.,  8.,  4.,  8.,  2.,  1.,  7.,  7.,  2.,
         2.,  7.,  2.,  2.,  2.,  4.,  4.,  4.,  7.,  2.,  2.,  1.,  2.,  7.,
         4.,  4.,  7.,  7.,  7.,  8.,  7.,  7.,  7.,  2.,  2.,  2.,  2.,  2.,
         7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  2.,  2.,  4.,  4.,  4.,  7.,
         1.,  7.,  2.,  7.,  4.,  7.,  2.,  4., -1.,  1.,  2.,  2.,  2.,  2.,
         4.,  7.,  7.,  7.,  8.,  7.,  1.,  2.,  2.,  2.,  2.,  2.,  4.,  8.,
         2.,  8.,  2.,  2.,  8.,  2.,  7.,  7.,  7.,  7.,  7.,  2.,  2.,  2.,
         2.,  7.,  7.,  7.,  7.,  7.,  2.,  4.,  4.,  7.,  8.,  8.,  2.,  8.,
         7.,  4.,  7.,  4.,  7.,  7.,  7.,  1.,  8.,  1.,  2.,  7.,  2.,  7.,
         7.,  7.,  7.,  8.,  4.,  2.,  8.,  1.,  2.,  2.,  2.,  2.,  4.,  7.,
         7.,  2.,  2.,  7.,  2.,  2.,  4.,  2.,  5.,  2.,  2.,  7.,  7.,  7.,
         7.,  2.,  4.,  7.,  2.,  2.,  4.,  4.,  7.,  7.,  7.,  8.,  7.,  7.,
         7.,  2.,  1.,  2.,  2.,  7.,  7.,  7.,  8.,  8.,  7.,  2.,  7.,  2.,
         7.,  8.,  7.,  1.,  7.,  8.,  1.,  7.,  7.,  8.,  1.,  8.,  2.,  7.,
         8.,  8.,  8.,  7.,  2.,  2.,  7.,  7.,  2.,  8.,  4.,  4.,  7.,  7.,
         7.,  7.,  7.,  8.,  4.,  1.,  4.,  2.,  1.,  4.,  7.,  7.,  2.,  7.,
         2.,  2.,  4.,  2.,  4.,  7.,  7.,  7.,  8.,  7.,  8.,  8.,  7.,  7.,
         7.,  7.,  1.,  1.,  8.,  2.,  7.,  4.,  4.,  7.,  8.,  8.,  1.,  8.,
         7.,  8.,  7.,  7.,  2.,  1.,  1.,  2.,  2.,  4.,  7.,  7.,  7.,  8.,
         7.,  7.,  7.,  4.,  2.,  8.,  4.,  7.,  2.,  4.,  7.,  7.,  7.,  7.,
         7.,  1.,  2.,  7.,  2.,  7.,  7.,  2.,  8.,  2.,  1.,  2.,  7.,  2.,
         4.,  8.,  8.,  2.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  4.,  7.,  7.,
         7.,  7.,  7.,  7.,  2.,  2.,  7.,  2.,  7.,  2.,  7.,  7.,  2.,  7.,
         7.,  7.,  2.,  7.,  7.,  1.,  4.,  2.,  2.,  2.,  4.,  8.,  8.,  7.,
         7.,  2.,  2.,  7.,  7.,  4.,  8.,  4.,  8.,  8.,  2.,  2.,  4.,  4.,
         2.,  4.,  7.,  7.,  7.,  2.,  2.,  2.,  2.,  2.,  2.,  7.,  4.,  2.,
         7.,  2.,  7.,  7.,  2.,  8.,  4.,  4.,  7.,  7.,  2.,  7.,  7.,  2.,
         6.,  2.,  7.,  8.,  2.,  2.,  7.,  7.,  7.,  7.,  2.,  2.,  2.,  2.,
         2.,  2.,  4.,  6.,  7.,  8.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  7.,
         7.,  7.,  2.,  7.,  2.,  7.,  2.,  2.,  2.,  4.,  7.,  8.,  2.,  7.,
         7.,  2.,  2.,  7.,  4.,  7.,  7.,  7.,  8.,  1.,  8.,  7.,  2.,  7.,
         7.,  7.,  2.,  7.,  7.,  4.,  1.,  2., -1.,  1.,  1.,  2.,  2.,  2.,
         2.,  7.,  2.,  2.,  2.,  2.,  2.,  2.,  7.,  7.,  7.,  2.,  1.,  1.,
         2.,  2.,  2.,  2.,  2.,  4.,  4.,  7.,  7.,  4.,  1.,  7.,  2.,  4.,
         2.,  4.,  7.,  2.,  2.,  2.,  7.,  2.,  2.,  2.,  2.,  7.,  2.,  2.,
         2.,  7.,  2.,  2.,  2.,  7.,  7.,  1.,  2.,  2.,  4.,  7.,  8.,  8.,
         1.,  2.,  7.,  2.,  2.,  7.,  7.,  2.,  4.,  4.,  7.,  7.,  2.,  7.,
         1.,  4.,  8.,  7.,  2.,  7.,  2.,  7.,  7.,  1.,  2.,  8.,  2.,  2.,
         2.,  4.,  4.,  7.,  8.,  1.,  1.,  7.,  7.,  8.,  2.,  7.,  4.,  7.,
         2.,  4.,  7.,  2.,  2.,  2.,  2.,  2.,  7.,  2.,  8.,  4.,  7.,  7.,
         2.,  2.,  7.,  2.,  7.,  2.,  7., -1., -1.,  1.,  1.,  2.,  2.,  2.,
         2.,  4.,  8.,  7.,  7.,  7.,  8.,  7.,  7.,  7.,  1.,  7.,  7.,  8.,
         7.,  7.,  7.,  7.,  4.,  2.,  2.,  2.,  1.,  2.,  2.,  2.,  2.,  2.,
         7.,  7.,  4.,  7.]), 'best match scores': tensor([1.0000, 0.9803, 0.9996, 0.4512, 0.9992, 1.0000, 0.2205, 0.9797, 0.9982,
        0.8534, 0.1053, 1.0000, 0.9835, 0.2605, 1.0000, 0.6414, 0.0699, 1.0000,
        0.6511, 0.9861, 0.9979, 0.9800, 0.9607, 0.7708, 0.1034, 1.0000, 0.9972,
        0.6710, 0.9999, 0.9797, 0.6173, 0.9231, 0.9872, 1.0000, 0.0000, 0.0000,
        0.0000, 1.0000, 0.9996, 0.0960, 0.1000, 0.9962, 0.9139, 0.7877, 0.1084,
        0.9352, 0.7371, 0.7038, 1.0000, 0.9996, 0.4059, 0.9897, 0.9999, 0.9789,
        0.9403, 0.9963, 0.9884, 0.9944, 0.0674, 0.9998, 0.9993, 0.0571, 0.4757,
        0.5849, 0.9333, 1.0000, 0.9386, 1.0000, 0.0798, 0.9999, 1.0000, 0.1965,
        0.9982, 1.0000, 0.9850, 0.5501, 0.4711, 0.1566, 0.9846, 0.0621, 1.0000,
        1.0000, 0.9953, 1.0000, 0.8218, 0.4575, 1.0000, 0.9985, 0.9948, 0.1945,
        0.1165, 0.9995, 0.4522, 0.1502, 0.3928, 1.0000, 0.3067, 0.1300, 0.0536,
        0.7830, 0.9517, 0.1026, 1.0000, 0.1145, 0.1134, 0.6011, 0.2474, 0.9970,
        0.1020, 0.6993, 0.2193, 0.9424, 0.9809, 0.1542, 1.0000, 0.9985, 0.8897,
        0.9950, 0.9999, 0.9941, 0.6792, 0.2148, 0.5078, 1.0000, 0.3433, 0.0846,
        0.4180, 1.0000, 0.1683, 0.9908, 0.0507, 0.2117, 1.0000, 0.1063, 1.0000,
        1.0000, 0.9998, 1.0000, 0.0589, 0.0851, 0.9998, 1.0000, 1.0000, 0.1794,
        0.1254, 0.6254, 0.0834, 0.8347, 0.1362, 1.0000, 0.4833, 0.8843, 0.9593,
        0.0539, 0.4309, 0.3821, 0.3825, 0.3578, 1.0000, 0.1284, 0.1859, 0.2649,
        0.9989, 0.9540, 0.3389, 0.1248, 1.0000, 1.0000, 0.9972, 0.7114, 0.9996,
        0.2877, 1.0000, 0.9900, 1.0000, 0.0775, 0.1483, 0.1597, 0.7523, 0.0716,
        0.1037, 0.0747, 0.9968, 1.0000, 0.0646, 1.0000, 0.9928, 0.1387, 0.9915,
        0.9748, 0.0661, 0.1566, 0.9721, 0.4647, 0.9891, 0.9987, 1.0000, 0.9914,
        0.2940, 0.1234, 0.8908, 0.9797, 0.9465, 0.9957, 1.0000, 0.9960, 0.9968,
        0.3388, 0.8058, 0.9999, 0.9413, 0.1224, 0.9993, 0.9949, 0.0587, 0.9996,
        0.3120, 1.0000, 0.9854, 0.6710, 0.5864, 0.9425, 0.8688, 0.9960, 0.8647,
        0.9872, 0.9999, 1.0000, 1.0000, 0.9872, 1.0000, 0.6653, 0.9997, 0.8609,
        0.9999, 0.8638, 0.9993, 0.7068, 1.0000, 0.8919, 0.2884, 0.0549, 1.0000,
        0.0886, 0.9341, 0.0586, 1.0000, 1.0000, 0.9995, 0.0816, 0.9849, 0.9999,
        0.0507, 0.9580, 0.0581, 0.6991, 0.5674, 0.1425, 1.0000, 0.4663, 0.0731,
        0.8647, 0.0669, 0.9938, 0.9950, 0.5102, 0.9099, 0.9998, 1.0000, 0.7968,
        0.2748, 0.0613, 0.9976, 0.0820, 0.0621, 1.0000, 0.5000, 1.0000, 1.0000,
        0.9973, 0.9968, 0.9995, 0.4705, 0.9975, 0.9034, 0.9479, 0.9840, 0.9999,
        0.9999, 1.0000, 0.0610, 0.5175, 0.0523, 0.9998, 0.1088, 0.8875, 1.0000,
        0.3318, 1.0000, 0.1593, 0.6659, 1.0000, 0.9996, 0.3753, 1.0000, 1.0000,
        1.0000, 0.0571, 0.9983, 0.9998, 1.0000, 0.4213, 0.9955, 0.9466, 0.0788,
        1.0000, 0.9750, 0.8454, 0.0510, 0.9230, 1.0000, 1.0000, 0.0805, 0.9965,
        0.9964, 0.4056, 0.9989, 1.0000, 1.0000, 0.5207, 0.0000, 0.1102, 1.0000,
        1.0000, 0.9991, 0.1806, 1.0000, 1.0000, 0.5269, 1.0000, 0.1962, 0.7164,
        0.9986, 1.0000, 1.0000, 0.9467, 1.0000, 1.0000, 0.9987, 1.0000, 0.9702,
        0.4621, 0.1668, 0.0653, 0.9998, 0.1849, 0.9979, 0.9972, 0.9460, 1.0000,
        0.7100, 0.9949, 0.9585, 0.9977, 1.0000, 0.2912, 1.0000, 0.0883, 0.3342,
        0.9994, 1.0000, 0.9988, 0.8701, 0.2877, 1.0000, 0.5045, 0.9999, 0.9783,
        0.9050, 0.3645, 1.0000, 0.9998, 0.1963, 0.1140, 0.1516, 0.9608, 0.1035,
        0.9981, 0.4709, 0.4517, 0.8399, 0.3872, 0.9983, 0.9970, 0.0902, 0.0809,
        0.1247, 1.0000, 0.9984, 0.7093, 0.3390, 1.0000, 0.9998, 0.9251, 0.7851,
        0.7703, 0.1368, 0.8630, 0.7898, 0.9998, 1.0000, 0.0704, 0.9452, 0.8077,
        0.9081, 0.7616, 0.9952, 0.9997, 0.9336, 0.1253, 1.0000, 0.5788, 1.0000,
        1.0000, 0.9790, 1.0000, 0.5714, 0.0594, 0.8847, 1.0000, 1.0000, 0.4724,
        0.9968, 1.0000, 0.9999, 0.8498, 1.0000, 0.3163, 0.7273, 0.9995, 0.1215,
        0.9685, 0.1062, 0.9988, 0.8676, 1.0000, 0.7556, 0.6278, 0.9996, 0.9981,
        0.9672, 0.1987, 0.9999, 1.0000, 1.0000, 0.9128, 1.0000, 1.0000, 0.9417,
        0.9903, 0.9295, 1.0000, 0.1458, 0.9983, 1.0000, 0.1273, 0.9997, 0.2716,
        1.0000, 0.9992, 1.0000, 0.0786, 0.9319, 0.9963, 1.0000, 0.9974, 0.0681,
        0.9994, 0.0557, 1.0000, 0.3492, 0.7832, 0.9711, 0.9932, 1.0000, 0.4307,
        0.0527, 0.9889, 1.0000, 0.8761, 0.9994, 0.8938, 0.9783, 0.9999, 0.7458,
        0.9997, 0.2531, 0.9955, 0.7022, 0.7068, 1.0000, 1.0000, 1.0000, 0.9672,
        0.0527, 0.5087, 0.6707, 0.0550, 0.9053, 1.0000, 0.0535, 0.9996, 1.0000,
        0.9984, 0.2126, 0.9465, 0.7556, 0.9928, 0.4570, 1.0000, 0.4754, 0.1431,
        1.0000, 0.7839, 0.9370, 0.2309, 1.0000, 0.8222, 0.0943, 1.0000, 1.0000,
        0.1961, 0.6410, 1.0000, 0.1404, 0.8959, 1.0000, 0.9003, 0.9725, 0.9658,
        0.9443, 0.1552, 1.0000, 0.9969, 0.5162, 0.9847, 1.0000, 0.6377, 0.2203,
        0.9433, 0.0687, 1.0000, 0.9564, 0.1001, 0.9448, 1.0000, 0.9578, 1.0000,
        1.0000, 0.5207, 0.6961, 0.2547, 0.0723, 0.0503, 0.6779, 0.3217, 0.0509,
        0.4527, 0.9999, 1.0000, 0.1070, 0.9973, 0.9998, 0.9735, 0.2972, 0.9542,
        0.1019, 0.3267, 0.9998, 0.5019, 0.0690, 0.0899, 1.0000, 0.9973, 0.0855,
        0.9582, 0.9952, 0.9998, 1.0000, 0.4485, 1.0000, 0.1141, 0.9277, 1.0000,
        0.8056, 0.8695, 0.9999, 1.0000, 0.9155, 0.9822, 0.9860, 1.0000, 0.9616,
        0.7963, 0.0665, 0.0610, 0.9991, 1.0000, 0.9993, 1.0000, 1.0000, 1.0000,
        0.9896, 0.1331, 0.0666, 0.9997, 0.9999, 1.0000, 0.9995, 1.0000, 0.9867,
        0.0810, 1.0000, 0.0886, 0.3039, 0.8014, 0.9993, 0.1986, 0.2079, 1.0000,
        0.9875, 1.0000, 0.7826, 0.0691, 0.9998, 0.9767, 0.9480, 0.9999, 0.2956,
        0.7074, 0.9840, 0.9903, 1.0000, 1.0000, 1.0000, 0.0811, 0.9925, 0.9995,
        0.6680, 0.9988, 0.9457, 0.9985, 0.6824, 0.0754, 0.4138, 0.9997, 1.0000,
        0.9981, 0.7600, 0.4113, 1.0000, 1.0000, 0.9996, 1.0000, 0.4107, 0.6586,
        0.9998, 1.0000, 0.9173, 0.1628, 0.9999, 0.0684, 0.9969, 1.0000, 0.9799,
        1.0000, 0.9998, 1.0000, 0.7587, 0.1229, 1.0000, 1.0000, 1.0000, 0.9999,
        0.8426, 0.9997, 0.9990, 0.2117, 1.0000, 1.0000, 0.2198, 0.8765, 0.2750,
        0.6273, 0.0677, 0.8618, 0.3775, 1.0000, 1.0000, 0.4437, 1.0000, 0.2362,
        0.2134, 0.1852, 0.5042, 0.7291, 0.1152, 1.0000, 0.0000, 1.0000, 0.4838,
        0.4320, 1.0000, 1.0000, 1.0000, 0.9419, 0.9937, 1.0000, 1.0000, 0.4281,
        1.0000, 0.9677, 0.5829, 0.0566, 0.0859, 1.0000, 0.3221, 0.9658, 0.9450,
        0.0649, 1.0000, 0.9843, 0.9259, 0.6368, 0.2850, 0.9979, 0.0654, 0.1814,
        0.9803, 0.7788, 0.4569, 0.9978, 0.7417, 1.0000, 0.8549, 0.3596, 1.0000,
        1.0000, 0.2812, 0.9974, 1.0000, 0.3518, 0.9454, 1.0000, 0.9984, 1.0000,
        0.9230, 0.3057, 0.4293, 0.9285, 0.7371, 0.5743, 0.9994, 0.5034, 1.0000,
        0.9582, 0.8690, 0.9999, 1.0000, 0.1769, 0.0539, 1.0000, 0.9975, 1.0000,
        0.5171, 1.0000, 1.0000, 0.1441, 0.0530, 0.9995, 0.8552, 0.5541, 0.2456,
        0.9999, 0.9982, 0.8601, 0.7448, 0.1130, 0.4734, 0.9988, 0.0954, 0.7220,
        0.9972, 0.0747, 1.0000, 1.0000, 1.0000, 0.1511, 0.9720, 0.5202, 0.8220,
        1.0000, 0.9995, 0.9986, 0.9999, 0.2061, 0.9975, 0.1241, 0.9923, 1.0000,
        1.0000, 1.0000, 0.1449, 0.8900, 0.7221, 0.0886, 0.0736, 0.1026, 0.9681,
        0.9041, 0.9936, 0.3521, 0.5813, 1.0000, 0.0702, 0.6317, 0.6850, 0.1353,
        1.0000, 0.4487, 0.2983, 1.0000, 0.9999, 0.0000, 0.0000, 0.1122, 0.9980,
        0.1721, 1.0000, 0.9918, 1.0000, 0.2747, 0.1530, 0.2369, 0.9998, 0.9999,
        0.3441, 0.7063, 0.3329, 0.1459, 0.4211, 0.9998, 0.1910, 0.9489, 0.1826,
        0.0513, 1.0000, 1.0000, 1.0000, 0.0725, 1.0000, 1.0000, 0.9779, 0.3266,
        0.9340, 0.9473, 0.0794, 1.0000, 0.0796, 0.9981, 0.6066, 0.5601]), 'num_pos': 872}
2020-12-12 13:26:40,416 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.316514
2020-12-12 13:26:40,418 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-12 13:26:45,224 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-12 13:28:02,495 maskrcnn_benchmark.trainer INFO: eta: 0:16:06  iter: 820  loss: 7.3177 (7.6398)  loss_classifier: 0.3819 (0.5305)  loss_box_reg: 0.5276 (0.4980)  loss_objectness: 1.3980 (1.4720)  loss_rpn_box_reg: 4.9526 (5.1393)  time: 3.8558 (5.3685)  data: 0.2132 (1.7046)  lr: 0.000000  max mem: 1424
2020-12-12 13:29:19,821 maskrcnn_benchmark.trainer INFO: eta: 0:14:13  iter: 840  loss: 7.5397 (7.6344)  loss_classifier: 0.5841 (0.5312)  loss_box_reg: 0.5949 (0.5015)  loss_objectness: 1.3612 (1.4693)  loss_rpn_box_reg: 4.8753 (5.1324)  time: 3.8689 (5.3327)  data: 0.2157 (1.6692)  lr: 0.000000  max mem: 1424
2020-12-12 13:30:37,625 maskrcnn_benchmark.trainer INFO: eta: 0:12:21  iter: 860  loss: 7.4322 (7.6336)  loss_classifier: 0.4452 (0.5304)  loss_box_reg: 0.4991 (0.5016)  loss_objectness: 1.4007 (1.4682)  loss_rpn_box_reg: 5.2064 (5.1334)  time: 3.8760 (5.2991)  data: 0.2177 (1.6354)  lr: 0.000000  max mem: 1424
2020-12-12 13:31:54,849 maskrcnn_benchmark.trainer INFO: eta: 0:10:31  iter: 880  loss: 6.8543 (7.6161)  loss_classifier: 0.4294 (0.5293)  loss_box_reg: 0.4207 (0.4999)  loss_objectness: 1.3618 (1.4652)  loss_rpn_box_reg: 4.5999 (5.1217)  time: 3.8541 (5.2665)  data: 0.2057 (1.6031)  lr: 0.000000  max mem: 1424
2020-12-12 13:33:11,923 maskrcnn_benchmark.trainer INFO: eta: 0:08:43  iter: 900  loss: 7.5917 (7.6163)  loss_classifier: 0.4828 (0.5288)  loss_box_reg: 0.4373 (0.5005)  loss_objectness: 1.3738 (1.4634)  loss_rpn_box_reg: 5.3619 (5.1237)  time: 3.8517 (5.2351)  data: 0.2112 (1.5722)  lr: 0.000000  max mem: 1424
2020-12-12 13:34:29,235 maskrcnn_benchmark.trainer INFO: eta: 0:06:56  iter: 920  loss: 7.1118 (7.6117)  loss_classifier: 0.4377 (0.5280)  loss_box_reg: 0.5238 (0.5009)  loss_objectness: 1.3595 (1.4614)  loss_rpn_box_reg: 4.9099 (5.1214)  time: 3.8632 (5.2053)  data: 0.2076 (1.5426)  lr: 0.000000  max mem: 1424
2020-12-12 13:35:46,510 maskrcnn_benchmark.trainer INFO: eta: 0:05:10  iter: 940  loss: 7.1326 (7.6056)  loss_classifier: 0.4887 (0.5269)  loss_box_reg: 0.5699 (0.5026)  loss_objectness: 1.3134 (1.4588)  loss_rpn_box_reg: 4.9063 (5.1173)  time: 3.8621 (5.1768)  data: 0.2097 (1.5143)  lr: 0.000000  max mem: 1424
2020-12-12 13:37:03,654 maskrcnn_benchmark.trainer INFO: eta: 0:03:25  iter: 960  loss: 7.2027 (7.6026)  loss_classifier: 0.4281 (0.5262)  loss_box_reg: 0.4630 (0.5033)  loss_objectness: 1.3147 (1.4562)  loss_rpn_box_reg: 4.9517 (5.1169)  time: 3.8541 (5.1493)  data: 0.2050 (1.4871)  lr: 0.000000  max mem: 1424
2020-12-12 13:37:03,656 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 13:37:03,725 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(148 images).
2020-12-12 13:40:46,324 maskrcnn_benchmark.inference INFO: Total run time: 0:03:42.599337 (1.5040495733957033 s / img per device, on 1 devices)
2020-12-12 13:40:46,324 maskrcnn_benchmark.inference INFO: Model inference time: 0:03:27.936058 (1.4049733651650917 s / img per device, on 1 devices)
2020-12-12 13:40:46,325 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 13:41:01,787 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 13:41:01,788 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([3.2977e-02, 0.0000e+00, 0.0000e+00, 4.0195e-02, 2.4178e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.6032e-02, 4.0237e-02, 2.7131e-02, 2.4092e-02, 9.3727e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4459e-02, 4.7557e-02, 3.3420e-02,
        1.8122e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5479e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3173e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.0342e-02, 1.7634e-02, 6.4991e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5745e-01, 8.4999e-02,
        5.6831e-02, 2.1758e-02, 5.2928e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.5827e-02, 2.1682e-02, 9.8219e-03, 2.4795e-01, 3.0221e-02,
        1.7334e-02, 9.5115e-03, 4.4467e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5586e-01, 5.1346e-02,
        3.2977e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7854e-02, 5.0262e-05,
        0.0000e+00, 1.2913e-03, 1.8274e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5741e-02, 0.0000e+00,
        0.0000e+00, 3.2977e-02, 2.3336e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.6473e-02, 6.2087e-02, 3.7750e-02, 2.3004e-02, 1.2065e-02, 4.2401e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0251e-01, 1.8959e-02, 4.6916e-04,
        1.4034e-01, 1.2017e-01, 5.5294e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.8025e-02, 4.6535e-02, 1.8174e-02, 3.5470e-02, 3.3548e-02, 2.3111e-06,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.3421e-02, 3.2139e-02, 2.6664e-02, 9.0835e-03, 2.8214e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0043e-02,
        5.7201e-02, 2.1682e-02, 1.1738e-01, 8.3757e-02, 0.0000e+00, 1.0673e-01,
        5.2282e-02, 5.6954e-03, 4.7417e-02, 3.2863e-02, 6.6264e-04, 2.8029e-02,
        6.4806e-03, 2.2353e-03, 1.1184e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.1850e-02, 0.0000e+00, 0.0000e+00, 4.2079e-02,
        6.7301e-02, 2.8150e-02, 0.0000e+00, 9.5717e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.9923e-03, 2.7139e-03, 0.0000e+00, 1.1954e-01, 3.3082e-02, 2.8661e-02,
        2.1551e-02, 1.9829e-02, 9.5581e-03, 2.1027e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.3285e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5076e-01,
        4.6932e-02, 1.4107e-02, 7.4864e-02, 1.7740e-02, 7.0704e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6550e-02,
        2.1682e-02, 0.0000e+00, 8.1588e-02, 2.1664e-04, 0.0000e+00, 5.5832e-02,
        3.2977e-02, 8.3777e-05, 3.2139e-02, 2.3361e-02, 2.1522e-02, 8.4333e-03,
        5.2537e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.7331e-02, 9.9863e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9521e-02, 1.8921e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.4496e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9963e-02, 3.6712e-02,
        6.9301e-02, 3.5120e-02, 0.0000e+00, 4.2750e-02, 2.3909e-02, 1.0193e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.0740e-01, 6.6607e-02, 2.1682e-02, 4.1956e-02, 0.0000e+00, 0.0000e+00,
        8.8937e-02, 8.6785e-02, 6.2037e-02, 3.3888e-02, 2.6161e-02, 2.4003e-02,
        1.0318e-02, 0.0000e+00, 0.0000e+00, 1.1276e-02, 4.8060e-03, 2.9176e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.5992e-02, 3.2499e-03, 1.4055e-04, 7.8693e-02, 6.1527e-02, 2.6960e-02,
        1.4749e-02, 1.0014e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.2352e-02, 6.1993e-02, 7.7545e-03, 2.5027e-02,
        2.1183e-02, 1.2316e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 2.3348e-02, 8.1745e-03, 6.7922e-02,
        6.3487e-02, 2.3553e-02, 1.4584e-02, 8.5145e-03, 5.7545e-05, 3.2766e-05,
        0.0000e+00, 0.0000e+00, 2.4598e-02, 1.8978e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2523e-01,
        3.0085e-02, 2.8661e-02, 1.9798e-02, 1.5829e-02, 7.7254e-03, 5.5570e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4225e-01, 1.0780e-01,
        7.6616e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.0607e-01, 5.0154e-02, 4.6733e-02, 1.1667e-01, 8.1232e-02,
        3.7191e-03, 1.9045e-01, 3.4708e-02, 2.5684e-02, 6.8449e-03, 5.2523e-03,
        1.3215e-03, 1.5437e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.5285e-03, 0.0000e+00, 0.0000e+00, 1.9151e-02, 4.3392e-04, 1.8166e-04,
        2.9226e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5598e-02, 2.5148e-02, 1.3970e-02, 1.2273e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5122e-02,
        1.0525e-02, 0.0000e+00, 4.6455e-02, 3.9814e-02, 3.9014e-02, 1.9591e-02,
        1.6537e-02, 1.5874e-02, 1.2526e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.1749e-02, 0.0000e+00, 0.0000e+00, 2.8639e-02, 1.7986e-02,
        1.4429e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3709e-02, 2.1558e-02, 2.1457e-02,
        1.9548e-01, 2.1682e-02, 0.0000e+00, 8.3196e-02, 7.0863e-03, 0.0000e+00,
        5.2200e-02, 4.8957e-02, 1.1417e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4549e-02, 3.2584e-05, 0.0000e+00, 5.6294e-03, 2.2725e-03, 2.0433e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.6926e-02, 2.9510e-02, 1.3994e-02, 5.9783e-03, 5.3440e-03, 3.4562e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2139e-02,
        2.7715e-02, 9.4751e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0183e-02, 1.5567e-02,
        9.8298e-03, 5.3847e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.9646e-02, 1.2463e-02, 1.0294e-02, 9.9242e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6486e-02, 5.7338e-02,
        4.2540e-04, 1.1927e-01, 2.9319e-02, 2.2974e-02, 1.9770e-02, 7.7716e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0262e-01, 1.6181e-02, 6.0631e-03, 7.4521e-02, 1.2910e-01, 1.0264e-01,
        1.1280e-02, 8.0166e-03, 1.8330e-03, 1.7443e-03, 1.4547e-03, 1.4417e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3985e-02, 1.1884e-02, 1.0667e-03,
        3.1749e-02, 2.3736e-03, 0.0000e+00, 6.0177e-02, 1.0193e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 7.0117e-03, 5.0794e-03, 1.4003e-03, 6.5158e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2429e-02,
        5.1372e-02, 0.0000e+00, 7.8261e-03, 0.0000e+00, 6.1721e-02, 5.6008e-02,
        1.5681e-02, 7.2849e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.3316e-01, 7.4152e-02, 1.2316e-02, 8.7718e-02, 2.9533e-02,
        1.6501e-02, 1.5798e-02, 1.1898e-02, 4.6242e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0923e-02, 3.2977e-02, 0.0000e+00,
        3.2977e-02, 0.0000e+00, 0.0000e+00, 3.2977e-02, 2.1682e-02, 6.7460e-05,
        1.4536e-01, 4.3845e-02, 1.7994e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5037e-03, 3.3726e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.8397e-02, 3.5626e-02, 8.8711e-06, 3.0605e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.9721e-02, 1.8721e-02, 4.4117e-05, 3.7151e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.4804e-02, 0.0000e+00,
        0.0000e+00, 3.6215e-02, 3.5274e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0952e-02, 3.1593e-03,
        2.8901e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.2374e-01, 8.1888e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0265e-02, 1.6753e-02, 4.2335e-03, 6.2982e-02, 4.8595e-02, 1.5516e-02,
        2.2954e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3975e-01, 2.8804e-02, 2.1682e-02, 1.9849e-01, 0.0000e+00, 0.0000e+00,
        5.1754e-02, 0.0000e+00, 0.0000e+00, 1.1903e-01, 5.5214e-02, 3.7751e-02,
        3.5927e-02, 1.6139e-02, 5.5006e-03, 1.2039e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0734e-03, 1.7011e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0559e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4424e-01,
        5.2114e-02, 0.0000e+00, 8.4722e-02, 6.5670e-02, 5.2033e-02, 4.0519e-03,
        2.3192e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8212e-02,
        6.7648e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.7202e-02, 2.4232e-02, 3.9741e-03, 0.0000e+00,
        0.0000e+00, 3.2139e-02, 2.5652e-02, 2.1064e-02, 1.3034e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4150e-02, 2.7333e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0968e-02,
        0.0000e+00, 0.0000e+00, 9.1293e-02, 5.0405e-02, 2.1682e-02, 1.0117e-01,
        0.0000e+00, 0.0000e+00, 5.7505e-02, 2.2013e-02, 6.2315e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5033e-02,
        1.2602e-03, 9.6350e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.3642e-02, 4.9762e-02, 4.0850e-02, 3.6037e-02, 1.5874e-02, 1.3665e-02,
        7.4881e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0723e-01, 4.1516e-02, 3.2290e-02, 4.7139e-02,
        6.9736e-05, 0.0000e+00, 7.9078e-02, 3.9534e-02, 2.3345e-03, 9.3163e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.1749e-02, 3.5796e-04, 0.0000e+00, 2.0385e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.8539e-02, 0.0000e+00, 0.0000e+00, 3.3771e-01,
        4.1703e-02, 3.8472e-02, 7.6687e-02, 2.4437e-02, 3.7379e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02,
        0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 1, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7,
        4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 4, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 7, 7, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 7, 7, 4]), 'best match labels': tensor([ 8.,  7.,  8.,  2.,  2.,  2.,  2.,  2.,  4.,  7.,  7.,  7.,  7.,  2.,
         7.,  1.,  6.,  7.,  8.,  1.,  8.,  7.,  1.,  7.,  7.,  2.,  7.,  7.,
         7.,  7.,  7.,  7.,  7.,  7., -1.,  1.,  1.,  2.,  2.,  2.,  4.,  2.,
         7.,  4.,  4.,  4.,  1.,  7.,  2.,  7.,  7.,  1.,  4.,  4.,  7.,  7.,
         7.,  4.,  7.,  7.,  1.,  7.,  7.,  4.,  1.,  2.,  7.,  2.,  2.,  2.,
         2.,  2.,  2.,  2.,  2.,  2.,  1.,  7.,  7., -1., -1.,  1.,  1.,  2.,
         2.,  4.,  7.,  7.,  8.,  1.,  4.,  2.,  2.,  4.,  4.,  7.,  1.,  7.,
         8.,  1.,  2.,  7.,  7.,  8.,  7.,  4.,  7.,  8.,  2.,  7.,  7.,  1.,
         2.,  2.,  7.,  7.,  2.,  7.,  8.,  2.,  7.,  1.,  7.,  1.,  1.,  1.,
         2.,  2.,  2.,  2.,  4.,  7.,  7.,  2.,  1.,  2.,  2.,  1.,  2.,  4.,
         7.,  7.,  7.,  7.,  1.,  2.,  2.,  4.,  7.,  7.,  1.,  7.,  2.,  2.,
         7.,  2.,  2.,  7.,  2.,  2.,  8.,  4.,  7.,  2.,  7.,  8.,  2.,  7.,
         2.,  4.,  8.,  7.,  7.,  8.,  2.,  7.,  7.,  1.,  7.,  7.,  7.,  7.,
         7.,  2.,  2.,  2.,  2.,  2.,  7.,  7.,  2.,  7.,  2.,  7.,  2.,  7.,
         7.,  2.,  7.,  7.,  7.,  7.,  1.,  7.,  8.,  8.,  1.,  2.,  2.,  2.,
         4.,  4.,  4.,  7.,  8.,  7.,  7.,  7.,  1.,  1.,  1.,  2.,  7.,  2.,
         2.,  7.,  1.,  7.,  4.,  8.,  8.,  1.,  1.,  1.,  4.,  7.,  4.,  8.,
         2.,  7.,  2.,  1.,  4.,  5.,  7.,  7.,  8., -1.,  1.,  1.,  1.,  2.,
         2.,  2.,  2.,  8.,  1.,  1.,  2.,  2.,  7.,  7.,  2.,  4.,  7.,  2.,
         2.,  2.,  2.,  4.,  7.,  7.,  7.,  2.,  7.,  2.,  7.,  7.,  2.,  1.,
         2.,  7.,  2.,  2.,  2.,  4.,  7.,  4.,  7.,  1.,  7.,  8.,  8.,  7.,
         7.,  4.,  7.,  7.,  7.,  7.,  2.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,
         7.,  1.,  8.,  7.,  7.,  7.,  2.,  2.,  7.,  2.,  2.,  7.,  4.,  4.,
         7.,  7.,  1.,  1.,  7.,  7.,  7.,  4.,  2., -1.,  2.,  1.,  2.,  2.,
         2.,  7.,  2.,  7.,  2.,  2.,  2.,  2.,  7.,  7.,  7.,  2.,  7.,  2.,
         7., -1., -1.,  2.,  2.,  2.,  2.,  2.,  7.,  2.,  1.,  8.,  2.,  2.,
         2.,  7.,  8.,  8.,  7.,  8.,  7.,  2.,  7.,  2.,  7.,  8.,  8.,  8.,
         7.,  2.,  2.,  7.,  7.,  1.,  7.,  1.,  7.,  1.,  2.,  2.,  2.,  4.,
         6.,  7.,  8.,  7.,  7.,  1.,  8.,  4.,  4.,  4.,  1.,  1.,  2.,  7.,
         7.,  7.,  2.,  1.,  2.,  2.,  5.,  1.,  7.,  7.,  2.,  7.,  8.,  1.,
         2.,  8.,  4.,  1.,  7.,  1.,  7.,  1.,  7.,  8.,  8.,  7.,  1.,  7.,
         7.,  7.,  2.,  1.,  2.,  2.,  2.,  7.,  4.,  7.,  7.,  2.,  7.,  7.,
         2.,  1.,  7.,  2.,  8.,  8.,  1.,  7.,  1.,  2.,  2.,  4.,  4.,  7.,
         7.,  1.,  7.,  8.,  1.,  7.,  8.,  2.,  2.,  8.,  2.,  4.,  4.,  1.,
         7.,  7.,  7.,  7.,  1.,  4.,  2.,  7.,  1.,  2.,  7.,  7.,  7.,  7.,
         7.,  2.,  4.,  2.,  2.,  2.,  7.,  4.,  4.,  7.,  7.,  7.,  1.,  7.,
         1.,  2.,  7.,  7.,  7.,  8.,  2.,  4.,  8.,  4.,  4.,  4.,  7.,  1.,
         8.,  4.,  2.,  2.,  7.,  1.,  7.,  2.,  2.,  2.,  1.,  7.,  2.,  7.,
         7.,  7.,  2.,  8.,  4.,  7.,  1.,  7.,  2.,  4.,  7.,  7.,  7.,  8.,
         1.,  2.,  2.,  7.,  4.,  2.,  8.,  2.,  2.,  2.,  2.,  2.,  4.,  7.,
         7.,  2.,  7.,  4.,  1.,  4.,  7.,  2.,  2.,  2.,  4.,  7.,  7.,  8.,
         2.,  2.,  7.,  7.,  7.,  7.,  7.,  2.,  7.,  2.,  7.,  7.,  1.,  7.,
         7.,  7.,  7.,  7.,  7.,  8.,  8.,  7.,  4.,  7.,  7.,  8.,  8.,  7.,
         8.,  2.,  7.,  7.,  8.,  4.,  8.,  4.,  8.,  2.,  4.,  4.,  4.,  4.,
         7.,  7.,  2.,  7.,  7.,  2.,  2.,  4.,  7.,  7.,  7.,  4.,  8.,  2.,
         2.,  7.,  8.,  4.,  2.,  2.,  2.,  2.,  2.,  4.,  7.,  7.,  8.,  2.,
         2.,  2.,  7.,  2.,  2.,  1.,  7.,  8.,  7.,  7.,  2.,  7.,  2.,  4.,
         6.,  4.,  7.,  7.,  7.,  7.,  2.,  1.,  1.,  1.,  7.,  2.,  2.,  2.,
         7.,  1.,  2.,  2.,  2.,  7.,  7.,  7.,  7.,  8.,  8.,  8.,  1.,  2.,
         1.,  2.,  7.,  4.,  1.,  2.,  7.,  8.,  8.,  7.,  2.,  8.,  7.,  7.,
         7.,  2.,  7.,  2.,  8.,  4.,  1.,  2.,  2.,  2.,  2.,  2.,  1.,  2.,
         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  7.,  7.,  7.,  2.,  1.,  1.,
         1.,  1.,  1.,  2.,  2.,  2.,  4.,  4.,  7.,  4.,  7.,  8.,  1.,  7.,
         4.,  1.,  7.,  1.,  2.,  7.,  7.,  2.,  2.,  2.,  2.,  1.,  2.,  4.,
         7.,  8.,  2.,  2.,  7.,  7.,  7.,  2.,  7.,  2.,  2.,  7.,  7.,  8.,
         8.,  1.,  2.,  2.,  2.,  7.,  2.,  4.,  4.,  4.,  7.,  7.,  7.,  8.,
         7.,  8.,  8.,  8.,  2.,  8.,  7.,  2.,  7.,  7.,  2.,  8.,  2.,  2.,
         2.,  2.,  1.,  4.,  4.,  7.,  2.,  7.,  7.,  7.,  7.,  7.,  4.,  4.,
         1.,  4.,  1.,  2.,  1.,  2.,  2.,  4.,  7.,  8.,  8.,  7.,  1.,  7.,
         1.,  1.,  7.,  7.,  2.,  1.,  7.,  2.,  2.,  1.,  2.,  2.,  4.,  4.,
         8.,  8.,  1.,  7.,  4.,  6.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  8.,
         7.,  4.,  7.,  4.,  2.,  7.,  2., -1.,  1.,  1.,  1.,  2.,  2.,  7.,
         4.,  7.,  4.,  7.]), 'best match scores': tensor([0.9862, 0.9990, 0.8686, 0.9990, 0.9986, 0.7864, 0.9996, 1.0000, 0.9999,
        0.9973, 0.3212, 1.0000, 0.9743, 0.2530, 0.5635, 0.0618, 1.0000, 0.8223,
        0.9991, 0.8455, 0.9998, 0.2632, 1.0000, 1.0000, 0.9991, 0.9032, 1.0000,
        1.0000, 0.0682, 0.9991, 0.4078, 1.0000, 0.0617, 0.4600, 0.0000, 0.9996,
        0.1441, 0.2340, 1.0000, 1.0000, 1.0000, 0.9998, 0.7097, 0.9997, 0.1204,
        0.3082, 0.6806, 0.5977, 0.9998, 0.9996, 1.0000, 0.0632, 0.4645, 0.8031,
        0.9999, 0.9999, 0.9953, 0.9975, 0.5348, 0.0954, 0.9599, 0.9956, 1.0000,
        0.9998, 0.1104, 0.0679, 0.9975, 0.9999, 0.9999, 1.0000, 0.9989, 0.9998,
        0.9997, 0.3968, 0.9673, 0.9850, 0.0912, 0.9859, 0.8645, 0.0000, 0.0000,
        0.9990, 1.0000, 1.0000, 1.0000, 0.9996, 0.9999, 0.1547, 0.1174, 0.9729,
        1.0000, 0.9149, 0.5224, 0.9264, 1.0000, 0.1037, 0.9998, 0.1439, 1.0000,
        0.2004, 1.0000, 0.8138, 0.7592, 0.5305, 0.2846, 0.1224, 1.0000, 0.0960,
        1.0000, 0.8698, 0.9888, 0.1053, 0.7294, 0.9345, 0.8851, 0.9013, 0.9767,
        0.7950, 0.6663, 0.9994, 0.4499, 0.3924, 0.9978, 0.2698, 0.9910, 0.5772,
        0.9944, 0.9972, 1.0000, 0.1816, 0.1268, 0.4382, 0.9475, 1.0000, 0.0583,
        0.9990, 0.9919, 0.9025, 0.5533, 0.2153, 0.0549, 0.9039, 0.2258, 0.9999,
        0.0811, 0.9989, 1.0000, 0.9999, 0.3567, 0.0748, 0.4176, 0.7965, 0.9455,
        0.9761, 0.1233, 0.9526, 1.0000, 1.0000, 1.0000, 0.9997, 1.0000, 0.4145,
        0.3828, 0.3135, 0.8217, 0.8533, 0.9166, 0.9960, 0.9480, 0.1791, 0.3215,
        0.0705, 0.9999, 0.1479, 0.8198, 0.4662, 0.9999, 0.4515, 1.0000, 0.0608,
        0.7177, 0.9999, 0.9869, 1.0000, 0.0650, 0.0620, 1.0000, 1.0000, 0.8003,
        0.7745, 0.3178, 0.3680, 0.8014, 0.9842, 0.9998, 0.5055, 0.7136, 0.0713,
        0.9336, 0.9999, 0.3340, 1.0000, 0.9683, 0.7921, 0.2453, 0.9863, 0.0724,
        1.0000, 0.0764, 1.0000, 0.9986, 0.9993, 0.4396, 0.0799, 0.2067, 0.7492,
        0.9918, 0.7448, 1.0000, 0.4861, 0.3452, 0.2607, 0.9609, 0.9211, 1.0000,
        0.9963, 0.9704, 0.9924, 1.0000, 0.0608, 0.9999, 0.9129, 0.3791, 0.3995,
        1.0000, 0.5229, 0.9982, 0.1988, 0.0803, 0.2712, 0.3150, 0.9466, 0.9998,
        0.6100, 0.2504, 0.4518, 0.9884, 0.0000, 0.3069, 0.9407, 0.9846, 0.8990,
        0.9860, 0.8695, 0.1958, 0.1888, 0.2802, 0.0513, 0.5596, 1.0000, 0.9568,
        0.9999, 0.2003, 0.3001, 0.9917, 1.0000, 0.8442, 1.0000, 0.1296, 0.7365,
        0.1342, 0.1132, 0.5326, 0.1283, 0.0748, 0.6701, 1.0000, 0.0782, 0.2480,
        0.1130, 0.6294, 0.2575, 0.8648, 0.0884, 0.0609, 0.8792, 0.1191, 0.8810,
        0.9979, 0.9980, 1.0000, 0.9866, 0.9327, 0.8412, 1.0000, 0.9767, 1.0000,
        1.0000, 0.3999, 0.4064, 0.5677, 0.9328, 0.9933, 0.9510, 0.6073, 0.2231,
        0.0798, 1.0000, 0.9768, 0.5451, 0.8057, 0.0907, 0.5793, 0.9257, 0.9660,
        0.1451, 1.0000, 0.9951, 0.0843, 0.9918, 0.9893, 1.0000, 0.4683, 0.9938,
        0.0819, 0.8179, 0.8759, 0.9175, 0.9985, 1.0000, 0.4573, 0.0000, 0.9990,
        1.0000, 0.9962, 0.9924, 0.1069, 0.0738, 0.0995, 1.0000, 1.0000, 0.8855,
        0.6599, 0.2510, 0.5967, 0.2015, 0.9943, 1.0000, 0.9744, 0.9962, 0.5114,
        0.0000, 0.0000, 0.9322, 0.3474, 0.8923, 1.0000, 0.0705, 0.2526, 1.0000,
        0.1063, 0.0523, 0.9970, 0.9998, 0.8069, 0.9531, 0.1242, 0.1279, 0.9998,
        0.1181, 0.9758, 0.9945, 0.1011, 0.9955, 0.0844, 0.9901, 0.9045, 0.1930,
        0.9971, 1.0000, 0.9148, 1.0000, 1.0000, 0.1096, 0.0788, 0.9957, 0.1550,
        0.9814, 0.0629, 0.3556, 0.9799, 0.9995, 1.0000, 0.9986, 0.9667, 0.8523,
        0.0548, 0.1503, 0.9723, 1.0000, 0.9994, 0.3656, 0.9997, 0.1429, 0.9222,
        0.3690, 0.0525, 1.0000, 0.9992, 0.1029, 0.8913, 0.9999, 0.9934, 0.9999,
        1.0000, 1.0000, 0.6477, 0.9999, 0.1063, 0.9997, 1.0000, 0.6355, 1.0000,
        0.1340, 0.9993, 0.0792, 0.3757, 0.9476, 1.0000, 0.1982, 0.0518, 1.0000,
        0.9985, 0.1582, 1.0000, 1.0000, 0.9999, 0.8825, 0.2501, 0.9998, 0.2853,
        1.0000, 0.9901, 0.9951, 1.0000, 0.8114, 0.9989, 0.0942, 0.3118, 0.8238,
        0.9981, 1.0000, 0.9671, 0.9841, 1.0000, 1.0000, 0.3696, 0.9999, 0.1882,
        0.1123, 0.8346, 0.0769, 0.9697, 0.5883, 1.0000, 0.3638, 0.9768, 1.0000,
        0.9977, 0.0543, 0.9999, 0.9737, 0.3884, 0.9970, 0.6936, 0.3240, 0.9751,
        1.0000, 0.3064, 0.0555, 0.9956, 0.0752, 0.9418, 0.1764, 0.9999, 0.1029,
        0.4791, 0.9263, 0.3866, 0.9961, 0.4517, 1.0000, 0.8941, 1.0000, 0.9752,
        0.9703, 0.9961, 0.2911, 1.0000, 0.1336, 0.7503, 0.9792, 0.4806, 1.0000,
        0.9995, 0.3577, 0.1841, 0.9987, 0.0666, 0.9998, 0.5299, 0.9000, 0.6242,
        0.9316, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.1027, 0.6082, 0.9368,
        1.0000, 0.0681, 0.6108, 1.0000, 1.0000, 1.0000, 0.6315, 1.0000, 0.4711,
        1.0000, 0.7187, 1.0000, 0.9996, 0.9858, 0.9999, 0.7536, 0.9994, 0.1635,
        0.9843, 0.9920, 0.8220, 1.0000, 0.8109, 0.9998, 0.2621, 0.9843, 0.9774,
        0.8254, 0.9991, 0.7259, 1.0000, 0.8188, 0.2909, 1.0000, 1.0000, 0.1524,
        0.8942, 0.9998, 0.9998, 0.1488, 1.0000, 0.9859, 1.0000, 0.1418, 0.7770,
        0.8459, 0.3974, 1.0000, 0.9998, 1.0000, 0.0806, 0.9076, 1.0000, 1.0000,
        0.2998, 0.2506, 0.1129, 0.1058, 0.9948, 0.9322, 0.1081, 0.2317, 0.5671,
        0.0717, 0.3565, 0.9602, 1.0000, 1.0000, 0.5813, 0.9995, 0.1501, 0.9997,
        1.0000, 1.0000, 0.3265, 0.7193, 0.8550, 0.0622, 0.4816, 1.0000, 0.8009,
        0.7248, 0.9997, 0.9907, 1.0000, 0.9994, 1.0000, 0.9998, 0.9999, 0.9997,
        0.8969, 1.0000, 0.8536, 0.9973, 0.9983, 0.9179, 0.9999, 1.0000, 0.8211,
        1.0000, 0.1657, 1.0000, 0.9442, 0.5053, 0.9914, 0.9998, 0.0520, 1.0000,
        1.0000, 0.9935, 0.0858, 0.2094, 1.0000, 1.0000, 1.0000, 0.2367, 0.9070,
        0.9841, 0.4776, 1.0000, 1.0000, 0.7438, 0.9594, 0.9995, 1.0000, 0.9999,
        0.5464, 0.2748, 0.9978, 0.1817, 1.0000, 0.0656, 0.9077, 0.9999, 1.0000,
        1.0000, 0.3723, 0.9985, 0.3167, 0.7803, 0.9997, 0.1519, 1.0000, 0.9983,
        0.9337, 0.6313, 0.2076, 0.7100, 0.9683, 0.7589, 0.9824, 0.9999, 0.0996,
        0.0749, 0.3045, 0.2043, 0.1364, 0.1053, 1.0000, 0.0618, 0.9968, 0.9983,
        0.4768, 1.0000, 0.1056, 0.1073, 0.1578, 0.9814, 0.9287, 0.9950, 0.4959,
        0.5903, 0.4255, 0.5161, 0.4434, 1.0000, 1.0000, 1.0000, 0.0665, 0.2911,
        0.9995, 0.1179, 0.3125, 0.5145, 0.5919, 0.9950, 0.0888, 1.0000, 0.8627,
        0.9995, 0.0634, 0.9278, 1.0000, 0.9120, 0.9754, 1.0000, 0.3940, 1.0000,
        1.0000, 0.9983, 0.5853, 0.5784, 0.9882, 1.0000, 0.2009, 0.9991, 0.9990,
        0.9590, 0.8005, 0.4663, 0.0557, 0.0970, 1.0000, 0.7068, 1.0000, 0.9992,
        0.0749, 1.0000, 0.5022, 0.9926, 0.5933, 0.0665, 1.0000, 0.0640, 0.9999,
        0.9943, 0.9976, 0.1929, 0.1021, 0.9997, 0.9993, 0.1247, 1.0000, 0.0708,
        1.0000, 0.5721, 0.7203, 0.9440, 0.9882, 0.9717, 0.4611, 0.9494, 0.9965,
        0.2711, 1.0000, 0.9992, 0.9995, 0.8925, 0.0584, 0.6918, 0.2976, 1.0000,
        0.7753, 0.9947, 1.0000, 0.1371, 0.9994, 0.1397, 0.8541, 0.5436, 0.9999,
        1.0000, 0.3725, 0.7581, 1.0000, 0.9745, 0.6073, 1.0000, 0.1118, 1.0000,
        0.4704, 0.9995, 0.5854, 1.0000, 0.9999, 1.0000, 0.0595, 0.9989, 0.1185,
        0.9947, 0.9938, 0.4764, 0.3828, 1.0000, 0.7100, 0.3474, 0.3562, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9424, 0.9988, 0.9909, 0.8018, 0.3088,
        0.8829, 0.6956, 0.9982, 0.1668, 0.9910, 0.5821, 0.8048, 0.9817, 0.9996,
        0.9994, 1.0000, 1.0000, 0.9470, 0.8494, 1.0000, 1.0000, 1.0000, 0.9961,
        1.0000, 0.0970, 0.9998, 0.2686, 0.4197, 0.0699, 1.0000, 1.0000, 0.4467,
        0.9962, 0.9965, 0.6045, 0.9998, 0.0557, 0.0820, 0.0668, 0.5533, 1.0000,
        0.9973, 0.9996, 1.0000, 0.9999, 0.1215, 0.1319, 0.0000, 1.0000, 0.0641,
        0.1928, 0.5626, 0.2410, 1.0000, 0.9996, 0.1328, 1.0000, 1.0000]), 'num_pos': 872}
2020-12-12 13:41:01,895 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.284404
2020-12-12 13:42:19,216 maskrcnn_benchmark.trainer INFO: eta: 0:01:47  iter: 980  loss: 7.5467 (7.6005)  loss_classifier: 0.3830 (0.5252)  loss_box_reg: 0.3139 (0.5019)  loss_objectness: 1.3988 (1.4551)  loss_rpn_box_reg: 5.2979 (5.1184)  time: 3.8661 (5.3662)  data: 0.2139 (1.7042)  lr: 0.000000  max mem: 1424
2020-12-12 13:43:36,393 maskrcnn_benchmark.trainer INFO: eta: 0:00:00  iter: 1000  loss: 7.2763 (7.5926)  loss_classifier: 0.4724 (0.5237)  loss_box_reg: 0.5229 (0.5020)  loss_objectness: 1.3413 (1.4533)  loss_rpn_box_reg: 4.8568 (5.1137)  time: 3.8577 (5.3360)  data: 0.2116 (1.6744)  lr: 0.000000  max mem: 1424
2020-12-12 13:43:36,395 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./final_mode_r3.pth
2020-12-12 13:43:41,119 maskrcnn_benchmark.trainer INFO: final model, saving model to: final_mode_r3
2020-12-12 13:43:41,119 maskrcnn_benchmark.trainer INFO: Total training time: 1:29:00.755815 (5.3408 s / it)
2020-12-12 13:43:43,241 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_test dataset(258 images).
2020-12-12 13:50:12,857 maskrcnn_benchmark.inference INFO: Total run time: 0:06:29.615569 (1.510137865709704 s / img per device, on 1 devices)
2020-12-12 13:50:12,857 maskrcnn_benchmark.inference INFO: Model inference time: 0:06:01.890747 (1.4026773123778113 s / img per device, on 1 devices)
2020-12-12 13:50:12,897 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 13:50:39,746 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 13:50:39,746 maskrcnn_benchmark.inference INFO: {'ar': tensor(6.5963e-05), 'recalls': tensor([0.0007, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.4207e-01, 6.4356e-03, 1.3765e-04,  ..., 0.0000e+00, 0.0000e+00,
        0.0000e+00]), 'gt_labels': tensor([7, 7, 4,  ..., 2, 2, 2]), 'best match labels': tensor([7., 7., 7.,  ..., 7., 7., 8.]), 'best match scores': tensor([0.2594, 1.0000, 1.0000,  ..., 0.9999, 0.2846, 0.2722]), 'num_pos': 1516}
2020-12-12 13:50:39,752 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_test dataset(7 images).
2020-12-12 13:50:50,278 maskrcnn_benchmark.inference INFO: Total run time: 0:00:10.525940 (1.5037057059151786 s / img per device, on 1 devices)
2020-12-12 13:50:50,279 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:09.811073 (1.4015818664005824 s / img per device, on 1 devices)
2020-12-12 13:50:50,280 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 13:50:50,995 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 13:50:50,995 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0351, 0.0310, 0.0045, 0.0200, 0.0111, 0.0032, 0.0048, 0.0000, 0.0222,
        0.0076, 0.0124, 0.0055, 0.0041, 0.0131, 0.0000, 0.0291, 0.0059, 0.0055]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([2., 7., 7., 7., 1., 7., 7., 7., 4., 2., 4., 1., 7., 7., 7., 7., 1., 7.]), 'best match scores': tensor([0.9442, 0.1900, 0.9992, 0.5470, 0.9973, 1.0000, 0.0685, 0.8208, 0.9975,
        0.5714, 0.0915, 1.0000, 0.9998, 0.9905, 0.9520, 0.5544, 0.8751, 0.9782]), 'num_pos': 18}
2020-12-12 13:50:51,002 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_test dataset(3 images).
2020-12-12 13:50:55,585 maskrcnn_benchmark.inference INFO: Total run time: 0:00:04.582236 (1.5274120966593425 s / img per device, on 1 devices)
2020-12-12 13:50:55,585 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:04.202415 (1.4008050759633381 s / img per device, on 1 devices)
2020-12-12 13:50:55,594 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 13:50:55,898 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 13:50:55,898 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0507, 0.0201, 0.0130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0040,
        0.0024, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0194, 0.0062,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1]), 'best match labels': tensor([-1.,  7.,  1.,  2.,  2.,  2.,  7.,  7., -1., -1.,  1.,  1.,  8.,  1.,
         2.,  4., -1., -1.,  1.,  1.,  1.,  2.,  2.,  7.,  2.]), 'best match scores': tensor([0.0000, 0.6190, 0.9999, 0.9987, 0.9967, 0.9395, 0.6747, 0.9524, 0.0000,
        0.0000, 0.9995, 0.4592, 0.9991, 0.9074, 1.0000, 1.0000, 0.0000, 0.0000,
        0.4884, 0.5099, 0.1632, 1.0000, 0.1012, 0.8105, 0.9982]), 'num_pos': 25}
2020-12-12 13:56:10,628 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 13:56:10,628 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='draw_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 13:56:10,628 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 13:56:13,950 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 13:56:13,951 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 13:56:13,952 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000004
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1000
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 13:56:13,955 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 4e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 13:56:15,631 maskrcnn_benchmark INFO: reloading weigts from final_mode_r3.pth
2020-12-12 14:23:26,241 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 14:23:26,241 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='draw_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, threshold=0.98, weights='visdrone_model_0360000.pth')
2020-12-12 14:23:26,242 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 14:23:28,345 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 14:23:28,346 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 14:23:28,347 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000004
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1000
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 14:23:28,350 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 4e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 14:23:29,882 maskrcnn_benchmark INFO: reloading weigts from final_mode_r3.pth
2020-12-12 14:31:14,240 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 14:31:14,240 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 14:31:14,240 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 14:31:16,252 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 14:31:16,252 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 14:31:16,253 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000004
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 14:31:16,254 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.01
    FG_IOU_THRESHOLD: 0.2
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 4e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 14:31:17,785 maskrcnn_benchmark INFO: reloading weigts from final_mode_r3
2020-12-12 14:31:35,798 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 14:31:35,798 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 14:31:35,798 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 14:31:37,836 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 14:31:37,836 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 14:31:37,836 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000004
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 14:31:37,837 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.01
    FG_IOU_THRESHOLD: 0.2
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 4e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 14:31:39,369 maskrcnn_benchmark INFO: reloading weigts from final_mode_r3.pth
2020-12-12 14:31:41,423 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-12 14:31:41,423 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-12 14:31:41,424 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-12 14:31:41,424 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-12 14:31:41,595 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-12 14:31:42,005 maskrcnn_benchmark.trainer INFO: Start training
2020-12-12 14:32:57,682 maskrcnn_benchmark.trainer INFO: eta: 0:36:34  iter: 20  loss: 6.9144 (6.7422)  loss_classifier: 0.4236 (0.4302)  loss_box_reg: 0.5037 (0.5299)  loss_objectness: 1.1487 (1.1635)  loss_rpn_box_reg: 4.6539 (4.6186)  time: 3.7741 (3.7838)  data: 0.2000 (0.2007)  lr: 0.000000  max mem: 1313
2020-12-12 14:34:13,288 maskrcnn_benchmark.trainer INFO: eta: 0:35:17  iter: 40  loss: 6.7742 (6.6404)  loss_classifier: 0.3986 (0.4212)  loss_box_reg: 0.3144 (0.4649)  loss_objectness: 1.1434 (1.1665)  loss_rpn_box_reg: 4.6194 (4.5879)  time: 3.7760 (3.7820)  data: 0.1998 (0.2024)  lr: 0.000000  max mem: 1313
2020-12-12 14:35:28,953 maskrcnn_benchmark.trainer INFO: eta: 0:34:02  iter: 60  loss: 6.6782 (6.6628)  loss_classifier: 0.4385 (0.4369)  loss_box_reg: 0.4071 (0.4787)  loss_objectness: 1.1966 (1.1674)  loss_rpn_box_reg: 4.6584 (4.5798)  time: 3.7807 (3.7824)  data: 0.2059 (0.2027)  lr: 0.000000  max mem: 1313
2020-12-12 14:36:44,687 maskrcnn_benchmark.trainer INFO: eta: 0:32:47  iter: 80  loss: 6.7620 (6.6955)  loss_classifier: 0.3930 (0.4498)  loss_box_reg: 0.5017 (0.4827)  loss_objectness: 1.1735 (1.1670)  loss_rpn_box_reg: 4.6615 (4.5960)  time: 3.7864 (3.7835)  data: 0.2053 (0.2033)  lr: 0.000000  max mem: 1313
2020-12-12 14:38:00,415 maskrcnn_benchmark.trainer INFO: eta: 0:31:32  iter: 100  loss: 6.3888 (6.6642)  loss_classifier: 0.4865 (0.4581)  loss_box_reg: 0.4246 (0.4847)  loss_objectness: 1.2201 (1.1729)  loss_rpn_box_reg: 4.2736 (4.5485)  time: 3.7819 (3.7841)  data: 0.2028 (0.2032)  lr: 0.000000  max mem: 1313
2020-12-12 14:39:16,196 maskrcnn_benchmark.trainer INFO: eta: 0:30:16  iter: 120  loss: 6.5400 (6.6453)  loss_classifier: 0.3938 (0.4581)  loss_box_reg: 0.3062 (0.4793)  loss_objectness: 1.1375 (1.1713)  loss_rpn_box_reg: 4.4317 (4.5366)  time: 3.7866 (3.7849)  data: 0.2051 (0.2036)  lr: 0.000000  max mem: 1313
2020-12-12 14:40:31,995 maskrcnn_benchmark.trainer INFO: eta: 0:29:01  iter: 140  loss: 6.4635 (6.6221)  loss_classifier: 0.4032 (0.4510)  loss_box_reg: 0.4688 (0.4769)  loss_objectness: 1.1913 (1.1729)  loss_rpn_box_reg: 4.4811 (4.5213)  time: 3.7920 (3.7856)  data: 0.2067 (0.2039)  lr: 0.000000  max mem: 1313
2020-12-12 14:41:47,874 maskrcnn_benchmark.trainer INFO: eta: 0:27:46  iter: 160  loss: 6.6157 (6.6305)  loss_classifier: 0.5189 (0.4581)  loss_box_reg: 0.5213 (0.4831)  loss_objectness: 1.1343 (1.1723)  loss_rpn_box_reg: 4.3944 (4.5170)  time: 3.7956 (3.7867)  data: 0.2066 (0.2041)  lr: 0.000000  max mem: 1313
2020-12-12 14:41:47,876 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 14:41:47,943 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(148 images).
2020-12-12 14:45:29,884 maskrcnn_benchmark.inference INFO: Total run time: 0:03:41.941106 (1.4996020648930524 s / img per device, on 1 devices)
2020-12-12 14:45:29,884 maskrcnn_benchmark.inference INFO: Model inference time: 0:03:27.433814 (1.4015798230428953 s / img per device, on 1 devices)
2020-12-12 14:45:29,885 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 14:45:45,290 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 14:45:45,290 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([3.6668e-02, 0.0000e+00, 0.0000e+00, 4.0601e-02, 2.4917e-02, 1.8400e-02,
        1.4136e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.7411e-02, 5.3234e-02, 4.7540e-02, 1.7345e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0193e-02, 5.4937e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.8396e-02, 1.5582e-04, 0.0000e+00, 9.9138e-02, 8.4619e-03, 4.3387e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.4939e-02, 2.0775e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3225e-01, 1.5911e-01,
        4.9979e-02, 3.2946e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.0613e-01, 9.4448e-02, 5.3828e-02, 1.8511e-01, 0.0000e+00,
        0.0000e+00, 5.3392e-02, 4.8209e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4370e-02, 3.2977e-02,
        4.1915e-06, 9.2384e-02, 9.0859e-02, 4.6446e-02, 1.4355e-02, 1.3281e-03,
        6.4010e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7868e-02, 1.1288e-02,
        0.0000e+00, 6.3050e-03, 2.6292e-03, 3.8478e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02, 3.0549e-02,
        0.0000e+00, 2.3585e-02, 0.0000e+00, 0.0000e+00, 1.8847e-02, 0.0000e+00,
        1.6597e-01, 9.4576e-02, 1.2507e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8586e-02, 5.5581e-04, 0.0000e+00,
        1.1642e-01, 5.7913e-03, 5.7888e-03, 3.1593e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2977e-02, 1.2187e-03, 0.0000e+00, 6.0879e-02, 2.1695e-02, 1.7053e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4110e-01, 2.1581e-02, 1.6510e-02, 1.5874e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7460e-02,
        3.3720e-02, 2.1682e-02, 1.2389e-01, 2.8959e-04, 0.0000e+00, 9.6414e-02,
        7.5923e-02, 5.3295e-02, 1.0604e-01, 4.5821e-02, 1.2909e-05, 2.3319e-03,
        1.7809e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2546e-02, 0.0000e+00, 0.0000e+00, 6.2260e-02,
        4.5680e-02, 3.2929e-02, 4.9016e-03, 6.7477e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8057e-01, 1.2472e-02, 8.4613e-04, 5.5231e-02, 3.6824e-02, 3.0689e-02,
        2.8100e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.0382e-02, 2.3930e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5516e-02,
        1.3700e-02, 1.1318e-04, 1.2436e-01, 7.3676e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7712e-02,
        4.1775e-03, 0.0000e+00, 8.7500e-02, 5.0282e-02, 0.0000e+00, 9.2419e-02,
        4.8897e-02, 0.0000e+00, 8.0204e-02, 3.8018e-02, 2.4810e-02, 1.8640e-02,
        1.6346e-02, 6.1947e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.0403e-01, 4.1085e-02, 2.8825e-02, 2.3934e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1593e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.9029e-02, 4.8360e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0074e-02, 0.0000e+00,
        9.1861e-02, 4.2352e-02, 0.0000e+00, 1.9142e-03, 8.6101e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.5338e-01, 3.6601e-02, 3.2977e-02, 1.0124e-01, 0.0000e+00, 0.0000e+00,
        9.6817e-02, 9.2670e-02, 4.9657e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5753e-02, 6.5620e-03, 5.3981e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8205e-01, 1.8090e-01, 5.4046e-02, 2.4477e-02, 2.3467e-02, 9.5961e-03,
        4.1319e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2796e-01, 4.0847e-02, 3.9463e-02, 1.8864e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.9512e-02, 2.3336e-02, 2.1682e-02, 8.6976e-02,
        3.0326e-02, 2.1851e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.9388e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.4051e-02,
        3.2961e-02, 3.0893e-02, 1.5098e-02, 5.7526e-03, 2.6413e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5207e-02, 4.1277e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.6843e-02, 3.2977e-02, 0.0000e+00, 8.3737e-02, 3.2977e-02,
        0.0000e+00, 1.6756e-01, 8.7666e-02, 1.5874e-02, 7.4107e-03, 3.6411e-03,
        2.3254e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4788e-01, 8.6763e-03, 6.9007e-03, 6.0126e-02, 6.7989e-09, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3255e-02, 1.7221e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3392e-02,
        4.7749e-02, 5.4877e-03, 4.6122e-02, 2.8629e-02, 1.3470e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.5318e-01, 7.6753e-02, 3.1805e-02, 2.5956e-01, 3.4761e-02,
        3.2139e-02, 1.1699e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8515e-02, 5.7225e-02, 3.6107e-03,
        1.7710e-02, 0.0000e+00, 0.0000e+00, 1.2189e-01, 8.0587e-02, 2.3887e-02,
        6.1672e-02, 2.3864e-02, 1.9725e-02, 6.3255e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3210e-02, 0.0000e+00, 0.0000e+00,
        4.0480e-02, 3.2977e-02, 2.7226e-04, 1.6014e-02, 2.1261e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.6280e-02, 2.0959e-02, 9.6883e-03, 1.3984e-03, 8.7399e-04, 2.5453e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5488e-01,
        5.9136e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.9784e-02, 7.3029e-02,
        4.4706e-02, 2.7181e-02, 2.5666e-02, 2.7404e-06, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1622e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3151e-02, 7.3364e-04,
        0.0000e+00, 3.5692e-01, 5.7070e-02, 2.1438e-02, 1.9584e-02, 2.6302e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3778e-01, 9.2884e-03, 0.0000e+00, 0.0000e+00, 3.9187e-02, 1.9963e-02,
        1.5874e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0919e-02, 1.5298e-02, 0.0000e+00,
        8.3903e-02, 8.2631e-02, 5.3079e-03, 1.1273e-02, 9.8640e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.6815e-02, 5.6442e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5488e-01,
        6.3789e-02, 7.7557e-03, 0.0000e+00, 0.0000e+00, 4.2578e-02, 1.3371e-02,
        6.7477e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.5719e-02, 0.0000e+00, 0.0000e+00, 1.1375e-01, 3.2329e-02,
        6.3413e-03, 3.9620e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8960e-03, 1.7457e-06, 3.8005e-07,
        1.2489e-01, 7.2782e-02, 3.0688e-02, 3.7384e-02, 2.1682e-02, 2.8929e-03,
        4.2474e-02, 2.1249e-02, 5.9717e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.0046e-02, 8.6424e-05, 0.0000e+00, 1.0949e-01, 1.6578e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.3383e-01, 5.0844e-02, 2.3088e-02, 2.2275e-04, 1.2645e-04,
        7.7522e-06, 3.5721e-07, 0.0000e+00, 0.0000e+00, 6.7113e-02, 3.3492e-02,
        3.2139e-02, 8.2238e-02, 3.4545e-02, 2.1854e-02, 1.6763e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.1179e-02, 2.9880e-02, 1.9657e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.6748e-02, 2.7903e-03, 0.0000e+00, 6.4068e-02, 2.4243e-03, 1.1768e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.7379e-02, 3.2977e-02, 0.0000e+00, 2.8554e-03, 0.0000e+00, 0.0000e+00,
        4.3504e-02, 1.5909e-02, 8.5559e-04, 1.1979e-01, 5.0421e-02, 3.8225e-03,
        3.1797e-02, 4.5318e-03, 1.9174e-03, 4.5826e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9244e-02, 3.3079e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.5953e-02, 3.2139e-02, 9.0672e-03, 2.6302e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4804e-04,
        0.0000e+00, 0.0000e+00, 4.8807e-02, 1.6549e-02, 4.1323e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1123e-01, 6.6645e-02, 3.2977e-02, 1.8605e-08,
        0.0000e+00, 7.9779e-02, 6.5608e-02, 2.7906e-02, 1.7600e-02, 7.6501e-03,
        3.8303e-03, 2.9260e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9733e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3654e-02,
        3.0758e-03, 0.0000e+00, 2.1984e-01, 1.5267e-01, 6.8961e-02, 2.7482e-01,
        9.8441e-02, 0.0000e+00, 8.1041e-02, 5.6709e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9720e-02,
        4.4225e-05, 0.0000e+00, 2.5759e-02, 3.2977e-02, 0.0000e+00, 0.0000e+00,
        1.0695e-01, 3.2977e-02, 0.0000e+00, 7.5724e-02, 5.7971e-02, 3.2139e-02,
        1.6284e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.5256e-02, 9.0047e-03, 0.0000e+00, 4.7139e-02,
        3.2977e-02, 0.0000e+00, 3.9534e-02, 1.7385e-02, 0.0000e+00, 1.4029e-01,
        2.4851e-02, 6.1735e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.6921e-02, 2.1682e-02, 8.3096e-03, 2.4734e-02,
        9.1809e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.3705e-04, 1.5083e-03, 0.0000e+00, 9.4174e-02,
        4.3549e-02, 1.6543e-02, 6.9104e-02, 1.1139e-02, 1.4283e-03, 2.8722e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4547e-02,
        1.6746e-04, 0.0000e+00]), 'gt_labels': tensor([7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 1, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7,
        4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 4, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 7, 7, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 7, 7, 4]), 'best match labels': tensor([ 4.,  7.,  7.,  4.,  2.,  7.,  2.,  7.,  7.,  2.,  1.,  7.,  7.,  1.,
         8.,  1.,  7.,  2.,  2.,  4.,  7.,  2.,  2.,  2.,  2.,  2.,  2.,  7.,
         7.,  4.,  7.,  2.,  7.,  7.,  2.,  7.,  2.,  4.,  7.,  7.,  7.,  7.,
         8.,  1.,  1.,  2.,  2.,  7.,  2.,  2.,  8.,  7.,  2.,  2.,  2.,  1.,
         4.,  7.,  7.,  7.,  7.,  4.,  7.,  2.,  7.,  2.,  8., -1., -1., -1.,
        -1.,  7.,  1.,  2.,  7.,  7.,  1.,  7.,  7.,  7.,  2.,  4.,  2.,  7.,
         2.,  7.,  7.,  7.,  8.,  2.,  7.,  2.,  7.,  4.,  4.,  7.,  1.,  7.,
         1.,  7.,  2.,  2.,  7.,  7.,  8.,  7.,  7.,  7.,  2.,  7.,  2.,  7.,
         2.,  2.,  2.,  8.,  2.,  8.,  7.,  2.,  8.,  2.,  7.,  1.,  2.,  2.,
         2.,  1.,  2.,  2.,  2.,  7.,  8.,  7.,  2.,  2.,  7.,  2.,  7.,  7.,
         8.,  7.,  7.,  7.,  7.,  2.,  2.,  7.,  2.,  2.,  2.,  2.,  4.,  1.,
         4.,  7.,  7.,  1.,  7.,  1.,  2.,  4.,  7.,  1.,  1.,  2.,  7.,  4.,
         4.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  2.,  2.,  7.,  7.,  1.,  1.,
         2.,  2.,  2.,  2.,  2.,  2.,  4.,  7.,  7.,  7.,  7.,  2.,  2.,  2.,
         1.,  2.,  2.,  3.,  7.,  7.,  8.,  1.,  8.,  7.,  4.,  4.,  4.,  7.,
         2.,  7.,  7.,  2.,  7.,  2.,  8.,  7.,  2.,  2.,  2.,  2.,  4.,  7.,
         7.,  8.,  1.,  7.,  4.,  8.,  8.,  2.,  7.,  8.,  7.,  1.,  7.,  1.,
         2.,  7.,  7.,  2.,  7.,  7.,  7.,  8.,  7.,  1.,  2.,  2.,  7.,  2.,
         2.,  4.,  4.,  7., -1.,  1.,  1.,  2.,  4.,  2.,  4.,  7.,  7.,  1.,
         7.,  1.,  2.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  2.,  7.,  7.,  2.,
         2.,  2.,  4.,  4.,  4.,  6.,  7.,  4.,  4.,  7.,  7.,  7.,  7.,  7.,
         7.,  4.,  4.,  7.,  7.,  7.,  7.,  8.,  7.,  2.,  7.,  7.,  1.,  7.,
         7.,  2.,  7.,  2.,  2.,  7.,  2.,  2.,  1.,  2.,  4.,  4.,  2.,  6.,
         7.,  2.,  7.,  7.,  2.,  2.,  1.,  1.,  7.,  1.,  1.,  2.,  2.,  2.,
         2.,  7.,  4.,  8.,  7.,  7.,  1.,  2.,  2.,  7.,  7.,  2.,  7.,  7.,
        -1., -1.,  2.,  2.,  7.,  7.,  7.,  7.,  7.,  2.,  7.,  7.,  7.,  2.,
         2.,  2.,  2.,  4.,  7.,  7.,  7.,  1.,  7.,  7.,  7.,  8.,  2.,  8.,
         8.,  7.,  4.,  8.,  7.,  7.,  8.,  7.,  7.,  2.,  2.,  2.,  2.,  4.,
         7.,  7.,  7.,  8.,  2.,  7.,  2.,  2.,  2.,  2.,  2.,  4.,  4.,  7.,
         7.,  1.,  2.,  2.,  2.,  2.,  2.,  1.,  4.,  7.,  7.,  7.,  8.,  1.,
         2.,  2.,  1.,  7.,  4.,  4.,  7.,  8.,  8.,  8.,  8.,  8.,  7.,  2.,
         7.,  7.,  7.,  2.,  7.,  7.,  7.,  7.,  7.,  7.,  1.,  8.,  7.,  7.,
         2.,  1.,  2.,  2.,  2.,  7.,  1.,  7.,  7.,  2.,  2.,  1.,  2.,  2.,
         2.,  7.,  4.,  1.,  7.,  7.,  2.,  7.,  2.,  7.,  4.,  4.,  7.,  7.,
         7.,  7.,  7.,  8.,  2.,  1.,  7.,  2.,  4.,  2.,  7.,  7.,  4.,  7.,
         8.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  8.,  7.,  7.,
         8.,  8.,  7.,  2.,  2.,  1.,  2.,  4.,  4.,  4.,  4.,  4.,  4.,  8.,
         8.,  4.,  1.,  2.,  7.,  1.,  7.,  4.,  4.,  7.,  7.,  8.,  8.,  7.,
         7.,  4.,  7.,  7.,  7.,  7.,  2.,  4.,  2.,  2.,  4.,  7.,  7.,  7.,
         7.,  8.,  7.,  7.,  2.,  1.,  8.,  7.,  2., -1.,  7., -1., -1., -1.,
         1.,  1.,  2.,  4.,  1.,  7.,  2.,  2.,  2.,  2.,  2.,  2.,  7.,  7.,
         7.,  1.,  2.,  2.,  1.,  1.,  6.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,
         7.,  7.,  8.,  2.,  7.,  4.,  4.,  7.,  7.,  7.,  7.,  8.,  8.,  7.,
         4.,  7.,  1.,  2.,  8.,  7.,  1.,  4.,  7.,  8.,  2.,  2.,  2.,  2.,
         7.,  7.,  2.,  7.,  2., -1.,  2.,  2.,  2.,  2.,  2.,  4.,  4.,  7.,
         7.,  1.,  7.,  7.,  2.,  2.,  2.,  2.,  2.,  2.,  4.,  7.,  7.,  2.,
         7.,  2.,  7.,  1.,  2.,  7.,  1.,  2.,  1.,  2.,  2.,  4.,  4.,  7.,
         7.,  7.,  7.,  7.,  7.,  7.,  2.,  2.,  4.,  4.,  4.,  4.,  7.,  7.,
         8., -1.,  1., -1., -1.,  1.,  1.,  2.,  2.,  7.,  1.,  7.,  7.,  7.,
         1.,  2.,  2.,  4.,  4.,  7.,  7.,  2.,  2.,  8.,  7.,  4.,  7.,  7.,
         8.,  7.,  2.,  2.,  4.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  4.,  4.,
         7.,  7.,  2.,  8.,  2.,  2.,  2.,  7.,  2.,  2.,  4.,  7.,  1.,  7.,
         2.,  2.,  2.,  4.,  4.,  7.,  7.,  7.,  2.,  4.,  7.,  7.,  2.,  2.,
         7.,  2.,  7.,  4.,  7.,  7.,  8., -1., -1., -1., -1.,  1.,  1.,  2.,
         2.,  2.,  2.,  4.,  2.,  2.,  4.,  1.,  7.,  7.,  7.,  7.,  1.,  8.,
         8.,  2.,  2.,  1.,  1.,  2.,  1.,  1.,  1.,  1.,  2.,  2.,  2.,  4.,
         4.,  8.,  8.,  7.,  2.,  2.,  2.,  7.,  2.,  8.,  1.,  2.,  2.,  2.,
         7.,  2.,  4.,  7.,  2.,  2.,  7.,  7.,  7.,  7.,  7.,  8.,  4.,  7.,
         8.,  2.,  7.,  4.,  4.,  7.,  1.,  2.,  8.,  7.,  7.,  7.,  8.,  1.,
         2.,  7.,  2.,  7.,  8.,  1.,  7.,  2.,  7.,  8.,  2.,  2.,  4.,  4.,
         7.,  7.,  7.,  1.,  2.,  2.,  2.,  2.,  2.,  4.,  1.,  7.,  2.,  7.,
         1.,  7.,  1.,  4.,  2.,  7.,  7.,  7.,  2.,  2.,  2.,  7.,  2.,  7.,
         7.,  8.,  7.,  4.]), 'best match scores': tensor([0.9997, 0.9708, 0.1857, 0.9928, 0.9564, 0.9321, 1.0000, 0.5058, 0.9998,
        0.7223, 0.2271, 1.0000, 0.1862, 0.9987, 0.5216, 0.3888, 0.9762, 0.9952,
        0.2736, 0.8335, 0.1152, 0.0788, 1.0000, 0.9999, 0.6899, 0.9854, 1.0000,
        0.9913, 0.6231, 0.0809, 0.1148, 0.0667, 0.1511, 0.9941, 1.0000, 0.9849,
        1.0000, 0.6673, 0.1408, 0.9943, 0.9996, 0.9946, 0.9970, 0.0828, 0.9693,
        1.0000, 0.7881, 1.0000, 0.9343, 0.9999, 0.5304, 0.3157, 0.9794, 0.3837,
        1.0000, 0.9943, 0.4444, 0.0831, 0.3494, 1.0000, 1.0000, 0.9977, 1.0000,
        0.9997, 0.7362, 0.9998, 0.3688, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,
        0.7082, 0.9998, 0.9997, 0.3604, 0.9551, 0.7637, 0.9998, 0.6961, 0.9458,
        1.0000, 1.0000, 0.7836, 0.9847, 0.9552, 0.6186, 0.9365, 0.2250, 0.7181,
        0.0721, 0.8616, 0.1048, 0.1951, 0.9995, 0.9692, 0.5108, 0.9995, 0.2945,
        0.9900, 0.9999, 0.1534, 0.9991, 0.9611, 1.0000, 1.0000, 0.9940, 0.7731,
        0.0597, 1.0000, 0.9372, 1.0000, 1.0000, 0.4532, 0.7564, 0.1892, 0.9934,
        0.9980, 0.4271, 1.0000, 0.9798, 0.9985, 0.9997, 0.9997, 0.9733, 0.9975,
        0.9656, 0.1457, 0.1413, 0.2284, 0.1157, 0.5814, 0.9916, 0.9324, 0.8865,
        0.9999, 0.1065, 0.9998, 0.9793, 0.9571, 0.0538, 1.0000, 0.0705, 0.1893,
        0.3974, 0.4657, 0.1191, 0.1827, 0.1492, 0.9646, 0.9906, 0.5028, 0.8894,
        0.7511, 0.0862, 1.0000, 1.0000, 1.0000, 0.9999, 0.8051, 0.0691, 0.9487,
        1.0000, 0.1887, 0.9975, 0.3179, 0.9969, 0.8887, 0.9997, 0.2324, 1.0000,
        0.9998, 0.0507, 0.6037, 0.9897, 1.0000, 1.0000, 1.0000, 0.8240, 0.9992,
        0.9937, 0.0632, 0.9848, 0.1168, 0.9981, 0.1098, 0.9728, 0.9912, 0.9973,
        1.0000, 0.9785, 0.9999, 1.0000, 0.9122, 0.9280, 1.0000, 0.9764, 0.9701,
        0.0685, 0.5952, 0.9995, 0.4045, 0.9102, 1.0000, 0.8894, 1.0000, 0.8662,
        0.1359, 0.4337, 1.0000, 1.0000, 0.9924, 0.8584, 0.9990, 0.9992, 0.0505,
        1.0000, 0.2518, 0.9999, 0.0738, 0.0968, 1.0000, 0.6700, 0.9996, 0.0549,
        0.6959, 0.9994, 0.9537, 1.0000, 0.3474, 1.0000, 0.7363, 1.0000, 0.9977,
        0.9945, 0.2243, 1.0000, 0.9949, 1.0000, 0.7749, 1.0000, 0.9509, 0.2864,
        1.0000, 1.0000, 0.0906, 0.9978, 0.9325, 1.0000, 0.9709, 0.9992, 0.1046,
        0.9983, 1.0000, 0.9829, 0.9992, 0.0000, 0.1902, 0.2127, 1.0000, 0.9506,
        0.6652, 1.0000, 0.0524, 0.9997, 0.2115, 0.9998, 0.3268, 0.0609, 0.9995,
        0.9998, 0.8561, 0.2775, 0.9939, 0.2624, 0.1368, 0.6225, 0.9985, 1.0000,
        0.1995, 1.0000, 0.9624, 0.4799, 0.6565, 1.0000, 1.0000, 0.9198, 0.0695,
        0.1618, 1.0000, 1.0000, 1.0000, 0.9954, 0.4411, 0.9732, 0.9820, 0.1004,
        1.0000, 0.0668, 0.4590, 0.9686, 0.8210, 1.0000, 0.8406, 0.9939, 0.1106,
        0.0642, 1.0000, 0.9925, 0.7571, 0.9998, 0.9951, 0.6235, 0.9990, 0.8034,
        0.9987, 0.3506, 0.9247, 1.0000, 0.9285, 0.9195, 1.0000, 0.9998, 0.8454,
        0.7575, 0.1426, 0.2755, 0.9908, 0.2071, 0.9757, 0.7336, 0.9205, 0.9607,
        0.1077, 0.5721, 0.9956, 0.2997, 1.0000, 0.9889, 0.6952, 0.3679, 0.1762,
        0.8189, 1.0000, 0.9561, 0.4754, 0.9560, 0.3006, 0.7318, 0.0592, 0.0000,
        0.0000, 0.9580, 0.9952, 0.9929, 0.6806, 0.0732, 0.6529, 1.0000, 0.7433,
        0.9225, 0.3780, 0.9674, 0.6165, 1.0000, 0.6991, 0.9775, 0.9996, 0.9953,
        1.0000, 1.0000, 0.9969, 1.0000, 0.9129, 0.8982, 0.4305, 0.9257, 0.7881,
        0.8351, 0.9957, 1.0000, 1.0000, 0.5324, 1.0000, 0.9966, 0.9967, 0.5037,
        0.0829, 0.0977, 0.9934, 0.5565, 0.9659, 0.9988, 0.9966, 0.9709, 0.9951,
        0.1803, 0.9572, 1.0000, 0.1141, 0.2921, 1.0000, 0.9782, 0.9998, 1.0000,
        0.6978, 0.5178, 1.0000, 0.1396, 0.7516, 0.5658, 0.2957, 0.7530, 0.2150,
        0.9512, 0.9385, 0.9988, 0.9985, 0.9999, 0.2100, 0.9327, 0.9955, 0.9993,
        0.9890, 0.3111, 0.9696, 1.0000, 0.1707, 0.0886, 0.1368, 0.0606, 1.0000,
        1.0000, 1.0000, 0.8917, 0.0545, 0.9711, 0.1344, 0.0818, 0.2572, 0.5189,
        0.9808, 0.0735, 0.1317, 0.1417, 0.9992, 0.9635, 1.0000, 0.9722, 0.9948,
        0.3305, 0.8128, 0.9503, 0.9752, 0.4449, 0.9581, 0.2411, 0.9938, 0.5713,
        1.0000, 1.0000, 0.7520, 0.0607, 0.9961, 1.0000, 0.9959, 0.1047, 0.3077,
        0.9005, 0.9992, 0.6496, 0.3694, 0.4606, 0.6302, 1.0000, 0.9989, 0.9999,
        0.0988, 1.0000, 0.9929, 0.9884, 0.9998, 0.9033, 0.7344, 0.1113, 0.9605,
        0.9148, 0.3178, 1.0000, 1.0000, 0.9379, 0.9930, 1.0000, 0.5517, 0.9471,
        1.0000, 0.5673, 1.0000, 0.9978, 0.9971, 0.7593, 0.2482, 0.0710, 1.0000,
        1.0000, 0.7883, 1.0000, 0.9997, 0.9999, 0.2588, 0.9056, 0.9378, 0.5719,
        0.4010, 0.7125, 0.9997, 1.0000, 0.4652, 0.9997, 1.0000, 0.9964, 0.1744,
        0.9482, 1.0000, 0.9061, 0.9746, 0.9999, 0.1229, 0.9998, 0.2268, 0.1094,
        0.9996, 0.9946, 1.0000, 0.8618, 0.9999, 0.1497, 0.9992, 1.0000, 0.9916,
        1.0000, 0.9999, 0.9973, 0.9929, 0.8753, 0.9991, 1.0000, 0.1959, 0.8508,
        1.0000, 0.9997, 0.1199, 0.9958, 1.0000, 0.8878, 0.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.1853, 1.0000, 1.0000, 1.0000, 0.9963, 1.0000, 1.0000,
        0.0503, 0.9999, 0.9226, 1.0000, 0.9888, 0.9838, 0.8238, 0.9997, 0.7937,
        0.9998, 1.0000, 1.0000, 0.8167, 1.0000, 0.0981, 0.0908, 0.3087, 0.6877,
        0.7460, 0.0698, 0.9987, 0.5914, 0.9615, 0.9999, 0.5846, 0.1029, 0.1378,
        0.5569, 1.0000, 1.0000, 0.8621, 0.8321, 0.4532, 0.9979, 1.0000, 0.1044,
        0.0769, 0.7086, 0.0957, 0.9285, 1.0000, 0.9995, 0.9995, 1.0000, 0.8799,
        0.5255, 1.0000, 0.6117, 0.9999, 0.8544, 0.9928, 0.4500, 0.7361, 0.9999,
        0.0000, 0.9717, 0.9936, 0.9643, 0.5423, 0.2164, 0.0847, 1.0000, 0.1152,
        0.0672, 0.7411, 1.0000, 0.9357, 0.9963, 0.9617, 0.9999, 0.2660, 0.3413,
        0.9392, 0.7481, 1.0000, 0.9998, 0.3222, 1.0000, 0.2221, 0.0638, 0.6997,
        0.0516, 0.9779, 0.9997, 0.9999, 0.9435, 0.1754, 0.9899, 0.2110, 0.9871,
        0.9999, 0.9840, 0.1720, 0.9833, 0.4465, 0.0905, 1.0000, 0.9999, 0.6958,
        0.5095, 0.5630, 0.9873, 0.9998, 0.5223, 0.1039, 0.1794, 0.0000, 0.9994,
        0.0000, 0.0000, 0.0676, 0.3082, 0.3713, 0.9999, 1.0000, 0.6564, 1.0000,
        0.8975, 0.9975, 0.3013, 0.4665, 0.9622, 0.9740, 0.6907, 0.1957, 0.0708,
        0.1573, 0.4606, 0.7558, 0.9791, 0.4684, 1.0000, 0.9989, 0.5945, 0.0600,
        0.1114, 0.0564, 1.0000, 1.0000, 0.9995, 0.5873, 0.1031, 0.9110, 0.9990,
        0.0862, 0.9098, 1.0000, 0.8783, 0.0547, 0.9998, 0.9413, 0.6421, 0.8962,
        0.8346, 0.8633, 0.0843, 1.0000, 0.7666, 0.8831, 0.4473, 1.0000, 0.3919,
        1.0000, 0.1918, 1.0000, 0.9634, 0.9902, 1.0000, 0.3373, 0.9918, 0.2199,
        0.9994, 0.9649, 1.0000, 0.6272, 0.9972, 1.0000, 0.0749, 0.5625, 0.9797,
        0.9892, 0.0774, 0.0000, 0.0000, 0.0000, 0.0000, 0.0750, 0.8027, 0.9876,
        0.0969, 1.0000, 0.2526, 0.0687, 0.0934, 0.9954, 0.1528, 0.3696, 0.5001,
        0.7343, 0.9826, 0.8654, 0.2950, 0.1711, 0.0551, 0.9993, 1.0000, 0.9528,
        0.9317, 0.9920, 0.6530, 0.9044, 1.0000, 1.0000, 1.0000, 0.0597, 0.9959,
        0.7719, 1.0000, 0.0664, 0.2951, 0.9720, 0.1848, 1.0000, 0.9933, 1.0000,
        1.0000, 0.5826, 0.1514, 0.7989, 1.0000, 0.8993, 1.0000, 1.0000, 0.7966,
        0.5300, 0.6143, 1.0000, 0.7887, 0.6763, 0.5768, 1.0000, 1.0000, 0.1505,
        1.0000, 1.0000, 0.9972, 0.9929, 0.9993, 0.0866, 1.0000, 0.0698, 0.9267,
        0.9163, 1.0000, 0.9594, 0.9251, 0.7061, 0.1674, 0.9991, 0.2682, 0.9323,
        0.1646, 0.6287, 0.0547, 0.1213, 0.9989, 0.2231, 0.6396, 1.0000, 1.0000,
        1.0000, 0.2492, 0.9981, 0.8703, 1.0000, 0.2401, 0.7911, 0.5652, 0.0624,
        0.6750, 0.9913, 0.9386, 0.0867, 1.0000, 0.9994, 0.0861, 0.1850, 0.9925,
        1.0000, 0.8349, 1.0000, 0.5710, 0.9998, 1.0000, 1.0000, 0.1695, 0.9917,
        0.1234, 0.7870, 0.5194, 0.5101, 0.2888, 0.0768, 0.2706, 0.6689]), 'num_pos': 872}
2020-12-12 14:45:45,401 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.275229
2020-12-12 14:45:45,403 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r3.pth
2020-12-12 14:45:49,024 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r3
2020-12-12 14:47:05,256 maskrcnn_benchmark.trainer INFO: eta: 0:35:54  iter: 180  loss: 6.6043 (6.6304)  loss_classifier: 0.4599 (0.4604)  loss_box_reg: 0.4816 (0.4879)  loss_objectness: 1.1228 (1.1703)  loss_rpn_box_reg: 4.4624 (4.5118)  time: 3.7920 (5.1292)  data: 0.2036 (1.5440)  lr: 0.000000  max mem: 1313
2020-12-12 14:48:20,989 maskrcnn_benchmark.trainer INFO: eta: 0:33:17  iter: 200  loss: 6.6883 (6.6244)  loss_classifier: 0.3895 (0.4601)  loss_box_reg: 0.4869 (0.4835)  loss_objectness: 1.1701 (1.1696)  loss_rpn_box_reg: 4.5858 (4.5113)  time: 3.7861 (4.9949)  data: 0.2021 (1.4101)  lr: 0.000000  max mem: 1313
2020-12-12 14:49:36,762 maskrcnn_benchmark.trainer INFO: eta: 0:30:56  iter: 220  loss: 6.4021 (6.6101)  loss_classifier: 0.4438 (0.4621)  loss_box_reg: 0.4543 (0.4827)  loss_objectness: 1.1379 (1.1676)  loss_rpn_box_reg: 4.2456 (4.4978)  time: 3.7868 (4.8852)  data: 0.2040 (1.3004)  lr: 0.000000  max mem: 1313
2020-12-12 14:50:52,548 maskrcnn_benchmark.trainer INFO: eta: 0:28:45  iter: 240  loss: 6.7910 (6.6193)  loss_classifier: 0.4848 (0.4672)  loss_box_reg: 0.5793 (0.4903)  loss_objectness: 1.1464 (1.1658)  loss_rpn_box_reg: 4.4599 (4.4960)  time: 3.7886 (4.7939)  data: 0.2042 (1.2091)  lr: 0.000000  max mem: 1313
2020-12-12 14:52:08,374 maskrcnn_benchmark.trainer INFO: eta: 0:26:43  iter: 260  loss: 6.7045 (6.6350)  loss_classifier: 0.4826 (0.4716)  loss_box_reg: 0.5375 (0.4940)  loss_objectness: 1.1698 (1.1682)  loss_rpn_box_reg: 4.5676 (4.5013)  time: 3.7917 (4.7168)  data: 0.2009 (1.1318)  lr: 0.000000  max mem: 1313
2020-12-12 14:53:24,678 maskrcnn_benchmark.trainer INFO: eta: 0:24:48  iter: 280  loss: 6.7070 (6.6413)  loss_classifier: 0.4684 (0.4716)  loss_box_reg: 0.5083 (0.4968)  loss_objectness: 1.1361 (1.1671)  loss_rpn_box_reg: 4.6408 (4.5058)  time: 3.7990 (4.6524)  data: 0.2059 (1.0659)  lr: 0.000000  max mem: 1313
2020-12-12 14:54:40,825 maskrcnn_benchmark.trainer INFO: eta: 0:22:58  iter: 300  loss: 6.4339 (6.6176)  loss_classifier: 0.3984 (0.4709)  loss_box_reg: 0.4752 (0.4929)  loss_objectness: 1.0965 (1.1640)  loss_rpn_box_reg: 4.3180 (4.4898)  time: 3.8067 (4.5961)  data: 0.2063 (1.0088)  lr: 0.000000  max mem: 1313
2020-12-12 14:55:56,879 maskrcnn_benchmark.trainer INFO: eta: 0:21:13  iter: 320  loss: 6.6967 (6.6243)  loss_classifier: 0.5221 (0.4751)  loss_box_reg: 0.5172 (0.4961)  loss_objectness: 1.1754 (1.1646)  loss_rpn_box_reg: 4.5483 (4.4885)  time: 3.8016 (4.5465)  data: 0.2029 (0.9587)  lr: 0.000000  max mem: 1313
2020-12-12 14:55:56,881 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 14:55:56,948 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(148 images).
2020-12-12 14:59:43,694 maskrcnn_benchmark.inference INFO: Total run time: 0:03:46.746388 (1.5320701889089636 s / img per device, on 1 devices)
2020-12-12 14:59:43,695 maskrcnn_benchmark.inference INFO: Model inference time: 0:03:31.536229 (1.4292988422754649 s / img per device, on 1 devices)
2020-12-12 14:59:43,695 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 14:59:59,445 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 14:59:59,446 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([3.2972e-03, 0.0000e+00, 0.0000e+00, 4.5947e-02, 4.5476e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.3776e-02, 3.5530e-02, 1.7345e-02, 1.3743e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0193e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8911e-01, 9.8770e-02, 0.0000e+00, 3.9755e-02, 6.9615e-03, 3.5955e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.2535e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3826e-01, 6.8102e-02,
        3.0993e-02, 3.0642e-02, 1.3226e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.0112e-02, 6.9456e-02, 3.7862e-02, 3.2185e-02, 3.1893e-02,
        0.0000e+00, 8.4888e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9300e-01, 6.0217e-02,
        3.9804e-02, 1.3392e-01, 2.5719e-02, 2.3869e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4316e-04, 0.0000e+00,
        0.0000e+00, 1.0576e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0813e-03, 1.1330e-04,
        0.0000e+00, 3.7239e-02, 1.0837e-02, 8.9922e-04, 8.4246e-03, 8.6277e-09,
        1.4243e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8256e-02, 3.1854e-02, 0.0000e+00,
        2.4987e-04, 7.2292e-05, 0.0000e+00, 3.1593e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.1322e-01, 0.0000e+00, 0.0000e+00, 2.3082e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.8183e-02, 6.3803e-02, 1.5874e-02, 1.4072e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5804e-01,
        5.7852e-02, 4.7210e-02, 4.9333e-02, 3.2977e-02, 0.0000e+00, 1.0171e-01,
        6.5058e-02, 1.2942e-02, 1.4588e-01, 6.1974e-02, 1.2098e-03, 2.9283e-01,
        8.1378e-03, 2.2353e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1653e-01, 0.0000e+00, 0.0000e+00, 2.1495e-02,
        4.0920e-02, 2.8421e-02, 8.4763e-05, 1.7385e-01, 5.0434e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.4176e-03, 0.0000e+00, 0.0000e+00, 6.4264e-02, 2.9183e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.9739e-02, 1.5033e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8061e-02,
        2.6298e-03, 1.2904e-03, 8.6074e-02, 1.2664e-02, 2.8436e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0489e-01,
        5.0463e-02, 2.4639e-02, 1.9131e-01, 3.9945e-02, 3.3152e-03, 4.9986e-02,
        0.0000e+00, 0.0000e+00, 1.1923e-01, 1.9885e-02, 1.3062e-02, 5.9466e-03,
        3.2436e-03, 1.0511e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.2378e-02, 1.2615e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1593e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 5.1137e-02, 4.2323e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4124e-01, 1.0263e-01,
        3.2977e-02, 2.8280e-02, 9.2529e-05, 5.5519e-02, 1.6057e-02, 1.3914e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.6241e-02, 6.6460e-02, 2.1682e-02, 3.2977e-02, 2.7744e-04, 0.0000e+00,
        8.3618e-02, 6.8676e-02, 2.7314e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4463e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.6931e-02, 2.2204e-02, 2.1682e-02, 3.2139e-02, 2.2332e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.1334e-02, 5.0990e-04, 0.0000e+00, 2.7522e-07,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.2579e-02, 3.6347e-02, 0.0000e+00, 9.1860e-02,
        7.9959e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.1855e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2292e-02,
        3.2139e-02, 2.4712e-02, 7.8026e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.5128e-02, 4.2902e-02,
        3.0763e-02, 8.5852e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.4933e-02, 3.2977e-02, 2.1682e-02, 1.4776e-01, 6.8285e-02,
        5.2656e-02, 1.9906e-01, 3.4521e-02, 3.3295e-02, 2.1906e-02, 2.0482e-02,
        5.2186e-03, 3.9438e-03, 3.0877e-03, 2.0809e-03, 0.0000e+00, 0.0000e+00,
        2.5563e-01, 2.1682e-02, 0.0000e+00, 7.2995e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 2.8032e-02, 6.8521e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3650e-02,
        0.0000e+00, 0.0000e+00, 2.5229e-01, 2.1659e-01, 1.2999e-02, 1.1476e-02,
        5.8482e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.9118e-01, 4.8190e-02, 0.0000e+00, 2.5801e-01, 1.6669e-02,
        9.9356e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3681e-01, 4.8124e-02, 0.0000e+00,
        5.9973e-02, 1.8548e-02, 1.2113e-03, 6.9835e-02, 5.3295e-02, 0.0000e+00,
        5.7575e-02, 5.3076e-02, 4.8662e-02, 3.7865e-02, 2.8692e-02, 7.2404e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1253e-03, 9.9838e-02, 0.0000e+00,
        1.3055e-01, 2.0695e-02, 2.9913e-03, 2.5336e-02, 2.0148e-02, 8.1336e-03,
        4.9128e-03, 2.0331e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.6089e-02, 5.0102e-02, 3.3152e-02, 1.7291e-02, 1.5874e-02, 7.2618e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1677e-01,
        2.7378e-02, 2.4059e-02, 5.1195e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7590e-02, 4.4394e-02,
        2.0852e-02, 6.9935e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 5.0370e-02, 5.5006e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4500e-04, 0.0000e+00,
        0.0000e+00, 5.9976e-02, 3.2215e-02, 1.8863e-02, 7.6581e-03, 2.6302e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.3927e-02, 3.8370e-02, 0.0000e+00, 1.1598e-01, 4.3943e-02, 3.5631e-02,
        2.6869e-02, 1.4816e-02, 3.4872e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02, 2.9465e-02, 0.0000e+00,
        3.1749e-02, 0.0000e+00, 0.0000e+00, 1.2269e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.4165e-02, 2.9775e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2942e-02,
        3.6795e-03, 0.0000e+00, 5.1928e-05, 2.1743e-07, 4.8731e-02, 4.6009e-02,
        6.7477e-03, 9.8182e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.5175e-02, 9.8025e-03, 0.0000e+00, 1.7075e-01, 3.3677e-02,
        2.9332e-02, 1.2856e-02, 4.2194e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4353e-01, 0.0000e+00, 0.0000e+00,
        1.4573e-01, 5.5796e-02, 2.3621e-02, 3.2977e-02, 2.1682e-02, 0.0000e+00,
        4.4029e-02, 2.8177e-02, 7.8727e-03, 1.2387e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2771e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.6112e-02, 4.6764e-03, 0.0000e+00, 0.0000e+00, 8.8673e-02, 4.2648e-02,
        2.6941e-02, 2.3140e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.5983e-01, 5.3983e-02, 2.4177e-02, 4.7617e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3300e-01, 6.7944e-02,
        2.7594e-02, 1.1129e-01, 4.7787e-02, 1.7033e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.2434e-02, 4.1971e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.2700e-02, 0.0000e+00, 0.0000e+00, 1.1522e-01, 1.8347e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.9598e-02, 5.2150e-02, 2.1682e-02, 1.1740e-01, 0.0000e+00, 0.0000e+00,
        5.0929e-02, 2.5573e-02, 0.0000e+00, 1.3540e-01, 6.3828e-02, 1.5117e-02,
        5.5006e-03, 4.3689e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1593e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.9980e-02, 7.7763e-02, 1.1842e-02, 3.5655e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8280e-02,
        3.2977e-02, 2.0559e-03, 3.9730e-02, 7.3894e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.5944e-02, 1.6274e-02, 3.0125e-03, 4.1202e-02,
        0.0000e+00, 2.1652e-01, 8.4879e-02, 4.8575e-02, 2.6841e-02, 2.6163e-02,
        1.8213e-02, 2.5812e-03, 8.8840e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.2567e-02, 3.2139e-02, 2.2777e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02,
        7.6308e-03, 0.0000e+00, 1.0287e-01, 1.0201e-01, 1.4246e-04, 1.5370e-01,
        1.2228e-01, 0.0000e+00, 1.7968e-01, 3.2978e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4250e-02,
        3.0800e-05, 0.0000e+00, 0.0000e+00, 1.6234e-01, 3.1065e-02, 2.2745e-07,
        9.6243e-02, 3.2977e-02, 2.3336e-02, 3.2139e-02, 1.1378e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.1556e-02, 0.0000e+00, 0.0000e+00, 1.4617e-01,
        1.5070e-02, 0.0000e+00, 6.5814e-02, 5.1087e-02, 2.1682e-02, 7.4008e-02,
        6.1303e-02, 3.1066e-02, 1.6090e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.4505e-01, 5.8362e-02, 2.1209e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.6323e-02, 2.5002e-02, 1.0854e-01,
        4.2472e-02, 2.2158e-02, 5.4924e-02, 2.5163e-02, 3.7981e-03, 5.8278e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0587e-02,
        4.6234e-05, 0.0000e+00]), 'gt_labels': tensor([7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 1, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7,
        4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 4, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 7, 7, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 7, 7, 4]), 'best match labels': tensor([ 8.,  7.,  8.,  2.,  7.,  2.,  2.,  4.,  4.,  7.,  2.,  7.,  7.,  4.,
         1.,  4.,  7.,  4.,  7.,  1.,  7.,  1.,  1.,  1.,  2.,  2.,  4.,  4.,
         7.,  4.,  7.,  7.,  2.,  7.,  2.,  2.,  4.,  4.,  1.,  4.,  7.,  7.,
         7.,  1.,  1.,  1.,  7.,  1.,  2.,  2.,  7.,  8.,  2.,  7.,  7.,  2.,
         4.,  7.,  2.,  7.,  7.,  2.,  2.,  7.,  2.,  8.,  4.,  2.,  2.,  2.,
         2.,  2.,  4.,  4.,  7.,  7.,  1.,  7.,  7.,  2.,  2.,  2.,  2.,  2.,
         2.,  7.,  2.,  7.,  1.,  7.,  7.,  2.,  2.,  2.,  2.,  7.,  7.,  7.,
         7.,  2.,  7.,  2.,  7.,  2.,  7.,  2.,  4.,  2.,  2.,  4.,  2.,  2.,
         4.,  7.,  8.,  8.,  8.,  8.,  2.,  2.,  7.,  1.,  8.,  2.,  2.,  2.,
         2.,  7.,  2.,  2.,  2.,  7.,  7.,  2.,  7., -1., -1.,  2.,  2.,  2.,
         2.,  7.,  7.,  7.,  4.,  2.,  2.,  7.,  2.,  2.,  2.,  7.,  7.,  7.,
         1.,  7.,  7.,  7.,  7.,  7.,  4.,  7.,  2.,  2.,  4.,  2.,  1.,  7.,
         7.,  7.,  7.,  7.,  7.,  7.,  1.,  2.,  4.,  7.,  2.,  4.,  1.,  2.,
         7.,  4.,  4.,  7.,  7.,  7.,  7.,  8.,  1.,  8.,  7.,  2.,  7.,  2.,
         7.,  3.,  4.,  5.,  7.,  7.,  7.,  7.,  7.,  8., -1., -1.,  7.,  4.,
         2.,  4.,  4.,  7.,  7.,  7.,  1.,  7.,  2.,  2.,  2.,  7.,  7.,  7.,
         7.,  4.,  1.,  2.,  4.,  2.,  1.,  1.,  7.,  2.,  3.,  2.,  2.,  7.,
         2.,  2.,  2.,  2.,  4.,  7.,  7.,  2.,  8., -1., -1.,  2., -1.,  1.,
         4.,  2.,  2.,  2., -1.,  1.,  1.,  1.,  7.,  2.,  2.,  2.,  2.,  2.,
         2.,  2.,  2.,  7.,  4.,  7.,  7.,  8.,  1.,  2.,  2.,  4.,  7.,  2.,
         4.,  7.,  2.,  2.,  2.,  4.,  7.,  7.,  7.,  7.,  7.,  8.,  2.,  2.,
         2.,  2.,  4.,  7.,  7.,  7.,  7.,  7.,  7.,  2.,  7.,  7.,  1.,  7.,
         7.,  7.,  7.,  8.,  4.,  1.,  7.,  1.,  7.,  2.,  2.,  4.,  4.,  4.,
         4.,  2.,  7.,  7.,  2.,  2.,  7., -1.,  8., -1.,  1.,  1.,  2.,  2.,
         4.,  4.,  7.,  4.,  8., -1., -1.,  1.,  7.,  2.,  2.,  7.,  2.,  2.,
        -1.,  7., -1., -1., -1., -1., -1.,  2.,  2.,  2.,  7.,  3.,  2.,  2.,
         2.,  4.,  7.,  7.,  8.,  8.,  7.,  7.,  8.,  8.,  8.,  2.,  7.,  2.,
         2.,  4.,  7.,  2.,  4.,  1.,  8.,  7.,  7.,  1.,  8.,  7.,  7.,  2.,
         8.,  7.,  8.,  2.,  2.,  4.,  8.,  2.,  2.,  2.,  4.,  7.,  7.,  7.,
         7.,  7.,  2.,  7.,  2.,  2.,  2.,  3.,  4.,  7.,  7.,  8.,  7.,  7.,
         1.,  7.,  2.,  2.,  4.,  7.,  7.,  8.,  8.,  2.,  8.,  1.,  7.,  2.,
         7.,  7.,  2.,  7.,  1.,  2.,  2.,  2.,  2.,  7.,  7.,  7.,  7.,  7.,
         4.,  7.,  7.,  1.,  7.,  2.,  8.,  7.,  7.,  1.,  7.,  1.,  1.,  1.,
         8.,  2.,  7.,  7.,  7.,  7.,  8.,  7.,  2.,  7.,  7.,  7.,  7.,  7.,
         8.,  7.,  8.,  7.,  2.,  7.,  7.,  7.,  7.,  1.,  7.,  1.,  8.,  2.,
         8.,  7.,  2.,  6.,  7.,  7.,  1.,  7.,  7.,  8.,  8.,  2.,  2.,  2.,
         2.,  2.,  7.,  2.,  8.,  8.,  4.,  2.,  7.,  4.,  4.,  4.,  4.,  7.,
         8.,  4.,  1.,  7.,  8.,  1.,  1.,  7.,  2.,  2.,  2.,  4.,  4.,  7.,
         1.,  7.,  7.,  7.,  7.,  7.,  4.,  8.,  7.,  7.,  7.,  7.,  1.,  7.,
         8.,  8.,  1.,  7.,  2.,  7.,  7.,  7.,  7., -1., -1., -1., -1.,  2.,
         2.,  2.,  7.,  7.,  2.,  4.,  2.,  7.,  2.,  2.,  2.,  7.,  7.,  7.,
         7.,  8.,  7.,  2.,  2.,  7.,  2.,  7.,  4.,  7.,  7.,  2.,  2.,  7.,
         7.,  2.,  8.,  7.,  7.,  7.,  2.,  2.,  2.,  4.,  3.,  7.,  8.,  8.,
         2.,  7.,  7.,  2.,  8.,  7.,  4.,  1.,  4.,  8.,  2.,  7.,  4.,  6.,
         7.,  4.,  2.,  7.,  2.,  1.,  1.,  2.,  2.,  2.,  2.,  7.,  4.,  4.,
         4.,  2.,  7.,  7.,  4.,  7.,  8.,  2.,  8.,  1.,  8.,  2.,  7.,  7.,
         2.,  2.,  7.,  2.,  2.,  2.,  7.,  1.,  1.,  2.,  4.,  7.,  7.,  7.,
         7.,  7.,  7.,  8.,  8.,  7.,  1.,  1.,  2.,  2.,  2.,  7.,  7.,  7.,
         8., -1., -1.,  2.,  7.,  2.,  2.,  7.,  7.,  7.,  7.,  8.,  7.,  2.,
         8.,  2.,  4.,  7.,  7.,  7.,  7.,  7.,  8.,  8.,  4.,  7.,  7.,  8.,
         7.,  8.,  7.,  7.,  8.,  1.,  2.,  2.,  8.,  1.,  2.,  2.,  2.,  2.,
         4.,  4.,  7.,  2.,  2.,  2.,  2.,  7.,  2.,  7.,  7.,  7.,  1.,  7.,
         7.,  4.,  4.,  7.,  7.,  7.,  7.,  8.,  1.,  2.,  7.,  7.,  1.,  1.,
         4.,  2.,  4.,  6.,  2.,  7.,  7.,  1.,  1.,  1.,  2.,  2.,  2.,  2.,
         2.,  4.,  2.,  7.,  7.,  7.,  8.,  7.,  7.,  7.,  7.,  8.,  2.,  7.,
         7.,  7.,  1.,  2.,  7.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,
         4.,  8.,  8.,  7.,  8.,  7.,  2.,  7.,  7.,  7.,  2.,  2.,  2.,  2.,
         2.,  4.,  7.,  8.,  2.,  1.,  2.,  7.,  8.,  1.,  8.,  7.,  4.,  7.,
         4.,  2.,  1.,  2.,  2.,  4.,  4.,  4.,  4.,  7.,  7.,  7.,  7.,  8.,
         1.,  7.,  7.,  2.,  4.,  1.,  7.,  2.,  7.,  4.,  4.,  7.,  7.,  8.,
         7.,  7.,  2.,  7.,  7.,  2.,  2.,  2.,  4.,  7.,  7.,  7.,  7.,  8.,
         7.,  1.,  7.,  7.,  7.,  7.,  7.,  2.,  2.,  2.,  7.,  7.,  2.,  8.,
         2.,  8.,  1.,  7.]), 'best match scores': tensor([0.1033, 0.8617, 0.8442, 1.0000, 0.6482, 0.9962, 0.9132, 0.1735, 0.0552,
        0.4978, 0.9983, 0.9826, 0.2057, 0.9998, 0.9930, 0.3124, 0.0589, 0.6366,
        0.7244, 0.0541, 0.1119, 0.9992, 1.0000, 0.0982, 0.2513, 0.9999, 0.9948,
        0.7443, 1.0000, 1.0000, 1.0000, 0.9999, 0.9955, 0.9976, 0.9784, 0.9659,
        0.3102, 0.8369, 0.9881, 0.8454, 0.8173, 1.0000, 0.9993, 0.2375, 1.0000,
        0.5593, 1.0000, 0.9833, 0.3376, 0.9974, 1.0000, 0.2397, 0.9994, 0.9945,
        0.9931, 1.0000, 1.0000, 0.6975, 1.0000, 0.9999, 1.0000, 0.0598, 1.0000,
        0.1205, 0.6098, 0.9938, 0.7214, 0.9798, 0.6795, 0.5361, 1.0000, 1.0000,
        0.9931, 0.9774, 0.6624, 0.2990, 0.1543, 1.0000, 1.0000, 1.0000, 0.0666,
        0.9833, 0.1207, 0.4021, 0.9984, 0.9362, 0.4894, 0.3865, 0.3127, 0.3538,
        0.2054, 0.9852, 0.7056, 0.9999, 1.0000, 0.5086, 0.9722, 0.9981, 0.8811,
        1.0000, 0.2965, 0.0599, 0.0994, 0.0544, 0.6368, 0.3298, 0.9981, 0.7398,
        1.0000, 0.9993, 0.3350, 0.2231, 1.0000, 0.9996, 0.1024, 0.9020, 0.9911,
        0.2456, 0.2059, 0.9997, 0.9947, 0.1140, 0.8386, 0.1535, 0.9957, 0.3215,
        0.9514, 1.0000, 0.1474, 0.0596, 0.9928, 0.9550, 0.0798, 0.8637, 0.9988,
        0.0000, 0.0000, 0.9992, 0.9973, 0.7803, 0.1261, 1.0000, 0.9728, 0.9974,
        1.0000, 1.0000, 0.9999, 0.3137, 0.9998, 1.0000, 0.9885, 0.1939, 0.0503,
        0.7785, 0.0519, 0.8976, 0.3237, 1.0000, 0.9986, 1.0000, 0.7470, 1.0000,
        0.1089, 0.9115, 0.9805, 1.0000, 0.9997, 0.8638, 0.9959, 0.9999, 0.9999,
        1.0000, 0.9998, 0.9736, 0.5567, 0.2793, 0.0573, 0.9877, 1.0000, 0.1349,
        0.6560, 0.8360, 0.1370, 0.9973, 0.9947, 0.3137, 0.2080, 0.9974, 1.0000,
        1.0000, 0.9808, 0.9999, 1.0000, 0.9920, 1.0000, 0.9992, 0.3623, 0.9490,
        0.0812, 0.0505, 1.0000, 1.0000, 0.9996, 1.0000, 0.9988, 0.9553, 0.0000,
        0.0000, 0.9986, 0.2513, 0.1485, 0.5119, 0.5720, 1.0000, 0.3651, 0.8664,
        0.1561, 1.0000, 0.1513, 0.3128, 1.0000, 1.0000, 0.0870, 0.8227, 0.9828,
        0.7777, 0.7838, 1.0000, 1.0000, 0.9680, 0.9963, 1.0000, 0.8845, 1.0000,
        0.1392, 0.9998, 0.9996, 1.0000, 0.9993, 0.5940, 0.9997, 0.9983, 0.9999,
        0.9988, 0.2052, 0.4599, 0.0771, 0.0000, 0.0000, 0.9949, 0.0000, 0.9593,
        1.0000, 1.0000, 0.7859, 1.0000, 0.0000, 0.2782, 1.0000, 0.0501, 1.0000,
        1.0000, 1.0000, 0.9837, 0.7061, 0.9975, 0.9984, 1.0000, 0.3298, 1.0000,
        0.2664, 0.6422, 0.9999, 0.1035, 0.3532, 0.9999, 0.9143, 0.2456, 1.0000,
        0.3904, 0.3651, 0.8627, 0.3306, 0.9967, 0.1750, 0.9815, 1.0000, 0.4154,
        1.0000, 0.9999, 0.5492, 0.0767, 0.9882, 0.1177, 0.0579, 0.9999, 1.0000,
        0.9842, 1.0000, 1.0000, 1.0000, 0.8271, 0.8690, 0.9996, 0.1634, 1.0000,
        0.7813, 0.9999, 0.9509, 0.4882, 0.4577, 0.0539, 0.7054, 0.9999, 0.9895,
        0.1105, 0.9169, 0.8471, 0.6902, 1.0000, 0.9994, 1.0000, 1.0000, 0.9970,
        0.7967, 0.9999, 0.0506, 1.0000, 0.4276, 0.0000, 0.3654, 0.0000, 0.2323,
        0.9970, 1.0000, 0.2815, 0.8099, 0.1082, 0.9966, 1.0000, 0.9439, 0.0000,
        0.0000, 0.9909, 1.0000, 0.7311, 1.0000, 0.0966, 0.3573, 0.7559, 0.0000,
        0.9928, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0545, 0.1110, 0.1793,
        0.1783, 0.9679, 0.9997, 0.9939, 0.5174, 0.1548, 1.0000, 1.0000, 0.4657,
        0.9995, 0.1550, 0.9572, 0.9990, 0.8351, 0.0674, 1.0000, 0.9703, 1.0000,
        1.0000, 1.0000, 0.2086, 0.9997, 1.0000, 0.0779, 1.0000, 0.1091, 0.9660,
        0.1415, 0.1009, 0.5448, 0.0735, 0.4156, 1.0000, 0.9311, 1.0000, 0.6870,
        0.9987, 0.0688, 0.9967, 0.9715, 1.0000, 0.9998, 0.2095, 1.0000, 1.0000,
        0.0733, 0.1191, 0.5820, 1.0000, 0.9964, 1.0000, 0.6195, 0.9254, 0.0565,
        0.9937, 0.9999, 0.9642, 0.9963, 0.9435, 0.1672, 0.0982, 1.0000, 0.3592,
        0.0626, 0.9789, 0.5334, 0.4892, 0.1151, 0.1132, 0.8614, 0.6640, 0.6246,
        0.1227, 0.0586, 0.9999, 1.0000, 0.9985, 0.7046, 0.9912, 0.9172, 0.7914,
        0.4039, 0.3861, 0.9114, 0.9991, 0.0755, 1.0000, 0.6671, 1.0000, 0.8727,
        0.9240, 0.1711, 1.0000, 0.9991, 0.0718, 0.0720, 0.8960, 0.8134, 0.9793,
        1.0000, 0.2037, 0.0846, 0.9877, 1.0000, 0.2016, 1.0000, 0.9959, 0.8688,
        0.9567, 1.0000, 0.9774, 0.4829, 1.0000, 0.7711, 1.0000, 0.1371, 0.2011,
        0.1487, 0.6205, 0.9996, 0.3801, 0.7422, 0.1410, 0.1448, 0.6199, 0.6309,
        0.0634, 0.8543, 0.8344, 1.0000, 0.5793, 0.0575, 0.9425, 0.4600, 1.0000,
        1.0000, 0.9999, 1.0000, 0.9999, 0.9141, 0.9979, 1.0000, 0.0700, 0.9999,
        0.9999, 0.6077, 0.6614, 1.0000, 0.8848, 0.9437, 0.3145, 1.0000, 0.1551,
        0.2788, 0.1125, 0.9999, 1.0000, 0.4178, 0.8047, 0.9997, 0.9997, 1.0000,
        0.0620, 1.0000, 0.9305, 0.9808, 0.0844, 0.4299, 0.9997, 0.9982, 0.1310,
        1.0000, 0.9903, 1.0000, 0.1242, 0.9982, 0.3342, 0.1845, 0.4839, 0.7349,
        1.0000, 0.7865, 1.0000, 0.1013, 0.4241, 0.0628, 0.9744, 0.9981, 0.1318,
        1.0000, 0.7717, 1.0000, 0.7750, 0.2809, 0.7357, 0.0000, 0.0000, 0.0000,
        0.0000, 0.9885, 1.0000, 1.0000, 0.9755, 1.0000, 0.9250, 1.0000, 0.9889,
        0.9932, 0.8887, 0.9997, 1.0000, 0.2303, 0.9795, 1.0000, 0.1114, 0.9959,
        0.3881, 1.0000, 0.4545, 0.5453, 0.9924, 1.0000, 0.0509, 0.1053, 0.1116,
        1.0000, 0.1422, 0.9728, 0.9742, 0.6683, 0.7876, 0.4013, 1.0000, 1.0000,
        0.5246, 0.9999, 0.7177, 0.2094, 0.9947, 1.0000, 0.8957, 0.6682, 1.0000,
        0.1190, 1.0000, 0.9673, 0.9779, 0.9023, 1.0000, 0.9998, 1.0000, 0.1017,
        0.5266, 1.0000, 1.0000, 1.0000, 0.0553, 0.1281, 0.2642, 1.0000, 0.0612,
        0.0683, 0.3997, 1.0000, 0.9999, 0.9999, 0.9992, 0.0962, 1.0000, 0.4172,
        1.0000, 0.0577, 1.0000, 0.0584, 0.9993, 0.9191, 0.5479, 0.1414, 0.8383,
        0.0554, 0.8882, 1.0000, 0.5170, 0.9934, 0.9990, 0.9811, 1.0000, 0.9719,
        0.6332, 0.0553, 0.6799, 0.1144, 0.7142, 1.0000, 0.1970, 1.0000, 1.0000,
        0.8155, 0.0905, 0.0630, 0.9805, 0.9984, 0.0964, 0.0897, 0.9189, 1.0000,
        1.0000, 0.3022, 0.8090, 1.0000, 0.5963, 0.0915, 0.0895, 0.0000, 0.0000,
        1.0000, 1.0000, 0.9252, 0.9925, 0.9039, 0.8232, 0.1837, 0.9320, 0.0848,
        0.9360, 1.0000, 1.0000, 0.5818, 0.9173, 1.0000, 0.6481, 0.9262, 0.1218,
        1.0000, 0.0872, 0.2397, 0.6227, 0.9992, 0.5330, 0.1421, 0.9994, 0.8072,
        0.3685, 0.7244, 0.2474, 0.9906, 0.5639, 0.1867, 0.9994, 1.0000, 0.0819,
        1.0000, 0.7377, 0.7832, 0.3438, 1.0000, 1.0000, 0.5184, 0.1356, 0.9999,
        0.9780, 1.0000, 1.0000, 0.2851, 1.0000, 0.0818, 0.9999, 0.9961, 0.9463,
        0.2930, 0.9986, 1.0000, 1.0000, 0.9930, 0.0642, 0.2030, 0.3256, 0.9480,
        0.9994, 0.9998, 0.9999, 0.6625, 1.0000, 0.1310, 0.8690, 1.0000, 1.0000,
        0.8672, 1.0000, 0.9768, 0.1835, 0.9595, 1.0000, 0.3412, 0.0700, 0.5405,
        0.9997, 1.0000, 0.8999, 1.0000, 1.0000, 1.0000, 0.4107, 1.0000, 0.8511,
        0.7415, 0.8947, 0.0634, 0.5328, 0.8460, 0.9999, 1.0000, 0.9996, 1.0000,
        1.0000, 0.4414, 0.5636, 0.9958, 0.9151, 0.3012, 0.9317, 0.9953, 0.9855,
        0.8393, 0.9644, 0.4539, 0.4941, 0.4658, 0.9997, 1.0000, 0.9998, 1.0000,
        0.9999, 0.9727, 0.4311, 0.9979, 1.0000, 0.9997, 0.9852, 0.6471, 0.9997,
        0.4718, 1.0000, 0.0757, 0.9998, 0.2991, 0.6358, 0.1111, 0.1286, 1.0000,
        1.0000, 0.9997, 0.9957, 0.9865, 0.2482, 0.9995, 1.0000, 0.7678, 0.9960,
        1.0000, 0.0880, 0.9934, 0.9991, 1.0000, 0.4214, 0.0991, 0.1039, 0.9229,
        0.1283, 0.3292, 0.1885, 0.0606, 0.0553, 0.1368, 0.6755, 0.9888, 0.7629,
        0.9997, 0.6727, 0.9815, 0.9959, 0.9997, 0.9882, 0.9645, 1.0000, 0.9165,
        0.4753, 1.0000, 0.1466, 0.3741, 0.4793, 0.0594, 0.7934, 0.6624, 0.9745,
        0.1238, 0.5137, 1.0000, 1.0000, 1.0000, 0.9998, 0.9920, 0.1775, 0.2085,
        0.9687, 1.0000, 0.9997, 0.2400, 0.5582, 1.0000, 0.8389, 0.8460]), 'num_pos': 872}
2020-12-12 14:59:59,565 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.275229
2020-12-12 15:01:18,223 maskrcnn_benchmark.trainer INFO: eta: 0:22:38  iter: 340  loss: 6.5319 (6.6083)  loss_classifier: 0.3679 (0.4729)  loss_box_reg: 0.4958 (0.4979)  loss_objectness: 1.1807 (1.1640)  loss_rpn_box_reg: 4.2844 (4.4735)  time: 3.8061 (5.2242)  data: 0.2066 (1.6287)  lr: 0.000000  max mem: 1313
2020-12-12 15:02:34,816 maskrcnn_benchmark.trainer INFO: eta: 0:20:35  iter: 360  loss: 6.5463 (6.6011)  loss_classifier: 0.4399 (0.4728)  loss_box_reg: 0.2776 (0.4943)  loss_objectness: 1.1406 (1.1625)  loss_rpn_box_reg: 4.5302 (4.4716)  time: 3.7995 (5.1467)  data: 0.2060 (1.5495)  lr: 0.000000  max mem: 1313
2020-12-12 15:03:50,642 maskrcnn_benchmark.trainer INFO: eta: 0:18:36  iter: 380  loss: 6.4885 (6.5960)  loss_classifier: 0.4525 (0.4722)  loss_box_reg: 0.4003 (0.4922)  loss_objectness: 1.1634 (1.1630)  loss_rpn_box_reg: 4.4828 (4.4686)  time: 3.7898 (5.0754)  data: 0.1992 (1.4786)  lr: 0.000000  max mem: 1313
2020-12-12 15:05:06,628 maskrcnn_benchmark.trainer INFO: eta: 0:16:42  iter: 400  loss: 6.7862 (6.6018)  loss_classifier: 0.5027 (0.4747)  loss_box_reg: 0.4804 (0.4940)  loss_objectness: 1.1198 (1.1621)  loss_rpn_box_reg: 4.5882 (4.4711)  time: 3.7942 (5.0116)  data: 0.2050 (1.4148)  lr: 0.000000  max mem: 1313
2020-12-12 15:06:23,014 maskrcnn_benchmark.trainer INFO: eta: 0:14:51  iter: 420  loss: 6.2211 (6.5819)  loss_classifier: 0.3958 (0.4714)  loss_box_reg: 0.2715 (0.4876)  loss_objectness: 1.1614 (1.1643)  loss_rpn_box_reg: 4.2670 (4.4586)  time: 3.8027 (4.9548)  data: 0.2014 (1.3575)  lr: 0.000000  max mem: 1313
2020-12-12 15:07:38,916 maskrcnn_benchmark.trainer INFO: eta: 0:13:04  iter: 440  loss: 6.8318 (6.5859)  loss_classifier: 0.4552 (0.4715)  loss_box_reg: 0.4888 (0.4889)  loss_objectness: 1.1692 (1.1644)  loss_rpn_box_reg: 4.6459 (4.4611)  time: 3.7934 (4.9021)  data: 0.1987 (1.3049)  lr: 0.000000  max mem: 1313
2020-12-12 15:08:54,740 maskrcnn_benchmark.trainer INFO: eta: 0:11:19  iter: 460  loss: 6.0970 (6.5665)  loss_classifier: 0.3835 (0.4689)  loss_box_reg: 0.3640 (0.4830)  loss_objectness: 1.1702 (1.1643)  loss_rpn_box_reg: 4.3115 (4.4502)  time: 3.7908 (4.8538)  data: 0.1989 (1.2570)  lr: 0.000000  max mem: 1313
2020-12-12 15:10:10,664 maskrcnn_benchmark.trainer INFO: eta: 0:09:37  iter: 480  loss: 6.5461 (6.5724)  loss_classifier: 0.4031 (0.4670)  loss_box_reg: 0.5630 (0.4875)  loss_objectness: 1.2013 (1.1657)  loss_rpn_box_reg: 4.4263 (4.4522)  time: 3.7956 (4.8097)  data: 0.1985 (1.2130)  lr: 0.000000  max mem: 1313
2020-12-12 15:10:10,666 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 15:10:10,732 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(148 images).
2020-12-12 15:13:52,360 maskrcnn_benchmark.inference INFO: Total run time: 0:03:41.627662 (1.4974842039314475 s / img per device, on 1 devices)
2020-12-12 15:13:52,360 maskrcnn_benchmark.inference INFO: Model inference time: 0:03:27.465508 (1.4017939744768917 s / img per device, on 1 devices)
2020-12-12 15:13:52,361 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 15:14:07,838 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 15:14:07,838 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([3.2977e-02, 9.3004e-05, 0.0000e+00, 5.3525e-03, 3.7618e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.0658e-02, 3.9338e-02, 3.1374e-02, 3.0867e-02, 1.7345e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5362e-02, 1.5745e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.9538e-01, 1.1350e-03, 0.0000e+00, 1.6499e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.7293e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4233e-01, 5.1998e-02,
        3.9355e-02, 3.5262e-02, 2.2594e-02, 2.2073e-02, 3.4339e-03, 1.2298e-03,
        0.0000e+00, 5.0855e-02, 3.4832e-02, 3.3421e-02, 1.9836e-02, 0.0000e+00,
        0.0000e+00, 9.2822e-02, 4.0627e-02, 1.7561e-02, 1.6763e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1981e-02, 3.5891e-02,
        2.5128e-02, 9.7739e-02, 6.5400e-02, 5.6865e-02, 4.4089e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.9594e-02, 1.7443e-02,
        0.0000e+00, 4.8324e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4959e-01, 3.3487e-02,
        0.0000e+00, 6.8185e-03, 2.1820e-03, 1.1783e-03, 0.0000e+00, 0.0000e+00,
        3.5890e-02, 1.8845e-02, 8.5535e-03, 6.8884e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8643e-02, 5.6694e-02, 2.1910e-02,
        1.2464e-01, 8.3764e-02, 2.3719e-02, 1.3500e-02, 4.9621e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.4040e-02, 6.2106e-02, 0.0000e+00, 9.2844e-02, 2.3082e-02, 1.9644e-02,
        2.6418e-03, 1.7188e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.2339e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3711e-02,
        1.4785e-02, 0.0000e+00, 4.7963e-02, 1.1824e-03, 0.0000e+00, 1.4368e-01,
        3.2977e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4007e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.6880e-02, 3.7956e-02, 1.7609e-08, 3.6573e-02,
        3.1749e-02, 1.9440e-05, 0.0000e+00, 1.1449e-01, 8.5101e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.3050e-02, 6.3234e-02, 2.1682e-02, 1.0322e-01, 3.3215e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.9403e-02, 7.5259e-02, 7.6292e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9569e-02,
        0.0000e+00, 0.0000e+00, 1.1005e-01, 8.9287e-02, 3.2701e-02, 5.5006e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6189e-02,
        1.0835e-02, 0.0000e+00, 9.0014e-02, 2.3287e-03, 3.8535e-04, 7.3423e-02,
        1.7014e-02, 0.0000e+00, 5.8131e-02, 2.3193e-02, 1.6699e-02, 1.5874e-02,
        8.2524e-03, 5.9717e-03, 3.4714e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 5.1376e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0489e-02, 1.0200e-02,
        6.0608e-03, 6.0100e-03, 4.2265e-03, 2.8843e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.9234e-01, 1.0579e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8813e-02, 1.8220e-02,
        8.1177e-07, 0.0000e+00, 0.0000e+00, 1.2057e-01, 5.9501e-02, 1.0193e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.3288e-02, 9.0500e-02, 6.9997e-02, 5.5693e-02, 3.2977e-02, 0.0000e+00,
        1.0778e-01, 8.3744e-02, 7.6909e-02, 1.7551e-02, 1.5030e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.5470e-02, 1.3825e-02, 2.3357e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7880e-01, 7.9390e-02, 0.0000e+00, 3.9642e-01, 4.3062e-02, 2.3955e-02,
        2.3424e-02, 2.2229e-02, 2.9356e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.5877e-01, 3.1749e-02, 9.3229e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.3152e-02, 3.5639e-02, 6.4526e-05, 9.2847e-02,
        3.3439e-02, 5.1903e-03, 4.6149e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.7734e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8274e-02,
        2.8522e-02, 2.4962e-02, 1.4750e-02, 7.4317e-03, 6.0701e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0806e-02, 6.0704e-02,
        5.1154e-02, 1.3677e-02, 3.8673e-03, 2.2774e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.2482e-01, 4.1530e-02, 0.0000e+00, 1.3709e-01, 4.0512e-02,
        5.0315e-04, 4.2948e-01, 5.6217e-02, 3.0754e-02, 1.5874e-02, 1.1135e-02,
        1.1213e-03, 1.3836e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.5624e-03, 1.1519e-03, 1.9397e-04, 1.6305e-01, 2.1320e-02, 1.8396e-02,
        7.9531e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.5332e-02, 3.0599e-02, 2.6899e-02, 2.5007e-02, 1.7178e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4085e-02,
        5.7287e-03, 0.0000e+00, 3.9973e-02, 3.2139e-02, 2.5135e-02, 2.0330e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.7629e-01, 7.3643e-02, 6.1672e-02, 2.3253e-02, 7.8991e-03,
        4.6405e-03, 1.3592e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0509e-01, 7.1610e-02, 0.0000e+00,
        3.2977e-02, 3.0536e-02, 0.0000e+00, 8.7972e-02, 4.2861e-02, 0.0000e+00,
        3.4587e-02, 5.5006e-03, 1.0259e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2012e-02, 8.6017e-04, 0.0000e+00,
        1.3351e-01, 5.8037e-02, 2.6615e-02, 8.4568e-03, 3.1055e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.5921e-02, 2.0112e-02, 2.5731e-03, 3.2056e-04, 2.2892e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4328e-01,
        4.4486e-02, 2.0485e-02, 8.3320e-03, 4.0356e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7705e-02, 3.2423e-02,
        1.9947e-02, 8.4714e-04, 1.7923e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.9762e-02, 5.5006e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3979e-01, 9.7106e-02,
        4.0635e-02, 5.6012e-02, 3.2139e-02, 1.5243e-02, 1.2069e-02, 9.5403e-03,
        5.5841e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.8693e-02, 0.0000e+00, 0.0000e+00, 1.9487e-02, 5.1717e-02, 2.1845e-02,
        9.5142e-03, 4.9383e-03, 3.5357e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7136e-02, 2.3719e-02, 0.0000e+00,
        6.2690e-02, 0.0000e+00, 0.0000e+00, 1.7294e-02, 1.0193e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.2464e-02, 2.5841e-02, 1.3561e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1032e-02,
        1.6644e-02, 1.1123e-03, 4.1007e-02, 0.0000e+00, 2.7875e-02, 1.2411e-02,
        1.0632e-02, 6.3908e-03, 6.1719e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 5.7673e-02, 3.6069e-02, 0.0000e+00, 3.2139e-02, 2.5308e-02,
        1.3292e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.4720e-01, 1.2426e-01, 2.9954e-02, 1.0751e-01, 3.7672e-02, 2.1682e-02,
        8.1455e-02, 4.9010e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1506e-01, 4.6957e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.3422e-02, 2.9948e-03, 0.0000e+00, 0.0000e+00, 5.1370e-02, 4.2914e-02,
        6.3682e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.7216e-02, 1.5352e-02, 1.3136e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8344e-01, 0.0000e+00,
        0.0000e+00, 9.0979e-02, 7.0611e-02, 5.3911e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.0365e-02, 1.1132e-02, 5.5499e-03, 4.7554e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.5920e-01, 6.0671e-02, 0.0000e+00, 1.1929e-01, 1.5552e-02, 3.8868e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.7634e-02, 0.0000e+00, 0.0000e+00, 1.4405e-01, 0.0000e+00, 0.0000e+00,
        7.4168e-02, 2.1511e-03, 0.0000e+00, 1.0908e-01, 4.7139e-02, 3.5767e-02,
        1.1151e-02, 5.5006e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7260e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.7090e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1492e-01,
        5.0866e-02, 4.0397e-05, 2.1729e-01, 4.2436e-02, 2.1358e-03, 1.0289e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2721e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00, 1.7218e-01,
        2.1682e-02, 3.2139e-02, 2.8754e-02, 2.0266e-02, 2.9892e-03, 2.0198e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0274e-02, 1.9172e-03, 2.2761e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7094e-02,
        2.3336e-02, 0.0000e+00, 2.6947e-01, 6.6275e-02, 1.1408e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3082e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8133e-02,
        2.1682e-02, 1.1367e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.9548e-02, 3.2977e-02, 2.3336e-02, 7.7801e-02, 4.7981e-02, 1.5874e-02,
        1.6761e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3086e-01, 0.0000e+00, 0.0000e+00, 1.9552e-01,
        5.6865e-02, 0.0000e+00, 2.5764e-01, 8.1595e-02, 6.4650e-03, 9.8403e-02,
        4.9972e-02, 3.1811e-02, 2.9465e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.0826e-01, 1.5078e-02, 0.0000e+00, 2.2698e-02,
        1.5640e-02, 3.2102e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6695e-02, 1.1697e-04, 2.9102e-01,
        4.1485e-02, 0.0000e+00, 9.5219e-02, 3.3744e-02, 2.2129e-02, 1.3943e-02,
        3.9805e-03, 1.9556e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4047e-02,
        0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 1, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7,
        4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 4, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 7, 7, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 7, 7, 4]), 'best match labels': tensor([ 8.,  7.,  2.,  2.,  7.,  2.,  2.,  7.,  7.,  7.,  8.,  8.,  1.,  2.,
         2.,  2.,  4.,  4.,  7.,  4.,  7.,  2.,  4.,  2.,  4.,  4.,  7.,  1.,
         7.,  7.,  7.,  7.,  1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,
         2.,  1.,  1.,  4.,  7.,  7.,  7.,  2.,  8.,  8.,  2.,  4.,  7.,  2.,
         1.,  7.,  7.,  2.,  7.,  7.,  2.,  7.,  7.,  7.,  7.,  4.,  7.,  7.,
         4.,  4.,  7.,  7.,  7.,  7.,  2.,  7.,  1.,  2.,  7.,  2.,  2.,  2.,
         2.,  2.,  7.,  7.,  1.,  7.,  7.,  2.,  2.,  2.,  7.,  2.,  2.,  2.,
         4.,  7.,  7.,  7.,  2.,  4.,  1.,  2.,  7.,  7.,  2.,  2.,  2.,  2.,
         7.,  1.,  4.,  8.,  7.,  4.,  2.,  7.,  7.,  7.,  2.,  7.,  2.,  2.,
         2.,  4.,  4.,  7.,  7.,  7.,  7.,  8.,  7.,  1.,  7.,  2.,  2.,  7.,
         7.,  1.,  7.,  7.,  1.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  7.,  2.,
         8.,  7.,  8.,  7.,  2.,  8.,  1.,  7.,  7.,  2.,  4.,  7.,  7.,  7.,
         7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  2.,  2.,  4.,  2.,  4.,
         7.,  2.,  2.,  2.,  2.,  7.,  2.,  7.,  7.,  7.,  7.,  1.,  1.,  1.,
         7.,  2.,  2.,  3.,  7.,  7.,  7.,  7.,  7.,  8., -1., -1.,  7.,  1.,
         2.,  7.,  2.,  2.,  7.,  7.,  7.,  2.,  7.,  7.,  7.,  7.,  7.,  1.,
         7.,  8.,  7.,  7.,  4.,  7.,  1.,  1.,  1.,  7.,  2.,  2.,  4.,  7.,
         2.,  2.,  7.,  7.,  2.,  4.,  7.,  7.,  7.,  7., -1., -1., -1.,  1.,
         2.,  2.,  2.,  7.,  7.,  1.,  8.,  2.,  7.,  7.,  7.,  7.,  2.,  2.,
         7.,  7.,  7.,  7.,  7.,  7.,  2.,  7.,  4.,  2.,  2.,  1.,  4.,  1.,
         1.,  4.,  2.,  2.,  2.,  7.,  4.,  7.,  7.,  2.,  7.,  7.,  2.,  7.,
         7.,  4.,  7.,  7.,  7.,  1.,  7.,  4.,  7.,  2.,  2.,  7.,  7.,  7.,
         7.,  2.,  1.,  7.,  8.,  7.,  2.,  2.,  7.,  4.,  7.,  4.,  6.,  7.,
         7.,  8.,  2.,  7.,  2.,  7.,  7., -1., -1., -1.,  2.,  2.,  7.,  7.,
         7.,  7.,  7.,  4.,  7.,  7.,  2., -1.,  2.,  1.,  2.,  2.,  7.,  4.,
        -1., -1., -1., -1., -1.,  2.,  2.,  2.,  7.,  7.,  7.,  2.,  7.,  2.,
         2.,  7.,  7.,  7.,  8.,  8.,  7.,  7.,  8.,  2.,  8.,  2.,  2.,  7.,
         8.,  7.,  7.,  4.,  1.,  7.,  2.,  7.,  7.,  1.,  4.,  7.,  2.,  2.,
         4.,  4.,  7.,  7.,  7.,  2.,  2.,  7.,  2.,  2.,  7.,  4.,  7.,  7.,
         8.,  7.,  2.,  2.,  2.,  2.,  2.,  7.,  7.,  7.,  7.,  7.,  7.,  8.,
         2.,  1.,  1.,  7.,  2.,  4.,  4.,  7.,  7.,  7.,  8.,  8.,  2.,  2.,
         7.,  7.,  1.,  1.,  1.,  2.,  7.,  7.,  7.,  7.,  7.,  1.,  8.,  7.,
         4.,  8.,  7.,  2.,  1.,  8.,  2.,  7.,  2.,  1.,  4.,  5.,  6.,  7.,
         7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  2.,  7.,  7.,  7.,  7.,  7.,
         7.,  7.,  7.,  7.,  2.,  2.,  4.,  4.,  1.,  1.,  7.,  7.,  7.,  7.,
         8.,  7.,  7.,  7.,  7.,  7.,  1.,  7.,  7.,  8.,  8.,  2.,  7.,  8.,
         8.,  1.,  2.,  8.,  1.,  2.,  2.,  4.,  4.,  4.,  4.,  4.,  4.,  8.,
         7.,  4.,  7.,  7.,  4.,  1.,  7.,  7.,  2.,  7.,  2.,  2.,  2.,  7.,
         2.,  7.,  7.,  4.,  7.,  7.,  8.,  7.,  7.,  2.,  6.,  7.,  7.,  7.,
         7.,  7.,  7.,  2.,  7.,  7.,  4.,  4.,  7., -1.,  4., -1., -1., -1.,
         1.,  4.,  7.,  7.,  4.,  1.,  7.,  4.,  4.,  7.,  7.,  7.,  7.,  7.,
         7.,  4.,  7.,  7.,  2.,  1.,  2.,  7.,  7.,  4.,  7.,  8.,  1.,  7.,
         7.,  8.,  2.,  2.,  7.,  4.,  2.,  2.,  2.,  2.,  7.,  7.,  8.,  8.,
         2.,  7.,  7.,  7.,  8.,  7.,  7.,  1.,  4.,  7.,  2.,  2.,  2.,  2.,
         2.,  7.,  7.,  4.,  7.,  1.,  2.,  2.,  2.,  2.,  4.,  2.,  2.,  4.,
         8.,  7.,  7.,  8.,  2.,  1.,  2.,  7.,  2.,  2.,  7.,  4.,  7.,  2.,
         2.,  8.,  7.,  7.,  7.,  7.,  7.,  2.,  7.,  7.,  4.,  4.,  4.,  6.,
         7.,  7.,  1.,  7.,  7.,  1., -1., -1.,  1.,  1.,  1.,  2.,  4.,  4.,
         7.,  1.,  2.,  2.,  2.,  2.,  4.,  7.,  7.,  1.,  7.,  7.,  7.,  2.,
         7.,  2.,  4.,  7.,  7.,  7.,  7.,  7.,  7.,  8.,  7.,  7.,  7.,  7.,
         7.,  7.,  7.,  7.,  8.,  1.,  4.,  2.,  4.,  2.,  2.,  2.,  2.,  4.,
         5.,  7.,  7.,  2.,  2.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  2.,  7.,
         2.,  2.,  2.,  4.,  4.,  4.,  7.,  7.,  7.,  2.,  7.,  7.,  4.,  4.,
         7.,  6.,  2.,  7.,  2.,  7.,  1., -1., -1., -1., -1.,  1., -1.,  1.,
         2.,  2.,  8.,  7.,  8.,  7.,  8.,  2.,  7.,  4.,  7.,  7.,  7.,  1.,
         7.,  7.,  2.,  7.,  1.,  2.,  2.,  2.,  4.,  4.,  6.,  7.,  7.,  1.,
         8.,  8.,  7.,  1.,  2.,  7.,  7.,  4.,  7.,  7.,  1.,  1.,  2.,  2.,
         2.,  2.,  4.,  2.,  7.,  2.,  2.,  7.,  7.,  7.,  7.,  7.,  4.,  7.,
         4.,  8.,  4.,  2.,  2.,  2.,  2.,  4.,  7.,  1.,  7.,  7.,  1.,  7.,
         8.,  7.,  7.,  7.,  7.,  2.,  7.,  2.,  7.,  2.,  7.,  7.,  7.,  7.,
         2.,  7.,  7.,  7.,  1.,  1.,  7.,  4.,  4.,  4.,  7.,  7.,  7.,  7.,
         7.,  2.,  1.,  8.,  7.,  2.,  7.,  7.,  7.,  2.,  7.,  7.,  4.,  7.,
         2.,  7.,  7.,  7.]), 'best match scores': tensor([0.3639, 0.9991, 0.2787, 0.9510, 0.4384, 0.1934, 1.0000, 0.9708, 0.6268,
        0.8958, 0.2760, 0.9999, 0.7987, 0.9995, 1.0000, 0.8003, 1.0000, 0.9491,
        0.9997, 0.9999, 0.8397, 0.9845, 1.0000, 0.9992, 0.9951, 0.9093, 0.9914,
        0.9593, 0.0599, 0.0521, 1.0000, 0.1695, 0.1457, 0.6949, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.1977, 1.0000, 0.8922, 1.0000, 0.7326, 0.9046,
        0.9743, 0.9936, 1.0000, 0.8623, 0.8110, 0.2169, 0.0915, 1.0000, 0.8800,
        0.5490, 0.9614, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 0.3003, 1.0000,
        0.9994, 0.8514, 0.9010, 0.0561, 0.7865, 0.9006, 0.9205, 0.9959, 0.1619,
        0.9956, 0.0685, 1.0000, 0.9948, 1.0000, 0.3393, 1.0000, 1.0000, 1.0000,
        0.0549, 0.8840, 0.9963, 0.9996, 0.0550, 0.9961, 0.9281, 0.0671, 1.0000,
        0.9999, 0.0791, 0.9987, 1.0000, 1.0000, 0.5449, 0.0714, 0.1974, 0.9998,
        0.9840, 1.0000, 0.0686, 0.5129, 0.0827, 0.5757, 0.4894, 0.9991, 0.9537,
        0.0869, 0.4179, 0.0687, 0.1028, 0.9995, 0.9848, 0.9853, 0.9283, 0.2188,
        0.1290, 0.9994, 0.9998, 0.0648, 0.9599, 0.9523, 0.0512, 0.9950, 0.9772,
        0.1013, 0.1664, 1.0000, 0.8382, 0.8016, 0.2050, 0.9489, 1.0000, 0.3123,
        0.1658, 1.0000, 1.0000, 0.0503, 0.1315, 0.9626, 0.2547, 0.9886, 1.0000,
        0.8076, 0.9354, 1.0000, 0.4668, 0.4571, 0.4696, 0.2274, 0.8366, 0.9610,
        0.6528, 0.9906, 0.9998, 0.9413, 0.9997, 0.8328, 0.1163, 0.0582, 0.0722,
        0.9998, 0.9609, 0.9948, 0.2170, 0.9999, 0.7880, 0.9733, 0.9941, 0.9684,
        0.7258, 0.9961, 1.0000, 0.9999, 0.1992, 0.9983, 0.8703, 0.0830, 1.0000,
        0.9998, 0.9990, 0.6036, 0.9878, 0.9164, 0.3271, 0.9976, 0.9701, 0.4811,
        0.0984, 1.0000, 0.9582, 0.8671, 0.9999, 0.9686, 1.0000, 0.9998, 0.9994,
        0.6870, 0.4737, 0.6149, 1.0000, 0.1528, 0.0735, 0.5263, 0.4502, 0.0000,
        0.0000, 0.2237, 0.8200, 0.2669, 1.0000, 0.5900, 0.9993, 1.0000, 0.8471,
        1.0000, 0.9604, 1.0000, 1.0000, 0.4899, 0.9999, 1.0000, 0.1748, 0.9909,
        0.9644, 0.1059, 0.9440, 0.9984, 0.3067, 0.1225, 0.1979, 0.5031, 1.0000,
        0.4580, 0.9723, 0.9948, 1.0000, 0.9775, 0.9978, 0.9913, 0.1935, 1.0000,
        0.1845, 0.0917, 0.9995, 0.5014, 0.9652, 0.0000, 0.0000, 0.0000, 0.1127,
        0.1674, 1.0000, 0.9999, 0.9900, 0.9586, 0.9954, 0.9990, 0.7608, 0.9788,
        0.9158, 0.9934, 1.0000, 0.9833, 0.0700, 1.0000, 0.9158, 0.5358, 0.1385,
        0.6237, 0.9526, 0.0835, 0.0609, 0.5169, 0.8645, 0.8628, 0.0562, 0.2205,
        1.0000, 0.3409, 0.9875, 0.9102, 0.7699, 0.6591, 0.9016, 0.1520, 0.9606,
        0.0864, 0.7796, 0.7904, 0.9938, 0.9867, 1.0000, 1.0000, 0.7669, 0.3606,
        0.1278, 0.1080, 0.1398, 0.9978, 0.9993, 1.0000, 1.0000, 0.9997, 0.9999,
        0.9884, 0.0948, 0.9801, 0.9413, 0.0677, 0.0587, 0.0681, 0.4388, 0.9998,
        0.9962, 0.9949, 1.0000, 0.9396, 1.0000, 1.0000, 0.5093, 1.0000, 0.0507,
        0.9932, 0.1790, 0.4740, 0.6572, 0.9992, 0.0000, 0.0000, 0.0000, 0.6552,
        0.7788, 0.9999, 0.0575, 0.5116, 0.9886, 0.9656, 0.9994, 1.0000, 0.9912,
        0.9966, 0.0000, 0.5681, 0.9587, 0.9048, 0.9997, 1.0000, 0.0756, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0736, 0.9999, 1.0000, 0.2009, 1.0000,
        1.0000, 0.3992, 0.2046, 1.0000, 0.8115, 0.9994, 1.0000, 0.6090, 0.9918,
        1.0000, 0.3674, 0.9681, 0.9984, 0.9889, 0.5395, 1.0000, 1.0000, 1.0000,
        0.9975, 0.9985, 0.2628, 1.0000, 0.9730, 0.1132, 1.0000, 0.9905, 0.2452,
        0.9212, 1.0000, 1.0000, 0.9994, 0.4024, 1.0000, 1.0000, 1.0000, 0.9962,
        0.9872, 1.0000, 0.9810, 0.0987, 0.9768, 0.3378, 0.1312, 0.5524, 0.9931,
        0.9983, 0.1981, 1.0000, 0.8649, 0.0540, 1.0000, 0.9985, 1.0000, 0.0712,
        1.0000, 0.9999, 0.1044, 1.0000, 0.9853, 0.9677, 0.2375, 0.4417, 0.8889,
        1.0000, 0.1132, 1.0000, 0.0791, 0.9998, 0.9888, 0.0706, 0.5524, 0.0769,
        0.9977, 0.2640, 0.7365, 0.7338, 0.8538, 0.1126, 0.7477, 0.2015, 0.1965,
        1.0000, 1.0000, 1.0000, 0.5967, 0.0823, 0.9384, 1.0000, 0.6118, 0.9252,
        0.9327, 0.4451, 0.4599, 0.9022, 0.9915, 0.9962, 0.8914, 0.8360, 0.7380,
        0.8800, 0.1312, 0.9967, 0.4860, 0.9983, 0.8825, 0.9999, 0.0661, 0.9808,
        0.9999, 0.9999, 1.0000, 1.0000, 0.9998, 0.9928, 1.0000, 0.9913, 0.7339,
        1.0000, 0.0573, 1.0000, 1.0000, 0.9982, 1.0000, 0.9998, 0.9553, 0.1259,
        0.2557, 0.6403, 0.9996, 0.9510, 0.4289, 0.9821, 1.0000, 0.6188, 0.8858,
        0.4672, 0.1618, 1.0000, 0.9999, 0.9265, 0.1783, 1.0000, 1.0000, 0.8784,
        0.9942, 0.9823, 1.0000, 0.9684, 0.2290, 0.9999, 1.0000, 0.1244, 0.9946,
        1.0000, 0.1238, 0.9783, 0.0525, 0.5730, 1.0000, 1.0000, 0.7450, 0.9957,
        0.9995, 1.0000, 1.0000, 0.9635, 0.4066, 0.4693, 0.1438, 1.0000, 0.9961,
        0.5667, 1.0000, 0.1728, 0.9425, 0.9991, 0.9955, 1.0000, 1.0000, 0.9999,
        1.0000, 0.0576, 0.9901, 0.0533, 1.0000, 0.7333, 0.0668, 1.0000, 0.4927,
        1.0000, 0.8949, 1.0000, 0.5234, 0.5101, 1.0000, 0.0000, 0.9997, 0.0000,
        0.0000, 0.0000, 0.2620, 0.9989, 0.5691, 0.9996, 0.8901, 0.0732, 1.0000,
        0.0970, 0.8687, 0.9937, 1.0000, 1.0000, 1.0000, 0.1014, 0.9589, 0.9999,
        0.9972, 0.9883, 1.0000, 0.9167, 0.8516, 0.0701, 0.1234, 1.0000, 0.2470,
        0.3296, 1.0000, 0.9921, 1.0000, 0.3651, 0.9999, 0.4074, 1.0000, 0.9999,
        1.0000, 0.7654, 0.1039, 1.0000, 0.9963, 0.9976, 1.0000, 0.2223, 0.9993,
        0.9944, 0.7535, 0.2571, 0.9946, 1.0000, 0.4173, 0.9999, 1.0000, 0.6209,
        1.0000, 0.2027, 0.1719, 1.0000, 0.2789, 0.3658, 1.0000, 0.5453, 0.9437,
        0.9981, 0.8434, 0.9998, 0.6307, 1.0000, 0.1784, 1.0000, 1.0000, 1.0000,
        0.3893, 0.2239, 0.8976, 0.1330, 0.3036, 0.9194, 1.0000, 0.9469, 0.9591,
        0.9999, 0.9552, 0.7109, 0.8878, 0.9275, 0.1449, 0.9740, 0.9240, 0.4475,
        0.5273, 0.5066, 0.8167, 0.9998, 0.9975, 1.0000, 0.8578, 0.7780, 0.7978,
        0.9996, 0.8135, 1.0000, 0.9997, 1.0000, 0.9947, 0.9994, 0.0000, 0.0000,
        0.9853, 0.9934, 0.9998, 0.0778, 0.0880, 0.0718, 0.9985, 1.0000, 0.6427,
        0.5569, 0.1073, 0.7567, 0.9766, 0.6814, 0.5621, 0.0824, 1.0000, 1.0000,
        0.9976, 0.9969, 1.0000, 0.1421, 0.4191, 0.9973, 0.9237, 0.9948, 1.0000,
        0.9273, 0.5044, 0.9546, 0.7033, 0.8847, 1.0000, 0.9999, 0.3752, 0.9569,
        1.0000, 0.5668, 0.3675, 0.9999, 0.9196, 0.5660, 0.9977, 0.0595, 0.9901,
        0.0851, 1.0000, 1.0000, 0.9946, 0.9973, 1.0000, 1.0000, 0.0677, 0.9428,
        0.9639, 0.4578, 0.9929, 0.1646, 0.9999, 1.0000, 1.0000, 0.9639, 1.0000,
        0.2239, 0.9881, 0.5588, 1.0000, 0.8554, 0.9595, 1.0000, 0.9912, 0.6607,
        0.9048, 0.9643, 0.9996, 0.9470, 1.0000, 1.0000, 0.2366, 0.3605, 1.0000,
        0.0590, 0.5245, 0.0000, 0.0000, 0.0000, 0.0000, 0.8477, 0.0000, 1.0000,
        1.0000, 0.9935, 1.0000, 0.8511, 1.0000, 0.9992, 1.0000, 0.1031, 1.0000,
        0.0860, 0.0785, 0.2795, 0.8012, 0.6540, 1.0000, 0.3890, 1.0000, 0.3597,
        0.1584, 1.0000, 0.9928, 0.9307, 0.9998, 0.9721, 0.7395, 1.0000, 0.0693,
        0.9913, 1.0000, 0.6226, 1.0000, 1.0000, 0.2438, 1.0000, 0.0841, 0.9803,
        0.3471, 0.9904, 0.9237, 0.9731, 1.0000, 0.2102, 1.0000, 0.9981, 1.0000,
        0.1941, 0.4954, 0.7778, 0.9969, 0.9996, 0.9999, 0.2918, 0.7812, 0.9843,
        1.0000, 1.0000, 0.9988, 0.2215, 0.9999, 0.7833, 0.0803, 0.9998, 0.1445,
        1.0000, 1.0000, 1.0000, 0.8304, 0.3992, 0.9992, 0.9808, 0.1020, 0.0504,
        1.0000, 0.9953, 0.0780, 0.0589, 0.8553, 1.0000, 0.9983, 1.0000, 0.9993,
        0.9998, 1.0000, 0.9228, 0.9738, 0.9927, 1.0000, 1.0000, 0.7262, 1.0000,
        0.8059, 0.0515, 0.0551, 0.9822, 1.0000, 1.0000, 0.4987, 0.2000, 1.0000,
        1.0000, 0.7520, 0.4763, 0.4336, 0.3311, 0.9999, 0.1584, 0.6633, 0.9999,
        0.9898, 0.9901, 0.7900, 0.6174, 0.9932, 0.8584, 0.0604, 0.9976]), 'num_pos': 872}
2020-12-12 15:14:07,948 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.254587
2020-12-12 15:15:23,731 maskrcnn_benchmark.trainer INFO: eta: 0:08:44  iter: 500  loss: 6.5868 (6.5695)  loss_classifier: 0.4932 (0.4673)  loss_box_reg: 0.4963 (0.4884)  loss_objectness: 1.1309 (1.1653)  loss_rpn_box_reg: 4.2884 (4.4486)  time: 3.7908 (5.2434)  data: 0.2021 (1.6471)  lr: 0.000000  max mem: 1313
2020-12-12 15:16:39,524 maskrcnn_benchmark.trainer INFO: eta: 0:06:55  iter: 520  loss: 6.2020 (6.5577)  loss_classifier: 0.3866 (0.4674)  loss_box_reg: 0.3636 (0.4869)  loss_objectness: 1.0864 (1.1630)  loss_rpn_box_reg: 4.3224 (4.4404)  time: 3.7904 (5.1875)  data: 0.1993 (1.5915)  lr: 0.000000  max mem: 1313
2020-12-12 15:17:55,336 maskrcnn_benchmark.trainer INFO: eta: 0:05:08  iter: 540  loss: 6.3415 (6.5562)  loss_classifier: 0.4129 (0.4664)  loss_box_reg: 0.4521 (0.4861)  loss_objectness: 1.2116 (1.1647)  loss_rpn_box_reg: 4.2053 (4.4391)  time: 3.7922 (5.1358)  data: 0.1983 (1.5401)  lr: 0.000000  max mem: 1313
2020-12-12 15:19:11,216 maskrcnn_benchmark.trainer INFO: eta: 0:03:23  iter: 560  loss: 6.5557 (6.5498)  loss_classifier: 0.3703 (0.4651)  loss_box_reg: 0.2305 (0.4838)  loss_objectness: 1.1852 (1.1650)  loss_rpn_box_reg: 4.5720 (4.4360)  time: 3.7903 (5.0879)  data: 0.2023 (1.4924)  lr: 0.000000  max mem: 1313
2020-12-12 15:20:27,206 maskrcnn_benchmark.trainer INFO: eta: 0:01:40  iter: 580  loss: 6.8930 (6.5538)  loss_classifier: 0.5072 (0.4675)  loss_box_reg: 0.5596 (0.4864)  loss_objectness: 1.1863 (1.1661)  loss_rpn_box_reg: 4.4361 (4.4337)  time: 3.7983 (5.0434)  data: 0.2048 (1.4481)  lr: 0.000000  max mem: 1313
2020-12-12 15:21:43,576 maskrcnn_benchmark.trainer INFO: eta: 0:00:00  iter: 600  loss: 6.4184 (6.5513)  loss_classifier: 0.4767 (0.4676)  loss_box_reg: 0.5583 (0.4865)  loss_objectness: 1.1349 (1.1657)  loss_rpn_box_reg: 4.2660 (4.4315)  time: 3.8026 (5.0026)  data: 0.2076 (1.4068)  lr: 0.000000  max mem: 1313
2020-12-12 15:21:43,578 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./final_mode_r3.pth
2020-12-12 15:21:47,164 maskrcnn_benchmark.trainer INFO: final model, saving model to: final_mode_r3
2020-12-12 15:21:47,171 maskrcnn_benchmark.trainer INFO: Total training time: 0:50:05.164166 (5.0086 s / it)
2020-12-12 15:21:47,429 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_test dataset(258 images).
2020-12-12 15:28:12,765 maskrcnn_benchmark.inference INFO: Total run time: 0:06:25.335582 (1.4935487665871316 s / img per device, on 1 devices)
2020-12-12 15:28:12,765 maskrcnn_benchmark.inference INFO: Model inference time: 0:06:00.388517 (1.3968547176021013 s / img per device, on 1 devices)
2020-12-12 15:28:12,795 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 15:28:38,859 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 15:28:38,859 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0795, 0.0123, 0.0037,  ..., 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([7, 7, 4,  ..., 2, 2, 2]), 'best match labels': tensor([7., 2., 2.,  ..., 7., 7., 7.]), 'best match scores': tensor([0.9976, 1.0000, 1.0000,  ..., 0.4175, 0.6953, 1.0000]), 'num_pos': 1516}
2020-12-12 15:28:38,864 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_test dataset(7 images).
2020-12-12 15:28:49,304 maskrcnn_benchmark.inference INFO: Total run time: 0:00:10.439121 (1.4913030351911272 s / img per device, on 1 devices)
2020-12-12 15:28:49,304 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:09.762642 (1.3946631635938371 s / img per device, on 1 devices)
2020-12-12 15:28:49,305 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 15:28:49,992 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 15:28:49,993 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([2.1110e-02, 3.2427e-03, 5.2773e-05, 3.1326e-02, 1.3228e-02, 5.3586e-04,
        4.1396e-03, 0.0000e+00, 2.5243e-02, 0.0000e+00, 1.1434e-02, 7.9696e-03,
        3.5439e-03, 2.9789e-02, 2.8875e-02, 1.9590e-02, 1.8666e-02, 3.2013e-03]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([1., 1., 7., 1., 1., 2., 7., 7., 7., 7., 7., 1., 2., 7., 7., 7., 1., 7.]), 'best match scores': tensor([0.9995, 0.6569, 0.6097, 0.9980, 0.8163, 0.9098, 1.0000, 1.0000, 0.9992,
        0.7491, 1.0000, 1.0000, 0.2189, 0.9947, 0.9980, 0.8765, 0.2469, 0.9871]), 'num_pos': 18}
2020-12-12 15:28:49,999 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_test dataset(3 images).
2020-12-12 15:28:54,485 maskrcnn_benchmark.inference INFO: Total run time: 0:00:04.485437 (1.4951456387837727 s / img per device, on 1 devices)
2020-12-12 15:28:54,485 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:04.184799 (1.3949331442515056 s / img per device, on 1 devices)
2020-12-12 15:28:54,486 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 15:28:54,774 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 15:28:54,774 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0235, 0.0071, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0249,
        0.0023, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0194, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1]), 'best match labels': tensor([ 7.,  7.,  7.,  7.,  7.,  7.,  8.,  8.,  4.,  2.,  4.,  7.,  7.,  1.,
         8.,  8., -1., -1., -1., -1., -1., -1.,  2., -1.,  1.]), 'best match scores': tensor([0.8475, 0.5607, 1.0000, 1.0000, 1.0000, 0.9993, 0.9407, 0.9915, 0.9271,
        0.9677, 0.4469, 1.0000, 0.3072, 0.0729, 0.3449, 0.9999, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.1012, 0.0000, 0.4099]), 'num_pos': 25}
2020-12-12 16:49:14,863 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 16:49:14,863 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='draw_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, threshold=0.99, weights='visdrone_model_0360000.pth')
2020-12-12 16:49:14,863 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 16:49:16,914 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 16:49:16,915 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 16:49:16,915 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000004
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 16:49:16,916 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 4e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 16:49:18,447 maskrcnn_benchmark INFO: reloading weigts from final_mode_r3.pth
2020-12-12 18:54:01,110 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 18:54:01,110 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 18:54:01,110 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 18:54:09,782 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 18:54:09,783 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 18:54:09,783 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000000001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 18:54:09,786 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 50
    BG_IOU_THRESHOLD: 1e-09
    FG_IOU_THRESHOLD: 0.001
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.8
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 1e-09
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 18:54:11,496 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-12 18:54:11,497 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-12 18:54:11,497 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-12 18:54:11,497 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-12 18:54:11,497 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-12 18:54:11,497 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-12 18:54:11,497 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-12 18:54:11,497 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-12 18:54:11,497 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-12 18:54:11,497 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-12 18:54:11,497 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-12 18:54:11,498 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-12 18:54:11,498 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-12 18:54:11,498 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-12 18:54:19,907 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-12 18:54:41,828 maskrcnn_benchmark.trainer INFO: Start training
2020-12-12 18:55:59,930 maskrcnn_benchmark.trainer INFO: eta: 0:37:44  iter: 20  loss: 148.4576 (149.4298)  loss_classifier: 77.4939 (80.2200)  loss_box_reg: 5.4687 (5.1067)  loss_objectness: 13.3440 (13.5016)  loss_rpn_box_reg: 49.7984 (50.6016)  time: 3.8780 (3.9048)  data: 0.2266 (0.2288)  lr: 0.000000  max mem: 1423
2020-12-12 18:57:17,347 maskrcnn_benchmark.trainer INFO: eta: 0:36:17  iter: 40  loss: 143.1724 (146.0623)  loss_classifier: 73.7376 (77.3873)  loss_box_reg: 3.2501 (4.8818)  loss_objectness: 13.4083 (13.7077)  loss_rpn_box_reg: 47.6673 (50.0855)  time: 3.8698 (3.8878)  data: 0.2278 (0.2279)  lr: 0.000000  max mem: 1423
2020-12-12 18:58:34,919 maskrcnn_benchmark.trainer INFO: eta: 0:34:57  iter: 60  loss: 130.6952 (141.3517)  loss_classifier: 64.6785 (72.9200)  loss_box_reg: 5.3547 (5.0738)  loss_objectness: 13.9134 (13.6794)  loss_rpn_box_reg: 49.2263 (49.6786)  time: 3.8730 (3.8847)  data: 0.2300 (0.2290)  lr: 0.000000  max mem: 1423
2020-12-12 18:59:55,507 maskrcnn_benchmark.trainer INFO: eta: 0:33:58  iter: 80  loss: 123.7873 (136.7815)  loss_classifier: 52.8729 (68.1341)  loss_box_reg: 4.2423 (5.1154)  loss_objectness: 13.4665 (13.6712)  loss_rpn_box_reg: 50.8454 (49.8607)  time: 3.9990 (3.9209)  data: 0.2546 (0.2359)  lr: 0.000000  max mem: 1423
2020-12-12 19:01:13,803 maskrcnn_benchmark.trainer INFO: eta: 0:32:39  iter: 100  loss: 110.7252 (131.6571)  loss_classifier: 41.9549 (62.9570)  loss_box_reg: 5.4062 (5.3751)  loss_objectness: 13.4293 (13.7524)  loss_rpn_box_reg: 48.2562 (49.5726)  time: 3.9087 (3.9197)  data: 0.2392 (0.2370)  lr: 0.000000  max mem: 1423
2020-12-12 19:02:32,036 maskrcnn_benchmark.trainer INFO: eta: 0:31:20  iter: 120  loss: 96.4506 (126.1193)  loss_classifier: 29.1544 (57.6722)  loss_box_reg: 5.2936 (5.3306)  loss_objectness: 12.4607 (13.7614)  loss_rpn_box_reg: 47.0866 (49.3551)  time: 3.9116 (3.9183)  data: 0.2397 (0.2374)  lr: 0.000000  max mem: 1423
2020-12-12 19:03:50,190 maskrcnn_benchmark.trainer INFO: eta: 0:30:01  iter: 140  loss: 86.7014 (120.4324)  loss_classifier: 18.6439 (52.2008)  loss_box_reg: 4.2407 (5.3196)  loss_objectness: 13.4514 (13.6885)  loss_rpn_box_reg: 50.0146 (49.2235)  time: 3.9044 (3.9168)  data: 0.2358 (0.2377)  lr: 0.000000  max mem: 1423
2020-12-12 19:05:47,216 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 19:05:47,216 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 19:05:47,216 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 19:05:49,483 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 19:05:49,483 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 19:05:49,483 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000000001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 19:05:49,484 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 50
    BG_IOU_THRESHOLD: 1e-09
    FG_IOU_THRESHOLD: 0.001
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.8
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 1e-09
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 19:05:51,243 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-12 19:05:51,243 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-12 19:05:53,235 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-12 19:05:53,733 maskrcnn_benchmark.trainer INFO: Start training
2020-12-12 19:07:10,523 maskrcnn_benchmark.trainer INFO: eta: 0:37:06  iter: 20  loss: 272.6835 (266.1146)  loss_classifier: 190.6439 (192.9785)  loss_box_reg: 7.1281 (7.9110)  loss_objectness: 8.9327 (9.1772)  loss_rpn_box_reg: 55.5944 (56.0478)  time: 3.8243 (3.8394)  data: 0.2250 (0.2282)  lr: 0.000000  max mem: 1312
2020-12-12 19:08:27,093 maskrcnn_benchmark.trainer INFO: eta: 0:35:47  iter: 40  loss: 261.5276 (262.6588)  loss_classifier: 183.0559 (188.9119)  loss_box_reg: 6.2921 (7.2194)  loss_objectness: 9.7351 (9.3815)  loss_rpn_box_reg: 57.8546 (57.1460)  time: 3.8279 (3.8339)  data: 0.2247 (0.2273)  lr: 0.000000  max mem: 1312
2020-12-12 19:09:43,534 maskrcnn_benchmark.trainer INFO: eta: 0:34:28  iter: 60  loss: 268.4390 (265.5336)  loss_classifier: 189.9666 (189.3560)  loss_box_reg: 7.5152 (7.3690)  loss_objectness: 10.1183 (9.6688)  loss_rpn_box_reg: 61.1209 (59.1398)  time: 3.8193 (3.8300)  data: 0.2249 (0.2277)  lr: 0.000000  max mem: 1312
2020-12-12 19:11:00,033 maskrcnn_benchmark.trainer INFO: eta: 0:33:10  iter: 80  loss: 265.3879 (265.1391)  loss_classifier: 181.0921 (187.8518)  loss_box_reg: 8.3481 (7.6134)  loss_objectness: 9.9024 (9.7507)  loss_rpn_box_reg: 61.7301 (59.9232)  time: 3.8197 (3.8287)  data: 0.2234 (0.2272)  lr: 0.000000  max mem: 1312
2020-12-12 19:12:16,605 maskrcnn_benchmark.trainer INFO: eta: 0:31:54  iter: 100  loss: 259.3627 (263.9024)  loss_classifier: 172.7814 (185.5506)  loss_box_reg: 7.5363 (7.6791)  loss_objectness: 10.6050 (9.8646)  loss_rpn_box_reg: 64.4382 (60.8081)  time: 3.8270 (3.8287)  data: 0.2252 (0.2271)  lr: 0.000000  max mem: 1312
2020-12-12 19:13:33,213 maskrcnn_benchmark.trainer INFO: eta: 0:30:37  iter: 120  loss: 256.4908 (263.1961)  loss_classifier: 174.6042 (183.9697)  loss_box_reg: 8.6364 (8.0815)  loss_objectness: 10.3098 (9.9728)  loss_rpn_box_reg: 64.6293 (61.1720)  time: 3.8286 (3.8290)  data: 0.2243 (0.2267)  lr: 0.000000  max mem: 1312
2020-12-12 19:14:49,896 maskrcnn_benchmark.trainer INFO: eta: 0:29:21  iter: 140  loss: 252.2777 (261.4508)  loss_classifier: 171.8835 (182.0024)  loss_box_reg: 6.6009 (8.0787)  loss_objectness: 9.7256 (9.9522)  loss_rpn_box_reg: 63.5591 (61.4175)  time: 3.8336 (3.8297)  data: 0.2291 (0.2269)  lr: 0.000000  max mem: 1312
2020-12-12 19:16:06,366 maskrcnn_benchmark.trainer INFO: eta: 0:28:04  iter: 160  loss: 248.4348 (259.4091)  loss_classifier: 165.4907 (179.6544)  loss_box_reg: 7.8429 (8.2502)  loss_objectness: 10.2106 (10.0325)  loss_rpn_box_reg: 62.4251 (61.4720)  time: 3.8241 (3.8289)  data: 0.2246 (0.2268)  lr: 0.000000  max mem: 1312
2020-12-12 19:16:06,368 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 19:16:07,267 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(148 images).
2020-12-12 19:19:45,810 maskrcnn_benchmark.inference INFO: Total run time: 0:03:38.542387 (1.4766377500585608 s / img per device, on 1 devices)
2020-12-12 19:19:45,810 maskrcnn_benchmark.inference INFO: Model inference time: 0:03:22.113740 (1.3656333765468083 s / img per device, on 1 devices)
2020-12-12 19:19:45,810 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 19:20:01,582 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 19:20:01,582 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([3.1959e-01, 7.7583e-02, 5.0160e-02, 7.4967e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8044e-02, 1.7345e-02, 1.1372e-02, 5.1632e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0249e-02, 4.9624e-02, 3.4589e-02,
        3.4493e-02, 1.7618e-02, 1.1222e-02, 5.0819e-03, 0.0000e+00, 0.0000e+00,
        3.2977e-02, 2.1706e-02, 2.4048e-04, 1.6499e-02, 3.3173e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.8510e-02, 2.0234e-02, 8.5493e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0976e-02, 2.0226e-02,
        1.7714e-02, 1.6943e-02, 1.5261e-03, 7.8394e-04, 7.5140e-06, 3.7712e-06,
        0.0000e+00, 2.1363e-01, 7.8495e-02, 9.8219e-03, 4.5247e-02, 2.3495e-03,
        0.0000e+00, 2.0852e-02, 1.7033e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02, 2.3336e-02,
        0.0000e+00, 2.0852e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8496e-01, 3.3160e-02,
        1.1761e-03, 6.4814e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02, 2.6273e-02,
        2.1682e-02, 3.2977e-02, 2.3336e-02, 0.0000e+00, 2.8666e-01, 5.3574e-02,
        2.0852e-02, 1.9947e-02, 7.3961e-05, 2.3571e-07, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7932e-02, 0.0000e+00, 0.0000e+00,
        9.0988e-02, 5.5387e-02, 3.2977e-02, 3.1593e-03, 2.9653e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2034e-04, 0.0000e+00, 0.0000e+00, 2.3082e-02, 1.6270e-02, 1.2530e-02,
        1.8825e-06, 4.2369e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9844e-01, 5.9330e-02, 1.3906e-02, 3.4811e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0163e-02,
        3.3711e-02, 1.6852e-02, 1.7740e-01, 7.7558e-02, 6.8051e-02, 1.4922e-01,
        4.7139e-02, 2.0076e-02, 1.4351e-01, 8.6623e-02, 7.3901e-02, 2.3319e-03,
        2.2353e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.7408e-02, 8.0749e-02, 1.2490e-02, 5.2028e-02, 4.0163e-02, 2.7896e-02,
        2.7830e-02, 6.7477e-03, 5.9717e-03, 5.4779e-03, 0.0000e+00, 0.0000e+00,
        3.2977e-02, 3.2384e-02, 0.0000e+00, 3.2139e-02, 1.5874e-02, 6.8681e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.1988e-02, 2.0234e-02, 1.0486e-02, 9.1439e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3953e-01,
        9.3417e-02, 1.4107e-02, 1.8971e-02, 5.5006e-03, 2.2886e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.6236e-02,
        2.1682e-02, 1.6543e-02, 3.2977e-02, 2.0784e-03, 3.6794e-05, 1.5920e-01,
        2.8804e-02, 2.1682e-02, 1.5858e-01, 2.1242e-02, 3.4811e-03, 3.3464e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.3068e-02, 6.6691e-02, 5.8764e-02, 2.5436e-02, 2.3440e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1593e-03, 3.1564e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 5.7515e-02, 4.8749e-02, 4.6808e-02, 2.3224e-02, 1.1290e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1395e-01, 1.7560e-02,
        2.6602e-01, 3.6743e-02, 2.8702e-02, 1.2913e-02, 1.0193e-02, 9.8640e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.7139e-02, 3.2977e-02, 0.0000e+00, 1.0456e-01, 3.3495e-02, 2.5949e-02,
        3.3032e-02, 1.2723e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8479e-01, 9.0715e-02, 1.9876e-02, 5.4909e-02, 1.5874e-02, 2.9173e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.9037e-01, 8.6906e-02, 1.9284e-02, 5.9217e-02,
        4.7124e-02, 2.8818e-02, 2.3834e-02, 1.6164e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.5608e-02, 3.2977e-02, 0.0000e+00, 4.7173e-02,
        1.5751e-02, 1.3965e-02, 1.2918e-02, 1.0212e-02, 2.9070e-05, 1.7183e-05,
        0.0000e+00, 0.0000e+00, 6.1295e-02, 5.4290e-02, 3.5151e-02, 1.3418e-02,
        1.3013e-02, 3.3797e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2139e-02,
        1.5874e-02, 3.4811e-03, 3.8250e-04, 1.8612e-06, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4477e-02, 1.3758e-02,
        1.1468e-02, 7.5763e-03, 4.1849e-03, 3.0866e-03, 2.6476e-03, 2.3573e-03,
        7.0065e-07, 1.0815e-01, 3.2977e-02, 0.0000e+00, 4.7139e-02, 2.4048e-04,
        0.0000e+00, 3.5406e-01, 7.9923e-02, 2.0443e-02, 1.6561e-02, 7.1820e-03,
        3.4811e-03, 2.5677e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2977e-02, 2.4333e-02, 2.1682e-02, 1.9151e-02, 1.1571e-03, 2.7650e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.8151e-02, 3.2139e-02, 6.1942e-03, 2.9497e-03, 5.3373e-04, 9.7308e-05,
        5.8509e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1383e-01,
        4.8355e-02, 1.7546e-02, 3.2139e-02, 1.5874e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.0308e-01, 8.4251e-02, 6.8543e-02, 1.3268e-01, 1.5874e-02,
        3.2049e-03, 1.9993e-03, 1.5195e-03, 2.6912e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1444e-01, 1.0166e-01, 2.4185e-02,
        1.2470e-01, 4.0686e-02, 2.1682e-02, 3.2977e-02, 2.3336e-02, 0.0000e+00,
        5.0409e-02, 4.6338e-02, 4.3719e-02, 4.0677e-02, 3.7949e-02, 2.0121e-02,
        8.0191e-03, 5.5006e-03, 2.5923e-03, 0.0000e+00, 3.2977e-02, 2.0231e-05,
        2.3620e-01, 9.1706e-02, 2.3336e-02, 2.2353e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.4983e-02, 3.2139e-02, 2.4151e-02, 7.0637e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1673e-01,
        5.3283e-02, 1.7804e-02, 2.2169e-03, 2.0240e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8532e-02, 3.5707e-02,
        1.9947e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9671e-01, 1.1715e-01,
        0.0000e+00, 3.2160e-01, 7.0204e-02, 3.9628e-03, 3.5861e-03, 2.0240e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1191e-01, 3.0810e-02, 1.6534e-02, 0.0000e+00, 2.7289e-01, 8.8530e-02,
        1.9176e-02, 2.0240e-03, 1.6078e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2422e-01, 9.9437e-02, 2.8864e-02,
        5.1796e-02, 2.1830e-02, 1.9673e-02, 1.0193e-02, 9.8640e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2521e-01, 3.7357e-02, 3.1214e-03, 2.4222e-03, 2.3256e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5799e-01,
        9.9409e-02, 5.9584e-02, 3.7383e-02, 3.2977e-02, 5.3370e-02, 4.4226e-02,
        4.0624e-02, 2.5918e-02, 1.8069e-02, 7.2217e-03, 5.8647e-03, 5.3854e-03,
        1.0502e-05, 4.5919e-02, 3.8923e-02, 0.0000e+00, 3.2139e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02, 1.6696e-04, 0.0000e+00,
        3.2977e-02, 2.1682e-02, 0.0000e+00, 3.2977e-02, 2.1682e-02, 1.6543e-02,
        2.2477e-02, 1.6707e-02, 7.0051e-03, 6.1886e-03, 1.6671e-06, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2771e-03, 3.1593e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4119e-01, 3.5854e-02, 2.3336e-02, 0.0000e+00, 4.5293e-02, 6.4814e-03,
        7.2695e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.7714e-02, 1.6943e-02, 7.5168e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4067e-01, 3.2139e-02,
        3.5538e-04, 4.8067e-02, 2.5130e-02, 2.0852e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1593e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.2139e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.1066e-01, 5.4418e-02, 1.1761e-03, 5.7411e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3522e-01, 2.8804e-02, 2.1682e-02, 6.6620e-02, 3.8605e-02, 3.1633e-02,
        2.9699e-01, 6.2744e-02, 1.1760e-03, 1.0522e-01, 0.0000e+00, 0.0000e+00,
        5.5006e-03, 4.5404e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9480e-02, 3.1593e-03, 4.4986e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.5276e-01, 1.3818e-01, 2.6302e-03, 2.2169e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3351e-02,
        3.8215e-02, 2.1773e-02, 1.6576e-02, 1.5687e-02, 1.7539e-06, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2440e-01, 2.8804e-02, 2.1682e-02, 4.3183e-01,
        3.5020e-02, 8.0454e-02, 1.5874e-02, 3.1341e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 2.9033e-02, 3.0435e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02,
        2.5365e-02, 6.9149e-06, 4.5617e-02, 3.2977e-02, 0.0000e+00, 1.4708e-01,
        3.1297e-02, 0.0000e+00, 6.5694e-02, 2.3082e-02, 2.3003e-02, 1.9378e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9672e-01,
        9.6205e-02, 4.5131e-03, 1.8054e-02, 1.9798e-01, 2.5131e-02, 2.5081e-02,
        3.2977e-02, 0.0000e+00, 0.0000e+00, 3.2139e-02, 2.3072e-02, 1.4249e-02,
        6.6798e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 2.1682e-02, 0.0000e+00, 3.0793e-01,
        4.8410e-02, 4.7139e-02, 2.3023e-01, 1.3063e-01, 9.2077e-02, 2.0852e-02,
        1.7123e-02, 3.8966e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.3362e-01, 7.9890e-02, 8.5653e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8881e-01, 1.6658e-02, 3.2977e-02,
        2.1682e-02, 0.0000e+00, 2.1183e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4850e-02,
        5.4046e-04, 0.0000e+00]), 'gt_labels': tensor([7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 1, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7,
        4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 4, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 7, 7, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 7, 7, 4]), 'best match labels': tensor([4., 4., 4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 7., 7., 8., 4., 8., 8., 4., 4., 4., 8., 8., 4., 8., 4., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 4., 8., 8., 8., 8., 8., 8., 8., 4., 5., 4.,
        8., 5., 4., 8., 7., 8., 8., 4., 4., 8., 8., 8., 8., 8., 8., 8., 8., 4.,
        8., 8., 8., 8., 8., 7., 4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 7.,
        8., 7., 7., 7., 7., 7., 8., 8., 8., 8., 7., 8., 4., 8., 8., 7., 7., 4.,
        8., 8., 8., 7., 5., 8., 8., 8., 8., 8., 8., 8., 4., 7., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 7., 4., 8., 8., 8., 4., 8., 8., 8., 8., 8., 8., 4.,
        8., 7., 8., 8., 4., 8., 8., 8., 8., 8., 8., 4., 4., 8., 4., 4., 4., 4.,
        4., 8., 4., 4., 4., 4., 7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        4., 4., 4., 8., 7., 4., 8., 4., 4., 4., 4., 8., 8., 8., 4., 7., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 4., 4., 8., 8., 8., 8., 8., 8., 8., 4., 4.,
        4., 8., 4., 8., 8., 8., 8., 4., 8., 8., 8., 8., 8., 7., 4., 8., 4., 4.,
        4., 8., 4., 7., 8., 8., 7., 8., 8., 8., 8., 8., 8., 4., 4., 8., 4., 8.,
        8., 8., 8., 4., 7., 8., 8., 8., 8., 8., 7., 8., 8., 4., 4., 8., 8., 8.,
        4., 8., 8., 4., 7., 7., 4., 7., 4., 8., 7., 8., 8., 4., 8., 8., 8., 8.,
        8., 7., 8., 4., 7., 7., 8., 4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 4., 4., 8., 8., 7., 8., 4., 8., 8., 8., 8., 8.,
        8., 8., 4., 4., 4., 4., 4., 8., 4., 8., 8., 8., 8., 4., 8., 8., 8., 4.,
        4., 8., 4., 8., 8., 4., 8., 4., 4., 4., 8., 4., 8., 8., 8., 4., 4., 7.,
        8., 8., 8., 8., 4., 8., 8., 8., 8., 4., 4., 4., 4., 5., 4., 4., 7., 4.,
        8., 8., 8., 4., 4., 8., 8., 4., 7., 4., 8., 8., 8., 8., 8., 8., 8., 7.,
        7., 8., 4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 4., 8., 8., 8., 8., 4.,
        4., 4., 8., 8., 4., 4., 7., 4., 7., 8., 7., 7., 7., 7., 7., 7., 8., 8.,
        8., 4., 4., 8., 8., 4., 8., 8., 8., 4., 4., 8., 8., 8., 4., 4., 8., 4.,
        7., 7., 4., 8., 8., 7., 4., 4., 4., 4., 4., 4., 4., 4., 8., 8., 5., 8.,
        4., 4., 8., 7., 8., 8., 8., 8., 8., 8., 8., 8., 4., 7., 8., 8., 8., 8.,
        8., 8., 8., 4., 4., 4., 4., 8., 8., 8., 8., 8., 8., 8., 7., 4., 8., 8.,
        4., 7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 4., 7.,
        8., 7., 7., 4., 8., 8., 8., 8., 8., 8., 7., 7., 4., 7., 8., 8., 4., 4.,
        8., 8., 8., 8., 8., 8., 7., 8., 4., 4., 4., 4., 4., 4., 8., 8., 7., 8.,
        8., 8., 8., 8., 8., 8., 7., 8., 7., 4., 8., 8., 8., 8., 8., 8., 8., 4.,
        4., 4., 4., 8., 7., 4., 4., 8., 4., 4., 7., 8., 4., 8., 4., 4., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 7., 4., 7., 8., 8., 7., 8., 4.,
        8., 7., 8., 8., 8., 4., 8., 8., 7., 8., 8., 8., 8., 7., 8., 8., 8., 8.,
        4., 4., 8., 8., 7., 8., 7., 7., 7., 7., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 7., 8., 8., 8., 8., 4., 8., 8., 8., 8., 4., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 7., 8., 7., 7., 8., 8., 8., 8., 8., 8., 8.,
        7., 7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 7., 8., 8., 4., 4., 7.,
        7., 7., 7., 8., 8., 4., 8., 8., 8., 8., 8., 4., 8., 8., 8., 8., 8., 8.,
        4., 8., 8., 4., 8., 8., 4., 7., 8., 8., 8., 7., 8., 8., 8., 8., 8., 4.,
        7., 4., 8., 8., 8., 7., 8., 8., 8., 8., 5., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 7., 4., 8., 7., 7., 8., 4., 8., 8., 8., 8., 8., 8., 8., 7., 8.,
        4., 8., 8., 7., 8., 8., 8., 8., 8., 8., 8., 4., 7., 5., 8., 8., 4., 4.,
        4., 8., 4., 4., 8., 8., 8., 8., 8., 8., 4., 4., 4., 8., 8., 4., 7., 8.,
        8., 8., 8., 4., 8., 4., 4., 8., 8., 8., 8., 8., 8., 8., 7., 8., 8., 4.,
        4., 8., 4., 4., 4., 8., 7., 8., 8., 8., 8., 8., 8., 8., 4., 4., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 7., 7., 7., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 7., 7., 8.]), 'best match scores': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]), 'num_pos': 872}
2020-12-12 19:20:01,700 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.086009
2020-12-12 19:20:01,703 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r4.pth
2020-12-12 19:20:02,211 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r4
2020-12-12 19:21:19,971 maskrcnn_benchmark.trainer INFO: eta: 0:36:01  iter: 180  loss: 234.0018 (256.8819)  loss_classifier: 158.1075 (177.4859)  loss_box_reg: 7.9345 (8.1661)  loss_objectness: 9.0253 (9.9288)  loss_rpn_box_reg: 60.7111 (61.3012)  time: 3.8231 (5.1458)  data: 0.2265 (1.5418)  lr: 0.000000  max mem: 1312
2020-12-12 19:22:36,560 maskrcnn_benchmark.trainer INFO: eta: 0:33:25  iter: 200  loss: 229.2015 (254.0310)  loss_classifier: 156.9141 (175.0088)  loss_box_reg: 7.1304 (8.0859)  loss_objectness: 10.0363 (9.8861)  loss_rpn_box_reg: 60.7925 (61.0503)  time: 3.8236 (5.0141)  data: 0.2232 (1.4104)  lr: 0.000000  max mem: 1312
2020-12-12 19:23:52,807 maskrcnn_benchmark.trainer INFO: eta: 0:31:03  iter: 220  loss: 231.4283 (251.9707)  loss_classifier: 149.1257 (172.6722)  loss_box_reg: 8.5950 (8.1979)  loss_objectness: 9.1757 (9.8688)  loss_rpn_box_reg: 62.2803 (61.2318)  time: 3.8123 (4.9049)  data: 0.2193 (1.3022)  lr: 0.000000  max mem: 1312
2020-12-12 19:25:09,280 maskrcnn_benchmark.trainer INFO: eta: 0:28:53  iter: 240  loss: 215.1730 (248.9550)  loss_classifier: 136.2276 (169.8709)  loss_box_reg: 6.6056 (8.1077)  loss_objectness: 9.7344 (9.8418)  loss_rpn_box_reg: 58.8636 (61.1346)  time: 3.8219 (4.8148)  data: 0.2245 (1.2123)  lr: 0.000000  max mem: 1312
2020-12-12 19:26:25,591 maskrcnn_benchmark.trainer INFO: eta: 0:26:50  iter: 260  loss: 214.4503 (246.3448)  loss_classifier: 138.9525 (167.4279)  loss_box_reg: 7.9272 (8.1341)  loss_objectness: 10.1040 (9.8364)  loss_rpn_box_reg: 59.0954 (60.9464)  time: 3.8166 (4.7379)  data: 0.2213 (1.1362)  lr: 0.000000  max mem: 1312
2020-12-12 19:27:41,796 maskrcnn_benchmark.trainer INFO: eta: 0:24:54  iter: 280  loss: 199.7082 (243.4318)  loss_classifier: 122.8845 (164.3991)  loss_box_reg: 8.3460 (8.1811)  loss_objectness: 9.3426 (9.7995)  loss_rpn_box_reg: 62.4299 (61.0522)  time: 3.8110 (4.6716)  data: 0.2211 (1.0708)  lr: 0.000000  max mem: 1312
2020-12-12 19:28:58,014 maskrcnn_benchmark.trainer INFO: eta: 0:23:04  iter: 300  loss: 204.6765 (240.6087)  loss_classifier: 124.7429 (161.5446)  loss_box_reg: 8.1551 (8.1627)  loss_objectness: 10.1346 (9.8104)  loss_rpn_box_reg: 62.5395 (61.0911)  time: 3.8052 (4.6143)  data: 0.2191 (1.0142)  lr: 0.000000  max mem: 1312
2020-12-12 19:30:14,611 maskrcnn_benchmark.trainer INFO: eta: 0:21:18  iter: 320  loss: 188.6898 (237.4623)  loss_classifier: 111.9219 (158.4914)  loss_box_reg: 6.1662 (8.0944)  loss_objectness: 9.4762 (9.8183)  loss_rpn_box_reg: 62.1434 (61.0583)  time: 3.8260 (4.5652)  data: 0.2241 (0.9650)  lr: 0.000000  max mem: 1312
2020-12-12 19:30:14,612 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 19:30:14,682 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(148 images).
2020-12-12 19:33:51,839 maskrcnn_benchmark.inference INFO: Total run time: 0:03:37.156806 (1.4672757145520803 s / img per device, on 1 devices)
2020-12-12 19:33:51,839 maskrcnn_benchmark.inference INFO: Model inference time: 0:03:22.135068 (1.365777486079448 s / img per device, on 1 devices)
2020-12-12 19:33:51,840 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 19:34:07,443 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 19:34:07,443 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([3.1959e-01, 7.7583e-02, 5.0160e-02, 7.4967e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8044e-02, 1.7345e-02, 1.1372e-02, 5.1632e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7428e-02, 6.0249e-02, 4.7119e-02,
        3.4493e-02, 3.4309e-02, 1.6470e-02, 1.1222e-02, 0.0000e+00, 0.0000e+00,
        2.1168e-01, 5.6723e-02, 2.1706e-02, 1.6499e-02, 3.3173e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.8510e-02, 3.0326e-02, 1.9327e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0976e-02, 2.0226e-02,
        1.7714e-02, 1.6943e-02, 1.5261e-03, 7.8394e-04, 7.5140e-06, 3.7712e-06,
        0.0000e+00, 2.1363e-01, 7.8495e-02, 9.8219e-03, 4.5247e-02, 2.3495e-03,
        0.0000e+00, 2.0852e-02, 1.7033e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02, 2.3336e-02,
        0.0000e+00, 2.8266e-02, 1.7123e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8496e-01, 3.3160e-02,
        1.1761e-03, 6.4814e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02, 2.6273e-02,
        2.1682e-02, 3.2977e-02, 2.3336e-02, 2.1682e-02, 2.8666e-01, 5.3574e-02,
        2.0852e-02, 1.9947e-02, 7.3961e-05, 2.3571e-07, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7932e-02, 0.0000e+00, 0.0000e+00,
        9.0988e-02, 5.0102e-02, 3.2977e-02, 3.1593e-03, 2.9653e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2034e-04, 0.0000e+00, 0.0000e+00, 2.3082e-02, 1.6270e-02, 1.2530e-02,
        1.8825e-06, 4.2369e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9844e-01, 5.9330e-02, 1.3906e-02, 8.3684e-03, 3.4811e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0207e-01,
        7.7105e-02, 3.6923e-02, 1.7740e-01, 7.7558e-02, 6.8051e-02, 4.7139e-02,
        0.0000e+00, 0.0000e+00, 1.4351e-01, 8.6623e-02, 7.2115e-02, 2.3319e-03,
        2.2353e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.6599e-02, 6.6817e-02, 2.7064e-02, 5.2028e-02, 4.0163e-02, 2.7896e-02,
        2.7830e-02, 6.7477e-03, 5.9717e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2977e-02, 3.2384e-02, 0.0000e+00, 3.2139e-02, 1.8608e-02, 1.5874e-02,
        6.8681e-03, 3.9092e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.0644e-02, 6.0692e-02, 1.9327e-02, 9.1439e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.3417e-02,
        3.2977e-02, 0.0000e+00, 1.8971e-02, 5.5006e-03, 2.2886e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.6236e-02,
        2.1682e-02, 1.6543e-02, 3.2977e-02, 2.0784e-03, 3.6794e-05, 1.5920e-01,
        2.8804e-02, 2.1682e-02, 1.5858e-01, 1.5874e-02, 3.4811e-03, 3.3464e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.3068e-02, 6.6691e-02, 5.8764e-02, 2.5436e-02, 2.3440e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1593e-03, 3.1564e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 5.7515e-02, 4.8749e-02, 4.6808e-02, 2.3224e-02, 1.1290e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8497e-02, 2.4319e-02,
        2.6602e-01, 3.6743e-02, 2.8702e-02, 1.2913e-02, 1.0193e-02, 9.8640e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.7139e-02, 3.2977e-02, 0.0000e+00, 1.0456e-01, 3.3495e-02, 2.5949e-02,
        3.3032e-02, 1.2723e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8479e-01, 9.0715e-02, 1.9876e-02, 6.0605e-02, 1.9517e-02, 2.9173e-03,
        2.6632e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.9037e-01, 5.0642e-02, 1.9284e-02, 5.9217e-02,
        5.1930e-02, 2.8818e-02, 2.3834e-02, 1.6164e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.2314e-01, 6.5608e-02, 2.3336e-02, 4.7173e-02,
        1.5751e-02, 1.3617e-02, 1.0328e-02, 7.2920e-03, 2.9070e-05, 1.7183e-05,
        0.0000e+00, 0.0000e+00, 6.7169e-02, 6.1295e-02, 5.4290e-02, 3.5151e-02,
        2.5414e-02, 1.3418e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2139e-02,
        1.5874e-02, 3.4811e-03, 3.8250e-04, 1.8612e-06, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4477e-02, 1.3758e-02,
        1.1468e-02, 7.5763e-03, 5.7585e-03, 4.1300e-03, 3.0816e-03, 2.5487e-03,
        7.0065e-07, 1.0815e-01, 3.2977e-02, 0.0000e+00, 4.0967e-01, 4.7139e-02,
        4.6114e-02, 3.5406e-01, 7.9923e-02, 2.0443e-02, 1.6561e-02, 7.1820e-03,
        3.4811e-03, 2.5677e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2977e-02, 2.4333e-02, 2.1682e-02, 1.9151e-02, 1.1571e-03, 2.7650e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8863e-01, 7.8151e-02, 6.1942e-03, 3.4811e-03, 2.9497e-03, 9.7308e-05,
        5.8509e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1383e-01,
        5.8132e-02, 2.9348e-02, 3.2139e-02, 1.5874e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.0308e-01, 9.2443e-02, 6.8543e-02, 1.3268e-01, 1.5874e-02,
        3.4811e-03, 3.2049e-03, 1.9993e-03, 1.5195e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1444e-01, 1.0166e-01, 2.4185e-02,
        1.2470e-01, 4.0686e-02, 2.1682e-02, 3.2977e-02, 2.3336e-02, 0.0000e+00,
        5.0409e-02, 4.6338e-02, 4.3719e-02, 4.0677e-02, 3.7949e-02, 2.5913e-02,
        1.3050e-02, 8.7007e-03, 8.0191e-03, 0.0000e+00, 3.2977e-02, 2.3400e-02,
        2.3620e-01, 9.1706e-02, 2.3336e-02, 2.2353e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.4983e-02, 3.2139e-02, 2.4151e-02, 7.0637e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1673e-01,
        5.3283e-02, 2.3107e-02, 1.0447e-02, 2.2169e-03, 2.0240e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8532e-02, 3.5707e-02,
        1.9947e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9671e-01, 1.1715e-01,
        0.0000e+00, 3.2160e-01, 5.8031e-02, 1.8548e-02, 3.9628e-03, 3.5861e-03,
        2.0240e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1191e-01, 3.0810e-02, 1.6534e-02, 0.0000e+00, 4.1009e-01, 8.8530e-02,
        1.9176e-02, 1.8322e-02, 2.0240e-03, 1.6078e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2422e-01, 8.3952e-02, 2.8864e-02,
        7.7285e-02, 5.1796e-02, 1.9673e-02, 1.0193e-02, 9.8640e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6937e-01, 6.1555e-02, 3.1214e-03, 2.4222e-03, 2.3256e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5799e-01,
        9.9409e-02, 5.9584e-02, 3.7383e-02, 3.2977e-02, 5.3370e-02, 5.2942e-02,
        4.4226e-02, 4.0624e-02, 3.4865e-02, 2.5918e-02, 1.1760e-02, 8.8140e-03,
        7.2217e-03, 4.5919e-02, 3.8923e-02, 0.0000e+00, 3.2139e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02, 1.6696e-04, 0.0000e+00,
        3.2977e-02, 2.1682e-02, 0.0000e+00, 3.2977e-02, 2.1682e-02, 1.6543e-02,
        2.2477e-02, 1.2625e-02, 7.7136e-03, 7.0051e-03, 6.1886e-03, 1.6671e-06,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2771e-03, 3.1593e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4119e-01, 3.5854e-02, 2.3336e-02, 0.0000e+00, 4.5293e-02, 6.4814e-03,
        7.2695e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.7714e-02, 1.6943e-02, 7.5168e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4067e-01, 3.3711e-02,
        3.2139e-02, 4.8067e-02, 2.5130e-02, 2.0852e-02, 1.7123e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1593e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.2139e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.6643e-01, 5.4418e-02, 1.1761e-03, 5.7411e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3448e-01, 7.8599e-02, 2.8804e-02, 6.6620e-02, 3.8605e-02, 3.1633e-02,
        2.9699e-01, 6.2744e-02, 1.1760e-03, 2.3493e-01, 1.0522e-01, 0.0000e+00,
        5.5006e-03, 4.5404e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9480e-02, 3.1593e-03, 4.4986e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.5276e-01, 1.3818e-01, 2.6302e-03, 2.2169e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3351e-02,
        3.8215e-02, 1.5134e-02, 1.6576e-02, 1.5687e-02, 1.7539e-06, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2440e-01, 2.8804e-02, 2.1682e-02, 4.3183e-01,
        4.0699e-02, 8.0454e-02, 1.5874e-02, 3.1341e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 2.9033e-02, 3.0435e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02,
        2.5365e-02, 6.9149e-06, 4.5617e-02, 3.2977e-02, 2.1682e-02, 1.4708e-01,
        3.1297e-02, 0.0000e+00, 2.3082e-02, 2.3003e-02, 1.9720e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9672e-01,
        1.0377e-01, 4.5131e-03, 1.8054e-02, 1.9798e-01, 2.5131e-02, 2.5081e-02,
        3.2977e-02, 7.0526e-03, 0.0000e+00, 3.2139e-02, 2.3072e-02, 1.4249e-02,
        6.6798e-03, 9.7308e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 2.1682e-02, 0.0000e+00, 4.7139e-02,
        0.0000e+00, 0.0000e+00, 2.3023e-01, 1.3063e-01, 9.2077e-02, 2.0852e-02,
        1.7123e-02, 3.8966e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.1765e-01, 8.9142e-02, 8.5653e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8881e-01, 4.8298e-02, 3.2977e-02,
        2.1682e-02, 0.0000e+00, 2.1183e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7547e-01,
        4.7351e-02, 0.0000e+00]), 'gt_labels': tensor([7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 1, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7,
        4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 4, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 7, 7, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 7, 7, 4]), 'best match labels': tensor([4., 4., 4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 7., 7., 8., 4., 4., 8., 4., 4., 4., 8., 8., 4., 7., 4., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 4., 8., 8., 8., 8., 8., 8., 4., 5., 4.,
        8., 5., 4., 8., 7., 8., 8., 4., 4., 8., 8., 8., 8., 8., 8., 8., 8., 4.,
        8., 8., 8., 8., 8., 7., 4., 8., 8., 8., 8., 8., 8., 8., 8., 4., 8., 7.,
        8., 7., 7., 7., 7., 7., 8., 8., 8., 8., 7., 8., 4., 4., 8., 7., 7., 4.,
        8., 8., 8., 7., 5., 8., 8., 8., 8., 8., 8., 8., 4., 7., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 7., 4., 8., 8., 8., 4., 8., 8., 8., 8., 8., 8., 4.,
        8., 7., 8., 8., 4., 8., 8., 8., 8., 7., 8., 4., 4., 4., 4., 4., 4., 8.,
        8., 8., 4., 4., 4., 4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        4., 4., 4., 8., 7., 8., 8., 4., 4., 4., 4., 8., 8., 8., 4., 7., 8., 4.,
        8., 8., 8., 8., 5., 8., 8., 4., 8., 4., 8., 8., 8., 8., 8., 8., 4., 4.,
        8., 8., 4., 8., 8., 8., 8., 4., 8., 8., 8., 8., 8., 7., 4., 8., 4., 4.,
        4., 8., 8., 7., 8., 8., 4., 7., 8., 8., 8., 8., 8., 4., 4., 8., 4., 8.,
        8., 8., 8., 4., 8., 8., 8., 8., 8., 8., 7., 8., 8., 4., 4., 8., 8., 8.,
        4., 8., 8., 4., 7., 7., 4., 7., 4., 8., 7., 8., 8., 4., 8., 8., 8., 8.,
        8., 7., 8., 4., 7., 7., 8., 4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 4., 4., 8., 7., 7., 8., 8., 8., 8., 8., 8., 8.,
        4., 8., 4., 4., 4., 4., 4., 8., 4., 8., 8., 8., 8., 4., 8., 7., 8., 4.,
        4., 8., 4., 8., 8., 4., 8., 4., 4., 4., 8., 7., 4., 8., 8., 8., 4., 7.,
        8., 8., 8., 8., 4., 8., 8., 8., 8., 4., 4., 4., 4., 5., 4., 4., 7., 4.,
        8., 8., 8., 4., 4., 4., 8., 4., 7., 4., 8., 8., 8., 8., 8., 8., 8., 7.,
        7., 8., 4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 4., 4., 8., 8., 8., 8.,
        4., 4., 8., 8., 4., 4., 7., 4., 7., 8., 7., 7., 7., 7., 7., 8., 8., 8.,
        8., 4., 4., 8., 8., 4., 8., 8., 8., 7., 4., 8., 8., 8., 4., 4., 8., 4.,
        7., 7., 4., 8., 8., 7., 4., 4., 4., 4., 4., 4., 7., 4., 7., 8., 4., 8.,
        4., 4., 8., 7., 8., 8., 8., 8., 8., 8., 8., 8., 4., 7., 8., 8., 8., 8.,
        8., 8., 8., 4., 4., 4., 4., 8., 7., 8., 8., 8., 8., 8., 7., 4., 8., 8.,
        4., 7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 4., 7.,
        8., 4., 7., 4., 8., 7., 8., 8., 8., 8., 7., 7., 4., 7., 8., 8., 4., 4.,
        7., 8., 8., 8., 8., 8., 7., 8., 4., 4., 4., 4., 4., 4., 8., 8., 7., 8.,
        8., 8., 8., 8., 8., 8., 8., 7., 7., 4., 8., 8., 8., 8., 8., 8., 8., 4.,
        4., 4., 4., 8., 7., 4., 4., 7., 4., 4., 7., 4., 7., 8., 4., 4., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 7., 4., 7., 8., 8., 7., 8., 4.,
        8., 7., 8., 8., 8., 4., 8., 4., 7., 8., 8., 8., 8., 7., 8., 8., 8., 8.,
        4., 4., 8., 8., 7., 8., 7., 7., 7., 7., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 7., 8., 8., 4., 8., 4., 8., 7., 8., 8., 4., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 7., 8., 7., 7., 8., 8., 8., 8., 8., 8., 8.,
        7., 7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 7., 8., 4., 4., 7.,
        7., 7., 8., 8., 4., 4., 8., 8., 8., 8., 8., 4., 8., 8., 8., 8., 8., 8.,
        4., 8., 8., 4., 8., 8., 4., 7., 8., 8., 8., 7., 8., 8., 8., 8., 8., 4.,
        7., 8., 8., 8., 8., 7., 8., 8., 8., 8., 5., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 7., 4., 8., 7., 7., 8., 4., 8., 8., 8., 8., 8., 8., 8., 7., 8.,
        4., 8., 8., 7., 8., 8., 8., 8., 8., 8., 8., 4., 7., 5., 7., 8., 4., 4.,
        4., 8., 8., 4., 8., 8., 8., 8., 8., 8., 4., 4., 4., 8., 8., 4., 7., 8.,
        4., 8., 8., 4., 8., 4., 4., 8., 8., 8., 8., 8., 8., 4., 7., 8., 8., 8.,
        8., 8., 4., 4., 4., 8., 7., 8., 8., 8., 8., 8., 8., 8., 4., 4., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 7., 7., 7., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 7., 7., 8.]), 'best match scores': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]), 'num_pos': 872}
2020-12-12 19:34:07,552 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.089450
2020-12-12 19:34:07,555 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r4.pth
2020-12-12 19:34:11,325 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r4
2020-12-12 19:35:27,660 maskrcnn_benchmark.trainer INFO: eta: 0:22:36  iter: 340  loss: 184.6457 (234.5651)  loss_classifier: 111.8598 (155.7888)  loss_box_reg: 6.0075 (8.0092)  loss_objectness: 9.4113 (9.7942)  loss_rpn_box_reg: 58.9922 (60.9728)  time: 3.8096 (5.2174)  data: 0.2226 (1.6180)  lr: 0.000000  max mem: 1312
2020-12-12 19:36:44,078 maskrcnn_benchmark.trainer INFO: eta: 0:20:33  iter: 360  loss: 180.3048 (231.7442)  loss_classifier: 101.9508 (152.9145)  loss_box_reg: 7.7379 (8.0437)  loss_objectness: 8.9526 (9.7730)  loss_rpn_box_reg: 63.8101 (61.0130)  time: 3.8189 (5.1398)  data: 0.2205 (1.5405)  lr: 0.000000  max mem: 1312
2020-12-12 19:38:00,409 maskrcnn_benchmark.trainer INFO: eta: 0:18:35  iter: 380  loss: 174.1292 (228.8630)  loss_classifier: 94.4839 (149.9640)  loss_box_reg: 7.4524 (8.0829)  loss_objectness: 9.5781 (9.7645)  loss_rpn_box_reg: 62.3349 (61.0516)  time: 3.8164 (5.0702)  data: 0.2233 (1.4711)  lr: 0.000000  max mem: 1312
2020-12-12 19:39:16,864 maskrcnn_benchmark.trainer INFO: eta: 0:16:41  iter: 400  loss: 169.2289 (225.8433)  loss_classifier: 86.6040 (146.8986)  loss_box_reg: 6.9659 (8.0498)  loss_objectness: 9.7110 (9.7745)  loss_rpn_box_reg: 61.5792 (61.1204)  time: 3.8170 (5.0078)  data: 0.2248 (1.4089)  lr: 0.000000  max mem: 1312
2020-12-12 19:40:33,345 maskrcnn_benchmark.trainer INFO: eta: 0:14:51  iter: 420  loss: 158.6111 (222.7457)  loss_classifier: 79.6723 (143.7950)  loss_box_reg: 6.6826 (8.0490)  loss_objectness: 9.8958 (9.7963)  loss_rpn_box_reg: 61.5964 (61.1054)  time: 3.8231 (4.9515)  data: 0.2208 (1.3525)  lr: 0.000000  max mem: 1312
2020-12-12 19:41:50,640 maskrcnn_benchmark.trainer INFO: eta: 0:13:04  iter: 440  loss: 148.6132 (219.3357)  loss_classifier: 72.8536 (140.5201)  loss_box_reg: 7.5077 (7.9932)  loss_objectness: 9.5832 (9.7849)  loss_rpn_box_reg: 59.8990 (61.0376)  time: 3.8631 (4.9021)  data: 0.2265 (1.3016)  lr: 0.000000  max mem: 1312
2020-12-12 19:43:07,751 maskrcnn_benchmark.trainer INFO: eta: 0:11:19  iter: 460  loss: 150.0331 (216.4085)  loss_classifier: 70.1974 (137.4703)  loss_box_reg: 7.8958 (8.0310)  loss_objectness: 9.8922 (9.7886)  loss_rpn_box_reg: 63.6738 (61.1185)  time: 3.8449 (4.8566)  data: 0.2295 (1.2550)  lr: 0.000000  max mem: 1312
2020-12-12 19:44:24,476 maskrcnn_benchmark.trainer INFO: eta: 0:09:37  iter: 480  loss: 143.9536 (213.1553)  loss_classifier: 60.5242 (134.2384)  loss_box_reg: 7.6592 (8.0108)  loss_objectness: 10.0474 (9.7860)  loss_rpn_box_reg: 61.9850 (61.1200)  time: 3.8319 (4.8140)  data: 0.2265 (1.2122)  lr: 0.000000  max mem: 1312
2020-12-12 19:44:24,478 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 19:44:24,556 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(148 images).
2020-12-12 19:48:03,731 maskrcnn_benchmark.inference INFO: Total run time: 0:03:39.174845 (1.4809111163422868 s / img per device, on 1 devices)
2020-12-12 19:48:03,732 maskrcnn_benchmark.inference INFO: Model inference time: 0:03:22.943447 (1.3712395059095848 s / img per device, on 1 devices)
2020-12-12 19:48:03,732 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 19:48:19,594 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 19:48:19,594 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([3.6422e-01, 7.7583e-02, 5.0160e-02, 7.4967e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8044e-02, 1.7345e-02, 1.1372e-02, 5.1632e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7428e-02, 4.7119e-02, 3.4309e-02,
        1.6470e-02, 1.1369e-02, 5.1633e-03, 1.4037e-03, 0.0000e+00, 0.0000e+00,
        5.6723e-02, 3.2977e-02, 2.1706e-02, 1.6499e-02, 3.3173e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.7376e-02, 2.9831e-02, 2.0234e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0976e-02, 2.0226e-02,
        1.7714e-02, 1.6943e-02, 1.5261e-03, 7.8394e-04, 7.5140e-06, 3.7712e-06,
        0.0000e+00, 2.1363e-01, 3.8531e-02, 9.8219e-03, 1.2740e-01, 7.8809e-02,
        4.5247e-02, 2.0852e-02, 1.7033e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02, 2.3336e-02,
        0.0000e+00, 2.8266e-02, 1.7123e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4148e-01, 3.3160e-02,
        1.1761e-03, 6.4814e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02, 2.6273e-02,
        2.1682e-02, 3.2977e-02, 2.3336e-02, 2.1682e-02, 2.8666e-01, 5.3574e-02,
        2.8551e-02, 1.9947e-02, 7.3961e-05, 2.3571e-07, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7932e-02, 0.0000e+00, 0.0000e+00,
        1.1893e-01, 5.0102e-02, 4.1520e-02, 3.1593e-03, 2.9653e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.4263e-02, 1.8439e-03, 0.0000e+00, 4.7418e-02, 2.3082e-02, 1.2530e-02,
        1.8825e-06, 4.2369e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.9844e-01, 5.9330e-02, 1.3906e-02, 8.3684e-03, 3.4811e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8807e-01,
        7.9026e-02, 3.3711e-02, 9.0632e-02, 7.7558e-02, 6.9275e-02, 4.7139e-02,
        1.4048e-02, 0.0000e+00, 1.4904e-01, 1.4351e-01, 7.2115e-02, 2.3319e-03,
        2.2353e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00, 6.0544e-05,
        9.7408e-02, 3.8517e-02, 3.0481e-02, 5.2028e-02, 4.0163e-02, 3.3732e-02,
        2.7896e-02, 8.2327e-03, 5.9717e-03, 5.8647e-03, 0.0000e+00, 0.0000e+00,
        3.2977e-02, 2.5813e-02, 0.0000e+00, 3.2233e-01, 1.8608e-02, 1.5874e-02,
        2.8100e-03, 3.9092e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4939e-02, 4.6233e-03, 9.1439e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.3417e-02,
        3.2977e-02, 0.0000e+00, 1.8971e-02, 5.5006e-03, 2.2886e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02,
        2.1682e-02, 0.0000e+00, 3.4280e-02, 3.2977e-02, 0.0000e+00, 3.2977e-02,
        1.4907e-03, 1.5149e-05, 1.6888e-01, 1.8020e-02, 3.4811e-03, 3.3464e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 8.7978e-02, 7.3068e-02, 6.6470e-02, 5.8764e-02, 2.3440e-02,
        9.2826e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8054e-03, 3.1564e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 5.7515e-02, 4.8749e-02, 4.6808e-02, 2.3224e-02, 1.1290e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1070e-02, 3.2340e-02,
        2.6602e-01, 2.8702e-02, 1.2997e-02, 1.2913e-02, 1.0193e-02, 9.8640e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.7139e-02, 3.2977e-02, 0.0000e+00, 1.7822e-01, 4.2680e-02, 0.0000e+00,
        3.3032e-02, 1.2723e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1258e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8479e-01, 9.0715e-02, 1.9876e-02, 6.0605e-02, 4.8005e-02, 2.9173e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.9037e-01, 8.6906e-02, 1.9284e-02, 5.9217e-02,
        4.7124e-02, 2.1426e-02, 1.7293e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.5608e-02, 3.2977e-02, 2.3336e-02, 4.7173e-02,
        1.4356e-02, 1.0328e-02, 7.4825e-03, 2.9070e-05, 1.7183e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.7169e-02, 6.1295e-02, 5.4290e-02, 2.5414e-02,
        1.6139e-02, 1.3418e-02, 1.3013e-02, 0.0000e+00, 0.0000e+00, 4.8020e-02,
        3.2139e-02, 3.4811e-03, 1.8612e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4477e-02, 1.3758e-02,
        1.1468e-02, 7.5763e-03, 5.7585e-03, 4.1300e-03, 3.0816e-03, 2.5487e-03,
        7.0065e-07, 2.0066e-01, 1.0815e-01, 2.1682e-02, 4.0967e-01, 4.7139e-02,
        4.6114e-02, 3.5406e-01, 7.9923e-02, 1.6561e-02, 7.1820e-03, 2.5677e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5364e-01, 2.1735e-02, 2.1682e-02, 1.9151e-02, 1.1571e-03, 2.7650e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.8863e-01, 7.8151e-02, 6.1942e-03, 3.4811e-03, 2.9497e-03, 5.8509e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0151e-01,
        5.8132e-02, 2.9348e-02, 3.2139e-02, 1.5874e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.2443e-02, 6.8543e-02, 3.1749e-02, 1.3268e-01, 1.5874e-02,
        3.2049e-03, 1.9993e-03, 1.5195e-03, 2.6912e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1927e-01, 1.0166e-01, 2.4185e-02,
        1.2470e-01, 6.5662e-02, 4.0686e-02, 3.2977e-02, 2.3336e-02, 0.0000e+00,
        5.0409e-02, 4.6338e-02, 4.3719e-02, 4.0677e-02, 3.7284e-02, 2.5913e-02,
        9.6900e-03, 8.0191e-03, 5.5006e-03, 0.0000e+00, 3.2977e-02, 2.3400e-02,
        9.1706e-02, 3.2977e-02, 2.3336e-02, 2.2353e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.2698e-02, 6.4983e-02, 2.4151e-02, 7.0637e-03, 3.4811e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7690e-02,
        1.5874e-02, 1.0447e-02, 2.6302e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8532e-02, 3.5707e-02,
        1.9947e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9671e-01, 1.1715e-01,
        0.0000e+00, 2.8970e-01, 3.2776e-02, 1.8548e-02, 3.9628e-03, 2.6302e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1191e-01, 2.1682e-02, 1.6534e-02, 0.0000e+00, 2.1356e-01, 1.8322e-02,
        1.5874e-02, 2.6302e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6270e-01, 9.9361e-02, 2.8985e-02,
        1.6292e-01, 7.7285e-02, 1.9673e-02, 1.0193e-02, 9.8640e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6937e-01, 6.1555e-02, 3.5307e-03, 3.1214e-03, 2.4222e-03, 2.3256e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5799e-01,
        9.9409e-02, 5.9584e-02, 3.2977e-02, 1.7341e-05, 5.3370e-02, 4.4226e-02,
        4.0624e-02, 2.5918e-02, 1.3704e-02, 7.2217e-03, 5.8647e-03, 4.3271e-04,
        1.0502e-05, 2.0649e-04, 0.0000e+00, 0.0000e+00, 1.5361e-01, 2.2517e-02,
        1.5874e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00,
        3.2977e-02, 2.1682e-02, 0.0000e+00, 3.2977e-02, 2.1682e-02, 1.6543e-02,
        2.2477e-02, 1.2625e-02, 7.7136e-03, 6.7477e-03, 1.6671e-06, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2771e-03, 3.1593e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.4119e-01, 2.6124e-02, 2.3336e-02, 0.0000e+00, 4.5293e-02, 6.4814e-03,
        7.2695e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.2891e-02, 1.7714e-02, 1.6943e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4067e-01, 3.3711e-02,
        3.2139e-02, 4.8067e-02, 2.5130e-02, 2.0852e-02, 1.7123e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1593e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.5216e-01, 2.2121e-02, 2.8100e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.8961e-01, 6.5289e-02, 1.1761e-03, 5.7411e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3522e-01, 2.8804e-02, 2.1682e-02, 3.2977e-02, 1.3311e-02, 0.0000e+00,
        2.6565e-01, 6.4801e-02, 1.3580e-02, 2.3493e-01, 8.7919e-02, 0.0000e+00,
        5.5006e-03, 4.5404e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9480e-02, 3.1593e-03, 4.4986e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.2071e-02, 1.5874e-02, 2.6302e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3351e-02,
        2.1682e-02, 1.5134e-02, 1.6576e-02, 1.5687e-02, 4.9087e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2440e-01, 2.8804e-02, 2.1682e-02, 4.3183e-01,
        3.5020e-02, 8.0454e-02, 1.5874e-02, 3.1341e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.1006e-02, 2.9033e-02, 3.0435e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5000e-02,
        2.5365e-02, 2.3336e-02, 4.5617e-02, 3.2977e-02, 2.1682e-02, 1.7500e-01,
        8.0761e-02, 0.0000e+00, 2.3082e-02, 2.3003e-02, 1.9720e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9672e-01,
        1.0377e-01, 4.5131e-03, 1.8054e-02, 1.9798e-01, 5.6446e-02, 2.5131e-02,
        3.2977e-02, 2.3336e-02, 0.0000e+00, 3.2139e-02, 2.3072e-02, 1.4249e-02,
        6.6798e-03, 9.7308e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 2.1682e-02, 0.0000e+00, 4.7139e-02,
        0.0000e+00, 0.0000e+00, 2.3023e-01, 1.3063e-01, 9.2077e-02, 2.0852e-02,
        1.7123e-02, 3.8966e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.1765e-01, 8.9142e-02, 8.5653e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8881e-01, 4.8298e-02, 3.2977e-02,
        2.1682e-02, 0.0000e+00, 2.1183e-02, 1.4140e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7547e-01,
        4.7351e-02, 0.0000e+00]), 'gt_labels': tensor([7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 1, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7,
        4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 4, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 7, 7, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 7, 7, 4]), 'best match labels': tensor([4., 4., 4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 7., 7., 8., 4., 4., 8., 4., 8., 8., 8., 4., 4., 8., 4., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 4., 8., 8., 8., 8., 8., 4., 5., 4.,
        8., 5., 4., 8., 7., 8., 8., 7., 4., 8., 7., 7., 8., 8., 8., 8., 8., 4.,
        8., 8., 8., 8., 8., 7., 4., 8., 8., 8., 8., 8., 8., 8., 8., 4., 8., 7.,
        8., 7., 7., 7., 7., 7., 8., 8., 8., 8., 7., 8., 4., 4., 8., 7., 7., 4.,
        8., 8., 8., 7., 5., 8., 8., 8., 8., 8., 8., 8., 7., 7., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 7., 4., 8., 4., 8., 4., 8., 8., 8., 8., 8., 8., 4.,
        8., 7., 8., 8., 4., 8., 8., 8., 8., 7., 8., 4., 7., 8., 4., 4., 4., 8.,
        4., 8., 4., 4., 4., 4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 7.,
        4., 4., 4., 8., 8., 8., 7., 4., 4., 4., 4., 4., 8., 8., 4., 8., 4., 4.,
        8., 8., 8., 8., 5., 8., 8., 7., 8., 8., 8., 4., 8., 8., 8., 8., 8., 4.,
        8., 8., 4., 8., 8., 8., 8., 4., 8., 8., 8., 7., 8., 8., 4., 8., 8., 4.,
        8., 7., 4., 7., 8., 8., 7., 8., 8., 8., 8., 8., 8., 4., 4., 8., 7., 8.,
        8., 8., 7., 4., 8., 8., 8., 8., 7., 8., 8., 8., 8., 4., 4., 8., 8., 8.,
        4., 8., 8., 4., 7., 7., 4., 7., 8., 8., 7., 8., 8., 4., 8., 8., 8., 8.,
        8., 7., 8., 4., 7., 8., 8., 4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 4., 8., 4., 4., 8., 4., 7., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 4., 4., 4., 4., 4., 8., 8., 8., 8., 8., 8., 4., 8., 8., 7., 4.,
        4., 8., 4., 8., 8., 8., 8., 4., 4., 4., 8., 7., 4., 8., 8., 4., 4., 4.,
        8., 8., 8., 8., 7., 8., 8., 8., 8., 8., 4., 4., 4., 5., 4., 4., 7., 4.,
        8., 8., 4., 4., 4., 4., 8., 4., 7., 8., 8., 8., 8., 8., 8., 8., 8., 7.,
        8., 7., 4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 4., 4., 8., 8., 8., 8.,
        4., 4., 8., 8., 8., 4., 4., 4., 7., 8., 7., 7., 7., 7., 7., 8., 8., 8.,
        8., 4., 8., 8., 8., 4., 8., 8., 8., 4., 4., 8., 8., 8., 4., 4., 4., 4.,
        7., 7., 4., 8., 8., 7., 4., 4., 4., 4., 4., 4., 7., 4., 8., 8., 4., 8.,
        4., 8., 7., 7., 8., 8., 8., 8., 8., 8., 8., 8., 4., 7., 8., 8., 8., 7.,
        8., 8., 8., 4., 4., 8., 7., 8., 7., 8., 8., 8., 8., 8., 8., 7., 8., 8.,
        4., 7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 4., 7.,
        8., 7., 7., 4., 8., 7., 8., 8., 8., 8., 8., 7., 8., 7., 7., 8., 8., 4.,
        7., 8., 8., 8., 8., 8., 8., 8., 7., 4., 4., 4., 4., 4., 8., 8., 7., 8.,
        8., 8., 8., 8., 8., 8., 8., 7., 7., 4., 8., 8., 8., 7., 8., 8., 8., 4.,
        4., 4., 5., 8., 4., 4., 4., 8., 4., 4., 7., 8., 4., 8., 8., 4., 8., 7.,
        4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 7., 8., 7., 8., 8., 7., 8., 4.,
        8., 7., 8., 8., 8., 4., 8., 4., 8., 8., 8., 8., 8., 7., 8., 8., 8., 8.,
        7., 4., 8., 8., 8., 8., 8., 7., 8., 8., 8., 8., 8., 8., 8., 4., 8., 8.,
        8., 7., 8., 8., 4., 8., 4., 8., 7., 8., 8., 4., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 7., 7., 7., 8., 8., 8., 8., 8., 8., 8., 8.,
        7., 7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 7., 8., 8., 4., 8., 8.,
        7., 7., 4., 8., 4., 7., 8., 8., 8., 8., 8., 4., 8., 8., 8., 8., 8., 8.,
        4., 8., 8., 4., 8., 8., 8., 7., 8., 8., 8., 8., 8., 8., 8., 8., 7., 8.,
        7., 7., 8., 8., 8., 7., 8., 8., 8., 8., 7., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 7., 4., 8., 7., 7., 8., 4., 8., 8., 8., 8., 8., 8., 8., 7., 8.,
        4., 7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 4., 4., 7., 7., 8., 4., 4.,
        7., 8., 8., 4., 8., 8., 8., 8., 8., 8., 4., 4., 4., 8., 8., 7., 7., 8.,
        8., 8., 7., 4., 8., 4., 4., 8., 8., 8., 8., 8., 8., 4., 7., 8., 8., 8.,
        8., 8., 4., 4., 4., 8., 7., 8., 8., 8., 8., 8., 8., 8., 4., 4., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 7., 7., 7., 8., 8., 8., 4., 8., 8.,
        8., 8., 8., 8., 8., 7., 7., 8.]), 'best match scores': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.9996, 1.0000, 1.0000, 1.0000, 0.9997, 1.0000, 1.0000, 0.9992,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]), 'num_pos': 872}
2020-12-12 19:48:19,707 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.092890
2020-12-12 19:48:19,709 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r4.pth
2020-12-12 19:48:24,022 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r4
2020-12-12 19:49:41,539 maskrcnn_benchmark.trainer INFO: eta: 0:08:45  iter: 500  loss: 127.7039 (209.8498)  loss_classifier: 47.4211 (130.8310)  loss_box_reg: 7.7883 (8.0403)  loss_objectness: 10.6825 (9.8089)  loss_rpn_box_reg: 61.4442 (61.1697)  time: 3.8648 (5.2556)  data: 0.2324 (1.6526)  lr: 0.000000  max mem: 1312
2020-12-12 19:52:27,499 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 19:52:27,499 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 19:52:27,499 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 19:52:29,891 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 19:52:29,892 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 19:52:29,892 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000000001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 19:52:29,893 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 50
    BG_IOU_THRESHOLD: 1e-09
    FG_IOU_THRESHOLD: 0.001
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.8
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 1e-09
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 19:52:31,755 maskrcnn_benchmark INFO: reloading weigts from _best_acc_r4.pth
2020-12-12 19:52:34,301 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-12 19:52:34,301 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-12 19:52:34,301 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-12 19:52:34,301 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-12 19:52:34,490 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-12 19:52:35,033 maskrcnn_benchmark.trainer INFO: Start training
2020-12-12 19:53:52,471 maskrcnn_benchmark.trainer INFO: eta: 0:37:25  iter: 20  loss: 123.0057 (126.9245)  loss_classifier: 46.6340 (48.7598)  loss_box_reg: 6.8550 (7.8014)  loss_objectness: 9.8011 (9.8599)  loss_rpn_box_reg: 60.2884 (60.5034)  time: 3.8455 (3.8717)  data: 0.2350 (0.2334)  lr: 0.000000  max mem: 1313
2020-12-12 19:55:09,332 maskrcnn_benchmark.trainer INFO: eta: 0:36:00  iter: 40  loss: 135.8708 (131.7451)  loss_classifier: 53.7272 (50.7722)  loss_box_reg: 6.8877 (8.0900)  loss_objectness: 10.4065 (10.1254)  loss_rpn_box_reg: 64.6055 (62.7574)  time: 3.8426 (3.8574)  data: 0.2263 (0.2307)  lr: 0.000000  max mem: 1313
2020-12-12 19:56:28,220 maskrcnn_benchmark.trainer INFO: eta: 0:34:58  iter: 60  loss: 128.4747 (131.4470)  loss_classifier: 44.1702 (50.3222)  loss_box_reg: 7.7038 (8.4202)  loss_objectness: 9.5725 (10.0380)  loss_rpn_box_reg: 62.7169 (62.6666)  time: 3.8749 (3.8864)  data: 0.2364 (0.2350)  lr: 0.000000  max mem: 1313
2020-12-12 19:57:50,772 maskrcnn_benchmark.trainer INFO: eta: 0:34:12  iter: 80  loss: 122.6572 (129.2781)  loss_classifier: 46.1193 (49.3382)  loss_box_reg: 7.4387 (8.1637)  loss_objectness: 8.7095 (9.8980)  loss_rpn_box_reg: 57.6543 (61.8783)  time: 4.1339 (3.9467)  data: 0.2594 (0.2441)  lr: 0.000000  max mem: 1313
2020-12-12 19:59:12,803 maskrcnn_benchmark.trainer INFO: eta: 0:33:08  iter: 100  loss: 117.0041 (127.5511)  loss_classifier: 42.5916 (47.9193)  loss_box_reg: 7.9585 (8.1653)  loss_objectness: 9.8169 (9.7968)  loss_rpn_box_reg: 61.6851 (61.6696)  time: 4.1414 (3.9777)  data: 0.2615 (0.2494)  lr: 0.000000  max mem: 1313
2020-12-12 20:00:33,477 maskrcnn_benchmark.trainer INFO: eta: 0:31:53  iter: 120  loss: 116.0797 (125.0243)  loss_classifier: 39.4237 (46.4954)  loss_box_reg: 5.5068 (7.8306)  loss_objectness: 9.1665 (9.7385)  loss_rpn_box_reg: 61.5366 (60.9598)  time: 4.0334 (3.9870)  data: 0.2351 (0.2492)  lr: 0.000000  max mem: 1313
2020-12-12 20:01:52,149 maskrcnn_benchmark.trainer INFO: eta: 0:30:30  iter: 140  loss: 111.1644 (123.6882)  loss_classifier: 31.7878 (45.0303)  loss_box_reg: 7.7801 (7.9008)  loss_objectness: 10.0604 (9.7627)  loss_rpn_box_reg: 62.7268 (60.9944)  time: 3.8689 (3.9794)  data: 0.2385 (0.2487)  lr: 0.000000  max mem: 1313
2020-12-12 20:03:11,289 maskrcnn_benchmark.trainer INFO: eta: 0:29:09  iter: 160  loss: 114.7501 (122.2299)  loss_classifier: 34.4089 (43.7071)  loss_box_reg: 7.3117 (7.8853)  loss_objectness: 10.3849 (9.8200)  loss_rpn_box_reg: 59.9587 (60.8174)  time: 3.9091 (3.9766)  data: 0.2404 (0.2487)  lr: 0.000000  max mem: 1313
2020-12-12 20:04:32,010 maskrcnn_benchmark.trainer INFO: eta: 0:27:52  iter: 180  loss: 110.7438 (120.9519)  loss_classifier: 30.8337 (42.4360)  loss_box_reg: 7.4720 (7.9540)  loss_objectness: 9.3138 (9.7628)  loss_rpn_box_reg: 62.2751 (60.7990)  time: 4.0395 (3.9832)  data: 0.2426 (0.2485)  lr: 0.000000  max mem: 1313
2020-12-12 20:05:52,006 maskrcnn_benchmark.trainer INFO: eta: 0:26:33  iter: 200  loss: 108.6121 (119.8736)  loss_classifier: 29.6064 (41.3956)  loss_box_reg: 8.0115 (7.9552)  loss_objectness: 9.3474 (9.7579)  loss_rpn_box_reg: 61.3567 (60.7649)  time: 3.9758 (3.9848)  data: 0.2439 (0.2487)  lr: 0.000000  max mem: 1313
2020-12-12 20:07:14,701 maskrcnn_benchmark.trainer INFO: eta: 0:25:19  iter: 220  loss: 102.0711 (118.5655)  loss_classifier: 26.9463 (40.2323)  loss_box_reg: 6.5783 (7.8938)  loss_objectness: 9.4098 (9.7317)  loss_rpn_box_reg: 60.5646 (60.7076)  time: 4.1271 (3.9985)  data: 0.2696 (0.2508)  lr: 0.000000  max mem: 1313
2020-12-12 20:08:32,881 maskrcnn_benchmark.trainer INFO: eta: 0:23:56  iter: 240  loss: 104.6782 (117.5325)  loss_classifier: 23.5505 (38.9816)  loss_box_reg: 7.9392 (8.0216)  loss_objectness: 9.3063 (9.7199)  loss_rpn_box_reg: 62.4838 (60.8094)  time: 3.8372 (3.9910)  data: 0.2390 (0.2502)  lr: 0.000000  max mem: 1313
2020-12-12 20:09:49,418 maskrcnn_benchmark.trainer INFO: eta: 0:22:32  iter: 260  loss: 99.7287 (116.1062)  loss_classifier: 20.9119 (37.6949)  loss_box_reg: 7.3343 (7.9933)  loss_objectness: 9.0664 (9.6764)  loss_rpn_box_reg: 62.5055 (60.7416)  time: 3.8256 (3.9784)  data: 0.2239 (0.2483)  lr: 0.000000  max mem: 1313
2020-12-12 20:11:05,963 maskrcnn_benchmark.trainer INFO: eta: 0:21:09  iter: 280  loss: 103.1625 (115.3400)  loss_classifier: 23.3853 (36.6882)  loss_box_reg: 7.2355 (8.0456)  loss_objectness: 10.3789 (9.7089)  loss_rpn_box_reg: 62.2983 (60.8973)  time: 3.8275 (3.9676)  data: 0.2234 (0.2465)  lr: 0.000000  max mem: 1313
2020-12-12 20:12:22,751 maskrcnn_benchmark.trainer INFO: eta: 0:19:47  iter: 300  loss: 98.1786 (114.2598)  loss_classifier: 20.6463 (35.6474)  loss_box_reg: 7.8783 (8.0963)  loss_objectness: 9.8567 (9.7280)  loss_rpn_box_reg: 59.6405 (60.7882)  time: 3.8353 (3.9591)  data: 0.2259 (0.2454)  lr: 0.000000  max mem: 1313
2020-12-12 20:13:39,530 maskrcnn_benchmark.trainer INFO: eta: 0:18:26  iter: 320  loss: 98.1297 (113.1971)  loss_classifier: 19.2282 (34.5995)  loss_box_reg: 6.7329 (8.0525)  loss_objectness: 9.7309 (9.7347)  loss_rpn_box_reg: 60.2100 (60.8104)  time: 3.8369 (3.9515)  data: 0.2268 (0.2445)  lr: 0.000000  max mem: 1313
2020-12-12 20:14:56,282 maskrcnn_benchmark.trainer INFO: eta: 0:17:05  iter: 340  loss: 100.0097 (112.3973)  loss_classifier: 19.5125 (33.7554)  loss_box_reg: 7.7307 (8.0877)  loss_objectness: 10.0908 (9.7384)  loss_rpn_box_reg: 60.6509 (60.8157)  time: 3.8305 (3.9448)  data: 0.2288 (0.2436)  lr: 0.000000  max mem: 1313
2020-12-12 20:16:13,087 maskrcnn_benchmark.trainer INFO: eta: 0:15:45  iter: 360  loss: 94.6659 (111.5592)  loss_classifier: 14.8403 (32.8487)  loss_box_reg: 7.6159 (8.1095)  loss_objectness: 10.2305 (9.7555)  loss_rpn_box_reg: 62.4816 (60.8454)  time: 3.8374 (3.9390)  data: 0.2259 (0.2428)  lr: 0.000000  max mem: 1313
2020-12-12 20:17:29,723 maskrcnn_benchmark.trainer INFO: eta: 0:14:25  iter: 380  loss: 97.2865 (110.7821)  loss_classifier: 17.4320 (32.0852)  loss_box_reg: 7.8534 (8.1270)  loss_objectness: 10.0352 (9.7603)  loss_rpn_box_reg: 60.1790 (60.8096)  time: 3.8301 (3.9334)  data: 0.2229 (0.2418)  lr: 0.000000  max mem: 1313
2020-12-12 20:18:46,475 maskrcnn_benchmark.trainer INFO: eta: 0:13:05  iter: 400  loss: 94.2440 (109.9866)  loss_classifier: 14.7691 (31.2262)  loss_box_reg: 8.1426 (8.1314)  loss_objectness: 9.7524 (9.7555)  loss_rpn_box_reg: 59.7668 (60.8735)  time: 3.8350 (3.9286)  data: 0.2267 (0.2411)  lr: 0.000000  max mem: 1313
2020-12-12 20:20:03,404 maskrcnn_benchmark.trainer INFO: eta: 0:11:46  iter: 420  loss: 90.9931 (109.0415)  loss_classifier: 14.0417 (30.4104)  loss_box_reg: 6.7456 (8.0472)  loss_objectness: 9.4242 (9.7391)  loss_rpn_box_reg: 59.6420 (60.8448)  time: 3.8314 (3.9247)  data: 0.2267 (0.2405)  lr: 0.000000  max mem: 1313
2020-12-12 20:21:21,159 maskrcnn_benchmark.trainer INFO: eta: 0:10:27  iter: 440  loss: 92.5539 (108.2228)  loss_classifier: 11.9070 (29.5986)  loss_box_reg: 6.5961 (8.0484)  loss_objectness: 8.9363 (9.7144)  loss_rpn_box_reg: 61.5024 (60.8614)  time: 3.8608 (3.9230)  data: 0.2355 (0.2402)  lr: 0.000000  max mem: 1313
2020-12-12 20:22:38,212 maskrcnn_benchmark.trainer INFO: eta: 0:09:08  iter: 460  loss: 94.1370 (107.5302)  loss_classifier: 12.7873 (28.9007)  loss_box_reg: 8.6739 (8.0723)  loss_objectness: 9.7304 (9.7112)  loss_rpn_box_reg: 63.0014 (60.8460)  time: 3.8555 (3.9199)  data: 0.2310 (0.2399)  lr: 0.000000  max mem: 1313
2020-12-12 20:23:55,611 maskrcnn_benchmark.trainer INFO: eta: 0:07:50  iter: 480  loss: 90.2187 (106.8144)  loss_classifier: 12.0448 (28.1936)  loss_box_reg: 7.1166 (8.0333)  loss_objectness: 10.0832 (9.7213)  loss_rpn_box_reg: 61.3272 (60.8662)  time: 3.8634 (3.9179)  data: 0.2348 (0.2400)  lr: 0.000000  max mem: 1313
2020-12-12 20:25:12,921 maskrcnn_benchmark.trainer INFO: eta: 0:06:31  iter: 500  loss: 88.5917 (106.1438)  loss_classifier: 12.4947 (27.5790)  loss_box_reg: 6.5246 (8.0098)  loss_objectness: 10.0142 (9.7271)  loss_rpn_box_reg: 59.5424 (60.8279)  time: 3.8583 (3.9158)  data: 0.2364 (0.2398)  lr: 0.000000  max mem: 1313
2020-12-12 20:25:12,923 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 20:25:13,000 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(148 images).
2020-12-12 20:28:52,418 maskrcnn_benchmark.inference INFO: Total run time: 0:03:39.418062 (1.4825544727815163 s / img per device, on 1 devices)
2020-12-12 20:28:52,418 maskrcnn_benchmark.inference INFO: Model inference time: 0:03:23.622931 (1.375830618110863 s / img per device, on 1 devices)
2020-12-12 20:28:52,419 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 20:29:08,468 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 20:29:08,468 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([8.7903e-02, 3.0658e-02, 2.1682e-02, 3.7984e-02, 7.4297e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        2.3272e-02, 1.7345e-02, 1.6480e-02, 1.1416e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1426e-02, 1.0193e-02, 9.8640e-03,
        5.1914e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.2129e-02, 2.1682e-02, 1.1785e-02, 1.6499e-02, 3.3173e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.7376e-02, 2.9831e-02, 2.0234e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.6878e-02, 3.1098e-02,
        1.9503e-02, 1.7714e-02, 1.6943e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.2780e-02, 4.3593e-02, 2.9975e-02, 1.1322e-01, 3.2977e-02,
        2.3663e-03, 2.0852e-02, 1.7033e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02, 2.9336e-02,
        2.1682e-02, 2.1010e-02, 1.7123e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6012e-02, 1.8329e-02,
        1.1761e-03, 9.1832e-03, 6.4814e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02, 2.1682e-02,
        0.0000e+00, 4.3464e-02, 2.3336e-02, 2.1682e-02, 3.2977e-02, 0.0000e+00,
        2.0852e-02, 1.9947e-02, 1.7123e-02, 7.4432e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8091e-02, 3.2977e-02, 2.1682e-02,
        1.1901e-01, 5.5007e-02, 6.8377e-05, 3.1593e-03, 2.9653e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2977e-02, 0.0000e+00, 0.0000e+00, 2.3082e-02, 1.9580e-06, 4.2369e-07,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1761e-01, 1.5874e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4537e-02,
        3.2977e-02, 2.1682e-02, 1.7752e-01, 7.7558e-02, 3.9552e-02, 4.7884e-02,
        3.2977e-02, 0.0000e+00, 4.5821e-02, 3.2139e-02, 0.0000e+00, 2.2771e-02,
        2.3319e-03, 2.2353e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00, 2.1495e-02,
        9.7408e-02, 2.1682e-02, 0.0000e+00, 3.3732e-02, 6.1886e-03, 5.9717e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.7943e-02, 2.5813e-02, 2.1682e-02, 3.2139e-02, 1.5874e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.4939e-02, 9.2116e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02,
        2.1682e-02, 0.0000e+00, 5.5006e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4392e-02,
        2.1682e-02, 1.6543e-02, 3.2977e-02, 2.1682e-02, 0.0000e+00, 8.3320e-02,
        2.8804e-02, 2.1682e-02, 3.6468e-02, 1.5874e-02, 3.4811e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.5416e-02, 1.8714e-04, 3.7330e-07, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0291e-03, 4.1002e-03,
        2.9653e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.1528e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1831e-02, 1.5874e-02,
        2.5227e-01, 6.2401e-02, 1.6218e-02, 2.0741e-02, 9.8640e-03, 9.5782e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2732e-01, 6.4250e-02, 2.1911e-02, 6.4161e-02, 2.5949e-02, 0.0000e+00,
        1.2723e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.2220e-02, 1.9981e-02, 2.0231e-05, 4.9587e-02, 1.5874e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.2561e-01, 2.3136e-02, 2.1682e-02, 2.1183e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.7021e-02, 4.2803e-02, 2.3336e-02, 2.5416e-02,
        2.9524e-05, 1.7624e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.1356e-02, 1.5181e-02, 1.3418e-02, 8.7253e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2139e-02,
        1.8884e-02, 1.5874e-02, 1.3006e-03, 1.8612e-06, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9944e-02, 1.0111e-02,
        7.6141e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.0813e-01, 3.8506e-02, 2.1682e-02, 4.0967e-01, 7.2703e-02,
        2.1682e-02, 7.3011e-02, 5.6382e-02, 3.4811e-03, 2.7433e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.4303e-02, 2.1682e-02, 9.4547e-03, 1.9151e-02, 1.1633e-03, 2.7802e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.0546e-02, 1.5874e-02, 6.2235e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7125e-02,
        2.9348e-02, 0.0000e+00, 3.2139e-02, 1.5874e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 6.8642e-02, 3.1749e-02, 1.6378e-05, 4.2303e-02, 2.6535e-02,
        3.0214e-03, 1.9192e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5595e-01, 9.9462e-02, 2.4185e-02,
        3.6615e-02, 2.1682e-02, 1.9287e-02, 3.2977e-02, 2.3336e-02, 2.1682e-02,
        5.5006e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02, 2.0231e-05,
        8.4499e-02, 2.3336e-02, 2.1682e-02, 2.9507e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 1.5874e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2290e-01,
        1.5874e-02, 2.6302e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8532e-02, 3.5704e-02,
        1.9947e-02, 1.7123e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 5.5006e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0342e-01, 3.6998e-02,
        0.0000e+00, 1.7053e-01, 4.1464e-02, 5.1130e-03, 2.0240e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.3355e-01, 1.1086e-01, 1.6534e-02, 2.8843e-02, 3.2139e-02, 1.5874e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2434e-01, 8.6785e-02, 2.6772e-02,
        1.9536e-01, 2.1682e-02, 0.0000e+00, 1.0193e-02, 9.8640e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.2305e-01, 1.5874e-02, 2.6333e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4324e-02,
        3.2977e-02, 6.4243e-03, 7.2980e-02, 3.2977e-02, 5.3370e-02, 1.8069e-02,
        6.1886e-03, 5.9717e-03, 5.8647e-03, 1.0502e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2139e-02, 1.5874e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2977e-02, 0.0000e+00, 0.0000e+00,
        3.2977e-02, 2.1682e-02, 1.6543e-02, 3.2977e-02, 2.1682e-02, 0.0000e+00,
        6.8469e-03, 6.1886e-03, 5.9717e-03, 1.6671e-06, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2771e-03, 3.1593e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.3146e-02, 2.3336e-02, 0.0000e+00, 0.0000e+00, 1.5271e-02, 6.4814e-03,
        7.1952e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.2780e-02, 2.2873e-02, 1.7714e-02, 1.4687e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6711e-02, 3.2139e-02,
        3.5830e-04, 4.8235e-02, 2.5120e-02, 2.0852e-02, 1.7123e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1593e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 5.7303e-02, 1.5874e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.7836e-02, 1.6603e-02, 1.1761e-03, 1.5516e-02, 5.7784e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.7225e-02, 3.5631e-02, 2.1682e-02, 4.7448e-02, 2.1682e-02, 0.0000e+00,
        3.5267e-02, 1.5874e-02, 1.3580e-02, 4.7139e-02, 0.0000e+00, 0.0000e+00,
        5.5006e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1593e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        7.0068e-02, 1.5874e-02, 2.6302e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3694e-02,
        2.1682e-02, 1.5134e-02, 1.6576e-02, 1.5687e-02, 1.5335e-02, 1.7539e-06,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.4415e-02, 2.8804e-02, 2.3934e-02, 3.3697e-02,
        2.1682e-02, 8.5286e-02, 1.5874e-02, 3.1341e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2139e-02, 1.5874e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4987e-02,
        2.3336e-02, 2.1682e-02, 4.4743e-02, 3.2977e-02, 0.0000e+00, 3.2977e-02,
        3.1419e-02, 0.0000e+00, 2.3082e-02, 7.4441e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1749e-02,
        2.1682e-02, 3.9073e-06, 1.8054e-02, 8.4935e-02, 2.5131e-02, 2.1682e-02,
        3.2977e-02, 2.3336e-02, 2.1682e-02, 3.2139e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.0510e-02, 2.1682e-02, 1.1177e-02, 4.7139e-02,
        0.0000e+00, 0.0000e+00, 5.2290e-02, 3.4085e-02, 2.1682e-02, 3.6700e-02,
        1.7123e-02, 3.8966e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 9.1663e-02, 2.1682e-02, 9.4684e-03, 2.2353e-03,
        2.0021e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2862e-02, 1.5874e-02, 3.2977e-02,
        2.1682e-02, 1.6543e-02, 2.1183e-02, 1.7293e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9405e-02,
        2.1682e-02, 0.0000e+00]), 'gt_labels': tensor([7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 1, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7,
        4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 4, 4, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4,
        7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7,
        7, 4, 7, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        7, 7, 4, 7, 7, 4, 7, 7, 1, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 7, 7, 7, 7, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7,
        7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 7, 4, 4, 7, 7, 4, 7, 7, 4, 7, 7, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 4, 7, 7, 4, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 7, 7, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 7, 7, 7, 7, 4, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 7, 7, 4]), 'best match labels': tensor([4., 8., 8., 8., 8., 8., 7., 8., 8., 8., 8., 8., 4., 8., 8., 8., 7., 8.,
        8., 8., 8., 8., 7., 8., 8., 8., 8., 8., 8., 8., 8., 4., 7., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 4., 8., 8., 8., 8., 8., 4., 8., 8.,
        8., 8., 8., 4., 7., 8., 8., 7., 4., 7., 8., 8., 7., 8., 8., 8., 8., 4.,
        8., 8., 8., 8., 4., 7., 7., 8., 8., 8., 8., 8., 8., 8., 8., 7., 8., 8.,
        8., 8., 7., 8., 8., 8., 8., 8., 8., 8., 7., 8., 8., 7., 4., 8., 8., 8.,
        8., 4., 8., 7., 8., 8., 8., 8., 8., 4., 8., 8., 8., 7., 8., 7., 8., 8.,
        8., 8., 8., 8., 8., 7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 7., 8., 4., 4., 4., 4., 8.,
        8., 4., 8., 7., 8., 4., 8., 8., 8., 8., 8., 4., 8., 8., 8., 8., 8., 7.,
        8., 4., 8., 8., 7., 8., 8., 8., 8., 8., 8., 4., 8., 4., 4., 7., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 7.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 7., 7., 8., 8., 7.,
        4., 8., 8., 4., 8., 8., 8., 7., 8., 8., 8., 8., 8., 8., 4., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 4., 8., 7., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 4., 4., 7., 4., 8., 8., 7., 8., 8., 8., 8., 8., 4.,
        4., 7., 8., 8., 8., 7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 4., 8., 8., 4., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 4., 4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 4., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 4., 4., 4., 8., 8., 7.,
        8., 4., 8., 8., 8., 8., 8., 7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 7.,
        4., 8., 4., 4., 8., 4., 4., 4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 4., 7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 4., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 4., 7., 8., 7., 7., 7., 7., 7., 7., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 7., 7., 8., 8., 4., 4., 4.,
        8., 4., 7., 4., 8., 7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 5., 8.,
        7., 4., 8., 4., 8., 8., 8., 8., 8., 8., 8., 8., 7., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 4., 8., 8., 8., 8., 8., 8., 8., 8., 7., 8., 4.,
        4., 7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 4., 7., 8., 8., 8., 8., 8., 8., 8., 8., 7., 7., 4., 8., 4., 7., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 4., 4., 4., 8., 4., 8., 8., 7., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 7., 7., 8., 8., 8., 8., 8., 8., 8., 4.,
        8., 4., 4., 8., 8., 7., 8., 4., 8., 4., 8., 8., 4., 8., 8., 8., 7., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 7., 8., 7., 8., 4., 7., 8., 8.,
        8., 7., 8., 8., 8., 8., 8., 8., 4., 7., 7., 7., 8., 7., 8., 8., 8., 8.,
        8., 7., 8., 8., 8., 7., 8., 8., 8., 8., 8., 8., 8., 7., 8., 4., 8., 8.,
        8., 4., 8., 8., 8., 8., 4., 8., 7., 8., 8., 4., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 7., 8., 7., 8., 8., 8., 8., 8., 8., 8., 8.,
        4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 4., 8., 4., 8.,
        7., 8., 4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 8., 8., 8., 7., 8., 8., 8., 8., 8., 8., 8., 8., 7., 8.,
        7., 7., 8., 8., 8., 7., 8., 4., 8., 8., 5., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 4., 8., 8., 4., 8., 4., 8., 8., 8., 8., 8., 8., 8., 7., 8.,
        7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 7., 4., 8., 8., 4., 8., 8.,
        8., 7., 7., 4., 8., 8., 8., 8., 8., 8., 8., 7., 8., 8., 8., 7., 4., 8.,
        4., 8., 7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 4., 7., 8.,
        8., 8., 8., 7., 8., 8., 8., 8., 8., 8., 8., 8., 8., 4., 8., 4., 4., 8.,
        4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 7., 8., 4., 8., 8., 8., 4.,
        8., 8., 8., 8., 8., 8., 4., 8.]), 'best match scores': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9813, 1.0000, 1.0000,
        1.0000, 0.1295, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0943,
        0.8461, 1.0000, 1.0000, 0.9958, 1.0000, 0.9993, 0.0726, 0.9741, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 0.9935, 1.0000,
        0.9434, 0.9957, 0.9985, 0.9141, 1.0000, 1.0000, 0.9105, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.9932, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.9413, 0.9999, 0.0625, 0.9990, 0.9998, 1.0000,
        0.7360, 1.0000, 1.0000, 0.9378, 1.0000, 1.0000, 1.0000, 0.9712, 1.0000,
        1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 0.9973, 1.0000, 0.9972, 1.0000,
        1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 0.2206, 0.9998, 1.0000,
        1.0000, 1.0000, 0.1002, 0.9996, 0.9332, 0.0560, 0.9137, 1.0000, 0.8740,
        1.0000, 0.7463, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.2851, 0.9999,
        1.0000, 0.9961, 1.0000, 1.0000, 1.0000, 0.9999, 0.9590, 0.9999, 1.0000,
        0.8199, 0.8505, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9292,
        1.0000, 1.0000, 0.1162, 1.0000, 0.0596, 1.0000, 1.0000, 0.9935, 0.3367,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9991,
        1.0000, 1.0000, 0.6194, 0.9979, 0.5043, 0.8135, 0.9731, 0.9390, 0.0673,
        1.0000, 0.7334, 0.7059, 1.0000, 0.6741, 0.9382, 0.9745, 1.0000, 0.9988,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.8212, 1.0000, 1.0000,
        0.6386, 0.7769, 0.9852, 0.9997, 1.0000, 1.0000, 1.0000, 0.8871, 0.9430,
        1.0000, 1.0000, 0.9995, 1.0000, 1.0000, 1.0000, 0.9996, 0.0613, 1.0000,
        1.0000, 1.0000, 0.6205, 1.0000, 0.9883, 0.9999, 0.9998, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.0772, 1.0000, 1.0000, 1.0000, 1.0000,
        0.9999, 1.0000, 1.0000, 1.0000, 0.9999, 0.9917, 1.0000, 1.0000, 0.9906,
        0.3221, 0.0674, 1.0000, 0.9955, 0.1580, 1.0000, 1.0000, 1.0000, 1.0000,
        0.1816, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9998, 0.9991, 1.0000,
        1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 0.9668, 0.5070, 1.0000, 1.0000,
        0.9997, 0.9154, 0.9999, 1.0000, 1.0000, 0.2092, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 0.9636, 1.0000, 1.0000, 1.0000, 0.7809, 0.1652, 0.2191,
        0.8938, 1.0000, 0.9995, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9857,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.7132, 1.0000, 1.0000,
        0.8533, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9998, 0.9991, 0.9997,
        1.0000, 0.8972, 1.0000, 1.0000, 0.9979, 1.0000, 1.0000, 1.0000, 1.0000,
        0.2893, 1.0000, 0.3766, 0.9994, 1.0000, 1.0000, 0.9997, 1.0000, 1.0000,
        0.9997, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.9989, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.9979, 1.0000, 0.8109, 0.9980, 0.9042, 0.9730, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.1346, 1.0000, 0.9996, 1.0000, 0.9950,
        0.4947, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.6337, 0.3976, 1.0000,
        1.0000, 1.0000, 0.9998, 0.3808, 0.0876, 1.0000, 1.0000, 0.3359, 1.0000,
        1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9985, 0.9999, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.9994, 1.0000, 0.9928, 0.0747, 0.9970, 1.0000,
        1.0000, 0.9980, 0.9913, 1.0000, 0.0934, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.9947, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 0.9851, 1.0000, 0.9986,
        0.9986, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.5438, 1.0000,
        1.0000, 1.0000, 1.0000, 0.1251, 0.9998, 0.5032, 0.9998, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9994, 0.9998, 1.0000,
        1.0000, 1.0000, 0.7769, 0.5462, 0.9995, 1.0000, 0.9670, 0.5468, 1.0000,
        0.7911, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.4482, 1.0000, 1.0000,
        1.0000, 1.0000, 0.9996, 0.3189, 0.4528, 1.0000, 0.8893, 0.9944, 1.0000,
        1.0000, 0.9889, 1.0000, 0.9996, 1.0000, 1.0000, 1.0000, 0.9988, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.9999, 1.0000, 0.9998, 1.0000, 1.0000, 0.9869, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.7687, 0.9975, 1.0000, 0.9911, 1.0000,
        0.9999, 1.0000, 1.0000, 0.9998, 0.9998, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.6754, 0.2815, 1.0000, 1.0000,
        0.9999, 0.1671, 1.0000, 1.0000, 1.0000, 1.0000, 0.8328, 0.8531, 0.9872,
        1.0000, 0.9998, 1.0000, 1.0000, 0.9847, 1.0000, 0.9524, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9948, 1.0000, 0.2508,
        1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.1242,
        0.5219, 1.0000, 0.6622, 1.0000, 0.9585, 1.0000, 1.0000, 1.0000, 0.9999,
        1.0000, 1.0000, 0.9998, 0.3572, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.9999, 0.7160, 0.9739, 1.0000, 0.0555, 0.8668, 1.0000, 0.9445, 1.0000,
        0.8669, 0.9999, 0.9996, 0.7913, 1.0000, 0.0838, 0.9482, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9716, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 0.9993, 1.0000, 1.0000, 0.3041, 1.0000, 1.0000, 1.0000,
        1.0000, 0.9877, 1.0000, 1.0000, 1.0000, 0.9998, 1.0000, 0.9985, 0.9996,
        1.0000, 0.0517, 0.9932, 1.0000, 1.0000, 0.8795, 1.0000, 0.8478, 0.1080,
        0.9507, 0.9945, 1.0000, 0.9986, 1.0000, 0.8671, 1.0000, 0.1261, 0.9988,
        0.0626, 1.0000, 0.6403, 0.9944, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.9962, 0.9999, 1.0000, 1.0000, 1.0000, 0.6763, 1.0000, 1.0000,
        0.6981, 1.0000, 1.0000, 0.9995, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.9845, 1.0000, 0.9956, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.9973, 1.0000, 1.0000, 1.0000, 0.9769, 1.0000,
        0.8297, 1.0000, 1.0000, 1.0000, 0.9941, 1.0000, 1.0000, 0.9853, 1.0000,
        1.0000, 0.9799, 0.9989, 1.0000, 1.0000, 0.9996, 1.0000, 0.9666, 0.9504,
        0.9990, 1.0000, 1.0000, 0.6635, 1.0000, 0.9043, 1.0000, 0.0502, 0.0651,
        0.6980, 1.0000, 1.0000, 1.0000, 0.9990, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 0.8670, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 0.9735, 1.0000, 1.0000, 1.0000, 0.9928, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.0905, 1.0000, 1.0000, 1.0000, 0.9095, 1.0000,
        1.0000, 0.0917, 0.9917, 0.6540, 0.5031, 0.9836, 0.9894, 0.9866, 1.0000,
        1.0000, 0.8508, 1.0000, 1.0000, 1.0000, 0.4095, 0.1112, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9949, 1.0000, 0.3634, 1.0000, 0.9214,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9998, 1.0000, 0.9992, 1.0000, 1.0000,
        0.9753, 0.1172, 1.0000, 0.3395, 0.9312, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0616, 1.0000,
        0.1543, 1.0000, 1.0000, 1.0000, 1.0000, 0.0756, 1.0000, 1.0000, 1.0000,
        0.0886, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        0.1444, 1.0000, 1.0000, 0.5001, 1.0000, 1.0000, 0.4398, 1.0000, 0.8851,
        1.0000, 1.0000, 1.0000, 0.9983, 0.2117, 1.0000, 0.1518, 0.6516, 0.9999,
        0.9010, 0.9985, 1.0000, 0.9944, 0.9999, 0.9947, 1.0000, 1.0000, 0.7777,
        1.0000, 0.9993, 1.0000, 1.0000, 1.0000, 1.0000, 0.8127, 1.0000, 1.0000,
        0.9994, 1.0000, 1.0000, 1.0000, 0.1483, 0.9998, 0.9097, 1.0000]), 'num_pos': 872}
2020-12-12 20:29:08,584 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.060780
2020-12-12 20:29:08,586 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r4.pth
2020-12-12 20:29:12,290 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r4
2020-12-12 20:30:29,819 maskrcnn_benchmark.trainer INFO: eta: 0:05:49  iter: 520  loss: 90.7580 (105.5168)  loss_classifier: 9.6558 (26.9499)  loss_box_reg: 8.1398 (8.0315)  loss_objectness: 9.8049 (9.7199)  loss_rpn_box_reg: 61.8157 (60.8156)  time: 3.8635 (4.3746)  data: 0.2368 (0.7005)  lr: 0.000000  max mem: 1313
2020-12-12 20:32:29,116 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 20:32:29,117 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 20:32:29,117 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 20:32:32,167 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 20:32:32,168 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 20:32:32,169 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000000001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 20:32:32,173 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 50
    BG_IOU_THRESHOLD: 1e-09
    FG_IOU_THRESHOLD: 0.001
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.8
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 1e-09
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 20:32:33,940 maskrcnn_benchmark INFO: reloading weigts from r4_fin.pth
2020-12-12 20:32:36,272 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-12 20:32:36,272 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-12 20:32:36,272 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-12 20:32:36,272 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-12 20:32:36,272 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-12 20:32:36,272 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-12 20:32:36,450 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-12 20:32:36,909 maskrcnn_benchmark.trainer INFO: Start training
2020-12-12 20:33:54,324 maskrcnn_benchmark.trainer INFO: eta: 0:37:24  iter: 20  loss: 94.1805 (93.8999)  loss_classifier: 11.7243 (12.4525)  loss_box_reg: 7.6685 (8.0644)  loss_objectness: 10.1334 (10.0840)  loss_rpn_box_reg: 61.9992 (63.2990)  time: 3.8505 (3.8706)  data: 0.2309 (0.2377)  lr: 0.000000  max mem: 1317
2020-12-12 20:35:11,247 maskrcnn_benchmark.trainer INFO: eta: 0:36:00  iter: 40  loss: 89.7755 (91.3065)  loss_classifier: 10.3037 (12.2324)  loss_box_reg: 6.8426 (7.4653)  loss_objectness: 9.4741 (9.7883)  loss_rpn_box_reg: 62.0938 (61.8206)  time: 3.8414 (3.8584)  data: 0.2341 (0.2352)  lr: 0.000000  max mem: 1317
2020-12-12 20:36:28,297 maskrcnn_benchmark.trainer INFO: eta: 0:34:42  iter: 60  loss: 93.7344 (91.8175)  loss_classifier: 12.7638 (12.3967)  loss_box_reg: 8.5447 (7.8574)  loss_objectness: 9.4620 (9.7898)  loss_rpn_box_reg: 60.4298 (61.7736)  time: 3.8514 (3.8564)  data: 0.2257 (0.2329)  lr: 0.000000  max mem: 1317
2020-12-12 20:37:32,174 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 20:37:32,174 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='draw_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, threshold=0.8, weights='visdrone_model_0360000.pth')
2020-12-12 20:37:32,174 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 20:37:34,487 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 20:37:34,488 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 20:37:34,488 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000000001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 20:37:34,489 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 1e-09
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 20:37:36,253 maskrcnn_benchmark INFO: reloading weigts from r4_fin.pth
2020-12-12 20:39:48,643 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 20:39:48,643 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 20:39:48,643 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 20:39:50,905 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 20:39:50,905 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 20:39:50,906 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000000001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 20:39:50,907 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 50
    BG_IOU_THRESHOLD: 1e-09
    FG_IOU_THRESHOLD: 0.001
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.8
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 1e-09
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 20:39:52,660 maskrcnn_benchmark INFO: reloading weigts from r4_fin.pth
2020-12-12 20:39:54,960 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-12 20:39:54,961 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-12 20:39:54,961 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-12 20:39:54,961 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-12 20:39:54,961 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-12 20:39:54,961 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-12 20:39:55,139 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-12 20:39:55,612 maskrcnn_benchmark.trainer INFO: Start training
2020-12-12 20:41:12,830 maskrcnn_benchmark.trainer INFO: eta: 0:37:19  iter: 20  loss: 88.5107 (91.0430)  loss_classifier: 10.6718 (12.5515)  loss_box_reg: 6.8478 (7.4263)  loss_objectness: 9.7862 (9.9738)  loss_rpn_box_reg: 61.4264 (61.0915)  time: 3.8495 (3.8607)  data: 0.2374 (0.2387)  lr: 0.000000  max mem: 1317
2020-12-12 20:42:29,785 maskrcnn_benchmark.trainer INFO: eta: 0:35:58  iter: 40  loss: 91.7279 (91.9563)  loss_classifier: 10.8822 (12.0035)  loss_box_reg: 7.0900 (7.4540)  loss_objectness: 9.6027 (9.9915)  loss_rpn_box_reg: 63.8768 (62.5074)  time: 3.8450 (3.8542)  data: 0.2273 (0.2349)  lr: 0.000000  max mem: 1317
2020-12-12 20:43:46,769 maskrcnn_benchmark.trainer INFO: eta: 0:34:40  iter: 60  loss: 86.2392 (90.0601)  loss_classifier: 10.9186 (12.0458)  loss_box_reg: 5.1401 (7.0827)  loss_objectness: 9.1685 (9.7653)  loss_rpn_box_reg: 59.1238 (61.1664)  time: 3.8470 (3.8526)  data: 0.2342 (0.2339)  lr: 0.000000  max mem: 1317
2020-12-12 20:45:03,858 maskrcnn_benchmark.trainer INFO: eta: 0:33:23  iter: 80  loss: 92.1308 (90.4871)  loss_classifier: 12.0389 (12.2879)  loss_box_reg: 7.0138 (7.2112)  loss_objectness: 9.4345 (9.7156)  loss_rpn_box_reg: 59.6586 (61.2723)  time: 3.8554 (3.8530)  data: 0.2342 (0.2344)  lr: 0.000000  max mem: 1317
2020-12-12 20:46:20,374 maskrcnn_benchmark.trainer INFO: eta: 0:32:03  iter: 100  loss: 88.2314 (90.2297)  loss_classifier: 13.2079 (12.5108)  loss_box_reg: 7.1377 (7.2094)  loss_objectness: 9.9889 (9.7726)  loss_rpn_box_reg: 59.8479 (60.7368)  time: 3.8273 (3.8476)  data: 0.2326 (0.2344)  lr: 0.000000  max mem: 1317
2020-12-12 20:47:37,626 maskrcnn_benchmark.trainer INFO: eta: 0:30:48  iter: 120  loss: 88.7489 (90.1234)  loss_classifier: 12.6647 (12.7082)  loss_box_reg: 6.8207 (7.2514)  loss_objectness: 9.4611 (9.7216)  loss_rpn_box_reg: 57.9090 (60.4422)  time: 3.8474 (3.8501)  data: 0.2305 (0.2336)  lr: 0.000000  max mem: 1317
2020-12-12 20:48:54,755 maskrcnn_benchmark.trainer INFO: eta: 0:29:31  iter: 140  loss: 83.3286 (89.4661)  loss_classifier: 10.6667 (12.4536)  loss_box_reg: 6.4823 (7.2832)  loss_objectness: 9.2535 (9.6739)  loss_rpn_box_reg: 57.5195 (60.0553)  time: 3.8562 (3.8510)  data: 0.2300 (0.2331)  lr: 0.000000  max mem: 1317
2020-12-12 20:50:11,722 maskrcnn_benchmark.trainer INFO: eta: 0:28:14  iter: 160  loss: 86.2985 (89.0484)  loss_classifier: 11.1601 (12.3763)  loss_box_reg: 6.1767 (7.1448)  loss_objectness: 9.1080 (9.6112)  loss_rpn_box_reg: 58.3179 (59.9161)  time: 3.8503 (3.8507)  data: 0.2259 (0.2324)  lr: 0.000000  max mem: 1317
2020-12-12 20:51:28,477 maskrcnn_benchmark.trainer INFO: eta: 0:26:56  iter: 180  loss: 83.5548 (88.6430)  loss_classifier: 10.6782 (12.3088)  loss_box_reg: 6.1834 (7.0938)  loss_objectness: 9.0432 (9.5499)  loss_rpn_box_reg: 57.8592 (59.6905)  time: 3.8285 (3.8492)  data: 0.2351 (0.2327)  lr: 0.000000  max mem: 1317
2020-12-12 20:52:45,314 maskrcnn_benchmark.trainer INFO: eta: 0:25:39  iter: 200  loss: 84.4622 (88.2602)  loss_classifier: 10.7991 (12.2942)  loss_box_reg: 6.2694 (7.0853)  loss_objectness: 8.8715 (9.5023)  loss_rpn_box_reg: 55.7295 (59.3785)  time: 3.8437 (3.8485)  data: 0.2281 (0.2326)  lr: 0.000000  max mem: 1317
2020-12-12 20:52:45,316 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 20:52:45,340 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(1 images).
2020-12-12 20:52:46,869 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.528692 (1.5286922454833984 s / img per device, on 1 devices)
2020-12-12 20:52:46,869 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.387470 (1.3874702453613281 s / img per device, on 1 devices)
2020-12-12 20:52:46,869 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 20:52:46,970 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 20:52:46,970 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0041, 0.0000]), 'gt_labels': tensor([8, 8]), 'best match labels': tensor([8., 8.]), 'best match scores': tensor([1., 1.]), 'num_pos': 2}
2020-12-12 20:52:46,975 maskrcnn_benchmark.trainer INFO: validation accuracy: 1.000000
2020-12-12 20:52:46,978 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5.pth
2020-12-12 20:52:47,649 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5
2020-12-12 20:54:05,828 maskrcnn_benchmark.trainer INFO: eta: 0:24:28  iter: 220  loss: 79.0043 (87.4609)  loss_classifier: 11.5117 (12.2633)  loss_box_reg: 5.5782 (6.9600)  loss_objectness: 8.4533 (9.4119)  loss_rpn_box_reg: 53.3223 (58.8257)  time: 3.8744 (3.8646)  data: 0.2347 (0.2462)  lr: 0.000000  max mem: 1317
2020-12-12 20:55:22,955 maskrcnn_benchmark.trainer INFO: eta: 0:23:11  iter: 240  loss: 81.0347 (86.9379)  loss_classifier: 11.5042 (12.2541)  loss_box_reg: 5.2830 (6.8787)  loss_objectness: 8.4571 (9.3382)  loss_rpn_box_reg: 54.2190 (58.4669)  time: 3.8582 (3.8639)  data: 0.2363 (0.2453)  lr: 0.000000  max mem: 1317
2020-12-12 20:56:40,350 maskrcnn_benchmark.trainer INFO: eta: 0:21:53  iter: 260  loss: 80.8369 (86.5753)  loss_classifier: 12.1818 (12.2827)  loss_box_reg: 6.3791 (6.8846)  loss_objectness: 8.2769 (9.2669)  loss_rpn_box_reg: 54.9439 (58.1411)  time: 3.8689 (3.8644)  data: 0.2287 (0.2442)  lr: 0.000000  max mem: 1317
2020-12-12 20:57:57,395 maskrcnn_benchmark.trainer INFO: eta: 0:20:36  iter: 280  loss: 80.2377 (86.0189)  loss_classifier: 12.8487 (12.3603)  loss_box_reg: 5.7091 (6.8486)  loss_objectness: 8.3731 (9.2015)  loss_rpn_box_reg: 53.2664 (57.6086)  time: 3.8495 (3.8635)  data: 0.2356 (0.2436)  lr: 0.000000  max mem: 1317
2020-12-12 20:59:14,797 maskrcnn_benchmark.trainer INFO: eta: 0:19:19  iter: 300  loss: 83.0512 (85.7720)  loss_classifier: 12.3075 (12.3571)  loss_box_reg: 6.6933 (6.8489)  loss_objectness: 8.0812 (9.1125)  loss_rpn_box_reg: 54.9538 (57.4535)  time: 3.8722 (3.8639)  data: 0.2319 (0.2428)  lr: 0.000000  max mem: 1317
2020-12-12 21:00:31,962 maskrcnn_benchmark.trainer INFO: eta: 0:18:01  iter: 320  loss: 79.8353 (85.4361)  loss_classifier: 13.6727 (12.5177)  loss_box_reg: 6.1011 (6.8194)  loss_objectness: 7.8536 (9.0332)  loss_rpn_box_reg: 52.2597 (57.0657)  time: 3.8654 (3.8636)  data: 0.2311 (0.2422)  lr: 0.000000  max mem: 1317
2020-12-12 21:01:49,276 maskrcnn_benchmark.trainer INFO: eta: 0:16:44  iter: 340  loss: 76.4756 (85.0130)  loss_classifier: 14.2829 (12.6190)  loss_box_reg: 5.9090 (6.7878)  loss_objectness: 7.7207 (8.9490)  loss_rpn_box_reg: 49.6437 (56.6572)  time: 3.8662 (3.8637)  data: 0.2338 (0.2418)  lr: 0.000000  max mem: 1317
2020-12-12 21:03:06,331 maskrcnn_benchmark.trainer INFO: eta: 0:15:27  iter: 360  loss: 79.1928 (84.6650)  loss_classifier: 13.1999 (12.6725)  loss_box_reg: 6.5437 (6.8144)  loss_objectness: 7.5674 (8.8682)  loss_rpn_box_reg: 50.6212 (56.3100)  time: 3.8529 (3.8631)  data: 0.2297 (0.2412)  lr: 0.000000  max mem: 1317
2020-12-12 21:04:23,556 maskrcnn_benchmark.trainer INFO: eta: 0:14:09  iter: 380  loss: 74.1945 (84.1829)  loss_classifier: 15.3411 (12.8666)  loss_box_reg: 5.7890 (6.7649)  loss_objectness: 6.8495 (8.7775)  loss_rpn_box_reg: 45.4367 (55.7739)  time: 3.8533 (3.8630)  data: 0.2326 (0.2408)  lr: 0.000000  max mem: 1317
2020-12-12 21:05:40,891 maskrcnn_benchmark.trainer INFO: eta: 0:12:52  iter: 400  loss: 77.6382 (83.9400)  loss_classifier: 13.2557 (12.9548)  loss_box_reg: 5.9137 (6.7737)  loss_objectness: 7.5540 (8.7307)  loss_rpn_box_reg: 50.5938 (55.4809)  time: 3.8639 (3.8632)  data: 0.2302 (0.2403)  lr: 0.000000  max mem: 1317
2020-12-12 21:05:40,893 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 21:05:40,903 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(1 images).
2020-12-12 21:05:42,464 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.560852 (1.560851812362671 s / img per device, on 1 devices)
2020-12-12 21:05:42,465 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.406739 (1.406738519668579 s / img per device, on 1 devices)
2020-12-12 21:05:42,465 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 21:05:42,563 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 21:05:42,563 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0041, 0.0036]), 'gt_labels': tensor([8, 8]), 'best match labels': tensor([4., 8.]), 'best match scores': tensor([1., 1.]), 'num_pos': 2}
2020-12-12 21:05:42,567 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.500000
2020-12-12 21:06:59,899 maskrcnn_benchmark.trainer INFO: eta: 0:11:36  iter: 420  loss: 72.9076 (83.4617)  loss_classifier: 13.8091 (13.0326)  loss_box_reg: 5.3611 (6.7303)  loss_objectness: 6.9136 (8.6538)  loss_rpn_box_reg: 47.5092 (55.0449)  time: 3.8699 (3.8673)  data: 0.2329 (0.2441)  lr: 0.000000  max mem: 1317
2020-12-12 21:08:17,120 maskrcnn_benchmark.trainer INFO: eta: 0:10:18  iter: 440  loss: 73.6406 (83.1191)  loss_classifier: 16.4441 (13.1726)  loss_box_reg: 5.8153 (6.7275)  loss_objectness: 6.2217 (8.5626)  loss_rpn_box_reg: 46.4566 (54.6563)  time: 3.8585 (3.8671)  data: 0.2402 (0.2440)  lr: 0.000000  max mem: 1317
2020-12-12 21:09:34,153 maskrcnn_benchmark.trainer INFO: eta: 0:09:01  iter: 460  loss: 74.3025 (82.7168)  loss_classifier: 13.1481 (13.1812)  loss_box_reg: 5.4635 (6.6585)  loss_objectness: 6.7114 (8.4837)  loss_rpn_box_reg: 49.9223 (54.3933)  time: 3.8481 (3.8664)  data: 0.2357 (0.2437)  lr: 0.000000  max mem: 1317
2020-12-12 21:10:51,484 maskrcnn_benchmark.trainer INFO: eta: 0:07:43  iter: 480  loss: 70.7974 (82.2285)  loss_classifier: 13.2399 (13.2138)  loss_box_reg: 5.2945 (6.5961)  loss_objectness: 6.6561 (8.4073)  loss_rpn_box_reg: 44.9812 (54.0112)  time: 3.8640 (3.8664)  data: 0.2312 (0.2433)  lr: 0.000000  max mem: 1317
2020-12-12 21:12:08,753 maskrcnn_benchmark.trainer INFO: eta: 0:06:26  iter: 500  loss: 75.1227 (81.9419)  loss_classifier: 16.0695 (13.3783)  loss_box_reg: 5.4599 (6.5801)  loss_objectness: 6.3298 (8.3246)  loss_rpn_box_reg: 45.6997 (53.6588)  time: 3.8611 (3.8663)  data: 0.2356 (0.2430)  lr: 0.000000  max mem: 1317
2020-12-12 21:13:25,980 maskrcnn_benchmark.trainer INFO: eta: 0:05:09  iter: 520  loss: 73.2728 (81.5617)  loss_classifier: 15.6293 (13.4692)  loss_box_reg: 5.9206 (6.5381)  loss_objectness: 6.7424 (8.2653)  loss_rpn_box_reg: 43.2912 (53.2890)  time: 3.8486 (3.8661)  data: 0.2357 (0.2430)  lr: 0.000000  max mem: 1317
2020-12-12 21:14:43,710 maskrcnn_benchmark.trainer INFO: eta: 0:03:52  iter: 540  loss: 70.8165 (81.1305)  loss_classifier: 14.8346 (13.5233)  loss_box_reg: 5.3005 (6.5056)  loss_objectness: 5.8804 (8.1846)  loss_rpn_box_reg: 43.5454 (52.9170)  time: 3.8796 (3.8668)  data: 0.2372 (0.2429)  lr: 0.000000  max mem: 1317
2020-12-12 21:16:03,326 maskrcnn_benchmark.trainer INFO: eta: 0:02:34  iter: 560  loss: 71.5628 (80.8061)  loss_classifier: 16.8586 (13.6189)  loss_box_reg: 5.6148 (6.4863)  loss_objectness: 5.9993 (8.1037)  loss_rpn_box_reg: 43.3461 (52.5972)  time: 4.0205 (3.8709)  data: 0.2415 (0.2430)  lr: 0.000000  max mem: 1317
2020-12-12 21:17:20,641 maskrcnn_benchmark.trainer INFO: eta: 0:01:17  iter: 580  loss: 67.0131 (80.3684)  loss_classifier: 16.1382 (13.7148)  loss_box_reg: 5.5519 (6.4549)  loss_objectness: 4.9876 (8.0047)  loss_rpn_box_reg: 41.3331 (52.1940)  time: 3.8578 (3.8707)  data: 0.2350 (0.2427)  lr: 0.000000  max mem: 1317
2020-12-12 21:18:37,625 maskrcnn_benchmark.trainer INFO: eta: 0:00:00  iter: 600  loss: 69.8701 (80.0156)  loss_classifier: 16.6466 (13.8248)  loss_box_reg: 6.3211 (6.4473)  loss_objectness: 5.1949 (7.9187)  loss_rpn_box_reg: 41.7680 (51.8248)  time: 3.8474 (3.8700)  data: 0.2286 (0.2423)  lr: 0.000000  max mem: 1317
2020-12-12 21:18:37,627 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 21:18:37,637 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_valid dataset(1 images).
2020-12-12 21:18:39,203 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.566202 (1.5662024021148682 s / img per device, on 1 devices)
2020-12-12 21:18:39,203 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.411465 (1.4114646911621094 s / img per device, on 1 devices)
2020-12-12 21:18:39,204 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 21:18:39,305 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 21:18:39,305 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0059, 0.0036]), 'gt_labels': tensor([8, 8]), 'best match labels': tensor([4., 8.]), 'best match scores': tensor([1., 1.]), 'num_pos': 2}
2020-12-12 21:18:39,309 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.500000
2020-12-12 21:18:39,314 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./final_mode_r5.pth
2020-12-12 21:18:39,964 maskrcnn_benchmark.trainer INFO: final model, saving model to: final_mode_r5
2020-12-12 21:18:39,964 maskrcnn_benchmark.trainer INFO: Total training time: 0:38:44.349270 (3.8739 s / it)
2020-12-12 21:18:43,044 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_test dataset(258 images).
2020-12-12 21:25:15,084 maskrcnn_benchmark.inference INFO: Total run time: 0:06:32.038989 (1.5195309663003729 s / img per device, on 1 devices)
2020-12-12 21:25:15,084 maskrcnn_benchmark.inference INFO: Model inference time: 0:06:01.956675 (1.4029328481171481 s / img per device, on 1 devices)
2020-12-12 21:25:15,126 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 21:25:42,837 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 21:25:42,837 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0441, 0.0330, 0.0061,  ..., 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([7, 7, 4,  ..., 2, 2, 2]), 'best match labels': tensor([8., 4., 8.,  ..., 8., 8., 8.]), 'best match scores': tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 0.9987, 1.0000]), 'num_pos': 1516}
2020-12-12 21:25:42,843 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_test dataset(7 images).
2020-12-12 21:25:53,513 maskrcnn_benchmark.inference INFO: Total run time: 0:00:10.669781 (1.524254390171596 s / img per device, on 1 devices)
2020-12-12 21:25:53,514 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:09.890661 (1.4129516056605749 s / img per device, on 1 devices)
2020-12-12 21:25:53,515 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 21:25:54,264 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 21:25:54,265 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([2.4039e-02, 3.2013e-03, 2.5005e-06, 3.1660e-02, 1.4439e-02, 3.2013e-03,
        7.7120e-03, 4.1396e-03, 8.8090e-03, 3.5856e-03, 1.1559e-02, 3.2427e-03,
        3.1242e-03, 4.1396e-03, 2.0069e-04, 2.4627e-02, 6.3586e-03, 3.2427e-03]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([7., 8., 4., 7., 4., 4., 8., 8., 8., 8., 8., 7., 8., 8., 8., 8., 8., 4.]), 'best match scores': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'num_pos': 18}
2020-12-12 21:25:54,272 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_test dataset(3 images).
2020-12-12 21:25:58,874 maskrcnn_benchmark.inference INFO: Total run time: 0:00:04.601801 (1.5339337189992268 s / img per device, on 1 devices)
2020-12-12 21:25:58,875 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:04.229273 (1.4097576936086018 s / img per device, on 1 devices)
2020-12-12 21:25:58,875 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 21:25:59,194 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 21:25:59,195 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([2.4114e-02, 1.6865e-03, 1.5605e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.2914e-03, 1.1537e-03, 6.9510e-05, 5.0388e-05,
        1.4767e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8822e-04, 1.7211e-04,
        1.0040e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1]), 'best match labels': tensor([7., 4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.,
        8., 8., 8., 8., 7., 8., 8.]), 'best match scores': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1.]), 'num_pos': 25}
2020-12-12 21:29:18,613 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 21:29:18,613 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='draw_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, threshold=0.9, weights='visdrone_model_0360000.pth')
2020-12-12 21:29:18,613 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 21:29:27,100 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 21:29:27,101 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 21:29:27,102 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000000001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 21:29:27,105 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 1e-09
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 21:29:28,821 maskrcnn_benchmark INFO: reloading weigts from r5_after_small_lr.pth
2020-12-12 21:35:25,240 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 21:35:25,240 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 21:35:25,240 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 21:35:27,510 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 21:35:27,510 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 21:35:27,510 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000000005
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 21:35:27,511 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 40
    BG_IOU_THRESHOLD: 0.001
    FG_IOU_THRESHOLD: 0.02
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.6
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 5e-09
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 21:35:29,236 maskrcnn_benchmark INFO: reloading weigts from r5_after_small_lr.pth
2020-12-12 21:35:31,463 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-12 21:35:31,463 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-12 21:35:31,463 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-12 21:35:31,463 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-12 21:35:31,464 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-12 21:35:31,464 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-12 21:35:31,640 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-12 21:35:43,507 maskrcnn_benchmark.trainer INFO: Start training
2020-12-12 21:37:02,087 maskrcnn_benchmark.trainer INFO: eta: 0:37:58  iter: 20  loss: 62.3842 (61.8605)  loss_classifier: 16.1673 (16.6747)  loss_box_reg: 6.0777 (6.7309)  loss_objectness: 4.6038 (4.8913)  loss_rpn_box_reg: 32.5201 (33.5636)  time: 3.8514 (3.9285)  data: 0.2302 (0.2385)  lr: 0.000000  max mem: 1317
2020-12-12 21:38:24,478 maskrcnn_benchmark.trainer INFO: eta: 0:37:33  iter: 40  loss: 57.9975 (59.3352)  loss_classifier: 15.0153 (16.2569)  loss_box_reg: 4.8899 (5.9451)  loss_objectness: 4.6158 (4.7772)  loss_rpn_box_reg: 30.1251 (32.3559)  time: 4.1515 (4.0241)  data: 0.2433 (0.2423)  lr: 0.000000  max mem: 1317
2020-12-12 21:39:44,457 maskrcnn_benchmark.trainer INFO: eta: 0:36:08  iter: 60  loss: 58.2223 (59.3517)  loss_classifier: 16.6421 (16.6003)  loss_box_reg: 5.5209 (6.0296)  loss_objectness: 4.0010 (4.6751)  loss_rpn_box_reg: 30.7914 (32.0467)  time: 3.9457 (4.0157)  data: 0.2355 (0.2422)  lr: 0.000000  max mem: 1317
2020-12-12 21:41:04,972 maskrcnn_benchmark.trainer INFO: eta: 0:34:49  iter: 80  loss: 57.3566 (58.8094)  loss_classifier: 15.2630 (16.4874)  loss_box_reg: 5.4841 (5.9970)  loss_objectness: 4.4053 (4.5883)  loss_rpn_box_reg: 31.1521 (31.7367)  time: 3.9259 (4.0182)  data: 0.2445 (0.2442)  lr: 0.000000  max mem: 1317
2020-12-12 21:42:23,126 maskrcnn_benchmark.trainer INFO: eta: 0:33:18  iter: 100  loss: 58.4320 (58.4657)  loss_classifier: 15.6581 (16.4437)  loss_box_reg: 5.5886 (5.8733)  loss_objectness: 4.1470 (4.4918)  loss_rpn_box_reg: 31.6619 (31.6568)  time: 3.8748 (3.9961)  data: 0.2401 (0.2439)  lr: 0.000000  max mem: 1317
2020-12-12 21:43:43,031 maskrcnn_benchmark.trainer INFO: eta: 0:31:58  iter: 120  loss: 52.0606 (57.9901)  loss_classifier: 16.2248 (16.5903)  loss_box_reg: 5.3280 (5.7577)  loss_objectness: 3.8830 (4.4229)  loss_rpn_box_reg: 28.5892 (31.2192)  time: 3.9932 (3.9960)  data: 0.2430 (0.2455)  lr: 0.000000  max mem: 1317
2020-12-12 21:45:02,140 maskrcnn_benchmark.trainer INFO: eta: 0:30:35  iter: 140  loss: 57.7899 (57.9221)  loss_classifier: 19.9727 (16.9827)  loss_box_reg: 5.3825 (5.7784)  loss_objectness: 3.6545 (4.3344)  loss_rpn_box_reg: 26.5525 (30.8266)  time: 3.8869 (3.9902)  data: 0.2330 (0.2449)  lr: 0.000000  max mem: 1317
2020-12-12 21:46:23,965 maskrcnn_benchmark.trainer INFO: eta: 0:29:21  iter: 160  loss: 54.3792 (57.3280)  loss_classifier: 18.2394 (17.2177)  loss_box_reg: 3.7925 (5.6574)  loss_objectness: 3.6526 (4.2776)  loss_rpn_box_reg: 24.7162 (30.1753)  time: 4.1459 (4.0028)  data: 0.2499 (0.2459)  lr: 0.000000  max mem: 1317
2020-12-12 21:47:46,220 maskrcnn_benchmark.trainer INFO: eta: 0:28:06  iter: 180  loss: 57.6024 (57.3721)  loss_classifier: 19.6376 (17.5187)  loss_box_reg: 6.2648 (5.7788)  loss_objectness: 3.6194 (4.2249)  loss_rpn_box_reg: 26.4597 (29.8496)  time: 4.1383 (4.0150)  data: 0.2576 (0.2483)  lr: 0.000000  max mem: 1317
2020-12-12 21:49:05,290 maskrcnn_benchmark.trainer INFO: eta: 0:26:43  iter: 200  loss: 56.4733 (57.0200)  loss_classifier: 19.9195 (17.7674)  loss_box_reg: 5.4561 (5.7527)  loss_objectness: 3.2574 (4.1505)  loss_rpn_box_reg: 25.3827 (29.3494)  time: 3.9107 (4.0089)  data: 0.2406 (0.2476)  lr: 0.000000  max mem: 1317
2020-12-12 21:49:05,292 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 21:49:05,335 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 21:49:11,765 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.429825 (1.6074563264846802 s / img per device, on 1 devices)
2020-12-12 21:49:11,765 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.972908 (1.4932270646095276 s / img per device, on 1 devices)
2020-12-12 21:49:11,766 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 21:49:12,204 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 21:49:12,204 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.9484e-03, 4.0532e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.0252e-02, 3.7310e-03, 1.5625e-03, 1.5080e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6000e-02, 7.1318e-03, 1.6865e-03,
        1.5605e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1484e-03,
        2.0022e-03, 1.5625e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([8., 8., 8., 8., 8., 4., 8., 8., 8., 7., 8., 8., 7., 4., 4., 7., 4., 8.,
        8., 8., 8., 8., 7., 8., 8., 8., 8., 7., 8., 4.]), 'best match scores': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'num_pos': 30}
2020-12-12 21:49:12,215 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-12 21:49:12,218 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v2.pth
2020-12-12 21:49:13,016 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v2
2020-12-12 21:50:35,372 maskrcnn_benchmark.trainer INFO: eta: 0:25:40  iter: 220  loss: 56.2014 (56.8988)  loss_classifier: 19.8632 (18.0572)  loss_box_reg: 5.0157 (5.8419)  loss_objectness: 3.1173 (4.0610)  loss_rpn_box_reg: 24.7998 (28.9387)  time: 4.0932 (4.0539)  data: 0.2579 (0.2876)  lr: 0.000000  max mem: 1317
2020-12-12 21:51:54,706 maskrcnn_benchmark.trainer INFO: eta: 0:24:16  iter: 240  loss: 58.3558 (56.7939)  loss_classifier: 20.6093 (18.3490)  loss_box_reg: 5.8177 (5.8358)  loss_objectness: 3.0924 (3.9895)  loss_rpn_box_reg: 24.6198 (28.6196)  time: 3.8970 (4.0466)  data: 0.2458 (0.2843)  lr: 0.000000  max mem: 1317
2020-12-12 21:53:16,282 maskrcnn_benchmark.trainer INFO: eta: 0:22:56  iter: 260  loss: 55.8287 (56.6884)  loss_classifier: 22.1567 (18.6211)  loss_box_reg: 6.0296 (5.8715)  loss_objectness: 3.0552 (3.9189)  loss_rpn_box_reg: 23.4292 (28.2769)  time: 4.1051 (4.0491)  data: 0.2506 (0.2818)  lr: 0.000000  max mem: 1317
2020-12-12 21:54:36,516 maskrcnn_benchmark.trainer INFO: eta: 0:21:34  iter: 280  loss: 51.5769 (56.3920)  loss_classifier: 22.0605 (18.8945)  loss_box_reg: 4.4720 (5.8164)  loss_objectness: 3.1604 (3.8631)  loss_rpn_box_reg: 21.0582 (27.8180)  time: 4.0279 (4.0464)  data: 0.2499 (0.2807)  lr: 0.000000  max mem: 1317
2020-12-12 21:55:56,131 maskrcnn_benchmark.trainer INFO: eta: 0:20:12  iter: 300  loss: 54.0150 (56.2510)  loss_classifier: 22.5658 (19.1643)  loss_box_reg: 5.6809 (5.8662)  loss_objectness: 3.1591 (3.8147)  loss_rpn_box_reg: 21.0478 (27.4058)  time: 3.9225 (4.0421)  data: 0.2455 (0.2784)  lr: 0.000000  max mem: 1317
2020-12-12 21:57:19,235 maskrcnn_benchmark.trainer INFO: eta: 0:18:53  iter: 320  loss: 52.7526 (56.1329)  loss_classifier: 21.1446 (19.3620)  loss_box_reg: 5.6294 (5.9008)  loss_objectness: 2.9583 (3.7777)  loss_rpn_box_reg: 22.5838 (27.0924)  time: 4.1296 (4.0491)  data: 0.2743 (0.2784)  lr: 0.000000  max mem: 1317
2020-12-12 21:58:40,960 maskrcnn_benchmark.trainer INFO: eta: 0:17:33  iter: 340  loss: 52.8331 (55.9463)  loss_classifier: 23.6271 (19.5970)  loss_box_reg: 5.4451 (5.8734)  loss_objectness: 2.7625 (3.7262)  loss_rpn_box_reg: 19.6455 (26.7497)  time: 4.0826 (4.0513)  data: 0.2624 (0.2775)  lr: 0.000000  max mem: 1317
2020-12-12 22:00:00,308 maskrcnn_benchmark.trainer INFO: eta: 0:16:11  iter: 360  loss: 53.3911 (55.8370)  loss_classifier: 24.5831 (19.8547)  loss_box_reg: 6.0961 (5.9164)  loss_objectness: 2.7781 (3.6783)  loss_rpn_box_reg: 20.1235 (26.3877)  time: 3.9035 (4.0466)  data: 0.2397 (0.2760)  lr: 0.000000  max mem: 1317
2020-12-12 22:01:20,844 maskrcnn_benchmark.trainer INFO: eta: 0:14:50  iter: 380  loss: 49.9792 (55.6096)  loss_classifier: 22.5231 (20.0031)  loss_box_reg: 5.5887 (5.9172)  loss_objectness: 2.5370 (3.6237)  loss_rpn_box_reg: 20.2257 (26.0656)  time: 4.0243 (4.0456)  data: 0.2420 (0.2749)  lr: 0.000000  max mem: 1317
2020-12-12 22:02:41,131 maskrcnn_benchmark.trainer INFO: eta: 0:13:28  iter: 400  loss: 51.7076 (55.4959)  loss_classifier: 23.7408 (20.2024)  loss_box_reg: 5.6397 (5.9623)  loss_objectness: 2.4971 (3.5768)  loss_rpn_box_reg: 20.4714 (25.7544)  time: 3.9993 (4.0440)  data: 0.2503 (0.2739)  lr: 0.000000  max mem: 1317
2020-12-12 22:02:41,133 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 22:02:41,144 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 22:02:47,702 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.557484 (1.6393709182739258 s / img per device, on 1 devices)
2020-12-12 22:02:47,702 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:06.046232 (1.5115578770637512 s / img per device, on 1 devices)
2020-12-12 22:02:47,702 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 22:02:48,185 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 22:02:48,185 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0030, 0.0017, 0.0016, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0017,
        0.0016, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0102, 0.0017, 0.0016,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0100, 0.0061, 0.0027, 0.0015,
        0.0014, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([8., 4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 7., 4., 8., 7., 4., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 7., 8., 8., 4.]), 'best match scores': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'num_pos': 30}
2020-12-12 22:02:48,194 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-12 22:04:09,213 maskrcnn_benchmark.trainer INFO: eta: 0:12:11  iter: 420  loss: 51.9222 (55.3375)  loss_classifier: 24.1802 (20.3852)  loss_box_reg: 5.9993 (6.0113)  loss_objectness: 2.6187 (3.5285)  loss_rpn_box_reg: 18.5439 (25.4124)  time: 4.0497 (4.0612)  data: 0.2539 (0.2900)  lr: 0.000000  max mem: 1317
2020-12-12 22:05:29,898 maskrcnn_benchmark.trainer INFO: eta: 0:10:49  iter: 440  loss: 49.7923 (55.0638)  loss_classifier: 22.6996 (20.4953)  loss_box_reg: 5.4686 (5.9829)  loss_objectness: 2.3423 (3.4828)  loss_rpn_box_reg: 19.1291 (25.1028)  time: 4.0107 (4.0600)  data: 0.2581 (0.2891)  lr: 0.000000  max mem: 1317
2020-12-12 22:06:49,894 maskrcnn_benchmark.trainer INFO: eta: 0:09:28  iter: 460  loss: 48.5635 (54.8348)  loss_classifier: 21.5154 (20.5529)  loss_box_reg: 5.7369 (6.0108)  loss_objectness: 2.3958 (3.4404)  loss_rpn_box_reg: 18.2510 (24.8307)  time: 3.9260 (4.0573)  data: 0.2437 (0.2877)  lr: 0.000000  max mem: 1317
2020-12-12 22:08:09,063 maskrcnn_benchmark.trainer INFO: eta: 0:08:06  iter: 480  loss: 45.2127 (54.4449)  loss_classifier: 20.0365 (20.5225)  loss_box_reg: 5.5294 (5.9971)  loss_objectness: 2.2630 (3.4014)  loss_rpn_box_reg: 16.9629 (24.5239)  time: 3.9283 (4.0532)  data: 0.2473 (0.2861)  lr: 0.000000  max mem: 1317
2020-12-12 22:09:29,561 maskrcnn_benchmark.trainer INFO: eta: 0:06:45  iter: 500  loss: 47.9334 (54.1955)  loss_classifier: 21.3652 (20.5547)  loss_box_reg: 5.2381 (5.9931)  loss_objectness: 2.1829 (3.3606)  loss_rpn_box_reg: 18.3249 (24.2871)  time: 4.0165 (4.0521)  data: 0.2558 (0.2848)  lr: 0.000000  max mem: 1317
2020-12-12 22:10:50,899 maskrcnn_benchmark.trainer INFO: eta: 0:05:24  iter: 520  loss: 47.3063 (53.9403)  loss_classifier: 20.9708 (20.5536)  loss_box_reg: 5.6312 (6.0072)  loss_objectness: 2.2185 (3.3191)  loss_rpn_box_reg: 18.2410 (24.0604)  time: 4.1012 (4.0527)  data: 0.2571 (0.2838)  lr: 0.000000  max mem: 1317
2020-12-12 22:12:11,031 maskrcnn_benchmark.trainer INFO: eta: 0:04:03  iter: 540  loss: 47.9955 (53.7584)  loss_classifier: 22.4177 (20.6337)  loss_box_reg: 6.3155 (6.0336)  loss_objectness: 2.1520 (3.2777)  loss_rpn_box_reg: 17.0630 (23.8135)  time: 3.9447 (4.0510)  data: 0.2619 (0.2829)  lr: 0.000000  max mem: 1317
2020-12-12 22:13:34,010 maskrcnn_benchmark.trainer INFO: eta: 0:02:42  iter: 560  loss: 43.4908 (53.4613)  loss_classifier: 21.3629 (20.6384)  loss_box_reg: 5.5817 (6.0364)  loss_objectness: 1.9543 (3.2344)  loss_rpn_box_reg: 16.0935 (23.5520)  time: 4.1288 (4.0545)  data: 0.2830 (0.2834)  lr: 0.000000  max mem: 1317
2020-12-12 22:14:55,956 maskrcnn_benchmark.trainer INFO: eta: 0:01:21  iter: 580  loss: 42.8318 (53.0921)  loss_classifier: 21.1066 (20.6442)  loss_box_reg: 3.4640 (5.9856)  loss_objectness: 1.9109 (3.1930)  loss_rpn_box_reg: 14.2914 (23.2693)  time: 4.1151 (4.0559)  data: 0.2736 (0.2834)  lr: 0.000000  max mem: 1317
2020-12-12 22:16:17,728 maskrcnn_benchmark.trainer INFO: eta: 0:00:00  iter: 600  loss: 45.7740 (52.8774)  loss_classifier: 20.7607 (20.6487)  loss_box_reg: 5.3056 (5.9894)  loss_objectness: 2.5048 (3.1696)  loss_rpn_box_reg: 17.2063 (23.0697)  time: 4.1029 (4.0570)  data: 0.2627 (0.2830)  lr: 0.000000  max mem: 1317
2020-12-12 22:16:17,730 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 22:16:17,741 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 22:16:24,023 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.281232 (1.5703080296516418 s / img per device, on 1 devices)
2020-12-12 22:16:24,023 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.798164 (1.4495410919189453 s / img per device, on 1 devices)
2020-12-12 22:16:24,023 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 22:16:24,465 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 22:16:24,466 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.7170e-02, 1.6740e-03, 1.5061e-03, 1.5845e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.6557e-03, 3.6299e-03, 1.5625e-03, 1.5080e-03,
        1.4526e-03, 0.0000e+00, 0.0000e+00, 2.7313e-02, 8.7830e-03, 3.3639e-03,
        1.6865e-03, 1.5061e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1079e-02,
        5.4207e-03, 4.3102e-03, 1.5625e-03, 1.5080e-03, 1.4249e-03, 0.0000e+00]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([8., 4., 8., 8., 8., 8., 8., 7., 4., 8., 4., 8., 8., 7., 4., 7., 8., 4.,
        8., 8., 8., 8., 8., 8., 8., 4., 4., 8., 7., 4.]), 'best match scores': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'num_pos': 30}
2020-12-12 22:16:24,476 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-12 22:16:24,481 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./final_mode_r5_v2.pth
2020-12-12 22:16:25,324 maskrcnn_benchmark.trainer INFO: final model, saving model to: final_mode_r5_v2
2020-12-12 22:16:25,335 maskrcnn_benchmark.trainer INFO: Total training time: 0:40:41.819187 (4.0697 s / it)
2020-12-12 22:16:26,912 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_test dataset(258 images).
2020-12-12 22:23:01,455 maskrcnn_benchmark.inference INFO: Total run time: 0:06:34.542484 (1.5292344324348508 s / img per device, on 1 devices)
2020-12-12 22:23:01,455 maskrcnn_benchmark.inference INFO: Model inference time: 0:06:05.681985 (1.4173720345016598 s / img per device, on 1 devices)
2020-12-12 22:23:01,496 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 22:23:30,012 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 22:23:30,012 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1397, 0.0441, 0.0425,  ..., 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([7, 7, 4,  ..., 2, 2, 2]), 'best match labels': tensor([7., 8., 8.,  ..., 8., 8., 8.]), 'best match scores': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'num_pos': 1516}
2020-12-12 22:23:30,018 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_test dataset(7 images).
2020-12-12 22:23:40,722 maskrcnn_benchmark.inference INFO: Total run time: 0:00:10.704586 (1.529226507459368 s / img per device, on 1 devices)
2020-12-12 22:23:40,723 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:09.892816 (1.4132593699863978 s / img per device, on 1 devices)
2020-12-12 22:23:40,724 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 22:23:41,494 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 22:23:41,495 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0321, 0.0065, 0.0041, 0.1114, 0.0135, 0.0050, 0.0137, 0.0036, 0.0218,
        0.0074, 0.0106, 0.0032, 0.0031, 0.0056, 0.0036, 0.0040, 0.0032, 0.0031]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([7., 7., 8., 7., 4., 7., 8., 8., 8., 8., 8., 7., 4., 8., 4., 8., 7., 8.]), 'best match scores': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'num_pos': 18}
2020-12-12 22:23:41,502 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_test dataset(3 images).
2020-12-12 22:23:46,090 maskrcnn_benchmark.inference INFO: Total run time: 0:00:04.588001 (1.5293336709340413 s / img per device, on 1 devices)
2020-12-12 22:23:46,091 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:04.231534 (1.4105112552642822 s / img per device, on 1 devices)
2020-12-12 22:23:46,091 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 22:23:46,410 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 22:23:46,411 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0464, 0.0251, 0.0122, 0.0047, 0.0019, 0.0012, 0.0000, 0.0000, 0.0063,
        0.0045, 0.0028, 0.0021, 0.0020, 0.0010, 0.0000, 0.0000, 0.0041, 0.0030,
        0.0014, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1]), 'best match labels': tensor([7., 4., 4., 8., 8., 8., 8., 7., 8., 4., 8., 8., 4., 4., 8., 8., 8., 4.,
        8., 8., 4., 4., 7., 8., 8.]), 'best match scores': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1.]), 'num_pos': 25}
2020-12-12 22:24:56,984 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 22:24:56,984 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='draw_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, threshold=0.9, weights='visdrone_model_0360000.pth')
2020-12-12 22:24:56,984 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 22:25:00,840 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 22:25:00,841 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 22:25:00,842 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000000005
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 22:25:00,845 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 5e-09
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 22:25:02,610 maskrcnn_benchmark INFO: reloading weigts from final_mode_r5_v2.pth
2020-12-12 22:34:10,798 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-12 22:34:10,812 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-12 22:34:10,812 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-12 22:34:14,822 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-12 22:34:14,823 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-12 22:34:14,824 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000000003
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-12 22:34:14,827 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 40
    BG_IOU_THRESHOLD: 0.001
    FG_IOU_THRESHOLD: 0.02
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.6
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 3e-09
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-12 22:34:16,696 maskrcnn_benchmark INFO: reloading weigts from r5_after_small_lr.pth
2020-12-12 22:34:25,747 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-12 22:34:25,748 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-12 22:34:25,748 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-12 22:34:25,748 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-12 22:34:25,748 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-12 22:34:25,748 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-12 22:34:25,923 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-12 22:34:49,112 maskrcnn_benchmark.trainer INFO: Start training
2020-12-12 22:36:08,541 maskrcnn_benchmark.trainer INFO: eta: 0:38:23  iter: 20  loss: 71.0993 (71.8002)  loss_classifier: 17.9903 (18.4654)  loss_box_reg: 5.3876 (6.0061)  loss_objectness: 4.9334 (5.0744)  loss_rpn_box_reg: 43.1404 (42.2543)  time: 3.8645 (3.9710)  data: 0.2330 (0.2504)  lr: 0.000000  max mem: 1317
2020-12-12 22:37:25,817 maskrcnn_benchmark.trainer INFO: eta: 0:36:33  iter: 40  loss: 68.8466 (68.5684)  loss_classifier: 15.4685 (17.2825)  loss_box_reg: 5.5743 (5.8054)  loss_objectness: 4.1450 (4.7491)  loss_rpn_box_reg: 40.5052 (40.7313)  time: 3.8600 (3.9174)  data: 0.2301 (0.2427)  lr: 0.000000  max mem: 1317
2020-12-12 22:38:45,884 maskrcnn_benchmark.trainer INFO: eta: 0:35:30  iter: 60  loss: 64.7824 (67.7358)  loss_classifier: 16.5302 (17.0250)  loss_box_reg: 5.5470 (5.8221)  loss_objectness: 4.5285 (4.6547)  loss_rpn_box_reg: 38.8278 (40.2340)  time: 3.9935 (3.9461)  data: 0.2403 (0.2439)  lr: 0.000000  max mem: 1317
2020-12-12 22:40:08,157 maskrcnn_benchmark.trainer INFO: eta: 0:34:33  iter: 80  loss: 66.1128 (67.4607)  loss_classifier: 15.6688 (16.7827)  loss_box_reg: 5.6552 (5.8821)  loss_objectness: 4.5043 (4.6239)  loss_rpn_box_reg: 39.2807 (40.1720)  time: 4.1226 (3.9880)  data: 0.2475 (0.2452)  lr: 0.000000  max mem: 1317
2020-12-12 22:41:26,291 maskrcnn_benchmark.trainer INFO: eta: 0:33:05  iter: 100  loss: 64.1009 (67.3989)  loss_classifier: 18.4715 (17.1433)  loss_box_reg: 4.1040 (5.8318)  loss_objectness: 4.4169 (4.5666)  loss_rpn_box_reg: 38.8998 (39.8572)  time: 3.8849 (3.9717)  data: 0.2408 (0.2449)  lr: 0.000000  max mem: 1317
2020-12-12 22:42:44,028 maskrcnn_benchmark.trainer INFO: eta: 0:31:39  iter: 120  loss: 69.6884 (67.3491)  loss_classifier: 17.0087 (17.2362)  loss_box_reg: 5.8026 (5.9154)  loss_objectness: 4.2620 (4.5381)  loss_rpn_box_reg: 38.3177 (39.6594)  time: 3.8849 (3.9576)  data: 0.2380 (0.2437)  lr: 0.000000  max mem: 1317
2020-12-12 22:44:01,865 maskrcnn_benchmark.trainer INFO: eta: 0:30:16  iter: 140  loss: 66.8300 (67.1068)  loss_classifier: 17.9559 (17.3289)  loss_box_reg: 5.8243 (5.9120)  loss_objectness: 4.2853 (4.5090)  loss_rpn_box_reg: 37.3446 (39.3568)  time: 3.8882 (3.9482)  data: 0.2391 (0.2439)  lr: 0.000000  max mem: 1317
2020-12-12 22:45:20,000 maskrcnn_benchmark.trainer INFO: eta: 0:28:54  iter: 160  loss: 64.9586 (67.0874)  loss_classifier: 18.0092 (17.5120)  loss_box_reg: 5.4335 (5.8891)  loss_objectness: 4.0858 (4.4623)  loss_rpn_box_reg: 38.1100 (39.2239)  time: 3.8930 (3.9430)  data: 0.2416 (0.2444)  lr: 0.000000  max mem: 1317
2020-12-12 22:46:39,777 maskrcnn_benchmark.trainer INFO: eta: 0:27:38  iter: 180  loss: 62.7556 (66.7588)  loss_classifier: 17.3424 (17.5488)  loss_box_reg: 5.8148 (5.9561)  loss_objectness: 3.7641 (4.4038)  loss_rpn_box_reg: 35.9118 (38.8501)  time: 3.9339 (3.9481)  data: 0.2626 (0.2464)  lr: 0.000000  max mem: 1317
2020-12-12 22:48:00,426 maskrcnn_benchmark.trainer INFO: eta: 0:26:22  iter: 200  loss: 64.6026 (66.4694)  loss_classifier: 19.0292 (17.7519)  loss_box_reg: 5.3135 (5.8931)  loss_objectness: 3.8989 (4.3558)  loss_rpn_box_reg: 34.7730 (38.4685)  time: 4.0376 (3.9565)  data: 0.2458 (0.2474)  lr: 0.000000  max mem: 1317
2020-12-12 22:48:00,428 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 22:48:00,463 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 22:48:06,785 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.321930 (1.580482542514801 s / img per device, on 1 devices)
2020-12-12 22:48:06,785 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.758584 (1.4396460056304932 s / img per device, on 1 devices)
2020-12-12 22:48:06,785 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 22:48:07,275 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 22:48:07,275 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.6865e-03, 3.2296e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 5.5260e-03, 3.8970e-03, 1.5625e-03, 1.5080e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7959e-02, 1.6865e-03, 1.5605e-03,
        4.6708e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0523e-03,
        1.5625e-03, 1.5080e-03, 1.5300e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([8., 8., 8., 8., 8., 4., 8., 7., 8., 8., 4., 8., 8., 7., 4., 7., 4., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 7., 4.]), 'best match scores': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'num_pos': 30}
2020-12-12 22:48:07,304 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-12 22:48:07,307 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v3.pth
2020-12-12 22:48:08,054 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v3
2020-12-12 22:49:28,655 maskrcnn_benchmark.trainer INFO: eta: 0:25:19  iter: 220  loss: 62.8166 (66.4926)  loss_classifier: 19.0034 (17.9782)  loss_box_reg: 5.4093 (5.9216)  loss_objectness: 3.8376 (4.3143)  loss_rpn_box_reg: 35.1673 (38.2786)  time: 3.9512 (3.9979)  data: 0.2401 (0.2857)  lr: 0.000000  max mem: 1317
2020-12-12 22:50:47,601 maskrcnn_benchmark.trainer INFO: eta: 0:23:57  iter: 240  loss: 62.3889 (66.2401)  loss_classifier: 18.6736 (18.1148)  loss_box_reg: 5.7726 (5.9719)  loss_objectness: 3.6621 (4.2687)  loss_rpn_box_reg: 33.8131 (37.8847)  time: 3.8878 (3.9937)  data: 0.2395 (0.2821)  lr: 0.000000  max mem: 1317
2020-12-12 22:52:05,860 maskrcnn_benchmark.trainer INFO: eta: 0:22:35  iter: 260  loss: 62.9661 (66.1305)  loss_classifier: 21.4956 (18.3927)  loss_box_reg: 5.7248 (6.0458)  loss_objectness: 3.5176 (4.2129)  loss_rpn_box_reg: 31.1600 (37.4791)  time: 3.8778 (3.9875)  data: 0.2393 (0.2791)  lr: 0.000000  max mem: 1317
2020-12-12 22:53:24,709 maskrcnn_benchmark.trainer INFO: eta: 0:21:14  iter: 280  loss: 59.8514 (65.7013)  loss_classifier: 21.1845 (18.6917)  loss_box_reg: 4.0297 (5.9540)  loss_objectness: 3.2973 (4.1520)  loss_rpn_box_reg: 30.5394 (36.9036)  time: 3.8866 (3.9842)  data: 0.2433 (0.2765)  lr: 0.000000  max mem: 1317
2020-12-12 22:54:43,686 maskrcnn_benchmark.trainer INFO: eta: 0:19:54  iter: 300  loss: 65.9662 (65.6622)  loss_classifier: 22.2641 (18.9578)  loss_box_reg: 5.7467 (5.9561)  loss_objectness: 2.9889 (4.0938)  loss_rpn_box_reg: 33.3339 (36.6545)  time: 3.8709 (3.9819)  data: 0.2375 (0.2743)  lr: 0.000000  max mem: 1317
2020-12-12 22:56:03,089 maskrcnn_benchmark.trainer INFO: eta: 0:18:34  iter: 320  loss: 65.3500 (65.6972)  loss_classifier: 23.1046 (19.3240)  loss_box_reg: 6.0993 (6.0211)  loss_objectness: 3.1303 (4.0432)  loss_rpn_box_reg: 30.9488 (36.3089)  time: 3.9129 (3.9812)  data: 0.2357 (0.2725)  lr: 0.000000  max mem: 1317
2020-12-12 22:57:21,794 maskrcnn_benchmark.trainer INFO: eta: 0:17:14  iter: 340  loss: 62.9066 (65.5464)  loss_classifier: 24.2734 (19.6896)  loss_box_reg: 5.7693 (6.0211)  loss_objectness: 3.2321 (3.9929)  loss_rpn_box_reg: 27.3414 (35.8429)  time: 3.8811 (3.9784)  data: 0.2373 (0.2707)  lr: 0.000000  max mem: 1317
2020-12-12 22:58:40,418 maskrcnn_benchmark.trainer INFO: eta: 0:15:54  iter: 360  loss: 59.7988 (65.3359)  loss_classifier: 23.4777 (19.9369)  loss_box_reg: 4.4655 (5.9899)  loss_objectness: 3.1108 (3.9397)  loss_rpn_box_reg: 28.2204 (35.4694)  time: 3.8700 (3.9758)  data: 0.2387 (0.2690)  lr: 0.000000  max mem: 1317
2020-12-12 22:59:59,099 maskrcnn_benchmark.trainer INFO: eta: 0:14:34  iter: 380  loss: 62.2683 (65.1172)  loss_classifier: 22.8564 (20.0692)  loss_box_reg: 5.8923 (5.9786)  loss_objectness: 3.3628 (3.9145)  loss_rpn_box_reg: 28.3992 (35.1549)  time: 3.8625 (3.9736)  data: 0.2440 (0.2679)  lr: 0.000000  max mem: 1317
2020-12-12 23:01:19,707 maskrcnn_benchmark.trainer INFO: eta: 0:13:15  iter: 400  loss: 62.1556 (65.0775)  loss_classifier: 24.5751 (20.3524)  loss_box_reg: 5.6533 (5.9712)  loss_objectness: 2.8966 (3.8646)  loss_rpn_box_reg: 28.3537 (34.8893)  time: 4.0183 (3.9765)  data: 0.2446 (0.2699)  lr: 0.000000  max mem: 1317
2020-12-12 23:01:19,708 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 23:01:19,720 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 23:01:25,845 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.123922 (1.5309805870056152 s / img per device, on 1 devices)
2020-12-12 23:01:25,845 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.618293 (1.4045732021331787 s / img per device, on 1 devices)
2020-12-12 23:01:25,845 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 23:01:26,297 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 23:01:26,297 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0049, 0.0048, 0.0022, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0207,
        0.0099, 0.0045, 0.0018, 0.0015, 0.0014, 0.0000, 0.0233, 0.0119, 0.0035,
        0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0037, 0.0034, 0.0017, 0.0016,
        0.0015, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([8., 4., 8., 8., 8., 8., 8., 8., 7., 8., 8., 7., 8., 8., 4., 7., 8., 8.,
        7., 8., 8., 4., 8., 8., 8., 8., 8., 7., 4., 8.]), 'best match scores': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'num_pos': 30}
2020-12-12 23:01:26,311 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-12 23:02:45,238 maskrcnn_benchmark.trainer INFO: eta: 0:11:58  iter: 420  loss: 58.5739 (64.7506)  loss_classifier: 22.6050 (20.4443)  loss_box_reg: 5.6060 (5.9690)  loss_objectness: 3.0970 (3.8246)  loss_rpn_box_reg: 25.7704 (34.5127)  time: 3.9076 (3.9908)  data: 0.2521 (0.2848)  lr: 0.000000  max mem: 1317
2020-12-12 23:04:04,278 maskrcnn_benchmark.trainer INFO: eta: 0:10:38  iter: 440  loss: 58.8760 (64.4906)  loss_classifier: 23.2875 (20.5444)  loss_box_reg: 5.8424 (6.0045)  loss_objectness: 2.8737 (3.7787)  loss_rpn_box_reg: 25.5401 (34.1631)  time: 3.8781 (3.9890)  data: 0.2432 (0.2836)  lr: 0.000000  max mem: 1317
2020-12-12 23:05:22,711 maskrcnn_benchmark.trainer INFO: eta: 0:09:18  iter: 460  loss: 57.0646 (64.1468)  loss_classifier: 21.7223 (20.6196)  loss_box_reg: 5.0822 (5.9633)  loss_objectness: 2.9386 (3.7483)  loss_rpn_box_reg: 26.0592 (33.8156)  time: 3.8756 (3.9861)  data: 0.2513 (0.2824)  lr: 0.000000  max mem: 1317
2020-12-12 23:06:41,712 maskrcnn_benchmark.trainer INFO: eta: 0:07:58  iter: 480  loss: 57.0523 (63.8517)  loss_classifier: 22.0292 (20.6964)  loss_box_reg: 5.4755 (5.9532)  loss_objectness: 2.9985 (3.7143)  loss_rpn_box_reg: 25.1440 (33.4878)  time: 3.9032 (3.9846)  data: 0.2419 (0.2812)  lr: 0.000000  max mem: 1317
2020-12-12 23:08:00,135 maskrcnn_benchmark.trainer INFO: eta: 0:06:38  iter: 500  loss: 54.6158 (63.5146)  loss_classifier: 23.0835 (20.7891)  loss_box_reg: 5.8018 (5.9525)  loss_objectness: 2.8366 (3.6751)  loss_rpn_box_reg: 23.4525 (33.0979)  time: 3.8777 (3.9820)  data: 0.2407 (0.2797)  lr: 0.000000  max mem: 1317
2020-12-12 23:09:21,265 maskrcnn_benchmark.trainer INFO: eta: 0:05:18  iter: 520  loss: 53.0307 (63.1580)  loss_classifier: 22.2061 (20.8336)  loss_box_reg: 5.1754 (5.9533)  loss_objectness: 2.5868 (3.6351)  loss_rpn_box_reg: 22.8473 (32.7360)  time: 4.0709 (3.9849)  data: 0.2628 (0.2790)  lr: 0.000000  max mem: 1317
2020-12-12 23:10:41,399 maskrcnn_benchmark.trainer INFO: eta: 0:03:59  iter: 540  loss: 53.0501 (62.7615)  loss_classifier: 20.5116 (20.8315)  loss_box_reg: 5.1346 (5.9300)  loss_objectness: 2.7236 (3.6076)  loss_rpn_box_reg: 23.2146 (32.3924)  time: 3.9153 (3.9857)  data: 0.2456 (0.2783)  lr: 0.000000  max mem: 1317
2020-12-12 23:11:58,650 maskrcnn_benchmark.trainer INFO: eta: 0:02:39  iter: 560  loss: 55.3697 (62.4724)  loss_classifier: 20.7613 (20.8222)  loss_box_reg: 5.5470 (5.9559)  loss_objectness: 2.5283 (3.5721)  loss_rpn_box_reg: 23.8586 (32.1221)  time: 3.8603 (3.9813)  data: 0.2479 (0.2772)  lr: 0.000000  max mem: 1317
2020-12-12 23:13:16,059 maskrcnn_benchmark.trainer INFO: eta: 0:01:19  iter: 580  loss: 55.3767 (62.2397)  loss_classifier: 22.2743 (20.8684)  loss_box_reg: 5.4697 (5.9911)  loss_objectness: 2.7801 (3.5420)  loss_rpn_box_reg: 24.8350 (31.8382)  time: 3.8574 (3.9775)  data: 0.2355 (0.2761)  lr: 0.000000  max mem: 1317
2020-12-12 23:14:33,533 maskrcnn_benchmark.trainer INFO: eta: 0:00:00  iter: 600  loss: 50.7467 (61.8855)  loss_classifier: 21.5922 (20.8863)  loss_box_reg: 6.0547 (6.0048)  loss_objectness: 2.2440 (3.5090)  loss_rpn_box_reg: 20.8483 (31.4855)  time: 3.8705 (3.9740)  data: 0.2356 (0.2749)  lr: 0.000000  max mem: 1317
2020-12-12 23:14:33,535 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-12 23:14:33,547 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-12 23:14:39,693 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.146284 (1.5365710258483887 s / img per device, on 1 devices)
2020-12-12 23:14:39,693 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.675990 (1.4189974665641785 s / img per device, on 1 devices)
2020-12-12 23:14:39,693 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 23:14:40,127 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 23:14:40,127 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0203, 0.0025, 0.0024, 0.0020, 0.0016, 0.0000, 0.0000, 0.0000, 0.0017,
        0.0016, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0151, 0.0061, 0.0042,
        0.0018, 0.0016, 0.0015, 0.0000, 0.0000, 0.0252, 0.0050, 0.0017, 0.0015,
        0.0015, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([8., 8., 7., 8., 8., 4., 8., 8., 8., 8., 8., 8., 7., 4., 8., 7., 4., 8.,
        8., 8., 4., 8., 7., 4., 8., 4., 8., 8., 7., 8.]), 'best match scores': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'num_pos': 30}
2020-12-12 23:14:40,138 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-12 23:14:40,142 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./final_mode_r5_v3.pth
2020-12-12 23:14:40,732 maskrcnn_benchmark.trainer INFO: final model, saving model to: final_mode_r5_v3
2020-12-12 23:14:40,749 maskrcnn_benchmark.trainer INFO: Total training time: 0:39:51.628831 (3.9860 s / it)
2020-12-12 23:14:43,855 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_test dataset(258 images).
2020-12-12 23:21:30,056 maskrcnn_benchmark.inference INFO: Total run time: 0:06:46.200742 (1.5744214797204779 s / img per device, on 1 devices)
2020-12-12 23:21:30,056 maskrcnn_benchmark.inference INFO: Model inference time: 0:06:11.910540 (1.4415137204088906 s / img per device, on 1 devices)
2020-12-12 23:21:30,138 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 23:22:03,964 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 23:22:03,965 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0729, 0.0587, 0.0472,  ..., 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([7, 7, 4,  ..., 2, 2, 2]), 'best match labels': tensor([7., 7., 8.,  ..., 8., 8., 8.]), 'best match scores': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'num_pos': 1516}
2020-12-12 23:22:03,972 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_test dataset(7 images).
2020-12-12 23:22:15,736 maskrcnn_benchmark.inference INFO: Total run time: 0:00:11.763932 (1.6805616787501745 s / img per device, on 1 devices)
2020-12-12 23:22:15,736 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:10.722244 (1.5317491463252477 s / img per device, on 1 devices)
2020-12-12 23:22:15,738 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 23:22:16,656 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 23:22:16,656 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0297, 0.0066, 0.0032, 0.0067, 0.0032, 0.0031, 0.0072, 0.0036, 0.0271,
        0.0074, 0.0126, 0.0104, 0.0032, 0.0041, 0.0036, 0.0089, 0.0032, 0.0031]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([7., 4., 8., 8., 7., 8., 7., 8., 8., 8., 8., 4., 4., 7., 8., 8., 7., 8.]), 'best match scores': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'num_pos': 18}
2020-12-12 23:22:16,663 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_test dataset(3 images).
2020-12-12 23:22:21,735 maskrcnn_benchmark.inference INFO: Total run time: 0:00:05.071646 (1.6905488173166912 s / img per device, on 1 devices)
2020-12-12 23:22:21,735 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:04.579522 (1.5265072186787922 s / img per device, on 1 devices)
2020-12-12 23:22:21,736 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-12 23:22:22,194 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-12 23:22:22,194 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([2.9936e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.9418e-03, 6.5279e-03, 6.0490e-03, 4.6731e-03,
        3.4649e-03, 2.7060e-03, 1.7573e-03, 1.5031e-05, 3.4739e-03, 2.2249e-03,
        7.4538e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1]), 'best match labels': tensor([8., 8., 8., 8., 8., 8., 8., 8., 8., 4., 8., 4., 4., 7., 8., 4., 8., 4.,
        8., 8., 8., 4., 8., 8., 8.]), 'best match scores': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1.]), 'num_pos': 25}
2020-12-13 00:27:59,224 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 00:27:59,235 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 00:27:59,236 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 00:28:01,726 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 00:28:01,727 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 00:28:01,728 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train","giro4_train","giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000000003
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-13 00:28:01,732 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 10
    BG_IOU_THRESHOLD: 0.04
    FG_IOU_THRESHOLD: 0.05
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 1
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 3e-09
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-13 00:28:03,517 maskrcnn_benchmark INFO: reloading weigts from final_mode_r5_v3.pth
2020-12-13 00:28:05,829 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-13 00:28:05,830 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-13 00:28:05,830 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-13 00:28:05,830 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-13 00:28:05,830 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-13 00:28:05,830 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-13 00:28:06,014 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-13 00:28:26,824 maskrcnn_benchmark.trainer INFO: Start training
2020-12-13 00:29:44,743 maskrcnn_benchmark.trainer INFO: eta: 0:37:39  iter: 20  loss: 65.9927 (65.2225)  loss_classifier: 19.3887 (19.9347)  loss_box_reg: 5.1159 (4.9158)  loss_objectness: 2.1591 (2.5602)  loss_rpn_box_reg: 38.4108 (37.8118)  time: 3.8826 (3.8954)  data: 0.2384 (0.2411)  lr: 0.000000  max mem: 1317
2020-12-13 00:31:02,624 maskrcnn_benchmark.trainer INFO: eta: 0:36:21  iter: 40  loss: 65.3102 (65.2866)  loss_classifier: 20.6895 (19.6951)  loss_box_reg: 4.8801 (5.1433)  loss_objectness: 2.4436 (2.5446)  loss_rpn_box_reg: 40.3397 (37.9036)  time: 3.8916 (3.8947)  data: 0.2358 (0.2400)  lr: 0.000000  max mem: 1317
2020-12-13 00:32:21,932 maskrcnn_benchmark.trainer INFO: eta: 0:35:15  iter: 60  loss: 61.4447 (64.0978)  loss_classifier: 19.9814 (19.7519)  loss_box_reg: 5.8533 (5.3414)  loss_objectness: 1.8467 (2.3799)  loss_rpn_box_reg: 33.5688 (36.6245)  time: 3.9278 (3.9183)  data: 0.2420 (0.2425)  lr: 0.000000  max mem: 1317
2020-12-13 00:33:44,700 maskrcnn_benchmark.trainer INFO: eta: 0:34:26  iter: 80  loss: 64.3904 (64.1303)  loss_classifier: 18.8849 (19.7005)  loss_box_reg: 6.2898 (5.7182)  loss_objectness: 2.2112 (2.3022)  loss_rpn_box_reg: 35.8362 (36.4094)  time: 4.1385 (3.9733)  data: 0.2581 (0.2478)  lr: 0.000000  max mem: 1317
2020-12-13 00:35:09,548 maskrcnn_benchmark.trainer INFO: eta: 0:33:33  iter: 100  loss: 63.6567 (64.0505)  loss_classifier: 22.6979 (20.1640)  loss_box_reg: 5.6402 (5.7745)  loss_objectness: 1.6517 (2.2333)  loss_rpn_box_reg: 34.9430 (35.8787)  time: 4.2558 (4.0271)  data: 0.2689 (0.2526)  lr: 0.000000  max mem: 1317
2020-12-13 00:36:33,971 maskrcnn_benchmark.trainer INFO: eta: 0:32:28  iter: 120  loss: 59.4500 (63.8270)  loss_classifier: 19.8618 (20.2857)  loss_box_reg: 5.3334 (5.7359)  loss_objectness: 1.4785 (2.1349)  loss_rpn_box_reg: 30.5865 (35.6704)  time: 4.2375 (4.0595)  data: 0.2823 (0.2570)  lr: 0.000000  max mem: 1317
2020-12-13 00:36:33,973 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 00:36:34,003 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 00:36:40,550 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.546874 (1.6367184519767761 s / img per device, on 1 devices)
2020-12-13 00:36:40,550 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.985427 (1.4963566660881042 s / img per device, on 1 devices)
2020-12-13 00:36:40,551 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 00:36:41,016 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 00:36:41,016 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0229, 0.0108, 0.0055, 0.0019, 0.0015, 0.0015, 0.0014, 0.0000, 0.0017,
        0.0016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0249, 0.0248, 0.0026,
        0.0017, 0.0016, 0.0009, 0.0000, 0.0000, 0.0259, 0.0188, 0.0046, 0.0020,
        0.0018, 0.0015, 0.0014]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([4., 8., 8., 8., 8., 8., 8., 7., 8., 8., 8., 8., 7., 8., 8., 7., 4., 8.,
        8., 8., 8., 8., 8., 8., 7., 4., 7., 4., 8., 4.]), 'best match scores': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'num_pos': 30}
2020-12-13 00:36:41,028 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-13 00:36:41,031 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v4.pth
2020-12-13 00:36:41,828 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v4
2020-12-13 00:38:01,477 maskrcnn_benchmark.trainer INFO: eta: 0:31:28  iter: 140  loss: 56.6681 (63.1958)  loss_classifier: 19.1433 (20.2342)  loss_box_reg: 5.4956 (5.8310)  loss_objectness: 1.6061 (2.0823)  loss_rpn_box_reg: 31.0698 (35.0483)  time: 3.8890 (4.1046)  data: 0.2354 (0.3196)  lr: 0.000000  max mem: 1317
2020-12-13 00:39:19,063 maskrcnn_benchmark.trainer INFO: eta: 0:29:53  iter: 160  loss: 58.8637 (62.6041)  loss_classifier: 20.4588 (20.2505)  loss_box_reg: 5.5945 (5.8101)  loss_objectness: 1.1729 (2.0028)  loss_rpn_box_reg: 31.1901 (34.5406)  time: 3.8774 (4.0764)  data: 0.2291 (0.3087)  lr: 0.000000  max mem: 1317
2020-12-13 00:40:36,556 maskrcnn_benchmark.trainer INFO: eta: 0:28:22  iter: 180  loss: 56.1344 (62.1638)  loss_classifier: 20.4507 (20.3229)  loss_box_reg: 5.6919 (5.8378)  loss_objectness: 1.6831 (1.9490)  loss_rpn_box_reg: 32.7397 (34.0541)  time: 3.8691 (4.0540)  data: 0.2312 (0.3002)  lr: 0.000000  max mem: 1317
2020-12-13 00:41:54,186 maskrcnn_benchmark.trainer INFO: eta: 0:26:54  iter: 200  loss: 57.2184 (61.7705)  loss_classifier: 19.4583 (20.3222)  loss_box_reg: 6.2521 (5.9633)  loss_objectness: 1.0361 (1.8740)  loss_rpn_box_reg: 28.4357 (33.6111)  time: 3.8802 (4.0368)  data: 0.2293 (0.2933)  lr: 0.000000  max mem: 1317
2020-12-13 00:43:11,758 maskrcnn_benchmark.trainer INFO: eta: 0:25:28  iter: 220  loss: 62.5675 (61.7372)  loss_classifier: 21.0800 (20.4059)  loss_box_reg: 6.3033 (6.0720)  loss_objectness: 1.1129 (1.8164)  loss_rpn_box_reg: 32.8978 (33.4429)  time: 3.8709 (4.0224)  data: 0.2289 (0.2878)  lr: 0.000000  max mem: 1317
2020-12-13 00:44:29,316 maskrcnn_benchmark.trainer INFO: eta: 0:24:03  iter: 240  loss: 58.5682 (61.4855)  loss_classifier: 20.4397 (20.4159)  loss_box_reg: 7.4096 (6.1616)  loss_objectness: 0.9250 (1.7497)  loss_rpn_box_reg: 28.8999 (33.1582)  time: 3.8811 (4.0103)  data: 0.2334 (0.2833)  lr: 0.000000  max mem: 1317
2020-12-13 00:44:29,318 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 00:44:29,330 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 00:44:35,473 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.142788 (1.535697102546692 s / img per device, on 1 devices)
2020-12-13 00:44:35,473 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.676278 (1.4190694093704224 s / img per device, on 1 devices)
2020-12-13 00:44:35,473 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 00:44:35,896 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 00:44:35,897 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0059, 0.0019, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0058,
        0.0017, 0.0016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0060, 0.0058, 0.0033,
        0.0021, 0.0016, 0.0015, 0.0000, 0.0000, 0.0053, 0.0053, 0.0026, 0.0016,
        0.0015, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([8., 4., 8., 8., 8., 8., 8., 8., 8., 8., 8., 4., 7., 8., 8., 7., 8., 7.,
        8., 8., 4., 8., 8., 4., 8., 4., 8., 8., 7., 4.]), 'best match scores': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000]), 'num_pos': 30}
2020-12-13 00:44:35,906 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-13 00:45:53,515 maskrcnn_benchmark.trainer INFO: eta: 0:22:48  iter: 260  loss: 54.0582 (60.9583)  loss_classifier: 19.4955 (20.3584)  loss_box_reg: 5.6387 (6.1510)  loss_objectness: 0.8096 (1.6919)  loss_rpn_box_reg: 28.2977 (32.7570)  time: 3.8787 (4.0257)  data: 0.2298 (0.3046)  lr: 0.000000  max mem: 1317
2020-12-13 00:47:11,100 maskrcnn_benchmark.trainer INFO: eta: 0:21:24  iter: 280  loss: 49.4523 (60.3983)  loss_classifier: 18.5062 (20.2020)  loss_box_reg: 5.1891 (6.0969)  loss_objectness: 0.6546 (1.6257)  loss_rpn_box_reg: 28.6772 (32.4737)  time: 3.8779 (4.0152)  data: 0.2316 (0.2994)  lr: 0.000000  max mem: 1317
2020-12-13 00:48:28,634 maskrcnn_benchmark.trainer INFO: eta: 0:20:01  iter: 300  loss: 53.2569 (59.9085)  loss_classifier: 18.7995 (20.1243)  loss_box_reg: 5.4170 (6.0641)  loss_objectness: 0.7745 (1.5716)  loss_rpn_box_reg: 26.4931 (32.1485)  time: 3.8813 (4.0060)  data: 0.2303 (0.2949)  lr: 0.000000  max mem: 1317
2020-12-13 00:49:46,171 maskrcnn_benchmark.trainer INFO: eta: 0:18:39  iter: 320  loss: 52.7178 (59.5703)  loss_classifier: 18.3361 (20.0762)  loss_box_reg: 5.2920 (6.0615)  loss_objectness: 0.5108 (1.5113)  loss_rpn_box_reg: 28.2032 (31.9213)  time: 3.8755 (3.9979)  data: 0.2266 (0.2908)  lr: 0.000000  max mem: 1317
2020-12-13 00:51:03,779 maskrcnn_benchmark.trainer INFO: eta: 0:17:17  iter: 340  loss: 49.7748 (59.0882)  loss_classifier: 19.7764 (20.0395)  loss_box_reg: 5.7589 (6.0556)  loss_objectness: 0.5467 (1.4543)  loss_rpn_box_reg: 24.7199 (31.5389)  time: 3.8772 (3.9910)  data: 0.2297 (0.2871)  lr: 0.000000  max mem: 1317
2020-12-13 00:52:21,639 maskrcnn_benchmark.trainer INFO: eta: 0:15:56  iter: 360  loss: 53.8231 (58.8624)  loss_classifier: 19.5269 (20.0305)  loss_box_reg: 5.5731 (6.0581)  loss_objectness: 0.4448 (1.4014)  loss_rpn_box_reg: 27.5341 (31.3724)  time: 3.8779 (3.9856)  data: 0.2309 (0.2840)  lr: 0.000000  max mem: 1317
2020-12-13 00:52:21,641 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 00:52:21,652 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 00:52:27,748 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.096636 (1.524159014225006 s / img per device, on 1 devices)
2020-12-13 00:52:27,749 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.635136 (1.4087840914726257 s / img per device, on 1 devices)
2020-12-13 00:52:27,749 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 00:52:28,163 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 00:52:28,164 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0195, 0.0017, 0.0016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0035,
        0.0016, 0.0015, 0.0015, 0.0000, 0.0000, 0.0000, 0.0017, 0.0017, 0.0009,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0522, 0.0106, 0.0017, 0.0015,
        0.0015, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([8., 4., 8., 8., 8., 8., 4., 8., 4., 8., 8., 8., 8., 7., 4., 7., 8., 8.,
        8., 8., 8., 8., 8., 4., 7., 8., 8., 7., 7., 8.]), 'best match scores': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000]), 'num_pos': 30}
2020-12-13 00:52:28,172 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-13 00:53:44,798 maskrcnn_benchmark.trainer INFO: eta: 0:14:38  iter: 380  loss: 53.3708 (58.6104)  loss_classifier: 18.9532 (20.0230)  loss_box_reg: 5.5358 (6.0546)  loss_objectness: 0.4094 (1.3511)  loss_rpn_box_reg: 26.6086 (31.1817)  time: 3.8304 (3.9946)  data: 0.2216 (0.2980)  lr: 0.000000  max mem: 1317
2020-12-13 00:55:01,763 maskrcnn_benchmark.trainer INFO: eta: 0:13:17  iter: 400  loss: 46.6078 (58.1018)  loss_classifier: 18.3962 (19.9683)  loss_box_reg: 5.2133 (6.0351)  loss_objectness: 0.3056 (1.3047)  loss_rpn_box_reg: 22.9941 (30.7937)  time: 3.8459 (3.9873)  data: 0.2296 (0.2946)  lr: 0.000000  max mem: 1317
2020-12-13 00:56:18,356 maskrcnn_benchmark.trainer INFO: eta: 0:11:56  iter: 420  loss: 51.9484 (57.8222)  loss_classifier: 18.8159 (19.9453)  loss_box_reg: 5.7095 (6.0437)  loss_objectness: 0.3233 (1.2621)  loss_rpn_box_reg: 24.6132 (30.5711)  time: 3.8280 (3.9798)  data: 0.2265 (0.2912)  lr: 0.000000  max mem: 1317
2020-12-13 00:57:35,035 maskrcnn_benchmark.trainer INFO: eta: 0:10:35  iter: 440  loss: 51.5055 (57.5391)  loss_classifier: 18.8925 (19.8986)  loss_box_reg: 5.7354 (6.0495)  loss_objectness: 0.2537 (1.2163)  loss_rpn_box_reg: 25.2258 (30.3746)  time: 3.8330 (3.9732)  data: 0.2224 (0.2883)  lr: 0.000000  max mem: 1317
2020-12-13 00:58:53,346 maskrcnn_benchmark.trainer INFO: eta: 0:09:15  iter: 460  loss: 50.7016 (57.2527)  loss_classifier: 19.1243 (19.9055)  loss_box_reg: 5.5669 (6.0393)  loss_objectness: 0.1978 (1.1742)  loss_rpn_box_reg: 24.5080 (30.1336)  time: 3.8833 (3.9707)  data: 0.2353 (0.2865)  lr: 0.000000  max mem: 1317
2020-12-13 01:00:15,480 maskrcnn_benchmark.trainer INFO: eta: 0:07:57  iter: 480  loss: 51.9788 (57.0780)  loss_classifier: 19.6360 (19.9206)  loss_box_reg: 5.9829 (6.0814)  loss_objectness: 0.1345 (1.1356)  loss_rpn_box_reg: 24.1412 (29.9403)  time: 4.0880 (3.9763)  data: 0.2509 (0.2854)  lr: 0.000000  max mem: 1317
2020-12-13 01:00:15,483 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 01:00:15,495 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 01:00:22,295 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.799924 (1.699980914592743 s / img per device, on 1 devices)
2020-12-13 01:00:22,295 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:06.160435 (1.5401087403297424 s / img per device, on 1 devices)
2020-12-13 01:00:22,295 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 01:00:22,921 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 01:00:22,921 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.9582e-02, 1.7054e-02, 1.6865e-03, 1.5061e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.6723e-03, 1.5625e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5659e-02, 2.4478e-03, 1.5605e-03,
        4.5111e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8402e-03,
        4.4368e-03, 1.6723e-03, 1.5625e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([8., 8., 4., 8., 8., 8., 4., 8., 8., 8., 8., 8., 7., 8., 8., 7., 8., 8.,
        8., 8., 4., 8., 8., 8., 7., 4., 8., 7., 8., 8.]), 'best match scores': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000]), 'num_pos': 30}
2020-12-13 01:00:22,932 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-13 01:01:47,104 maskrcnn_benchmark.trainer INFO: eta: 0:06:40  iter: 500  loss: 45.3409 (56.6611)  loss_classifier: 18.2864 (19.8849)  loss_box_reg: 5.4559 (6.0375)  loss_objectness: 0.1951 (1.1009)  loss_rpn_box_reg: 21.2506 (29.6378)  time: 4.2358 (4.0005)  data: 0.2796 (0.3000)  lr: 0.000000  max mem: 1317
2020-12-13 01:03:11,689 maskrcnn_benchmark.trainer INFO: eta: 0:05:20  iter: 520  loss: 53.0378 (56.5447)  loss_classifier: 20.0091 (19.8846)  loss_box_reg: 6.6111 (6.1030)  loss_objectness: 0.1741 (1.0689)  loss_rpn_box_reg: 23.4914 (29.4882)  time: 4.2498 (4.0093)  data: 0.2756 (0.2990)  lr: 0.000000  max mem: 1317
2020-12-13 01:04:34,302 maskrcnn_benchmark.trainer INFO: eta: 0:04:00  iter: 540  loss: 49.2150 (56.2720)  loss_classifier: 19.1886 (19.8487)  loss_box_reg: 5.1343 (6.0851)  loss_objectness: 0.1140 (1.0366)  loss_rpn_box_reg: 26.6784 (29.3016)  time: 4.1841 (4.0138)  data: 0.2671 (0.2977)  lr: 0.000000  max mem: 1317
2020-12-13 01:05:56,946 maskrcnn_benchmark.trainer INFO: eta: 0:02:40  iter: 560  loss: 48.2498 (56.0029)  loss_classifier: 19.2908 (19.8266)  loss_box_reg: 5.2658 (6.0917)  loss_objectness: 0.1956 (1.0080)  loss_rpn_box_reg: 22.5781 (29.0766)  time: 4.1054 (4.0181)  data: 0.2559 (0.2962)  lr: 0.000000  max mem: 1317
2020-12-13 01:07:19,969 maskrcnn_benchmark.trainer INFO: eta: 0:01:20  iter: 580  loss: 46.2646 (55.7502)  loss_classifier: 19.3823 (19.8028)  loss_box_reg: 5.5235 (6.0752)  loss_objectness: 0.0514 (0.9769)  loss_rpn_box_reg: 22.0351 (28.8953)  time: 4.1426 (4.0226)  data: 0.2597 (0.2951)  lr: 0.000000  max mem: 1317
2020-12-13 01:08:43,053 maskrcnn_benchmark.trainer INFO: eta: 0:00:00  iter: 600  loss: 47.1444 (55.4332)  loss_classifier: 18.4418 (19.7711)  loss_box_reg: 5.5590 (6.0626)  loss_objectness: 0.0873 (0.9510)  loss_rpn_box_reg: 21.2369 (28.6484)  time: 4.1583 (4.0270)  data: 0.2709 (0.2942)  lr: 0.000000  max mem: 1317
2020-12-13 01:08:43,055 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 01:08:43,066 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 01:08:49,496 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.429538 (1.6073843836784363 s / img per device, on 1 devices)
2020-12-13 01:08:49,496 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.871611 (1.4679028391838074 s / img per device, on 1 devices)
2020-12-13 01:08:49,497 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 01:08:49,933 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 01:08:49,933 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.7256e-02, 6.5132e-03, 1.7456e-03, 1.4555e-03, 6.0767e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 6.5869e-03, 5.4281e-03, 1.5080e-03, 1.4526e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0444e-02, 1.6865e-03, 1.2627e-03,
        7.7668e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2666e-03,
        1.6723e-03, 1.5625e-03, 1.5300e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([8., 8., 7., 8., 8., 4., 8., 8., 7., 8., 8., 8., 4., 8., 4., 7., 7., 8.,
        8., 8., 8., 8., 8., 8., 8., 8., 4., 7., 8., 8.]), 'best match scores': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000]), 'num_pos': 30}
2020-12-13 01:08:49,943 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-13 01:08:49,948 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./final_mode_r5_v4.pth
2020-12-13 01:08:50,422 maskrcnn_benchmark.trainer INFO: final model, saving model to: final_mode_r5_v4
2020-12-13 01:08:50,431 maskrcnn_benchmark.trainer INFO: Total training time: 0:40:23.596287 (4.0393 s / it)
2020-12-13 01:08:53,588 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_test dataset(258 images).
2020-12-13 01:15:57,215 maskrcnn_benchmark.inference INFO: Total run time: 0:07:03.626755 (1.6419641666634137 s / img per device, on 1 devices)
2020-12-13 01:15:57,215 maskrcnn_benchmark.inference INFO: Model inference time: 0:06:24.263303 (1.489392645599306 s / img per device, on 1 devices)
2020-12-13 01:15:57,265 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 01:16:29,477 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 01:16:29,477 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0461, 0.0451, 0.0217,  ..., 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([7, 7, 4,  ..., 2, 2, 2]), 'best match labels': tensor([8., 8., 4.,  ..., 8., 8., 8.]), 'best match scores': tensor([1., 1., 1.,  ..., 1., 1., 1.]), 'num_pos': 1516}
2020-12-13 01:16:29,484 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_test dataset(7 images).
2020-12-13 01:16:41,246 maskrcnn_benchmark.inference INFO: Total run time: 0:00:11.760632 (1.6800902911594935 s / img per device, on 1 devices)
2020-12-13 01:16:41,246 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:10.619066 (1.5170094626290458 s / img per device, on 1 devices)
2020-12-13 01:16:41,248 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 01:16:41,996 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 01:16:41,996 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0090, 0.0041, 0.0031, 0.0106, 0.0036, 0.0031, 0.0113, 0.0041, 0.0293,
        0.0291, 0.0198, 0.0187, 0.0045, 0.0114, 0.0086, 0.0032, 0.0032, 0.0031]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([4., 8., 8., 8., 7., 7., 8., 8., 8., 8., 8., 4., 4., 8., 8., 7., 4., 8.]), 'best match scores': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'num_pos': 18}
2020-12-13 01:16:42,003 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_test dataset(3 images).
2020-12-13 01:16:46,996 maskrcnn_benchmark.inference INFO: Total run time: 0:00:04.992892 (1.6642972628275554 s / img per device, on 1 devices)
2020-12-13 01:16:46,997 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:04.587652 (1.52921724319458 s / img per device, on 1 devices)
2020-12-13 01:16:46,998 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 01:16:47,338 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 01:16:47,339 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0051, 0.0016, 0.0015, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0095,
        0.0047, 0.0020, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0088, 0.0059,
        0.0035, 0.0033, 0.0030, 0.0019, 0.0019, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1]), 'best match labels': tensor([8., 8., 7., 8., 8., 8., 8., 4., 8., 4., 8., 8., 8., 7., 8., 8., 8., 4.,
        8., 8., 4., 4., 4., 7., 4.]), 'best match scores': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]), 'num_pos': 25}
2020-12-13 01:46:23,272 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 01:46:23,272 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 01:46:23,272 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 01:46:28,286 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 01:46:28,287 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 01:46:28,288 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro8_valid",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000008
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-13 01:46:28,291 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro8_valid',)
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 20
    BG_IOU_THRESHOLD: 0.2
    FG_IOU_THRESHOLD: 0.5
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 8e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-13 01:46:30,069 maskrcnn_benchmark INFO: reloading weigts from final_mode_r5_v3.pth
2020-12-13 01:46:32,484 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-13 01:46:32,484 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-13 01:46:32,484 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-13 01:46:32,484 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-13 01:46:32,485 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-13 01:46:32,485 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-13 01:46:32,662 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-13 01:46:32,691 maskrcnn_benchmark.trainer INFO: Start training
2020-12-13 01:47:50,124 maskrcnn_benchmark.trainer INFO: eta: 0:37:25  iter: 20  loss: 41.8001 (41.8234)  loss_classifier: 17.6569 (17.6827)  loss_box_reg: 9.4769 (9.4833)  loss_objectness: 2.7526 (2.9029)  loss_rpn_box_reg: 11.3419 (11.7544)  time: 3.8588 (3.8715)  data: 0.2160 (0.2176)  lr: 0.000000  max mem: 1317
2020-12-13 01:49:07,338 maskrcnn_benchmark.trainer INFO: eta: 0:36:05  iter: 40  loss: 41.7357 (42.0832)  loss_classifier: 19.4972 (18.6546)  loss_box_reg: 9.4804 (9.4967)  loss_objectness: 2.0836 (2.5702)  loss_rpn_box_reg: 11.1409 (11.3616)  time: 3.8595 (3.8661)  data: 0.2181 (0.2171)  lr: 0.000000  max mem: 1317
2020-12-13 01:50:24,642 maskrcnn_benchmark.trainer INFO: eta: 0:34:47  iter: 60  loss: 43.1849 (42.5486)  loss_classifier: 19.8249 (19.2184)  loss_box_reg: 9.4769 (9.4936)  loss_objectness: 2.0860 (2.4726)  loss_rpn_box_reg: 11.2090 (11.3640)  time: 3.8623 (3.8658)  data: 0.2150 (0.2170)  lr: 0.000000  max mem: 1317
2020-12-13 01:51:42,043 maskrcnn_benchmark.trainer INFO: eta: 0:33:30  iter: 80  loss: 44.9525 (43.0936)  loss_classifier: 21.6480 (19.8127)  loss_box_reg: 9.4605 (9.4869)  loss_objectness: 2.1918 (2.4337)  loss_rpn_box_reg: 11.3758 (11.3603)  time: 3.8691 (3.8669)  data: 0.2185 (0.2178)  lr: 0.000000  max mem: 1317
2020-12-13 01:54:26,886 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 01:54:26,886 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 01:54:26,886 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 01:54:29,164 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 01:54:29,164 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 01:54:29,165 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro8_valid",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000008
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-13 01:54:29,166 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro8_valid',)
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 20
    BG_IOU_THRESHOLD: 0.2
    FG_IOU_THRESHOLD: 0.5
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 8e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-13 01:54:30,920 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-13 01:54:30,920 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-13 01:54:30,920 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-13 01:54:30,920 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-13 01:54:30,920 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-13 01:54:30,920 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-13 01:54:30,920 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-13 01:54:30,921 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-13 01:54:32,901 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-13 01:54:32,929 maskrcnn_benchmark.trainer INFO: Start training
2020-12-13 01:55:50,389 maskrcnn_benchmark.trainer INFO: eta: 0:37:26  iter: 20  loss: 315.6079 (308.5653)  loss_classifier: 234.9259 (227.0022)  loss_box_reg: 6.3879 (6.4638)  loss_objectness: 6.9428 (7.3650)  loss_rpn_box_reg: 67.2022 (67.7344)  time: 3.8498 (3.8728)  data: 0.2192 (0.2191)  lr: 0.000000  max mem: 1317
2020-12-13 01:57:07,349 maskrcnn_benchmark.trainer INFO: eta: 0:36:01  iter: 40  loss: 115.4759 (216.1973)  loss_classifier: 69.3880 (151.1887)  loss_box_reg: 6.3776 (6.4543)  loss_objectness: 6.9326 (7.1637)  loss_rpn_box_reg: 32.3661 (51.3905)  time: 3.8466 (3.8604)  data: 0.2168 (0.2177)  lr: 0.000000  max mem: 1317
2020-12-13 01:58:24,579 maskrcnn_benchmark.trainer INFO: eta: 0:34:44  iter: 60  loss: 46.4124 (159.6859)  loss_classifier: 18.3787 (106.8512)  loss_box_reg: 6.3776 (6.4500)  loss_objectness: 5.0917 (6.5752)  loss_rpn_box_reg: 16.7310 (39.8095)  time: 3.8604 (3.8608)  data: 0.2171 (0.2176)  lr: 0.000000  max mem: 1317
2020-12-13 01:58:24,581 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 01:58:24,593 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 01:58:30,660 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.066943 (1.5167357325553894 s / img per device, on 1 devices)
2020-12-13 01:58:30,660 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.594814 (1.3987034559249878 s / img per device, on 1 devices)
2020-12-13 01:58:30,660 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 01:58:31,099 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 01:58:31,099 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0034, 0.0016, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0027,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0373, 0.0017, 0.0016,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0017, 0.0014, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([7., 7., 1., 8., 8., 7., 8., 8., 8., 8., 8., 8., 1., 8., 8., 8., 1., 8.,
        8., 8., 7., 8., 8., 8., 8., 1., 8., 8., 8., 1.]), 'best match scores': tensor([0.1166, 0.9915, 1.0000, 0.9998, 0.6706, 0.3019, 0.9971, 0.6706, 0.9911,
        0.8900, 0.9055, 0.9143, 1.0000, 0.1346, 0.1514, 0.9971, 1.0000, 0.1876,
        0.2244, 0.1797, 0.6184, 0.8697, 0.9926, 0.9925, 0.9640, 1.0000, 0.2965,
        0.7652, 0.1549, 1.0000]), 'num_pos': 30}
2020-12-13 01:58:31,107 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.166667
2020-12-13 01:58:31,109 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v5.pth
2020-12-13 01:58:31,748 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v5
2020-12-13 01:59:49,057 maskrcnn_benchmark.trainer INFO: eta: 0:34:14  iter: 80  loss: 36.9991 (129.2349)  loss_classifier: 14.4893 (83.6785)  loss_box_reg: 6.3776 (6.4463)  loss_objectness: 3.9294 (5.9204)  loss_rpn_box_reg: 13.4611 (33.1897)  time: 3.8633 (3.9516)  data: 0.2169 (0.3075)  lr: 0.000000  max mem: 1317
2020-12-13 02:01:07,488 maskrcnn_benchmark.trainer INFO: eta: 0:32:52  iter: 100  loss: 30.4501 (109.5501)  loss_classifier: 10.3928 (69.0095)  loss_box_reg: 6.3776 (6.4482)  loss_objectness: 2.5441 (5.2959)  loss_rpn_box_reg: 10.8400 (28.7965)  time: 3.8675 (3.9456)  data: 0.2195 (0.2906)  lr: 0.000000  max mem: 1317
2020-12-13 02:05:33,760 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 02:05:33,760 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 02:05:33,760 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 02:05:36,050 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 02:05:36,051 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 02:05:36,051 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro8_valid",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.0000008
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-13 02:05:36,052 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro8_valid',)
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 100
    BG_IOU_THRESHOLD: 0.2
    FG_IOU_THRESHOLD: 0.6
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 8e-07
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-13 02:05:37,824 maskrcnn_benchmark INFO: reloading weigts from _best_acc_r5_v5.pth
2020-12-13 02:05:40,229 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-13 02:05:40,230 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-13 02:05:40,230 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-13 02:05:40,230 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-13 02:05:40,230 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-13 02:05:40,230 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-13 02:05:40,231 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-13 02:05:40,231 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-13 02:05:40,231 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-13 02:05:40,231 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-13 02:05:40,231 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-13 02:05:40,231 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-13 02:05:40,231 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-13 02:05:40,231 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-13 02:05:40,424 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-13 02:05:40,452 maskrcnn_benchmark.trainer INFO: Start training
2020-12-13 02:07:01,832 maskrcnn_benchmark.trainer INFO: eta: 0:39:19  iter: 20  loss: 18.5524 (21.1192)  loss_classifier: 5.0878 (7.5558)  loss_box_reg: 5.2119 (5.0605)  loss_objectness: 2.7720 (3.0715)  loss_rpn_box_reg: 5.4399 (5.4315)  time: 3.9825 (4.0689)  data: 0.2224 (0.2327)  lr: 0.000000  max mem: 1423
2020-12-13 02:08:19,335 maskrcnn_benchmark.trainer INFO: eta: 0:37:04  iter: 40  loss: 7.7299 (14.8097)  loss_classifier: 0.5705 (4.1227)  loss_box_reg: 1.2153 (3.2954)  loss_objectness: 1.4048 (2.2547)  loss_rpn_box_reg: 4.7973 (5.1369)  time: 3.8761 (3.9720)  data: 0.2134 (0.2233)  lr: 0.000000  max mem: 1423
2020-12-13 02:09:36,937 maskrcnn_benchmark.trainer INFO: eta: 0:35:28  iter: 60  loss: 6.6755 (12.1293)  loss_classifier: 0.3304 (2.8628)  loss_box_reg: 0.8814 (2.4962)  loss_objectness: 1.1162 (1.8694)  loss_rpn_box_reg: 4.4258 (4.9008)  time: 3.8785 (3.9414)  data: 0.2141 (0.2205)  lr: 0.000000  max mem: 1423
2020-12-13 02:09:36,939 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 02:09:36,951 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 02:09:43,083 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.131901 (1.5329753160476685 s / img per device, on 1 devices)
2020-12-13 02:09:43,084 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.657242 (1.4143105149269104 s / img per device, on 1 devices)
2020-12-13 02:09:43,084 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 02:09:43,521 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 02:09:43,521 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.9661e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.5686e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7274e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 8., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 7.]), 'best match scores': tensor([0.0527, 1.0000, 0.2088, 0.9812, 1.0000, 0.7911, 0.1642, 0.2197, 0.9826,
        0.9829, 1.0000, 0.8248, 0.5168, 0.3125, 0.8904, 0.6161, 0.9994, 0.0712,
        0.2870, 0.9193, 0.0517, 0.2226, 0.7769, 0.9997, 0.9979, 0.9991, 0.9990,
        0.9999, 0.3329, 0.3567]), 'num_pos': 30}
2020-12-13 02:09:43,530 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.933333
2020-12-13 02:09:43,534 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v5.pth
2020-12-13 02:09:47,790 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v5
2020-12-13 02:11:05,535 maskrcnn_benchmark.trainer INFO: eta: 0:35:13  iter: 80  loss: 5.9255 (10.5922)  loss_classifier: 0.1951 (2.1999)  loss_box_reg: 0.7271 (2.0556)  loss_objectness: 0.8404 (1.6199)  loss_rpn_box_reg: 4.1169 (4.7169)  time: 3.8820 (4.0635)  data: 0.2137 (0.3555)  lr: 0.000000  max mem: 1423
2020-12-13 02:12:26,989 maskrcnn_benchmark.trainer INFO: eta: 0:33:52  iter: 100  loss: 5.4827 (9.5803)  loss_classifier: 0.1711 (1.7939)  loss_box_reg: 0.6655 (1.7789)  loss_objectness: 0.7790 (1.4544)  loss_rpn_box_reg: 3.8663 (4.5530)  time: 4.1041 (4.0653)  data: 0.2248 (0.3304)  lr: 0.000000  max mem: 1423
2020-12-13 02:13:45,101 maskrcnn_benchmark.trainer INFO: eta: 0:32:18  iter: 120  loss: 5.1524 (8.8399)  loss_classifier: 0.1272 (1.5165)  loss_box_reg: 0.6229 (1.5872)  loss_objectness: 0.6799 (1.3227)  loss_rpn_box_reg: 3.7535 (4.4135)  time: 3.8796 (4.0387)  data: 0.2226 (0.3127)  lr: 0.000000  max mem: 1423
2020-12-13 02:13:45,103 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 02:13:45,113 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 02:13:51,231 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.118376 (1.5295938849449158 s / img per device, on 1 devices)
2020-12-13 02:13:51,232 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.645063 (1.4112656712532043 s / img per device, on 1 devices)
2020-12-13 02:13:51,232 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 02:13:51,657 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 02:13:51,657 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([3.8240e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.8295e-04, 3.2295e-06, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8798e-03, 6.7545e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'best match scores': tensor([0.2514, 0.0671, 1.0000, 0.6275, 0.9981, 0.9924, 0.9798, 0.6058, 0.5555,
        0.1418, 0.1785, 0.9827, 1.0000, 0.7778, 0.8314, 0.0561, 0.1030, 0.1302,
        1.0000, 0.0699, 0.6223, 0.9994, 0.9998, 0.2212, 0.5867, 1.0000, 0.9975,
        0.9971, 0.1867, 0.9989]), 'num_pos': 30}
2020-12-13 02:13:51,665 maskrcnn_benchmark.trainer INFO: validation accuracy: 1.000000
2020-12-13 02:13:51,668 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v5.pth
2020-12-13 02:13:56,208 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v5
2020-12-13 02:15:19,049 maskrcnn_benchmark.trainer INFO: eta: 0:31:41  iter: 140  loss: 4.8734 (8.2763)  loss_classifier: 0.1188 (1.3172)  loss_box_reg: 0.6014 (1.4462)  loss_objectness: 0.5759 (1.2186)  loss_rpn_box_reg: 3.5816 (4.2943)  time: 4.2901 (4.1328)  data: 0.2240 (0.3805)  lr: 0.000000  max mem: 1423
2020-12-13 02:16:43,918 maskrcnn_benchmark.trainer INFO: eta: 0:30:24  iter: 160  loss: 4.6700 (7.8275)  loss_classifier: 0.0974 (1.1652)  loss_box_reg: 0.5440 (1.3355)  loss_objectness: 0.5399 (1.1349)  loss_rpn_box_reg: 3.4699 (4.1919)  time: 4.2385 (4.1466)  data: 0.2285 (0.3622)  lr: 0.000000  max mem: 1423
2020-12-13 02:18:02,899 maskrcnn_benchmark.trainer INFO: eta: 0:28:52  iter: 180  loss: 4.6455 (7.4727)  loss_classifier: 0.0823 (1.0450)  loss_box_reg: 0.5298 (1.2462)  loss_objectness: 0.4636 (1.0613)  loss_rpn_box_reg: 3.5929 (4.1202)  time: 3.8931 (4.1247)  data: 0.2135 (0.3465)  lr: 0.000000  max mem: 1423
2020-12-13 02:18:02,901 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 02:18:02,912 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 02:18:09,327 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.414432 (1.6036078929901123 s / img per device, on 1 devices)
2020-12-13 02:18:09,327 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.864296 (1.466073989868164 s / img per device, on 1 devices)
2020-12-13 02:18:09,327 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 02:18:09,753 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 02:18:09,753 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0285,
        0.0237, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0056, 0.0008, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,
         1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  7.,  1.,  1.,  1.,  1.,  1.,
         1.,  1.]), 'best match scores': tensor([0.9990, 0.0915, 0.9449, 1.0000, 0.9978, 0.9960, 0.0829, 0.9407, 1.0000,
        0.9994, 0.0702, 0.9985, 0.2193, 0.0595, 0.1471, 0.0000, 0.0000, 0.8937,
        1.0000, 0.1397, 0.1200, 0.3937, 0.0859, 0.1370, 0.0768, 0.8598, 0.0769,
        0.9984, 0.7410, 0.9664]), 'num_pos': 30}
2020-12-13 02:18:09,762 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.900000
2020-12-13 02:19:27,008 maskrcnn_benchmark.trainer INFO: eta: 0:27:33  iter: 200  loss: 4.3158 (7.1607)  loss_classifier: 0.0805 (0.9489)  loss_box_reg: 0.5058 (1.1722)  loss_objectness: 0.4473 (1.0017)  loss_rpn_box_reg: 3.2818 (4.0379)  time: 3.8586 (4.1328)  data: 0.2209 (0.3684)  lr: 0.000000  max mem: 1423
2020-12-13 02:20:44,336 maskrcnn_benchmark.trainer INFO: eta: 0:26:01  iter: 220  loss: 3.9968 (6.8748)  loss_classifier: 0.0442 (0.8676)  loss_box_reg: 0.4747 (1.1103)  loss_objectness: 0.3535 (0.9438)  loss_rpn_box_reg: 3.1027 (3.9532)  time: 3.8659 (4.1086)  data: 0.2082 (0.3539)  lr: 0.000001  max mem: 1423
2020-12-13 02:22:01,750 maskrcnn_benchmark.trainer INFO: eta: 0:24:31  iter: 240  loss: 3.8995 (6.6316)  loss_classifier: 0.0526 (0.8000)  loss_box_reg: 0.5033 (1.0580)  loss_objectness: 0.3724 (0.8972)  loss_rpn_box_reg: 2.9568 (3.8764)  time: 3.8710 (4.0887)  data: 0.2073 (0.3418)  lr: 0.000001  max mem: 1423
2020-12-13 02:22:01,752 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 02:22:01,763 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 02:22:07,868 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.105333 (1.5263331532478333 s / img per device, on 1 devices)
2020-12-13 02:22:07,869 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.640311 (1.4100776314735413 s / img per device, on 1 devices)
2020-12-13 02:22:07,869 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 02:22:08,289 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 02:22:08,290 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.2595e-01, 1.2659e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.1364e-03, 1.0057e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3585e-02, 1.5276e-02, 5.3349e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0160e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'best match scores': tensor([0.9530, 1.0000, 0.9999, 0.2173, 0.0868, 0.9893, 0.0981, 1.0000, 0.9910,
        0.1540, 0.0645, 0.3453, 0.1988, 1.0000, 0.1021, 1.0000, 0.0881, 0.9901,
        0.0890, 0.9868, 0.3758, 0.8008, 1.0000, 0.9887, 1.0000, 0.4497, 0.9545,
        0.3778, 0.4593, 0.7919]), 'num_pos': 30}
2020-12-13 02:22:08,298 maskrcnn_benchmark.trainer INFO: validation accuracy: 1.000000
2020-12-13 02:23:25,674 maskrcnn_benchmark.trainer INFO: eta: 0:23:12  iter: 260  loss: 3.8586 (6.4133)  loss_classifier: 0.0597 (0.7433)  loss_box_reg: 0.4783 (1.0125)  loss_objectness: 0.3520 (0.8547)  loss_rpn_box_reg: 2.9138 (3.8028)  time: 3.8682 (4.0970)  data: 0.2071 (0.3567)  lr: 0.000001  max mem: 1423
2020-12-13 02:24:42,967 maskrcnn_benchmark.trainer INFO: eta: 0:21:45  iter: 280  loss: 3.6003 (6.2142)  loss_classifier: 0.0304 (0.6931)  loss_box_reg: 0.4257 (0.9709)  loss_objectness: 0.2890 (0.8163)  loss_rpn_box_reg: 2.8448 (3.7339)  time: 3.8694 (4.0804)  data: 0.2083 (0.3461)  lr: 0.000001  max mem: 1423
2020-12-13 02:26:00,244 maskrcnn_benchmark.trainer INFO: eta: 0:20:19  iter: 300  loss: 3.5461 (6.0331)  loss_classifier: 0.0569 (0.6507)  loss_box_reg: 0.4171 (0.9339)  loss_objectness: 0.3004 (0.7822)  loss_rpn_box_reg: 2.7335 (3.6662)  time: 3.8668 (4.0660)  data: 0.2069 (0.3369)  lr: 0.000001  max mem: 1423
2020-12-13 02:26:00,246 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 02:26:00,257 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 02:26:06,353 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.096014 (1.5240034461021423 s / img per device, on 1 devices)
2020-12-13 02:26:06,353 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.629426 (1.4073566198349 s / img per device, on 1 devices)
2020-12-13 02:26:06,353 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 02:26:06,768 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 02:26:06,768 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.5110e-01, 1.5791e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.5924e-02, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5165e-02,
        2.7713e-03, 2.0110e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,  8., -1.,  1.,  1.,
         1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,
         1.,  1.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9972, 0.9979, 1.0000,
        0.0000, 0.3117, 0.0000, 0.4704, 0.9918, 0.5576, 0.0000, 0.0000, 0.0000,
        0.1526, 1.0000, 0.0539, 0.4858, 0.9909, 0.6728, 0.6364, 1.0000, 0.1475,
        0.1806, 0.9465, 0.9914]), 'num_pos': 30}
2020-12-13 02:26:06,777 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.600000
2020-12-13 02:27:24,081 maskrcnn_benchmark.trainer INFO: eta: 0:19:00  iter: 320  loss: 3.3607 (5.8679)  loss_classifier: 0.0339 (0.6124)  loss_box_reg: 0.4039 (0.9011)  loss_objectness: 0.2804 (0.7515)  loss_rpn_box_reg: 2.6276 (3.6030)  time: 3.8617 (4.0738)  data: 0.2071 (0.3493)  lr: 0.000001  max mem: 1423
2020-12-13 02:28:41,447 maskrcnn_benchmark.trainer INFO: eta: 0:17:36  iter: 340  loss: 3.3662 (5.7194)  loss_classifier: 0.0285 (0.5782)  loss_box_reg: 0.3615 (0.8700)  loss_objectness: 0.2509 (0.7223)  loss_rpn_box_reg: 2.7116 (3.5488)  time: 3.8691 (4.0617)  data: 0.2079 (0.3410)  lr: 0.000001  max mem: 1423
2020-12-13 02:29:58,652 maskrcnn_benchmark.trainer INFO: eta: 0:16:12  iter: 360  loss: 3.2231 (5.5819)  loss_classifier: 0.0428 (0.5483)  loss_box_reg: 0.3438 (0.8411)  loss_objectness: 0.2443 (0.6961)  loss_rpn_box_reg: 2.5658 (3.4963)  time: 3.8627 (4.0505)  data: 0.2074 (0.3337)  lr: 0.000001  max mem: 1423
2020-12-13 02:29:58,654 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 02:29:58,665 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 02:30:04,745 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.079980 (1.519995093345642 s / img per device, on 1 devices)
2020-12-13 02:30:04,745 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.618397 (1.4045993089675903 s / img per device, on 1 devices)
2020-12-13 02:30:04,745 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 02:30:05,158 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 02:30:05,158 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([8.5641e-02, 1.4001e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.1249e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0294e-03,
        1.5028e-04, 5.6941e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,
         1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,
         1.,  1.]), 'best match scores': tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.1025, 1.0000, 0.9999, 1.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9929, 0.0000, 0.0000, 0.0000,
        1.0000, 0.0624, 0.2365, 0.0533, 0.6628, 0.6156, 1.0000, 0.0000, 0.0846,
        0.3035, 0.1292, 0.3125]), 'num_pos': 30}
2020-12-13 02:30:05,166 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.600000
2020-12-13 02:31:22,590 maskrcnn_benchmark.trainer INFO: eta: 0:14:52  iter: 380  loss: 3.1027 (5.4524)  loss_classifier: 0.0421 (0.5220)  loss_box_reg: 0.3262 (0.8140)  loss_objectness: 0.2430 (0.6728)  loss_rpn_box_reg: 2.4986 (3.4437)  time: 3.8736 (4.0583)  data: 0.2084 (0.3443)  lr: 0.000001  max mem: 1423
2020-12-13 02:32:40,042 maskrcnn_benchmark.trainer INFO: eta: 0:13:29  iter: 400  loss: 3.0897 (5.3353)  loss_classifier: 0.0337 (0.4978)  loss_box_reg: 0.3407 (0.7899)  loss_objectness: 0.2271 (0.6506)  loss_rpn_box_reg: 2.4816 (3.3970)  time: 3.8749 (4.0490)  data: 0.2095 (0.3376)  lr: 0.000001  max mem: 1423
2020-12-13 02:33:57,751 maskrcnn_benchmark.trainer INFO: eta: 0:12:07  iter: 420  loss: 3.0162 (5.2241)  loss_classifier: 0.0272 (0.4756)  loss_box_reg: 0.2941 (0.7668)  loss_objectness: 0.2069 (0.6308)  loss_rpn_box_reg: 2.4165 (3.3509)  time: 3.8737 (4.0412)  data: 0.2087 (0.3314)  lr: 0.000001  max mem: 1423
2020-12-13 02:33:57,753 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 02:33:57,763 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 02:34:03,826 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.062184 (1.5155460834503174 s / img per device, on 1 devices)
2020-12-13 02:34:03,826 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.615490 (1.4038724303245544 s / img per device, on 1 devices)
2020-12-13 02:34:03,826 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 02:34:04,231 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 02:34:04,231 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0133, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0870,
        0.0222, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0001, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0017, 0.0004, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,
         1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,
         1.,  1.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9708, 0.1097, 1.0000, 1.0000,
        1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9992, 0.0000, 0.0000, 0.0000,
        0.9586, 0.1131, 0.0912, 0.1927, 0.0851, 0.5895, 0.1257, 0.7646, 0.8353,
        0.1448, 0.2130, 0.0962]), 'num_pos': 30}
2020-12-13 02:34:04,239 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.600000
2020-12-13 02:35:21,378 maskrcnn_benchmark.trainer INFO: eta: 0:10:47  iter: 440  loss: 2.8285 (5.1177)  loss_classifier: 0.0341 (0.4557)  loss_box_reg: 0.3334 (0.7465)  loss_objectness: 0.1950 (0.6114)  loss_rpn_box_reg: 2.2768 (3.3041)  time: 3.8507 (4.0476)  data: 0.2048 (0.3404)  lr: 0.000001  max mem: 1423
2020-12-13 02:36:38,614 maskrcnn_benchmark.trainer INFO: eta: 0:09:25  iter: 460  loss: 2.7917 (5.0163)  loss_classifier: 0.0373 (0.4380)  loss_box_reg: 0.3037 (0.7273)  loss_objectness: 0.1741 (0.5929)  loss_rpn_box_reg: 2.2327 (3.2581)  time: 3.8620 (4.0395)  data: 0.2057 (0.3346)  lr: 0.000001  max mem: 1423
2020-12-13 02:37:55,802 maskrcnn_benchmark.trainer INFO: eta: 0:08:03  iter: 480  loss: 2.7275 (4.9205)  loss_classifier: 0.0280 (0.4212)  loss_box_reg: 0.2973 (0.7089)  loss_objectness: 0.1982 (0.5759)  loss_rpn_box_reg: 2.1697 (3.2145)  time: 3.8565 (4.0320)  data: 0.2055 (0.3292)  lr: 0.000001  max mem: 1423
2020-12-13 02:37:55,804 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 02:37:55,814 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 02:38:01,881 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.066034 (1.5165084600448608 s / img per device, on 1 devices)
2020-12-13 02:38:01,881 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.615859 (1.4039646983146667 s / img per device, on 1 devices)
2020-12-13 02:38:01,881 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 02:38:02,285 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 02:38:02,285 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([6.5056e-03, 4.1905e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.0353e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5229e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3467e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([ 1., -1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,
         1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,
        -1.,  1.]), 'best match scores': tensor([0.1889, 0.0000, 0.0000, 0.0000, 0.0000, 0.3584, 0.0000, 0.0601, 0.1312,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0641, 0.4192, 0.0000, 0.8730, 0.0000,
        0.0000, 0.0000, 0.9708, 1.0000, 1.0000, 0.1141, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.1138]), 'num_pos': 30}
2020-12-13 02:38:02,293 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.400000
2020-12-13 02:39:19,452 maskrcnn_benchmark.trainer INFO: eta: 0:06:43  iter: 500  loss: 2.6968 (4.8327)  loss_classifier: 0.0318 (0.4055)  loss_box_reg: 0.2934 (0.6917)  loss_objectness: 0.1929 (0.5606)  loss_rpn_box_reg: 2.2109 (3.1749)  time: 3.8559 (4.0380)  data: 0.2048 (0.3373)  lr: 0.000001  max mem: 1423
2020-12-13 02:40:36,528 maskrcnn_benchmark.trainer INFO: eta: 0:05:22  iter: 520  loss: 2.6414 (4.7477)  loss_classifier: 0.0304 (0.3911)  loss_box_reg: 0.2773 (0.6752)  loss_objectness: 0.1688 (0.5455)  loss_rpn_box_reg: 2.1441 (3.1360)  time: 3.8518 (4.0309)  data: 0.2155 (0.3326)  lr: 0.000001  max mem: 1423
2020-12-13 02:41:53,587 maskrcnn_benchmark.trainer INFO: eta: 0:04:01  iter: 540  loss: 2.5165 (4.6671)  loss_classifier: 0.0313 (0.3781)  loss_box_reg: 0.2419 (0.6596)  loss_objectness: 0.1561 (0.5315)  loss_rpn_box_reg: 2.0617 (3.0978)  time: 3.8506 (4.0243)  data: 0.2066 (0.3280)  lr: 0.000001  max mem: 1423
2020-12-13 02:41:53,589 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 02:41:53,600 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 02:41:59,690 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.090412 (1.5226030945777893 s / img per device, on 1 devices)
2020-12-13 02:41:59,691 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.625695 (1.4064236879348755 s / img per device, on 1 devices)
2020-12-13 02:41:59,691 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 02:42:00,104 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 02:42:00,104 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0507, 0.0392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0004,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0020, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0197, 0.0009, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,
         1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,
         1.,  1.]), 'best match scores': tensor([0.0000, 0.4880, 0.9163, 0.0000, 0.0000, 0.0000, 0.9551, 1.0000, 0.0526,
        0.0000, 0.0000, 0.0000, 0.0000, 0.9947, 0.9988, 0.0000, 0.0000, 0.0000,
        0.0000, 1.0000, 0.1404, 0.0564, 0.2210, 0.3041, 0.1490, 0.0000, 0.1266,
        0.3879, 0.9999, 0.3530]), 'num_pos': 30}
2020-12-13 02:42:00,112 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.566667
2020-12-13 02:43:17,143 maskrcnn_benchmark.trainer INFO: eta: 0:02:41  iter: 560  loss: 2.4810 (4.5865)  loss_classifier: 0.0431 (0.3664)  loss_box_reg: 0.2285 (0.6448)  loss_objectness: 0.1537 (0.5182)  loss_rpn_box_reg: 1.9809 (3.0571)  time: 3.8496 (4.0298)  data: 0.2075 (0.3353)  lr: 0.000001  max mem: 1423
2020-12-13 02:44:34,246 maskrcnn_benchmark.trainer INFO: eta: 0:01:20  iter: 580  loss: 2.3207 (4.5078)  loss_classifier: 0.0297 (0.3548)  loss_box_reg: 0.2557 (0.6310)  loss_objectness: 0.1417 (0.5055)  loss_rpn_box_reg: 1.8876 (3.0165)  time: 3.8552 (4.0238)  data: 0.2084 (0.3310)  lr: 0.000001  max mem: 1423
2020-12-13 02:45:51,347 maskrcnn_benchmark.trainer INFO: eta: 0:00:00  iter: 600  loss: 2.2192 (4.4333)  loss_classifier: 0.0272 (0.3440)  loss_box_reg: 0.2426 (0.6177)  loss_objectness: 0.1418 (0.4936)  loss_rpn_box_reg: 1.8282 (2.9780)  time: 3.8538 (4.0182)  data: 0.2086 (0.3269)  lr: 0.000001  max mem: 1423
2020-12-13 02:45:51,349 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 02:45:51,360 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 02:45:57,453 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.093674 (1.5234184265136719 s / img per device, on 1 devices)
2020-12-13 02:45:57,454 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.627096 (1.40677410364151 s / img per device, on 1 devices)
2020-12-13 02:45:57,454 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 02:45:57,871 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 02:45:57,872 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0525, 0.0051, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0378,
        0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0529, 0.0005, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,
         8., -1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1.,
         1.,  1.]), 'best match scores': tensor([0.0000, 0.0000, 0.0856, 0.0000, 0.0000, 0.0000, 0.2582, 0.2976, 0.1694,
        0.0000, 0.9949, 0.0000, 0.0000, 1.0000, 0.5414, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.1338, 0.0878, 0.0000, 0.0000, 0.0000,
        0.0000, 0.4529, 0.0992]), 'num_pos': 30}
2020-12-13 02:45:57,880 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 02:45:57,885 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./final_mode_r5_v5.pth
2020-12-13 02:45:58,910 maskrcnn_benchmark.trainer INFO: final model, saving model to: final_mode_r5_v5
2020-12-13 02:45:58,932 maskrcnn_benchmark.trainer INFO: Total training time: 0:40:18.477798 (4.0308 s / it)
2020-12-13 02:46:00,095 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_test dataset(258 images).
2020-12-13 02:47:43,318 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 02:47:43,318 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 02:47:43,318 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 02:47:45,740 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 02:47:45,741 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 02:47:45,741 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro8_valid",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00008
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 2000
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-13 02:47:45,742 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro8_valid',)
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 100
    BG_IOU_THRESHOLD: 0.2
    FG_IOU_THRESHOLD: 0.6
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 8e-05
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 2000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-13 02:47:47,407 maskrcnn_benchmark INFO: reloading weigts from final_mode_r5_v5.pth
2020-12-13 02:47:49,676 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-13 02:47:49,677 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-13 02:47:49,677 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-13 02:47:49,677 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-13 02:47:49,677 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-13 02:47:49,677 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-13 02:47:49,678 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-13 02:47:49,678 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-13 02:47:49,678 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-13 02:47:49,678 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-13 02:47:49,678 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-13 02:47:49,678 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-13 02:47:49,678 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-13 02:47:49,679 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-13 02:47:49,853 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-13 02:47:49,879 maskrcnn_benchmark.trainer INFO: Start training
2020-12-13 02:49:07,402 maskrcnn_benchmark.trainer INFO: eta: 2:07:54  iter: 20  loss: 33.5783 (30.7551)  loss_classifier: 12.0954 (15.1177)  loss_box_reg: 2.0053 (2.3190)  loss_objectness: 0.6164 (1.6583)  loss_rpn_box_reg: 0.2355 (11.6602)  time: 3.8613 (3.8760)  data: 0.2100 (0.2097)  lr: 0.000029  max mem: 1425
2020-12-13 02:50:24,754 maskrcnn_benchmark.trainer INFO: eta: 2:06:28  iter: 40  loss: 30.8904 (35.8662)  loss_classifier: 27.6969 (26.5469)  loss_box_reg: 2.2782 (2.2729)  loss_objectness: 0.6009 (1.1296)  loss_rpn_box_reg: 0.1713 (5.9169)  time: 3.8617 (3.8718)  data: 0.2091 (0.2095)  lr: 0.000031  max mem: 1425
2020-12-13 02:51:42,576 maskrcnn_benchmark.trainer INFO: eta: 2:05:23  iter: 60  loss: 20.2242 (33.6004)  loss_classifier: 17.1369 (26.5407)  loss_box_reg: 1.4579 (2.1208)  loss_objectness: 0.5428 (0.9367)  loss_rpn_box_reg: 0.1679 (4.0022)  time: 3.8868 (3.8782)  data: 0.2143 (0.2113)  lr: 0.000033  max mem: 1425
2020-12-13 02:51:42,578 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 02:51:42,589 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 02:51:48,696 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.107188 (1.5267969965934753 s / img per device, on 1 devices)
2020-12-13 02:51:48,697 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.633991 (1.4084977507591248 s / img per device, on 1 devices)
2020-12-13 02:51:48,697 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 02:51:49,121 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 02:51:49,122 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0102, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1., -1., -1., -1.,  3., -1., -1.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0810, 0.0000, 0.0000]), 'num_pos': 8}
2020-12-13 02:51:49,127 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-13 02:51:49,131 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v5.pth
2020-12-13 02:51:53,460 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v5
2020-12-13 02:53:31,913 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 02:53:31,914 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 02:53:31,914 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 02:53:34,207 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 02:53:34,208 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 02:53:34,208 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro8_valid",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00008
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 2000
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-13 02:53:34,209 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro8_valid',)
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 100
    BG_IOU_THRESHOLD: 0.2
    FG_IOU_THRESHOLD: 0.6
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 8e-05
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 2000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-13 02:53:35,951 maskrcnn_benchmark INFO: reloading weigts from final_mode_r5_v5.pth
2020-12-13 02:53:40,627 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-13 02:53:40,627 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-13 02:53:40,627 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-13 02:53:40,627 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-13 02:53:40,628 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-13 02:53:40,628 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-13 02:53:40,628 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-13 02:53:40,628 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-13 02:53:40,628 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-13 02:53:40,628 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-13 02:53:40,629 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-13 02:53:40,629 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-13 02:53:40,629 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-13 02:53:40,629 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-13 02:53:40,810 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-13 02:53:40,837 maskrcnn_benchmark.trainer INFO: Start training
2020-12-13 02:54:58,538 maskrcnn_benchmark.trainer INFO: eta: 2:08:12  iter: 20  loss: 12.8027 (43.6911)  loss_classifier: 0.1581 (19.4019)  loss_box_reg: 2.3575 (2.9218)  loss_objectness: 0.6177 (0.7042)  loss_rpn_box_reg: 0.3425 (20.6631)  time: 3.8779 (3.8849)  data: 0.2130 (0.2149)  lr: 0.000029  max mem: 1425
2020-12-13 02:56:16,253 maskrcnn_benchmark.trainer INFO: eta: 2:06:55  iter: 40  loss: 124.9261 (225.8569)  loss_classifier: 121.4203 (204.4848)  loss_box_reg: 11.6074 (10.2162)  loss_objectness: 0.6129 (0.6582)  loss_rpn_box_reg: 0.3271 (10.4978)  time: 3.8857 (3.8853)  data: 0.2137 (0.2152)  lr: 0.000031  max mem: 1425
2020-12-13 02:56:55,483 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 02:56:55,483 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 02:56:55,483 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 02:56:57,851 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 02:56:57,851 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 02:56:57,852 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro8_valid",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 2000
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-13 02:56:57,853 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro8_valid',)
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 100
    BG_IOU_THRESHOLD: 0.2
    FG_IOU_THRESHOLD: 0.6
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 1e-06
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 2000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-13 02:56:59,674 maskrcnn_benchmark INFO: reloading weigts from final_mode_r5_v5.pth
2020-12-13 02:57:02,274 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-13 02:57:02,274 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-13 02:57:02,274 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-13 02:57:02,274 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-13 02:57:02,274 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-13 02:57:02,275 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-13 02:57:02,275 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-13 02:57:02,275 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-13 02:57:02,275 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-13 02:57:02,275 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-13 02:57:02,276 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-13 02:57:02,276 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-13 02:57:02,276 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-13 02:57:02,276 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-13 02:57:02,473 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-13 02:57:02,499 maskrcnn_benchmark.trainer INFO: Start training
2020-12-13 02:58:20,331 maskrcnn_benchmark.trainer INFO: eta: 2:08:25  iter: 20  loss: 4.2059 (4.1926)  loss_classifier: 0.0308 (0.0372)  loss_box_reg: 0.2320 (0.2461)  loss_objectness: 0.1344 (0.1374)  loss_rpn_box_reg: 3.7423 (3.7720)  time: 3.8797 (3.8914)  data: 0.2154 (0.2165)  lr: 0.000000  max mem: 1425
2020-12-13 02:59:38,440 maskrcnn_benchmark.trainer INFO: eta: 2:07:20  iter: 40  loss: 4.1648 (4.1830)  loss_classifier: 0.0222 (0.0374)  loss_box_reg: 0.2325 (0.2420)  loss_objectness: 0.1386 (0.1391)  loss_rpn_box_reg: 3.7679 (3.7645)  time: 3.8855 (3.8984)  data: 0.2138 (0.2161)  lr: 0.000000  max mem: 1425
2020-12-13 03:00:56,287 maskrcnn_benchmark.trainer INFO: eta: 2:05:59  iter: 60  loss: 4.0438 (4.1320)  loss_classifier: 0.0211 (0.0347)  loss_box_reg: 0.1964 (0.2330)  loss_objectness: 0.1433 (0.1402)  loss_rpn_box_reg: 3.6447 (3.7241)  time: 3.8859 (3.8964)  data: 0.2171 (0.2169)  lr: 0.000000  max mem: 1425
2020-12-13 03:00:56,289 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:00:56,301 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 03:01:02,417 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.116072 (1.529017984867096 s / img per device, on 1 devices)
2020-12-13 03:01:02,417 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.643869 (1.4109673500061035 s / img per device, on 1 devices)
2020-12-13 03:01:02,417 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:01:02,846 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:01:02,846 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0019, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0098, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.,
         1., -1., -1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,
         1.,  1.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9987, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 1.0000, 0.0000, 0.7668, 1.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.4863, 0.9804]), 'num_pos': 30}
2020-12-13 03:01:02,854 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.233333
2020-12-13 03:01:02,859 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v5.pth
2020-12-13 03:01:07,121 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v5
2020-12-13 03:02:46,763 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 03:02:46,763 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 03:02:46,763 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 03:02:49,031 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 03:02:49,032 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 03:02:49,032 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro8_valid",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 2000
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-13 03:02:49,033 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro8_valid',)
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 50
    BG_IOU_THRESHOLD: 0.1
    FG_IOU_THRESHOLD: 0.2
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 1e-06
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 2000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-13 03:02:50,772 maskrcnn_benchmark INFO: reloading weigts from final_mode_r5_v5.pth
2020-12-13 03:02:53,105 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-13 03:02:53,105 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-13 03:02:53,105 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-13 03:02:53,105 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-13 03:02:53,106 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-13 03:02:53,106 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-13 03:02:53,106 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-13 03:02:53,106 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-13 03:02:53,106 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-13 03:02:53,106 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-13 03:02:53,107 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-13 03:02:53,107 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-13 03:02:53,107 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-13 03:02:53,107 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-13 03:02:53,286 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-13 03:02:53,313 maskrcnn_benchmark.trainer INFO: Start training
2020-12-13 03:04:16,356 maskrcnn_benchmark.trainer INFO: eta: 2:17:01  iter: 20  loss: 11.7425 (13.7050)  loss_classifier: 0.0268 (0.0326)  loss_box_reg: 0.2099 (0.2175)  loss_objectness: 2.8347 (3.2933)  loss_rpn_box_reg: 9.5524 (10.1616)  time: 4.2332 (4.1520)  data: 0.2249 (0.2312)  lr: 0.000000  max mem: 1425
2020-12-13 03:05:42,062 maskrcnn_benchmark.trainer INFO: eta: 2:17:48  iter: 40  loss: 6.6754 (10.4214)  loss_classifier: 0.0129 (0.0239)  loss_box_reg: 0.2060 (0.2143)  loss_objectness: 1.0812 (2.2300)  loss_rpn_box_reg: 5.3452 (7.9532)  time: 4.2798 (4.2186)  data: 0.2431 (0.2359)  lr: 0.000000  max mem: 1425
2020-12-13 03:07:07,521 maskrcnn_benchmark.trainer INFO: eta: 2:16:59  iter: 60  loss: 5.5239 (8.8015)  loss_classifier: 0.0098 (0.0208)  loss_box_reg: 0.2199 (0.2125)  loss_objectness: 0.9794 (1.8337)  loss_rpn_box_reg: 4.2990 (6.7346)  time: 4.2699 (4.2368)  data: 0.2430 (0.2391)  lr: 0.000000  max mem: 1425
2020-12-13 03:07:07,523 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:07:07,534 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 03:07:14,135 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.600697 (1.6501741409301758 s / img per device, on 1 devices)
2020-12-13 03:07:14,135 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:06.092165 (1.5230413675308228 s / img per device, on 1 devices)
2020-12-13 03:07:14,136 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:07:14,599 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:07:14,599 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,
         1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,
         1.,  1.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.4251, 0.5420, 0.0000,
        0.0000, 0.0812, 0.9954, 0.0875, 0.9891, 0.9981, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 1.0000, 0.1793, 0.0000, 0.0000, 0.9996, 0.9413,
        0.4091, 0.3624, 0.0693]), 'num_pos': 30}
2020-12-13 03:07:14,609 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.500000
2020-12-13 03:07:14,614 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v5.pth
2020-12-13 03:07:19,247 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v5
2020-12-13 03:08:43,632 maskrcnn_benchmark.trainer INFO: eta: 2:20:07  iter: 80  loss: 5.1230 (7.8983)  loss_classifier: 0.0132 (0.0198)  loss_box_reg: 0.1917 (0.2081)  loss_objectness: 0.9464 (1.6135)  loss_rpn_box_reg: 4.0666 (6.0570)  time: 4.2250 (4.3790)  data: 0.2384 (0.3861)  lr: 0.000000  max mem: 1425
2020-12-13 03:10:08,001 maskrcnn_benchmark.trainer INFO: eta: 2:17:39  iter: 100  loss: 5.0734 (7.3371)  loss_classifier: 0.0069 (0.0183)  loss_box_reg: 0.2132 (0.2067)  loss_objectness: 0.8806 (1.4703)  loss_rpn_box_reg: 3.9533 (5.6418)  time: 4.2154 (4.3468)  data: 0.2345 (0.3572)  lr: 0.000000  max mem: 1425
2020-12-13 03:11:32,085 maskrcnn_benchmark.trainer INFO: eta: 2:15:27  iter: 120  loss: 5.1325 (6.9681)  loss_classifier: 0.0056 (0.0173)  loss_box_reg: 0.2057 (0.2057)  loss_objectness: 0.9107 (1.3780)  loss_rpn_box_reg: 3.9840 (5.3671)  time: 4.2195 (4.3231)  data: 0.2405 (0.3379)  lr: 0.000000  max mem: 1425
2020-12-13 03:11:32,087 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:11:32,097 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 03:11:38,660 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.562330 (1.6405826210975647 s / img per device, on 1 devices)
2020-12-13 03:11:38,660 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:06.062900 (1.5157250761985779 s / img per device, on 1 devices)
2020-12-13 03:11:38,660 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:11:39,115 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:11:39,115 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1]), 'best match labels': tensor([-1., -1., -1., -1., -1.,  1.,  1.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.1203]), 'num_pos': 7}
2020-12-13 03:11:39,120 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.285714
2020-12-13 03:14:14,895 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 03:14:14,896 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 03:14:14,896 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 03:14:17,315 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 03:14:17,315 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 03:14:17,315 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_valid",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.0000005
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 2000
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-13 03:14:17,316 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_valid',)
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 50
    BG_IOU_THRESHOLD: 0.1
    FG_IOU_THRESHOLD: 0.2
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 5e-07
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 2000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-13 03:14:19,132 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-13 03:14:19,132 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-13 03:14:19,132 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-13 03:14:19,132 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-13 03:14:19,133 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-13 03:14:19,133 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-13 03:14:19,133 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-13 03:14:19,133 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-13 03:14:19,133 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-13 03:14:19,133 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-13 03:14:19,133 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-13 03:14:19,133 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-13 03:14:19,133 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-13 03:14:19,133 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-13 03:14:21,286 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-13 03:14:21,392 maskrcnn_benchmark.trainer INFO: Start training
2020-12-13 03:15:34,865 maskrcnn_benchmark.trainer INFO: eta: 2:01:13  iter: 20  loss: 33.4138 (46.6013)  loss_classifier: 4.3805 (16.9945)  loss_box_reg: 5.7628 (5.6680)  loss_objectness: 3.8627 (4.4163)  loss_rpn_box_reg: 19.2429 (19.5225)  time: 4.1732 (3.6735)  data: 0.2303 (0.2099)  lr: 0.000000  max mem: 1423
2020-12-13 03:16:45,920 maskrcnn_benchmark.trainer INFO: eta: 1:58:01  iter: 40  loss: 13.8787 (30.6249)  loss_classifier: 1.5591 (9.3612)  loss_box_reg: 1.6034 (3.8102)  loss_objectness: 1.0254 (2.7140)  loss_rpn_box_reg: 9.2656 (14.7394)  time: 3.8693 (3.6131)  data: 0.2104 (0.2059)  lr: 0.000000  max mem: 1423
2020-12-13 03:17:55,177 maskrcnn_benchmark.trainer INFO: eta: 1:55:12  iter: 60  loss: 9.7025 (23.7177)  loss_classifier: 0.6653 (6.5782)  loss_box_reg: 1.0388 (2.9250)  loss_objectness: 0.7881 (2.0909)  loss_rpn_box_reg: 6.9301 (12.1236)  time: 3.8716 (3.5630)  data: 0.2078 (0.2019)  lr: 0.000000  max mem: 1423
2020-12-13 03:17:55,179 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:17:55,240 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(9 images).
2020-12-13 03:18:09,954 maskrcnn_benchmark.inference INFO: Total run time: 0:00:14.714282 (1.6349201997121174 s / img per device, on 1 devices)
2020-12-13 03:18:09,954 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:13.641854 (1.515761587354872 s / img per device, on 1 devices)
2020-12-13 03:18:09,954 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:18:10,979 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:18:10,979 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([5.0164e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6433e-02, 3.2155e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.8279e-02, 6.1067e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3133e-02, 4.0994e-02, 2.8276e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.5997e-01, 1.3089e-01, 5.2844e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0397e-01, 5.8206e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.6272e-01, 5.1106e-02, 1.4659e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7661e-02, 3.3482e-02, 2.3250e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.6161e-02, 3.6950e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 2., 6., 2., 2., 2., 2., 2., 2., 2., 6., 2.,
        2., 2., 2., 2., 2., 2., 2., 2., 6., 2., 2., 2., 2., 2., 2., 2., 6., 2.,
        2., 2., 2., 2., 2., 2., 6., 6., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 6., 2.]), 'best match scores': tensor([0.7183, 1.0000, 1.0000, 1.0000, 0.1527, 0.8385, 0.0513, 1.0000, 1.0000,
        0.3352, 0.1714, 0.9996, 0.9998, 0.9791, 0.9993, 0.9701, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.7932, 1.0000, 1.0000, 0.8564, 0.2318, 0.2752,
        0.9990, 0.9998, 1.0000, 0.4175, 1.0000, 0.0965, 1.0000, 0.1210, 0.9997,
        0.0557, 0.1008, 1.0000, 0.5060, 0.5639, 0.5544, 1.0000, 0.9998, 0.0976,
        1.0000, 0.9998, 0.9885, 1.0000, 0.9339, 0.2199, 1.0000, 1.0000, 1.0000,
        1.0000, 0.9999, 0.9687, 0.9999, 1.0000, 1.0000, 0.9930, 1.0000, 0.9858,
        0.3253, 1.0000, 0.7281, 1.0000, 0.9993, 0.9996, 0.9805, 1.0000, 0.9988,
        1.0000, 0.9647, 1.0000, 1.0000, 0.5761, 0.3335, 1.0000, 0.5193, 0.5245]), 'num_pos': 81}
2020-12-13 03:18:10,994 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.913580
2020-12-13 03:18:10,997 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v5.pth
2020-12-13 03:18:15,479 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v5
2020-12-13 03:19:29,807 maskrcnn_benchmark.trainer INFO: eta: 2:03:21  iter: 80  loss: 8.5742 (20.0102)  loss_classifier: 0.4189 (5.1232)  loss_box_reg: 0.6793 (2.4212)  loss_objectness: 0.7714 (1.7587)  loss_rpn_box_reg: 6.4695 (10.7070)  time: 4.2160 (3.8552)  data: 0.2251 (0.4574)  lr: 0.000000  max mem: 1423
2020-12-13 03:20:43,974 maskrcnn_benchmark.trainer INFO: eta: 2:01:09  iter: 100  loss: 8.2663 (17.7096)  loss_classifier: 0.4752 (4.2650)  loss_box_reg: 0.6645 (2.1313)  loss_objectness: 0.7097 (1.5450)  loss_rpn_box_reg: 5.9709 (9.7684)  time: 4.2142 (3.8258)  data: 0.2275 (0.4084)  lr: 0.000000  max mem: 1423
2020-12-13 03:21:57,369 maskrcnn_benchmark.trainer INFO: eta: 1:59:03  iter: 120  loss: 7.6252 (16.0769)  loss_classifier: 0.2935 (3.6690)  loss_box_reg: 0.6907 (1.9289)  loss_objectness: 0.5966 (1.3931)  loss_rpn_box_reg: 5.3475 (9.0859)  time: 4.1595 (3.7998)  data: 0.2265 (0.3756)  lr: 0.000000  max mem: 1423
2020-12-13 03:21:57,371 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:21:57,428 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(9 images).
2020-12-13 03:22:11,972 maskrcnn_benchmark.inference INFO: Total run time: 0:00:14.543785 (1.6159761216905382 s / img per device, on 1 devices)
2020-12-13 03:22:11,972 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:13.504915 (1.5005461110009088 s / img per device, on 1 devices)
2020-12-13 03:22:11,972 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:22:12,985 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:22:12,985 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.1021e-01, 1.0541e-01, 9.1316e-04, 1.9850e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.4796e-01, 7.3835e-02, 4.7687e-02, 2.0852e-02, 1.0192e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2799e-01, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.4222e-02, 6.3107e-02, 2.0852e-02, 4.6220e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3612e-01, 1.0373e-01, 8.6006e-02,
        7.4462e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        8.9509e-02, 1.2336e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6832e-01, 1.8005e-01, 7.5572e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.2610e-01, 1.8987e-01, 6.8936e-02, 5.5350e-02, 1.1155e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2., -1.,  2.,  2.,  2.,  2.,
         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,
         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,
         2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  6.,  2.,  2., -1.,
        -1., -1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,
         2.,  6.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([1.0000, 1.0000, 0.9762, 0.9999, 0.9999, 0.3324, 0.3982, 0.7375, 1.0000,
        0.0000, 1.0000, 0.7912, 1.0000, 0.9679, 1.0000, 0.9977, 1.0000, 1.0000,
        1.0000, 1.0000, 1.0000, 0.0669, 0.9828, 0.2782, 1.0000, 1.0000, 0.6544,
        0.9999, 1.0000, 0.1335, 0.9911, 0.7511, 0.9648, 1.0000, 0.3316, 0.4626,
        0.7384, 0.9897, 0.0504, 1.0000, 0.9984, 0.9999, 0.9750, 1.0000, 1.0000,
        0.3790, 1.0000, 0.9958, 1.0000, 0.2877, 1.0000, 0.2820, 0.8172, 0.2615,
        0.6920, 0.0000, 0.0000, 0.0000, 0.9999, 1.0000, 0.9972, 0.9037, 0.0650,
        1.0000, 0.9990, 1.0000, 0.7688, 0.7787, 0.9998, 0.0826, 0.7822, 1.0000,
        1.0000, 0.9991, 0.9997, 0.9997, 0.7588, 0.3866, 0.9860, 0.7139, 0.3498]), 'num_pos': 81}
2020-12-13 03:22:13,001 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.925926
2020-12-13 03:22:13,004 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v5.pth
2020-12-13 03:25:51,837 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 03:25:51,837 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 03:25:51,837 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 03:25:54,684 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 03:25:54,685 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 03:25:54,685 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_valid",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.0000005
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 2000
  IMS_PER_BATCH: 1
TEST:
  IMS_PER_BATCH: 1

2020-12-13 03:25:54,687 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_valid',)
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 5e-07
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  MAX_ITER: 2000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-13 03:25:56,581 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-13 03:25:56,581 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-13 03:25:56,582 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-13 03:25:56,582 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-13 03:25:56,582 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-13 03:25:56,582 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-13 03:25:56,582 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-13 03:25:56,582 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-13 03:25:56,582 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-13 03:25:56,582 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-13 03:25:56,583 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-13 03:25:56,583 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-13 03:25:56,583 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-13 03:25:56,583 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-13 03:25:59,046 maskrcnn_benchmark.trainer INFO: Start training
2020-12-13 03:26:31,639 maskrcnn_benchmark.trainer INFO: eta: 0:53:46  iter: 20  loss: 14.2037 (17.2388)  loss_classifier: 5.6908 (8.0619)  loss_box_reg: 1.1776 (1.3398)  loss_objectness: 0.2602 (0.2747)  loss_rpn_box_reg: 7.5781 (7.5624)  time: 1.6189 (1.6295)  data: 0.1097 (0.1118)  lr: 0.000000  max mem: 970
2020-12-13 03:27:03,835 maskrcnn_benchmark.trainer INFO: eta: 0:52:54  iter: 40  loss: 6.0715 (11.9379)  loss_classifier: 3.2046 (5.7786)  loss_box_reg: 0.7105 (1.0199)  loss_objectness: 0.1162 (0.1986)  loss_rpn_box_reg: 2.0071 (4.9408)  time: 1.6076 (1.6197)  data: 0.1057 (0.1101)  lr: 0.000000  max mem: 970
2020-12-13 03:27:36,065 maskrcnn_benchmark.trainer INFO: eta: 0:52:16  iter: 60  loss: 2.3129 (8.7797)  loss_classifier: 0.3007 (3.9811)  loss_box_reg: 0.6009 (0.8966)  loss_objectness: 0.1100 (0.1786)  loss_rpn_box_reg: 1.1733 (3.7233)  time: 1.6083 (1.6170)  data: 0.1069 (0.1096)  lr: 0.000000  max mem: 970
2020-12-13 03:27:36,067 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:27:36,124 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 03:27:37,725 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.600893 (1.6008930206298828 s / img per device, on 1 devices)
2020-12-13 03:27:37,725 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.482676 (1.4826760292053223 s / img per device, on 1 devices)
2020-12-13 03:27:37,725 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:27:37,832 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:27:37,832 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0333, 0.0270, 0.0170, 0.0131, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 4., 2., 2., 5., 2., 2., 3., 1.]), 'best match scores': tensor([0.9998, 0.6050, 0.1960, 0.9974, 1.0000, 0.5228, 1.0000, 0.9784, 0.3886]), 'num_pos': 9}
2020-12-13 03:27:37,837 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 03:27:37,839 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v5.pth
2020-12-13 03:27:42,086 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v5
2020-12-13 03:28:14,636 maskrcnn_benchmark.trainer INFO: eta: 0:54:14  iter: 80  loss: 1.9680 (7.0965)  loss_classifier: 0.3046 (3.0686)  loss_box_reg: 0.5233 (0.8143)  loss_objectness: 0.0851 (0.1574)  loss_rpn_box_reg: 1.0392 (3.0563)  time: 1.6125 (1.6948)  data: 0.1057 (0.1854)  lr: 0.000000  max mem: 982
2020-12-13 03:28:45,693 maskrcnn_benchmark.trainer INFO: eta: 0:52:46  iter: 100  loss: 1.8694 (6.1303)  loss_classifier: 0.2306 (2.5492)  loss_box_reg: 0.5292 (0.7896)  loss_objectness: 0.0437 (0.1385)  loss_rpn_box_reg: 1.0149 (2.6531)  time: 1.5359 (1.6665)  data: 0.1019 (0.1690)  lr: 0.000000  max mem: 982
2020-12-13 03:29:16,959 maskrcnn_benchmark.trainer INFO: eta: 0:51:40  iter: 120  loss: 1.8643 (5.4411)  loss_classifier: 0.2322 (2.1751)  loss_box_reg: 0.5212 (0.7546)  loss_objectness: 0.0774 (0.1291)  loss_rpn_box_reg: 1.0193 (2.3823)  time: 1.5497 (1.6493)  data: 0.1018 (0.1580)  lr: 0.000000  max mem: 982
2020-12-13 03:29:16,961 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:29:17,019 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 03:29:18,593 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.573087 (1.573087215423584 s / img per device, on 1 devices)
2020-12-13 03:29:18,593 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.452622 (1.4526219367980957 s / img per device, on 1 devices)
2020-12-13 03:29:18,593 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:29:18,711 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:29:18,711 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0363, 0.0323, 0.0171, 0.0168, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 5., 1., 2., 4., 2., 2., 2., 4.]), 'best match scores': tensor([0.9999, 0.2552, 0.9295, 0.5917, 0.0610, 0.9310, 0.9975, 1.0000, 0.1468]), 'num_pos': 9}
2020-12-13 03:29:18,717 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 03:29:50,795 maskrcnn_benchmark.trainer INFO: eta: 0:51:18  iter: 140  loss: 1.7821 (4.9714)  loss_classifier: 0.1869 (1.9285)  loss_box_reg: 0.4688 (0.7361)  loss_objectness: 0.0728 (0.1225)  loss_rpn_box_reg: 0.9618 (2.1843)  time: 1.6128 (1.6553)  data: 0.1105 (0.1637)  lr: 0.000000  max mem: 982
2020-12-13 03:30:22,382 maskrcnn_benchmark.trainer INFO: eta: 0:50:28  iter: 160  loss: 1.6439 (4.5625)  loss_classifier: 0.1575 (1.7115)  loss_box_reg: 0.4374 (0.6996)  loss_objectness: 0.0784 (0.1172)  loss_rpn_box_reg: 1.0118 (2.0341)  time: 1.5599 (1.6458)  data: 0.1061 (0.1568)  lr: 0.000000  max mem: 982
2020-12-13 03:30:53,804 maskrcnn_benchmark.trainer INFO: eta: 0:49:40  iter: 180  loss: 1.6206 (4.2475)  loss_classifier: 0.1423 (1.5470)  loss_box_reg: 0.4095 (0.6734)  loss_objectness: 0.0640 (0.1129)  loss_rpn_box_reg: 0.9310 (1.9142)  time: 1.5502 (1.6375)  data: 0.1071 (0.1513)  lr: 0.000000  max mem: 982
2020-12-13 03:30:53,806 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:30:53,863 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 03:30:55,434 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.570310 (1.570310115814209 s / img per device, on 1 devices)
2020-12-13 03:30:55,434 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.435458 (1.435457706451416 s / img per device, on 1 devices)
2020-12-13 03:30:55,434 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:30:55,562 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:30:55,562 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.2055, 0.1161, 0.0594, 0.0542, 0.0307, 0.0249, 0.0223, 0.0163, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 4., 2., 1., 2.]), 'best match scores': tensor([0.0724, 0.9957, 0.8541, 0.4581, 1.0000, 0.9994, 0.2871, 0.1034, 0.9993]), 'num_pos': 9}
2020-12-13 03:30:55,567 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.777778
2020-12-13 03:30:55,569 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v5.pth
2020-12-13 03:31:00,299 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v5
2020-12-13 03:31:32,527 maskrcnn_benchmark.trainer INFO: eta: 0:50:01  iter: 200  loss: 1.5367 (3.9862)  loss_classifier: 0.1031 (1.4129)  loss_box_reg: 0.3491 (0.6471)  loss_objectness: 0.0612 (0.1083)  loss_rpn_box_reg: 0.9741 (1.8180)  time: 1.6149 (1.6674)  data: 0.1083 (0.1795)  lr: 0.000000  max mem: 982
2020-12-13 03:32:03,674 maskrcnn_benchmark.trainer INFO: eta: 0:49:10  iter: 220  loss: 1.4628 (3.7760)  loss_classifier: 0.1488 (1.3113)  loss_box_reg: 0.3626 (0.6270)  loss_objectness: 0.0428 (0.1032)  loss_rpn_box_reg: 0.8699 (1.7345)  time: 1.5323 (1.6574)  data: 0.1015 (0.1726)  lr: 0.000000  max mem: 982
2020-12-13 03:32:34,335 maskrcnn_benchmark.trainer INFO: eta: 0:48:18  iter: 240  loss: 1.4323 (3.5920)  loss_classifier: 0.0898 (1.2174)  loss_box_reg: 0.3413 (0.6078)  loss_objectness: 0.0647 (0.1004)  loss_rpn_box_reg: 0.9210 (1.6663)  time: 1.5316 (1.6470)  data: 0.0998 (0.1667)  lr: 0.000000  max mem: 982
2020-12-13 03:32:34,337 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:32:34,394 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 03:32:35,921 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.527403 (1.527402639389038 s / img per device, on 1 devices)
2020-12-13 03:32:35,922 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.411319 (1.4113194942474365 s / img per device, on 1 devices)
2020-12-13 03:32:35,922 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:32:36,024 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:32:36,024 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.2370, 0.0171, 0.0009, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 2.]), 'best match scores': tensor([0.3207, 0.9976, 0.9999, 0.0746, 0.9999, 0.3887, 0.9999, 0.7418, 0.8316]), 'num_pos': 9}
2020-12-13 03:32:36,028 maskrcnn_benchmark.trainer INFO: validation accuracy: 1.000000
2020-12-13 03:32:36,031 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v5.pth
2020-12-13 03:32:40,310 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v5
2020-12-13 03:33:10,991 maskrcnn_benchmark.trainer INFO: eta: 0:48:10  iter: 260  loss: 1.4403 (3.4291)  loss_classifier: 0.1144 (1.1357)  loss_box_reg: 0.3470 (0.5911)  loss_objectness: 0.0514 (0.0974)  loss_rpn_box_reg: 0.8815 (1.6048)  time: 1.5294 (1.6613)  data: 0.1012 (0.1848)  lr: 0.000000  max mem: 982
2020-12-13 03:33:41,562 maskrcnn_benchmark.trainer INFO: eta: 0:47:21  iter: 280  loss: 1.3431 (3.2838)  loss_classifier: 0.0907 (1.0636)  loss_box_reg: 0.3223 (0.5757)  loss_objectness: 0.0652 (0.0958)  loss_rpn_box_reg: 0.7783 (1.5487)  time: 1.5280 (1.6518)  data: 0.1007 (0.1788)  lr: 0.000000  max mem: 982
2020-12-13 03:34:13,326 maskrcnn_benchmark.trainer INFO: eta: 0:46:40  iter: 300  loss: 1.2742 (3.1596)  loss_classifier: 0.0889 (1.0062)  loss_box_reg: 0.2605 (0.5587)  loss_objectness: 0.0536 (0.0942)  loss_rpn_box_reg: 0.8418 (1.5006)  time: 1.5662 (1.6476)  data: 0.1079 (0.1742)  lr: 0.000000  max mem: 982
2020-12-13 03:34:13,328 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:34:13,380 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 03:34:15,036 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.654914 (1.654914379119873 s / img per device, on 1 devices)
2020-12-13 03:34:15,036 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.540478 (1.5404777526855469 s / img per device, on 1 devices)
2020-12-13 03:34:15,036 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:34:15,141 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:34:15,142 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.3575, 0.0990, 0.0973, 0.0876, 0.0206, 0.0164, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 4., 2., 2., 2., 2., 2., 2., 2.]), 'best match scores': tensor([0.9981, 0.9868, 0.0570, 0.9882, 0.8968, 0.4331, 0.3855, 0.5857, 0.0887]), 'num_pos': 9}
2020-12-13 03:34:15,146 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.888889
2020-12-13 03:34:47,023 maskrcnn_benchmark.trainer INFO: eta: 0:46:11  iter: 320  loss: 1.1513 (3.0353)  loss_classifier: 0.0622 (0.9480)  loss_box_reg: 0.2859 (0.5398)  loss_objectness: 0.0390 (0.0919)  loss_rpn_box_reg: 0.7467 (1.4557)  time: 1.5900 (1.6499)  data: 0.1109 (0.1760)  lr: 0.000000  max mem: 982
2020-12-13 03:35:18,322 maskrcnn_benchmark.trainer INFO: eta: 0:45:30  iter: 340  loss: 1.2027 (2.9315)  loss_classifier: 0.0716 (0.9004)  loss_box_reg: 0.2246 (0.5226)  loss_objectness: 0.0551 (0.0907)  loss_rpn_box_reg: 0.8226 (1.4178)  time: 1.5449 (1.6449)  data: 0.1069 (0.1720)  lr: 0.000000  max mem: 982
2020-12-13 03:35:50,334 maskrcnn_benchmark.trainer INFO: eta: 0:44:53  iter: 360  loss: 1.1233 (2.8382)  loss_classifier: 0.0768 (0.8587)  loss_box_reg: 0.2669 (0.5082)  loss_objectness: 0.0353 (0.0886)  loss_rpn_box_reg: 0.7972 (1.3826)  time: 1.5876 (1.6425)  data: 0.1092 (0.1686)  lr: 0.000000  max mem: 982
2020-12-13 03:35:50,336 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:35:50,392 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 03:35:52,041 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.649138 (1.6491377353668213 s / img per device, on 1 devices)
2020-12-13 03:35:52,041 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.528373 (1.5283734798431396 s / img per device, on 1 devices)
2020-12-13 03:35:52,042 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:35:52,156 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:35:52,156 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.3906, 0.2208, 0.0814, 0.0724, 0.0443, 0.0389, 0.0330, 0.0236, 0.0128]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 4., 2., 2., 2., 2., 2.]), 'best match scores': tensor([0.9969, 0.1190, 0.4862, 0.2666, 1.0000, 1.0000, 0.6163, 0.1799, 0.9868]), 'num_pos': 9}
2020-12-13 03:35:52,161 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.888889
2020-12-13 03:36:24,407 maskrcnn_benchmark.trainer INFO: eta: 0:44:26  iter: 380  loss: 1.0523 (2.7486)  loss_classifier: 0.0460 (0.8188)  loss_box_reg: 0.1875 (0.4923)  loss_objectness: 0.0433 (0.0874)  loss_rpn_box_reg: 0.7727 (1.3501)  time: 1.6304 (1.6457)  data: 0.1110 (0.1706)  lr: 0.000000  max mem: 982
2020-12-13 03:36:56,974 maskrcnn_benchmark.trainer INFO: eta: 0:43:51  iter: 400  loss: 1.0769 (2.6655)  loss_classifier: 0.0653 (0.7814)  loss_box_reg: 0.2018 (0.4783)  loss_objectness: 0.0606 (0.0865)  loss_rpn_box_reg: 0.7495 (1.3194)  time: 1.6269 (1.6448)  data: 0.1105 (0.1676)  lr: 0.000000  max mem: 982
2020-12-13 03:37:29,789 maskrcnn_benchmark.trainer INFO: eta: 0:43:18  iter: 420  loss: 1.0706 (2.5946)  loss_classifier: 0.0623 (0.7508)  loss_box_reg: 0.2751 (0.4689)  loss_objectness: 0.0331 (0.0846)  loss_rpn_box_reg: 0.6868 (1.2903)  time: 1.6338 (1.6446)  data: 0.1110 (0.1651)  lr: 0.000000  max mem: 982
2020-12-13 03:37:29,791 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:37:29,848 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 03:37:31,462 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.614221 (1.6142210960388184 s / img per device, on 1 devices)
2020-12-13 03:37:31,462 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.481494 (1.4814939498901367 s / img per device, on 1 devices)
2020-12-13 03:37:31,463 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:37:31,576 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:37:31,576 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1490, 0.0776, 0.0431, 0.0271, 0.0171, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 5., 2., 2., 2., 2., 2., 5., 2.]), 'best match scores': tensor([0.6954, 0.6945, 0.9985, 0.3092, 0.0788, 0.9977, 0.9999, 1.0000, 0.3490]), 'num_pos': 9}
2020-12-13 03:37:31,581 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.777778
2020-12-13 03:38:03,992 maskrcnn_benchmark.trainer INFO: eta: 0:42:50  iter: 440  loss: 0.9922 (2.5241)  loss_classifier: 0.0636 (0.7212)  loss_box_reg: 0.1853 (0.4565)  loss_objectness: 0.0289 (0.0827)  loss_rpn_box_reg: 0.7236 (1.2637)  time: 1.6210 (1.6476)  data: 0.1158 (0.1670)  lr: 0.000000  max mem: 982
2020-12-13 03:38:36,360 maskrcnn_benchmark.trainer INFO: eta: 0:42:15  iter: 460  loss: 0.9680 (2.4642)  loss_classifier: 0.0401 (0.6977)  loss_box_reg: 0.2004 (0.4475)  loss_objectness: 0.0491 (0.0819)  loss_rpn_box_reg: 0.6225 (1.2371)  time: 1.6162 (1.6463)  data: 0.1146 (0.1648)  lr: 0.000000  max mem: 982
2020-12-13 03:39:08,779 maskrcnn_benchmark.trainer INFO: eta: 0:41:40  iter: 480  loss: 0.9379 (2.4078)  loss_classifier: 0.0522 (0.6759)  loss_box_reg: 0.1840 (0.4388)  loss_objectness: 0.0595 (0.0809)  loss_rpn_box_reg: 0.6065 (1.2123)  time: 1.6183 (1.6453)  data: 0.1121 (0.1627)  lr: 0.000000  max mem: 982
2020-12-13 03:39:08,781 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:39:08,838 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 03:39:10,446 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.607108 (1.6071081161499023 s / img per device, on 1 devices)
2020-12-13 03:39:10,446 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.491572 (1.4915721416473389 s / img per device, on 1 devices)
2020-12-13 03:39:10,446 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:39:10,552 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:39:10,552 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1523, 0.1450, 0.1041, 0.0357, 0.0234, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 2.]), 'best match scores': tensor([0.9864, 0.9997, 0.0651, 0.4772, 0.1948, 0.9920, 0.9718, 0.6627, 0.5674]), 'num_pos': 9}
2020-12-13 03:39:10,556 maskrcnn_benchmark.trainer INFO: validation accuracy: 1.000000
2020-12-13 03:39:42,903 maskrcnn_benchmark.trainer INFO: eta: 0:41:11  iter: 500  loss: 1.0670 (2.3623)  loss_classifier: 0.0768 (0.6601)  loss_box_reg: 0.2402 (0.4321)  loss_objectness: 0.0479 (0.0797)  loss_rpn_box_reg: 0.6932 (1.1904)  time: 1.6164 (1.6477)  data: 0.1128 (0.1643)  lr: 0.000000  max mem: 982
2020-12-13 03:40:15,330 maskrcnn_benchmark.trainer INFO: eta: 0:40:37  iter: 520  loss: 0.8834 (2.3069)  loss_classifier: 0.0357 (0.6375)  loss_box_reg: 0.1580 (0.4224)  loss_objectness: 0.0380 (0.0785)  loss_rpn_box_reg: 0.5969 (1.1686)  time: 1.6189 (1.6467)  data: 0.1142 (0.1625)  lr: 0.000000  max mem: 982
2020-12-13 03:40:47,697 maskrcnn_benchmark.trainer INFO: eta: 0:40:02  iter: 540  loss: 0.9314 (2.2620)  loss_classifier: 0.0683 (0.6218)  loss_box_reg: 0.1707 (0.4141)  loss_objectness: 0.0493 (0.0774)  loss_rpn_box_reg: 0.6732 (1.1488)  time: 1.6185 (1.6456)  data: 0.1142 (0.1608)  lr: 0.000000  max mem: 982
2020-12-13 03:40:47,699 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:40:47,758 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 03:40:49,363 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.605561 (1.6055614948272705 s / img per device, on 1 devices)
2020-12-13 03:40:49,363 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.480286 (1.4802861213684082 s / img per device, on 1 devices)
2020-12-13 03:40:49,364 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:40:49,486 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:40:49,487 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0474, 0.0209, 0.0091, 0.0090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 2.]), 'best match scores': tensor([0.1676, 0.0924, 0.9888, 0.4355, 0.9507, 0.1199, 0.9798, 1.0000, 0.3721]), 'num_pos': 9}
2020-12-13 03:40:49,491 maskrcnn_benchmark.trainer INFO: validation accuracy: 1.000000
2020-12-13 03:41:21,846 maskrcnn_benchmark.trainer INFO: eta: 0:39:32  iter: 560  loss: 0.8277 (2.2112)  loss_classifier: 0.0418 (0.6014)  loss_box_reg: 0.1303 (0.4040)  loss_objectness: 0.0449 (0.0761)  loss_rpn_box_reg: 0.6496 (1.1297)  time: 1.6164 (1.6479)  data: 0.1160 (0.1625)  lr: 0.000000  max mem: 982
2020-12-13 03:41:53,874 maskrcnn_benchmark.trainer INFO: eta: 0:38:57  iter: 580  loss: 0.8463 (2.1646)  loss_classifier: 0.0427 (0.5824)  loss_box_reg: 0.1526 (0.3959)  loss_objectness: 0.0570 (0.0756)  loss_rpn_box_reg: 0.5396 (1.1107)  time: 1.5992 (1.6463)  data: 0.1141 (0.1609)  lr: 0.000000  max mem: 982
2020-12-13 03:42:25,840 maskrcnn_benchmark.trainer INFO: eta: 0:38:22  iter: 600  loss: 0.8063 (2.1218)  loss_classifier: 0.0304 (0.5661)  loss_box_reg: 0.1298 (0.3876)  loss_objectness: 0.0358 (0.0746)  loss_rpn_box_reg: 0.6241 (1.0936)  time: 1.5988 (1.6447)  data: 0.1138 (0.1594)  lr: 0.000000  max mem: 982
2020-12-13 03:42:25,842 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:42:25,904 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 03:42:27,505 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.601618 (1.6016182899475098 s / img per device, on 1 devices)
2020-12-13 03:42:27,506 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.476820 (1.4768202304840088 s / img per device, on 1 devices)
2020-12-13 03:42:27,506 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:42:27,610 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:42:27,611 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0211, 0.0184, 0.0171, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.9581, 1.0000, 1.0000, 0.7236, 0.4513, 0.9528, 0.9912, 0.0817]), 'num_pos': 9}
2020-12-13 03:42:27,615 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.777778
2020-12-13 03:42:59,602 maskrcnn_benchmark.trainer INFO: eta: 0:37:51  iter: 620  loss: 0.8180 (2.0799)  loss_classifier: 0.0587 (0.5495)  loss_box_reg: 0.1223 (0.3798)  loss_objectness: 0.0334 (0.0736)  loss_rpn_box_reg: 0.5980 (1.0769)  time: 1.5976 (1.6461)  data: 0.1134 (0.1608)  lr: 0.000000  max mem: 982
2020-12-13 03:43:31,529 maskrcnn_benchmark.trainer INFO: eta: 0:37:16  iter: 640  loss: 0.7492 (2.0384)  loss_classifier: 0.0229 (0.5333)  loss_box_reg: 0.1129 (0.3716)  loss_objectness: 0.0510 (0.0730)  loss_rpn_box_reg: 0.5222 (1.0605)  time: 1.5946 (1.6445)  data: 0.1128 (0.1593)  lr: 0.000000  max mem: 982
2020-12-13 03:44:03,556 maskrcnn_benchmark.trainer INFO: eta: 0:36:41  iter: 660  loss: 0.7315 (2.0003)  loss_classifier: 0.0289 (0.5192)  loss_box_reg: 0.1447 (0.3646)  loss_objectness: 0.0344 (0.0718)  loss_rpn_box_reg: 0.5072 (1.0447)  time: 1.6002 (1.6432)  data: 0.1082 (0.1578)  lr: 0.000000  max mem: 982
2020-12-13 03:44:03,558 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:44:03,612 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 03:44:05,207 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.594060 (1.5940601825714111 s / img per device, on 1 devices)
2020-12-13 03:44:05,207 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.481407 (1.4814074039459229 s / img per device, on 1 devices)
2020-12-13 03:44:05,207 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:44:05,313 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:44:05,313 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0476, 0.0305, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  2., -1., -1., -1., -1.,  2.,  5.,  2.]), 'best match scores': tensor([0.0000, 0.2348, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.8448, 0.5141]), 'num_pos': 9}
2020-12-13 03:44:05,317 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 03:44:37,319 maskrcnn_benchmark.trainer INFO: eta: 0:36:10  iter: 680  loss: 0.7087 (1.9639)  loss_classifier: 0.0261 (0.5060)  loss_box_reg: 0.1346 (0.3580)  loss_objectness: 0.0423 (0.0710)  loss_rpn_box_reg: 0.4846 (1.0289)  time: 1.6001 (1.6445)  data: 0.1131 (0.1591)  lr: 0.000000  max mem: 982
2020-12-13 03:45:09,318 maskrcnn_benchmark.trainer INFO: eta: 0:35:36  iter: 700  loss: 0.6906 (1.9309)  loss_classifier: 0.0177 (0.4950)  loss_box_reg: 0.1263 (0.3513)  loss_objectness: 0.0399 (0.0703)  loss_rpn_box_reg: 0.4737 (1.0143)  time: 1.5978 (1.6432)  data: 0.1142 (0.1578)  lr: 0.000000  max mem: 982
2020-12-13 03:45:41,265 maskrcnn_benchmark.trainer INFO: eta: 0:35:01  iter: 720  loss: 0.6840 (1.8969)  loss_classifier: 0.0296 (0.4825)  loss_box_reg: 0.1185 (0.3446)  loss_objectness: 0.0303 (0.0693)  loss_rpn_box_reg: 0.4757 (1.0005)  time: 1.5969 (1.6420)  data: 0.1130 (0.1566)  lr: 0.000000  max mem: 982
2020-12-13 03:45:41,267 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:45:41,325 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 03:45:42,908 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.583366 (1.5833656787872314 s / img per device, on 1 devices)
2020-12-13 03:45:42,908 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.462026 (1.4620256423950195 s / img per device, on 1 devices)
2020-12-13 03:45:42,908 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:45:43,017 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:45:43,017 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1.,  2., -1., -1., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.9994, 0.0000, 0.0000, 0.0000, 0.0000, 0.8328, 1.0000]), 'num_pos': 9}
2020-12-13 03:45:43,022 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 03:46:14,980 maskrcnn_benchmark.trainer INFO: eta: 0:34:30  iter: 740  loss: 0.6705 (1.8669)  loss_classifier: 0.0206 (0.4723)  loss_box_reg: 0.1019 (0.3383)  loss_objectness: 0.0400 (0.0685)  loss_rpn_box_reg: 0.5470 (0.9877)  time: 1.5956 (1.6432)  data: 0.1129 (0.1578)  lr: 0.000000  max mem: 982
2020-12-13 03:46:47,572 maskrcnn_benchmark.trainer INFO: eta: 0:33:57  iter: 760  loss: 0.6215 (1.8347)  loss_classifier: 0.0276 (0.4610)  loss_box_reg: 0.0353 (0.3315)  loss_objectness: 0.0195 (0.0675)  loss_rpn_box_reg: 0.4700 (0.9747)  time: 1.6303 (1.6428)  data: 0.1146 (0.1567)  lr: 0.000000  max mem: 982
2020-12-13 03:47:20,316 maskrcnn_benchmark.trainer INFO: eta: 0:33:24  iter: 780  loss: 0.6718 (1.8049)  loss_classifier: 0.0430 (0.4504)  loss_box_reg: 0.0746 (0.3252)  loss_objectness: 0.0334 (0.0669)  loss_rpn_box_reg: 0.5192 (0.9623)  time: 1.6351 (1.6427)  data: 0.1150 (0.1558)  lr: 0.000000  max mem: 982
2020-12-13 03:47:20,318 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:47:20,375 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 03:47:21,992 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.616557 (1.6165573596954346 s / img per device, on 1 devices)
2020-12-13 03:47:21,992 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.497025 (1.497025489807129 s / img per device, on 1 devices)
2020-12-13 03:47:21,992 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:47:22,100 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:47:22,100 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9011, 0.3082]), 'num_pos': 9}
2020-12-13 03:47:22,104 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 03:47:54,872 maskrcnn_benchmark.trainer INFO: eta: 0:32:53  iter: 800  loss: 0.6233 (1.7757)  loss_classifier: 0.0494 (0.4404)  loss_box_reg: 0.0741 (0.3191)  loss_objectness: 0.0257 (0.0659)  loss_rpn_box_reg: 0.5056 (0.9503)  time: 1.6361 (1.6448)  data: 0.1193 (0.1571)  lr: 0.000000  max mem: 982
2020-12-13 03:48:27,688 maskrcnn_benchmark.trainer INFO: eta: 0:32:20  iter: 820  loss: 0.6553 (1.7483)  loss_classifier: 0.0700 (0.4313)  loss_box_reg: 0.1040 (0.3136)  loss_objectness: 0.0234 (0.0650)  loss_rpn_box_reg: 0.4300 (0.9383)  time: 1.6391 (1.6447)  data: 0.1161 (0.1562)  lr: 0.000000  max mem: 982
2020-12-13 03:49:00,609 maskrcnn_benchmark.trainer INFO: eta: 0:31:47  iter: 840  loss: 0.6245 (1.7216)  loss_classifier: 0.0434 (0.4223)  loss_box_reg: 0.1081 (0.3084)  loss_objectness: 0.0245 (0.0642)  loss_rpn_box_reg: 0.4172 (0.9268)  time: 1.6404 (1.6447)  data: 0.1267 (0.1555)  lr: 0.000000  max mem: 982
2020-12-13 03:49:00,611 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:49:00,668 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 03:49:02,283 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.614968 (1.6149680614471436 s / img per device, on 1 devices)
2020-12-13 03:49:02,284 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.486870 (1.4868695735931396 s / img per device, on 1 devices)
2020-12-13 03:49:02,284 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:49:02,391 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:49:02,392 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0820, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1.,  2., -1., -1.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3673, 0.0000, 0.0000, 0.1158]), 'num_pos': 9}
2020-12-13 03:49:02,397 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 03:49:34,869 maskrcnn_benchmark.trainer INFO: eta: 0:31:16  iter: 860  loss: 0.6218 (1.6964)  loss_classifier: 0.0376 (0.4135)  loss_box_reg: 0.1247 (0.3041)  loss_objectness: 0.0323 (0.0635)  loss_rpn_box_reg: 0.4062 (0.9153)  time: 1.6200 (1.6463)  data: 0.1116 (0.1566)  lr: 0.000000  max mem: 982
2020-12-13 03:50:07,374 maskrcnn_benchmark.trainer INFO: eta: 0:30:43  iter: 880  loss: 0.6201 (1.6723)  loss_classifier: 0.0474 (0.4053)  loss_box_reg: 0.1230 (0.2998)  loss_objectness: 0.0329 (0.0629)  loss_rpn_box_reg: 0.4000 (0.9043)  time: 1.6236 (1.6458)  data: 0.1146 (0.1557)  lr: 0.000000  max mem: 982
2020-12-13 03:50:39,861 maskrcnn_benchmark.trainer INFO: eta: 0:30:09  iter: 900  loss: 0.6047 (1.6518)  loss_classifier: 0.0590 (0.3999)  loss_box_reg: 0.1205 (0.2958)  loss_objectness: 0.0267 (0.0622)  loss_rpn_box_reg: 0.4687 (0.8939)  time: 1.6240 (1.6453)  data: 0.1143 (0.1548)  lr: 0.000000  max mem: 982
2020-12-13 03:50:39,863 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:50:39,921 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 03:50:41,534 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.612780 (1.6127803325653076 s / img per device, on 1 devices)
2020-12-13 03:50:41,535 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.491703 (1.4917025566101074 s / img per device, on 1 devices)
2020-12-13 03:50:41,535 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:50:41,643 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:50:41,643 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0419, 0.0024, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1.,  2., -1.,  2., -1., -1., -1.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 1.0000, 0.0000, 0.9565, 0.0000, 0.0000, 0.0000, 0.1009]), 'num_pos': 9}
2020-12-13 03:50:41,647 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 03:51:14,162 maskrcnn_benchmark.trainer INFO: eta: 0:29:38  iter: 920  loss: 0.5948 (1.6337)  loss_classifier: 0.0577 (0.3963)  loss_box_reg: 0.1092 (0.2918)  loss_objectness: 0.0190 (0.0615)  loss_rpn_box_reg: 0.4645 (0.8841)  time: 1.6273 (1.6469)  data: 0.1136 (0.1559)  lr: 0.000000  max mem: 982
2020-12-13 03:51:46,703 maskrcnn_benchmark.trainer INFO: eta: 0:29:05  iter: 940  loss: 0.6013 (1.6156)  loss_classifier: 0.0708 (0.3929)  loss_box_reg: 0.1013 (0.2878)  loss_objectness: 0.0138 (0.0607)  loss_rpn_box_reg: 0.4476 (0.8743)  time: 1.6238 (1.6464)  data: 0.1152 (0.1551)  lr: 0.000000  max mem: 982
2020-12-13 03:52:19,326 maskrcnn_benchmark.trainer INFO: eta: 0:28:31  iter: 960  loss: 0.5630 (1.5982)  loss_classifier: 0.0609 (0.3894)  loss_box_reg: 0.0919 (0.2840)  loss_objectness: 0.0199 (0.0602)  loss_rpn_box_reg: 0.3747 (0.8646)  time: 1.6277 (1.6461)  data: 0.1172 (0.1543)  lr: 0.000000  max mem: 982
2020-12-13 03:52:19,328 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:52:19,392 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 03:52:21,032 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.639947 (1.639946699142456 s / img per device, on 1 devices)
2020-12-13 03:52:21,033 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.508476 (1.5084757804870605 s / img per device, on 1 devices)
2020-12-13 03:52:21,033 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:52:21,143 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:52:21,143 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.9992, 0.0798, 0.9863, 0.9833, 0.2302]), 'num_pos': 9}
2020-12-13 03:52:21,147 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 03:52:53,770 maskrcnn_benchmark.trainer INFO: eta: 0:28:00  iter: 980  loss: 0.6422 (1.5789)  loss_classifier: 0.0613 (0.3836)  loss_box_reg: 0.1041 (0.2805)  loss_objectness: 0.0192 (0.0596)  loss_rpn_box_reg: 0.4329 (0.8553)  time: 1.6302 (1.6477)  data: 0.1214 (0.1555)  lr: 0.000000  max mem: 982
2020-12-13 03:53:26,334 maskrcnn_benchmark.trainer INFO: eta: 0:27:27  iter: 1000  loss: 0.5346 (1.5601)  loss_classifier: 0.0470 (0.3784)  loss_box_reg: 0.0818 (0.2768)  loss_objectness: 0.0185 (0.0589)  loss_rpn_box_reg: 0.3607 (0.8460)  time: 1.6263 (1.6473)  data: 0.1184 (0.1548)  lr: 0.000000  max mem: 982
2020-12-13 03:53:59,005 maskrcnn_benchmark.trainer INFO: eta: 0:26:54  iter: 1020  loss: 0.6560 (1.5443)  loss_classifier: 0.1106 (0.3753)  loss_box_reg: 0.0942 (0.2735)  loss_objectness: 0.0186 (0.0582)  loss_rpn_box_reg: 0.4186 (0.8374)  time: 1.6323 (1.6470)  data: 0.1232 (0.1542)  lr: 0.000000  max mem: 982
2020-12-13 03:53:59,007 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:53:59,071 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 03:54:00,676 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.604576 (1.6045756340026855 s / img per device, on 1 devices)
2020-12-13 03:54:00,676 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.483092 (1.4830915927886963 s / img per device, on 1 devices)
2020-12-13 03:54:00,676 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:54:00,783 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:54:00,783 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.2198, 0.0664, 0.0487, 0.0452, 0.0404, 0.0365, 0.0168, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 2.]), 'best match scores': tensor([0.9692, 0.8000, 0.8826, 0.9764, 1.0000, 0.3588, 1.0000, 0.6588, 0.6498]), 'num_pos': 9}
2020-12-13 03:54:00,788 maskrcnn_benchmark.trainer INFO: validation accuracy: 1.000000
2020-12-13 03:54:33,200 maskrcnn_benchmark.trainer INFO: eta: 0:26:22  iter: 1040  loss: 0.5173 (1.5273)  loss_classifier: 0.0531 (0.3708)  loss_box_reg: 0.0837 (0.2704)  loss_objectness: 0.0174 (0.0575)  loss_rpn_box_reg: 0.3548 (0.8286)  time: 1.6328 (1.6482)  data: 0.1205 (0.1553)  lr: 0.000000  max mem: 982
2020-12-13 03:55:04,930 maskrcnn_benchmark.trainer INFO: eta: 0:25:48  iter: 1060  loss: 0.6105 (1.5136)  loss_classifier: 0.0625 (0.3681)  loss_box_reg: 0.1229 (0.2683)  loss_objectness: 0.0239 (0.0569)  loss_rpn_box_reg: 0.3973 (0.8202)  time: 1.5795 (1.6471)  data: 0.1131 (0.1545)  lr: 0.000000  max mem: 982
2020-12-13 03:55:37,010 maskrcnn_benchmark.trainer INFO: eta: 0:25:14  iter: 1080  loss: 0.8276 (1.5007)  loss_classifier: 0.2919 (0.3661)  loss_box_reg: 0.1439 (0.2664)  loss_objectness: 0.0308 (0.0564)  loss_rpn_box_reg: 0.3876 (0.8118)  time: 1.5915 (1.6463)  data: 0.1137 (0.1538)  lr: 0.000000  max mem: 982
2020-12-13 03:55:37,012 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:55:37,070 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 03:55:38,648 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.577823 (1.5778229236602783 s / img per device, on 1 devices)
2020-12-13 03:55:38,648 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.453852 (1.4538516998291016 s / img per device, on 1 devices)
2020-12-13 03:55:38,648 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 03:55:38,761 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 03:55:38,761 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.2935, 0.0518, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1.,  2., -1.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.9998, 0.0000, 0.7236, 1.0000, 0.0981, 0.9823, 0.7203]), 'num_pos': 9}
2020-12-13 03:55:38,766 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 03:58:16,084 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 03:58:16,084 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 03:58:16,085 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 03:58:18,442 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 03:58:18,442 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 03:58:18,442 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_valid",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000005
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 2000
  IMS_PER_BATCH: 1
TEST:
  IMS_PER_BATCH: 1

2020-12-13 03:58:18,443 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_valid',)
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.1
    FG_IOU_THRESHOLD: 0.2
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 5e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  MAX_ITER: 2000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-13 03:58:20,228 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-13 03:58:20,228 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-13 03:58:20,228 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-13 03:58:20,228 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-13 03:58:20,228 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-13 03:58:20,228 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-13 03:58:20,228 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-13 03:58:20,228 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-13 03:58:20,229 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-13 03:58:20,229 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-13 03:58:20,229 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-13 03:58:20,229 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-13 03:58:20,229 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-13 03:58:20,229 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-13 03:58:22,335 maskrcnn_benchmark.trainer INFO: Start training
2020-12-13 03:58:54,777 maskrcnn_benchmark.trainer INFO: eta: 0:53:31  iter: 20  loss: 114.2812 (132.9906)  loss_classifier: 48.5934 (67.6897)  loss_box_reg: 8.1758 (8.1975)  loss_objectness: 6.8256 (6.8979)  loss_rpn_box_reg: 50.1508 (50.2055)  time: 1.6151 (1.6219)  data: 0.1098 (0.1125)  lr: 0.000000  max mem: 970
2020-12-13 03:59:27,042 maskrcnn_benchmark.trainer INFO: eta: 0:52:50  iter: 40  loss: 78.6156 (105.6470)  loss_classifier: 26.8291 (47.1537)  loss_box_reg: 7.0396 (7.6066)  loss_objectness: 5.6018 (6.3976)  loss_rpn_box_reg: 38.6401 (44.4891)  time: 1.6058 (1.6176)  data: 0.1091 (0.1107)  lr: 0.000000  max mem: 970
2020-12-13 03:59:59,915 maskrcnn_benchmark.trainer INFO: eta: 0:52:35  iter: 60  loss: 53.5807 (88.7620)  loss_classifier: 16.5736 (37.1052)  loss_box_reg: 5.5266 (6.9569)  loss_objectness: 4.9778 (5.9289)  loss_rpn_box_reg: 25.7150 (38.7710)  time: 1.6436 (1.6263)  data: 0.1085 (0.1108)  lr: 0.000000  max mem: 970
2020-12-13 03:59:59,918 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 03:59:59,974 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:00:01,644 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.669761 (1.6697614192962646 s / img per device, on 1 devices)
2020-12-13 04:00:01,644 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.530849 (1.5308494567871094 s / img per device, on 1 devices)
2020-12-13 04:00:01,645 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:00:01,762 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:00:01,763 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0301, 0.0209, 0.0171, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([8., 1., 8., 8., 8., 8., 8., 8., 4.]), 'best match scores': tensor([1.0000, 0.9125, 1.0000, 0.9036, 1.0000, 1.0000, 1.0000, 1.0000, 0.9123]), 'num_pos': 9}
2020-12-13 04:00:01,768 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-13 04:00:01,772 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v5.pth
2020-12-13 04:00:06,900 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v5
2020-12-13 04:00:39,366 maskrcnn_benchmark.trainer INFO: eta: 0:54:48  iter: 80  loss: 40.0633 (76.6594)  loss_classifier: 12.5539 (31.0238)  loss_box_reg: 4.4842 (6.3548)  loss_objectness: 3.7345 (5.3952)  loss_rpn_box_reg: 18.5966 (33.8855)  time: 1.6259 (1.7129)  data: 0.1129 (0.1994)  lr: 0.000000  max mem: 982
2020-12-13 04:01:11,602 maskrcnn_benchmark.trainer INFO: eta: 0:53:36  iter: 100  loss: 27.0028 (66.8336)  loss_classifier: 6.8582 (26.3356)  loss_box_reg: 3.4790 (5.7854)  loss_objectness: 2.9274 (4.9040)  loss_rpn_box_reg: 13.5831 (29.8086)  time: 1.6179 (1.6926)  data: 0.1062 (0.1810)  lr: 0.000000  max mem: 982
2020-12-13 04:01:43,164 maskrcnn_benchmark.trainer INFO: eta: 0:52:26  iter: 120  loss: 18.9246 (58.8765)  loss_classifier: 3.1202 (22.5077)  loss_box_reg: 2.4832 (5.2153)  loss_objectness: 2.0927 (4.4387)  loss_rpn_box_reg: 11.2686 (26.7149)  time: 1.5412 (1.6736)  data: 0.1072 (0.1691)  lr: 0.000000  max mem: 982
2020-12-13 04:01:43,166 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:01:43,233 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:01:44,935 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.701957 (1.7019569873809814 s / img per device, on 1 devices)
2020-12-13 04:01:44,936 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.538031 (1.5380311012268066 s / img per device, on 1 devices)
2020-12-13 04:01:44,936 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:01:45,044 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:01:45,045 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0447, 0.0209, 0.0171, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([4., 1., 8., 4., 6., 8., 8., 8., 8.]), 'best match scores': tensor([0.2298, 1.0000, 0.0569, 1.0000, 0.9993, 1.0000, 1.0000, 1.0000, 0.9996]), 'num_pos': 9}
2020-12-13 04:01:45,051 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-13 04:02:17,959 maskrcnn_benchmark.trainer INFO: eta: 0:52:10  iter: 140  loss: 16.0086 (52.7624)  loss_classifier: 2.3729 (19.6311)  loss_box_reg: 1.2829 (4.6677)  loss_objectness: 1.5959 (4.0462)  loss_rpn_box_reg: 10.6504 (24.4174)  time: 1.6810 (1.6830)  data: 0.1226 (0.1759)  lr: 0.000000  max mem: 982
2020-12-13 04:02:50,333 maskrcnn_benchmark.trainer INFO: eta: 0:51:21  iter: 160  loss: 14.9229 (48.0558)  loss_classifier: 1.7996 (17.4175)  loss_box_reg: 0.9981 (4.2132)  loss_objectness: 1.6143 (3.7398)  loss_rpn_box_reg: 10.3954 (22.6853)  time: 1.6169 (1.6750)  data: 0.1097 (0.1680)  lr: 0.000000  max mem: 982
2020-12-13 04:03:23,143 maskrcnn_benchmark.trainer INFO: eta: 0:50:41  iter: 180  loss: 14.1425 (44.3328)  loss_classifier: 1.2090 (15.6674)  loss_box_reg: 0.8988 (3.8758)  loss_objectness: 1.4698 (3.4921)  loss_rpn_box_reg: 10.1392 (21.2975)  time: 1.6615 (1.6711)  data: 0.1156 (0.1624)  lr: 0.000000  max mem: 982
2020-12-13 04:03:23,145 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:03:23,201 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:03:24,810 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.608461 (1.6084609031677246 s / img per device, on 1 devices)
2020-12-13 04:03:24,810 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.459724 (1.4597241878509521 s / img per device, on 1 devices)
2020-12-13 04:03:24,811 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:03:24,907 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:03:24,908 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0232, 0.0206, 0.0170, 0.0036, 0.0002, 0.0002, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 8., 7., 8., 1., 8., 2., 2., 2.]), 'best match scores': tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.8323, 0.6857, 0.3263, 1.0000, 1.0000]), 'num_pos': 9}
2020-12-13 04:03:24,913 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.444444
2020-12-13 04:03:24,915 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v5.pth
2020-12-13 04:03:29,394 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v5
2020-12-13 04:04:01,382 maskrcnn_benchmark.trainer INFO: eta: 0:50:51  iter: 200  loss: 13.0444 (41.2447)  loss_classifier: 0.9726 (14.2062)  loss_box_reg: 0.8662 (3.5801)  loss_objectness: 1.2823 (3.2802)  loss_rpn_box_reg: 10.1001 (20.1782)  time: 1.5968 (1.6952)  data: 0.1101 (0.1887)  lr: 0.000000  max mem: 982
2020-12-13 04:04:33,676 maskrcnn_benchmark.trainer INFO: eta: 0:50:04  iter: 220  loss: 13.1292 (38.6944)  loss_classifier: 0.9298 (13.0068)  loss_box_reg: 0.7586 (3.3309)  loss_objectness: 1.2718 (3.0972)  loss_rpn_box_reg: 10.0283 (19.2594)  time: 1.6201 (1.6879)  data: 0.1207 (0.1824)  lr: 0.000000  max mem: 982
2020-12-13 04:05:42,764 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 04:05:42,765 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 04:05:42,765 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 04:05:45,293 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 04:05:45,294 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 04:05:45,294 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_valid",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000008
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 4000
  IMS_PER_BATCH: 1
TEST:
  IMS_PER_BATCH: 1

2020-12-13 04:05:45,295 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_valid',)
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.1
    FG_IOU_THRESHOLD: 0.2
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 8e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  MAX_ITER: 4000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-13 04:05:47,166 maskrcnn_benchmark INFO: reloading weigts from _best_acc_r5_v5.pth
2020-12-13 04:05:49,848 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-13 04:05:49,848 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-13 04:05:49,848 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-13 04:05:49,848 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-13 04:05:49,848 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-13 04:05:49,849 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-13 04:05:49,849 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-13 04:05:49,849 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-13 04:05:49,849 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-13 04:05:49,849 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-13 04:05:49,849 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-13 04:05:49,850 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-13 04:05:49,850 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-13 04:05:49,850 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-13 04:05:50,112 maskrcnn_benchmark.trainer INFO: Start training
2020-12-13 04:06:20,725 maskrcnn_benchmark.trainer INFO: eta: 1:41:31  iter: 20  loss: 13.7361 (13.9433)  loss_classifier: 0.9863 (1.2016)  loss_box_reg: 0.8077 (0.9392)  loss_objectness: 1.5061 (1.4452)  loss_rpn_box_reg: 10.2086 (10.3573)  time: 1.5171 (1.5305)  data: 0.0952 (0.0962)  lr: 0.000000  max mem: 974
2020-12-13 04:06:51,085 maskrcnn_benchmark.trainer INFO: eta: 1:40:36  iter: 40  loss: 13.4770 (13.8686)  loss_classifier: 0.9071 (1.1951)  loss_box_reg: 0.7546 (0.9611)  loss_objectness: 1.3571 (1.4423)  loss_rpn_box_reg: 10.1895 (10.2702)  time: 1.5174 (1.5243)  data: 0.0958 (0.0962)  lr: 0.000000  max mem: 974
2020-12-13 04:07:21,466 maskrcnn_benchmark.trainer INFO: eta: 1:39:58  iter: 60  loss: 12.8347 (13.6020)  loss_classifier: 0.8539 (1.1267)  loss_box_reg: 0.7819 (0.9552)  loss_objectness: 1.2544 (1.3925)  loss_rpn_box_reg: 9.7541 (10.1275)  time: 1.5168 (1.5225)  data: 0.0973 (0.0966)  lr: 0.000000  max mem: 974
2020-12-13 04:07:21,468 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:07:21,520 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:07:23,034 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.514313 (1.514312982559204 s / img per device, on 1 devices)
2020-12-13 04:07:23,035 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.408283 (1.4082834720611572 s / img per device, on 1 devices)
2020-12-13 04:07:23,035 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:07:23,131 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:07:23,131 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([3.7839e-02, 2.1918e-02, 2.0852e-02, 1.9760e-04, 3.7439e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 8., 3., 4., 5., 8., 2., 2., 1.]), 'best match scores': tensor([1.0000, 1.0000, 0.4755, 1.0000, 0.9979, 0.9999, 0.4032, 1.0000, 0.0553]), 'num_pos': 9}
2020-12-13 04:07:23,136 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 04:07:23,139 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v5.pth
2020-12-13 04:07:27,375 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v5
2020-12-13 04:07:57,759 maskrcnn_benchmark.trainer INFO: eta: 1:44:14  iter: 80  loss: 12.7682 (13.4198)  loss_classifier: 0.8002 (1.0525)  loss_box_reg: 0.7480 (0.9149)  loss_objectness: 1.2998 (1.3697)  loss_rpn_box_reg: 9.8383 (10.0826)  time: 1.5176 (1.5956)  data: 0.0968 (0.1708)  lr: 0.000000  max mem: 986
2020-12-13 04:08:28,161 maskrcnn_benchmark.trainer INFO: eta: 1:42:43  iter: 100  loss: 12.5230 (13.2740)  loss_classifier: 0.7447 (1.0136)  loss_box_reg: 0.9055 (0.9166)  loss_objectness: 1.1597 (1.3341)  loss_rpn_box_reg: 9.6481 (10.0096)  time: 1.5202 (1.5805)  data: 0.0977 (0.1562)  lr: 0.000000  max mem: 986
2020-12-13 04:08:58,606 maskrcnn_benchmark.trainer INFO: eta: 1:41:34  iter: 120  loss: 12.0953 (13.0845)  loss_classifier: 0.6832 (0.9630)  loss_box_reg: 0.6935 (0.8852)  loss_objectness: 1.0607 (1.2964)  loss_rpn_box_reg: 9.5218 (9.9398)  time: 1.5217 (1.5708)  data: 0.0957 (0.1463)  lr: 0.000000  max mem: 986
2020-12-13 04:08:58,608 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:08:58,661 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:09:00,174 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.513397 (1.5133967399597168 s / img per device, on 1 devices)
2020-12-13 04:09:00,174 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.403495 (1.4034945964813232 s / img per device, on 1 devices)
2020-12-13 04:09:00,175 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:09:00,274 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:09:00,274 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0209, 0.0176, 0.0168, 0.0112, 0.0080, 0.0060, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 3., 2., 3., 2., 2., 2., 2., 8.]), 'best match scores': tensor([0.9992, 0.2188, 0.2249, 0.9991, 0.2577, 1.0000, 0.9998, 1.0000, 1.0000]), 'num_pos': 9}
2020-12-13 04:09:00,279 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 04:09:00,281 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v5.pth
2020-12-13 04:09:04,480 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v5
2020-12-13 04:09:34,927 maskrcnn_benchmark.trainer INFO: eta: 1:43:18  iter: 140  loss: 11.7887 (12.9180)  loss_classifier: 0.5834 (0.9093)  loss_box_reg: 0.7107 (0.8598)  loss_objectness: 1.1428 (1.2791)  loss_rpn_box_reg: 9.4267 (9.8697)  time: 1.5211 (1.6058)  data: 0.0966 (0.1814)  lr: 0.000000  max mem: 986
2020-12-13 04:10:05,367 maskrcnn_benchmark.trainer INFO: eta: 1:42:06  iter: 160  loss: 11.7658 (12.7710)  loss_classifier: 0.5787 (0.8692)  loss_box_reg: 0.6829 (0.8386)  loss_objectness: 1.0725 (1.2513)  loss_rpn_box_reg: 9.3405 (9.8118)  time: 1.5226 (1.5953)  data: 0.0971 (0.1709)  lr: 0.000000  max mem: 986
2020-12-13 04:10:35,805 maskrcnn_benchmark.trainer INFO: eta: 1:41:02  iter: 180  loss: 11.4654 (12.6330)  loss_classifier: 0.5915 (0.8388)  loss_box_reg: 0.6427 (0.8239)  loss_objectness: 1.0596 (1.2278)  loss_rpn_box_reg: 9.1960 (9.7424)  time: 1.5204 (1.5872)  data: 0.0969 (0.1628)  lr: 0.000000  max mem: 986
2020-12-13 04:10:35,807 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:10:35,861 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:10:37,374 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.512527 (1.5125272274017334 s / img per device, on 1 devices)
2020-12-13 04:10:37,374 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.403770 (1.4037699699401855 s / img per device, on 1 devices)
2020-12-13 04:10:37,374 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:10:37,474 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:10:37,474 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0257, 0.0230, 0.0209, 0.0139, 0.0017, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([3., 2., 5., 7., 2., 2., 2., 8., 1.]), 'best match scores': tensor([0.0662, 1.0000, 0.9101, 0.2979, 0.9999, 1.0000, 1.0000, 0.9057, 0.7021]), 'num_pos': 9}
2020-12-13 04:10:37,478 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.444444
2020-12-13 04:11:07,883 maskrcnn_benchmark.trainer INFO: eta: 1:40:37  iter: 200  loss: 11.0784 (12.4900)  loss_classifier: 0.5036 (0.8067)  loss_box_reg: 0.6162 (0.8060)  loss_objectness: 1.0150 (1.2106)  loss_rpn_box_reg: 8.8669 (9.6668)  time: 1.5205 (1.5888)  data: 0.0972 (0.1647)  lr: 0.000000  max mem: 986
2020-12-13 04:11:38,323 maskrcnn_benchmark.trainer INFO: eta: 1:39:42  iter: 220  loss: 11.1542 (12.3811)  loss_classifier: 0.4604 (0.7882)  loss_box_reg: 0.6433 (0.7982)  loss_objectness: 0.9798 (1.1898)  loss_rpn_box_reg: 8.9428 (9.6049)  time: 1.5225 (1.5828)  data: 0.0968 (0.1586)  lr: 0.000000  max mem: 986
2020-12-13 04:12:08,791 maskrcnn_benchmark.trainer INFO: eta: 1:38:52  iter: 240  loss: 11.1078 (12.2942)  loss_classifier: 0.3879 (0.7702)  loss_box_reg: 0.5824 (0.7914)  loss_objectness: 1.0222 (1.1754)  loss_rpn_box_reg: 8.9748 (9.5572)  time: 1.5223 (1.5778)  data: 0.0993 (0.1538)  lr: 0.000000  max mem: 986
2020-12-13 04:12:08,793 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:12:08,851 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:12:10,369 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.517373 (1.5173728466033936 s / img per device, on 1 devices)
2020-12-13 04:12:10,369 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.398557 (1.3985569477081299 s / img per device, on 1 devices)
2020-12-13 04:12:10,369 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:12:10,475 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:12:10,476 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0420, 0.0279, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 2.]), 'best match scores': tensor([1.0000, 0.9621, 0.9233, 0.7717, 0.9996, 0.0819, 1.0000, 1.0000, 1.0000]), 'num_pos': 9}
2020-12-13 04:12:10,480 maskrcnn_benchmark.trainer INFO: validation accuracy: 1.000000
2020-12-13 04:12:10,482 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v5.pth
2020-12-13 04:12:14,727 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v5
2020-12-13 04:12:45,180 maskrcnn_benchmark.trainer INFO: eta: 1:39:30  iter: 260  loss: 10.7051 (12.2118)  loss_classifier: 0.3681 (0.7680)  loss_box_reg: 0.5665 (0.7943)  loss_objectness: 0.9806 (1.1608)  loss_rpn_box_reg: 8.6207 (9.4886)  time: 1.5219 (1.5964)  data: 0.1004 (0.1727)  lr: 0.000000  max mem: 986
2020-12-13 04:13:15,610 maskrcnn_benchmark.trainer INFO: eta: 1:38:38  iter: 280  loss: 10.6832 (12.1019)  loss_classifier: 0.4021 (0.7419)  loss_box_reg: 0.6021 (0.7837)  loss_objectness: 0.7876 (1.1380)  loss_rpn_box_reg: 8.7035 (9.4382)  time: 1.5211 (1.5911)  data: 0.0975 (0.1673)  lr: 0.000000  max mem: 986
2020-12-13 04:13:46,003 maskrcnn_benchmark.trainer INFO: eta: 1:37:49  iter: 300  loss: 10.3768 (11.9938)  loss_classifier: 0.3864 (0.7207)  loss_box_reg: 0.5814 (0.7756)  loss_objectness: 0.8206 (1.1180)  loss_rpn_box_reg: 8.4196 (9.3795)  time: 1.5195 (1.5863)  data: 0.0958 (0.1626)  lr: 0.000000  max mem: 986
2020-12-13 04:13:46,005 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:13:46,058 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:13:47,574 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.515635 (1.5156354904174805 s / img per device, on 1 devices)
2020-12-13 04:13:47,574 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.405922 (1.4059221744537354 s / img per device, on 1 devices)
2020-12-13 04:13:47,574 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:13:47,670 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:13:47,671 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0311, 0.0209, 0.0166, 0.0077, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([3., 5., 7., 2., 2., 8., 2., 2., 1.]), 'best match scores': tensor([0.0717, 0.1134, 0.7053, 1.0000, 1.0000, 0.0817, 1.0000, 0.9902, 0.0779]), 'num_pos': 9}
2020-12-13 04:13:47,675 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.444444
2020-12-13 04:14:18,102 maskrcnn_benchmark.trainer INFO: eta: 1:37:21  iter: 320  loss: 10.0732 (11.8811)  loss_classifier: 0.2283 (0.6917)  loss_box_reg: 0.5293 (0.7616)  loss_objectness: 0.7940 (1.0989)  loss_rpn_box_reg: 8.4837 (9.3290)  time: 1.5216 (1.5875)  data: 0.0971 (0.1638)  lr: 0.000000  max mem: 986
2020-12-13 04:14:50,168 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 04:14:50,168 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 04:14:50,168 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 04:14:52,363 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 04:14:52,364 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 04:14:52,364 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_valid",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000008
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 40000
  IMS_PER_BATCH: 1
TEST:
  IMS_PER_BATCH: 1

2020-12-13 04:14:52,365 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_valid',)
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.1
    FG_IOU_THRESHOLD: 0.2
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 8e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  MAX_ITER: 40000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-13 04:14:54,058 maskrcnn_benchmark INFO: reloading weigts from _best_acc_r5_v5.pth
2020-12-13 04:14:56,346 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-13 04:14:56,347 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-13 04:14:56,347 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-13 04:14:56,347 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-13 04:14:56,347 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-13 04:14:56,347 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-13 04:14:56,348 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-13 04:14:56,348 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-13 04:14:56,348 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-13 04:14:56,348 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-13 04:14:56,348 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-13 04:14:56,348 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-13 04:14:56,349 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-13 04:14:56,349 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-13 04:14:56,600 maskrcnn_benchmark.trainer INFO: Start training
2020-12-13 04:15:27,227 maskrcnn_benchmark.trainer INFO: eta: 17:00:19  iter: 20  loss: 10.9855 (11.1788)  loss_classifier: 0.4326 (0.5730)  loss_box_reg: 0.5698 (0.7159)  loss_objectness: 0.9913 (1.0016)  loss_rpn_box_reg: 8.9254 (8.8883)  time: 1.5201 (1.5312)  data: 0.0962 (0.0968)  lr: 0.000000  max mem: 974
2020-12-13 04:15:57,672 maskrcnn_benchmark.trainer INFO: eta: 16:56:49  iter: 40  loss: 10.7718 (10.9825)  loss_classifier: 0.4869 (0.5277)  loss_box_reg: 0.6920 (0.6915)  loss_objectness: 0.9461 (0.9851)  loss_rpn_box_reg: 8.6035 (8.7781)  time: 1.5215 (1.5268)  data: 0.0968 (0.0970)  lr: 0.000000  max mem: 974
2020-12-13 04:16:28,167 maskrcnn_benchmark.trainer INFO: eta: 16:55:51  iter: 60  loss: 10.6811 (10.9006)  loss_classifier: 0.3700 (0.4865)  loss_box_reg: 0.5694 (0.6727)  loss_objectness: 0.8977 (0.9654)  loss_rpn_box_reg: 8.7272 (8.7760)  time: 1.5225 (1.5261)  data: 0.0971 (0.0981)  lr: 0.000000  max mem: 974
2020-12-13 04:16:28,169 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:16:28,224 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:16:29,740 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.516307 (1.5163073539733887 s / img per device, on 1 devices)
2020-12-13 04:16:29,740 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.402429 (1.4024293422698975 s / img per device, on 1 devices)
2020-12-13 04:16:29,741 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:16:29,845 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:16:29,845 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([2.4972e-02, 1.7123e-02, 1.4773e-02, 8.3525e-04, 9.5690e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 1., 2., 2., 7., 2., 2., 2., 2.]), 'best match scores': tensor([1.0000, 0.6284, 1.0000, 0.7123, 0.3304, 0.8980, 1.0000, 1.0000, 1.0000]), 'num_pos': 9}
2020-12-13 04:16:29,851 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.777778
2020-12-13 04:16:29,854 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v5.pth
2020-12-13 04:16:33,989 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v5
2020-12-13 04:17:04,479 maskrcnn_benchmark.trainer INFO: eta: 17:43:30  iter: 80  loss: 10.5503 (10.8168)  loss_classifier: 0.3339 (0.4523)  loss_box_reg: 0.5617 (0.6637)  loss_objectness: 0.8572 (0.9455)  loss_rpn_box_reg: 8.7008 (8.7553)  time: 1.5247 (1.5985)  data: 0.0954 (0.1705)  lr: 0.000000  max mem: 986
2020-12-13 04:17:34,960 maskrcnn_benchmark.trainer INFO: eta: 17:33:04  iter: 100  loss: 10.3320 (10.7287)  loss_classifier: 0.4045 (0.4297)  loss_box_reg: 0.5900 (0.6511)  loss_objectness: 0.9318 (0.9324)  loss_rpn_box_reg: 8.5448 (8.7155)  time: 1.5233 (1.5836)  data: 0.0956 (0.1556)  lr: 0.000000  max mem: 986
2020-12-13 04:18:05,464 maskrcnn_benchmark.trainer INFO: eta: 17:26:05  iter: 120  loss: 10.3064 (10.6631)  loss_classifier: 0.3695 (0.4158)  loss_box_reg: 0.5389 (0.6386)  loss_objectness: 0.9081 (0.9307)  loss_rpn_box_reg: 8.4757 (8.6779)  time: 1.5257 (1.5739)  data: 0.0957 (0.1456)  lr: 0.000000  max mem: 986
2020-12-13 04:18:05,466 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:18:05,518 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:18:07,031 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.512562 (1.5125620365142822 s / img per device, on 1 devices)
2020-12-13 04:18:07,031 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.405035 (1.4050350189208984 s / img per device, on 1 devices)
2020-12-13 04:18:07,032 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:18:07,128 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:18:07,129 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0251, 0.0209, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 3., 7., 1.]), 'best match scores': tensor([0.9958, 1.0000, 1.0000, 0.1768, 0.2885, 1.0000, 1.0000, 0.1055, 0.0533]), 'num_pos': 9}
2020-12-13 04:18:07,133 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 04:18:37,670 maskrcnn_benchmark.trainer INFO: eta: 17:29:01  iter: 140  loss: 10.2136 (10.6304)  loss_classifier: 0.3916 (0.4267)  loss_box_reg: 0.5752 (0.6401)  loss_objectness: 0.7449 (0.9149)  loss_rpn_box_reg: 8.3596 (8.6486)  time: 1.5271 (1.5791)  data: 0.0971 (0.1510)  lr: 0.000000  max mem: 986
2020-12-13 04:19:08,289 maskrcnn_benchmark.trainer INFO: eta: 17:24:30  iter: 160  loss: 10.1474 (10.5716)  loss_classifier: 0.2787 (0.4079)  loss_box_reg: 0.5206 (0.6291)  loss_objectness: 0.8421 (0.9049)  loss_rpn_box_reg: 8.4340 (8.6297)  time: 1.5322 (1.5730)  data: 0.1066 (0.1455)  lr: 0.000000  max mem: 986
2020-12-13 04:19:38,930 maskrcnn_benchmark.trainer INFO: eta: 17:20:57  iter: 180  loss: 9.9137 (10.5033)  loss_classifier: 0.3216 (0.3962)  loss_box_reg: 0.5069 (0.6204)  loss_objectness: 0.7920 (0.8974)  loss_rpn_box_reg: 8.2083 (8.5892)  time: 1.5325 (1.5685)  data: 0.1079 (0.1414)  lr: 0.000000  max mem: 986
2020-12-13 04:19:38,932 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:19:38,990 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:19:40,502 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.512107 (1.5121066570281982 s / img per device, on 1 devices)
2020-12-13 04:19:40,502 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.399284 (1.3992836475372314 s / img per device, on 1 devices)
2020-12-13 04:19:40,502 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:19:40,607 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:19:40,607 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([9.7996e-02, 4.5659e-02, 2.7365e-02, 1.7123e-02, 1.4888e-02, 1.0853e-02,
        1.0555e-06, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 1., 2., 2., 5., 2., 2., 8., 2.]), 'best match scores': tensor([1.0000, 0.2311, 0.9985, 1.0000, 0.1057, 0.9998, 0.8802, 0.5439, 1.0000]), 'num_pos': 9}
2020-12-13 04:19:40,613 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 04:20:11,212 maskrcnn_benchmark.trainer INFO: eta: 17:23:27  iter: 200  loss: 9.7450 (10.4362)  loss_classifier: 0.3077 (0.3865)  loss_box_reg: 0.5522 (0.6153)  loss_objectness: 0.7722 (0.8869)  loss_rpn_box_reg: 8.1022 (8.5475)  time: 1.5287 (1.5730)  data: 0.1070 (0.1462)  lr: 0.000000  max mem: 986
2020-12-13 04:20:41,673 maskrcnn_benchmark.trainer INFO: eta: 17:19:55  iter: 220  loss: 9.8241 (10.3804)  loss_classifier: 0.2467 (0.3756)  loss_box_reg: 0.4824 (0.6056)  loss_objectness: 0.7736 (0.8800)  loss_rpn_box_reg: 8.2637 (8.5191)  time: 1.5211 (1.5685)  data: 0.0974 (0.1419)  lr: 0.000000  max mem: 986
2020-12-13 04:21:12,182 maskrcnn_benchmark.trainer INFO: eta: 17:17:01  iter: 240  loss: 9.8440 (10.3512)  loss_classifier: 0.2578 (0.3751)  loss_box_reg: 0.5396 (0.6057)  loss_objectness: 0.7838 (0.8743)  loss_rpn_box_reg: 8.1449 (8.4960)  time: 1.5246 (1.5649)  data: 0.0974 (0.1382)  lr: 0.000000  max mem: 986
2020-12-13 04:21:12,185 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:21:12,236 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:21:13,754 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.516981 (1.5169808864593506 s / img per device, on 1 devices)
2020-12-13 04:21:13,754 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.412594 (1.4125936031341553 s / img per device, on 1 devices)
2020-12-13 04:21:13,754 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:21:13,851 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:21:13,851 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([8.0546e-02, 2.0852e-02, 1.1299e-02, 2.1319e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 2.]), 'best match scores': tensor([1.0000, 0.1309, 1.0000, 1.0000, 0.9324, 0.3565, 0.9997, 0.2286, 1.0000]), 'num_pos': 9}
2020-12-13 04:21:13,855 maskrcnn_benchmark.trainer INFO: validation accuracy: 1.000000
2020-12-13 04:21:13,858 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v5.pth
2020-12-13 04:21:18,117 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v5
2020-12-13 04:21:48,609 maskrcnn_benchmark.trainer INFO: eta: 17:29:33  iter: 260  loss: 9.6972 (10.3094)  loss_classifier: 0.2373 (0.3709)  loss_box_reg: 0.4655 (0.6004)  loss_objectness: 0.7491 (0.8636)  loss_rpn_box_reg: 8.1734 (8.4745)  time: 1.5250 (1.5846)  data: 0.0966 (0.1580)  lr: 0.000000  max mem: 986
2020-12-13 04:22:19,081 maskrcnn_benchmark.trainer INFO: eta: 17:26:08  iter: 280  loss: 9.5112 (10.2689)  loss_classifier: 0.2521 (0.3707)  loss_box_reg: 0.5237 (0.5981)  loss_objectness: 0.7139 (0.8568)  loss_rpn_box_reg: 8.0476 (8.4432)  time: 1.5239 (1.5803)  data: 0.0972 (0.1536)  lr: 0.000000  max mem: 986
2020-12-13 04:22:49,591 maskrcnn_benchmark.trainer INFO: eta: 17:23:12  iter: 300  loss: 9.5751 (10.2428)  loss_classifier: 0.2103 (0.3781)  loss_box_reg: 0.5262 (0.6046)  loss_objectness: 0.6865 (0.8481)  loss_rpn_box_reg: 7.9158 (8.4120)  time: 1.5222 (1.5766)  data: 0.0973 (0.1500)  lr: 0.000000  max mem: 986
2020-12-13 04:22:49,593 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:22:49,645 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:22:51,154 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.508615 (1.508615493774414 s / img per device, on 1 devices)
2020-12-13 04:22:51,154 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.405191 (1.4051909446716309 s / img per device, on 1 devices)
2020-12-13 04:22:51,155 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:22:51,251 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:22:51,251 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([4.8971e-02, 2.0852e-02, 4.6765e-04, 1.4626e-04, 5.6150e-05, 2.9090e-06,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 8., 2., 2., 2., 1.]), 'best match scores': tensor([0.9295, 1.0000, 1.0000, 1.0000, 0.9998, 0.9850, 1.0000, 1.0000, 0.0918]), 'num_pos': 9}
2020-12-13 04:22:51,257 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.777778
2020-12-13 04:23:21,771 maskrcnn_benchmark.trainer INFO: eta: 17:24:00  iter: 320  loss: 9.5865 (10.2272)  loss_classifier: 0.1596 (0.3875)  loss_box_reg: 0.4281 (0.6082)  loss_objectness: 0.6678 (0.8385)  loss_rpn_box_reg: 8.1244 (8.3931)  time: 1.5228 (1.5787)  data: 0.0969 (0.1520)  lr: 0.000000  max mem: 986
2020-12-13 04:23:52,269 maskrcnn_benchmark.trainer INFO: eta: 17:21:24  iter: 340  loss: 9.5162 (10.1860)  loss_classifier: 0.2432 (0.3787)  loss_box_reg: 0.5070 (0.6043)  loss_objectness: 0.6463 (0.8299)  loss_rpn_box_reg: 8.1011 (8.3731)  time: 1.5232 (1.5755)  data: 0.0974 (0.1489)  lr: 0.000000  max mem: 986
2020-12-13 04:24:22,803 maskrcnn_benchmark.trainer INFO: eta: 17:19:05  iter: 360  loss: 9.1802 (10.1273)  loss_classifier: 0.1905 (0.3678)  loss_box_reg: 0.4127 (0.5962)  loss_objectness: 0.6278 (0.8191)  loss_rpn_box_reg: 7.8144 (8.3443)  time: 1.5249 (1.5728)  data: 0.0975 (0.1462)  lr: 0.000000  max mem: 986
2020-12-13 04:24:22,805 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:24:22,863 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:24:24,385 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.521848 (1.5218477249145508 s / img per device, on 1 devices)
2020-12-13 04:24:24,385 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.406769 (1.406768560409546 s / img per device, on 1 devices)
2020-12-13 04:24:24,385 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:24:24,482 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:24:24,482 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0877, 0.0209, 0.0098, 0.0066, 0.0009, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 3., 2.]), 'best match scores': tensor([0.0642, 0.0777, 1.0000, 1.0000, 0.9936, 1.0000, 1.0000, 0.9623, 1.0000]), 'num_pos': 9}
2020-12-13 04:24:24,486 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.888889
2020-12-13 04:24:54,972 maskrcnn_benchmark.trainer INFO: eta: 17:19:47  iter: 380  loss: 9.2597 (10.0814)  loss_classifier: 0.2400 (0.3613)  loss_box_reg: 0.4824 (0.5903)  loss_objectness: 0.6355 (0.8096)  loss_rpn_box_reg: 7.8012 (8.3202)  time: 1.5219 (1.5747)  data: 0.0971 (0.1482)  lr: 0.000000  max mem: 986
2020-12-13 04:25:25,560 maskrcnn_benchmark.trainer INFO: eta: 17:17:46  iter: 400  loss: 9.2782 (10.0540)  loss_classifier: 0.2349 (0.3604)  loss_box_reg: 0.5123 (0.5899)  loss_objectness: 0.6415 (0.8012)  loss_rpn_box_reg: 7.9663 (8.3026)  time: 1.5277 (1.5724)  data: 0.1021 (0.1459)  lr: 0.000000  max mem: 986
2020-12-13 04:25:56,041 maskrcnn_benchmark.trainer INFO: eta: 17:15:44  iter: 420  loss: 9.0274 (10.0065)  loss_classifier: 0.1720 (0.3517)  loss_box_reg: 0.4643 (0.5836)  loss_objectness: 0.5835 (0.7917)  loss_rpn_box_reg: 7.7077 (8.2796)  time: 1.5232 (1.5701)  data: 0.0969 (0.1437)  lr: 0.000000  max mem: 986
2020-12-13 04:25:56,043 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:25:56,096 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:25:57,613 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.516302 (1.5163023471832275 s / img per device, on 1 devices)
2020-12-13 04:25:57,613 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.411608 (1.4116075038909912 s / img per device, on 1 devices)
2020-12-13 04:25:57,613 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:25:57,710 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:25:57,710 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0226, 0.0080, 0.0010, 0.0006, 0.0005, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 8., 2., 2., 2.]), 'best match scores': tensor([0.8123, 1.0000, 0.9153, 0.9998, 1.0000, 0.0618, 1.0000, 1.0000, 1.0000]), 'num_pos': 9}
2020-12-13 04:25:57,714 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.888889
2020-12-13 04:26:28,229 maskrcnn_benchmark.trainer INFO: eta: 17:16:23  iter: 440  loss: 8.9195 (9.9621)  loss_classifier: 0.1572 (0.3467)  loss_box_reg: 0.4607 (0.5812)  loss_objectness: 0.5992 (0.7833)  loss_rpn_box_reg: 7.5620 (8.2509)  time: 1.5251 (1.5719)  data: 0.0975 (0.1454)  lr: 0.000000  max mem: 986
2020-12-13 04:26:58,771 maskrcnn_benchmark.trainer INFO: eta: 17:14:35  iter: 460  loss: 8.7923 (9.9224)  loss_classifier: 0.2240 (0.3433)  loss_box_reg: 0.3649 (0.5752)  loss_objectness: 0.5938 (0.7757)  loss_rpn_box_reg: 7.6221 (8.2282)  time: 1.5262 (1.5699)  data: 0.1000 (0.1436)  lr: 0.000000  max mem: 986
2020-12-13 04:27:29,243 maskrcnn_benchmark.trainer INFO: eta: 17:12:47  iter: 480  loss: 9.1002 (9.8918)  loss_classifier: 0.1239 (0.3404)  loss_box_reg: 0.4511 (0.5731)  loss_objectness: 0.6122 (0.7689)  loss_rpn_box_reg: 7.7604 (8.2094)  time: 1.5227 (1.5680)  data: 0.0969 (0.1417)  lr: 0.000000  max mem: 986
2020-12-13 04:27:29,246 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:27:29,298 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:27:30,813 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.514725 (1.5147252082824707 s / img per device, on 1 devices)
2020-12-13 04:27:30,814 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.406717 (1.4067168235778809 s / img per device, on 1 devices)
2020-12-13 04:27:30,814 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:27:30,931 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:27:30,931 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0309, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 8.]), 'best match scores': tensor([1.0000, 0.9890, 1.0000, 0.2170, 1.0000, 1.0000, 1.0000, 1.0000, 0.0789]), 'num_pos': 9}
2020-12-13 04:27:30,936 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.888889
2020-12-13 04:28:01,481 maskrcnn_benchmark.trainer INFO: eta: 17:13:25  iter: 500  loss: 8.7839 (9.8577)  loss_classifier: 0.1503 (0.3404)  loss_box_reg: 0.4328 (0.5725)  loss_objectness: 0.5724 (0.7610)  loss_rpn_box_reg: 7.5787 (8.1837)  time: 1.5264 (1.5698)  data: 0.0979 (0.1433)  lr: 0.000000  max mem: 986
2020-12-13 04:28:31,983 maskrcnn_benchmark.trainer INFO: eta: 17:11:46  iter: 520  loss: 8.6899 (9.8153)  loss_classifier: 0.1508 (0.3332)  loss_box_reg: 0.3462 (0.5652)  loss_objectness: 0.5504 (0.7530)  loss_rpn_box_reg: 7.6212 (8.1638)  time: 1.5265 (1.5680)  data: 0.0967 (0.1416)  lr: 0.000000  max mem: 986
2020-12-13 04:29:02,511 maskrcnn_benchmark.trainer INFO: eta: 17:10:13  iter: 540  loss: 8.6686 (9.7732)  loss_classifier: 0.1464 (0.3262)  loss_box_reg: 0.4405 (0.5601)  loss_objectness: 0.5306 (0.7454)  loss_rpn_box_reg: 7.5294 (8.1416)  time: 1.5262 (1.5665)  data: 0.0962 (0.1400)  lr: 0.000000  max mem: 986
2020-12-13 04:29:02,512 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:29:02,571 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:29:04,085 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.513578 (1.513578176498413 s / img per device, on 1 devices)
2020-12-13 04:29:04,085 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.399446 (1.3994464874267578 s / img per device, on 1 devices)
2020-12-13 04:29:04,085 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:29:04,190 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:29:04,190 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0434, 0.0016, 0.0008, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 2.]), 'best match scores': tensor([0.1280, 0.7169, 0.0699, 1.0000, 0.7818, 1.0000, 1.0000, 1.0000, 1.0000]), 'num_pos': 9}
2020-12-13 04:29:04,194 maskrcnn_benchmark.trainer INFO: validation accuracy: 1.000000
2020-12-13 04:29:34,787 maskrcnn_benchmark.trainer INFO: eta: 17:10:49  iter: 560  loss: 8.4118 (9.7404)  loss_classifier: 0.1445 (0.3279)  loss_box_reg: 0.3113 (0.5579)  loss_objectness: 0.5395 (0.7379)  loss_rpn_box_reg: 7.4035 (8.1168)  time: 1.5286 (1.5682)  data: 0.1035 (0.1417)  lr: 0.000000  max mem: 986
2020-12-13 04:30:05,392 maskrcnn_benchmark.trainer INFO: eta: 17:09:26  iter: 580  loss: 8.5021 (9.7012)  loss_classifier: 0.1042 (0.3226)  loss_box_reg: 0.4231 (0.5536)  loss_objectness: 0.5073 (0.7305)  loss_rpn_box_reg: 7.4804 (8.0946)  time: 1.5259 (1.5669)  data: 0.0968 (0.1402)  lr: 0.000000  max mem: 986
2020-12-13 04:30:36,126 maskrcnn_benchmark.trainer INFO: eta: 17:08:15  iter: 600  loss: 8.4285 (9.6566)  loss_classifier: 0.0897 (0.3154)  loss_box_reg: 0.2937 (0.5469)  loss_objectness: 0.4696 (0.7222)  loss_rpn_box_reg: 7.3878 (8.0720)  time: 1.5273 (1.5659)  data: 0.0960 (0.1388)  lr: 0.000000  max mem: 986
2020-12-13 04:30:36,128 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:30:36,178 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:30:37,693 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.514371 (1.5143711566925049 s / img per device, on 1 devices)
2020-12-13 04:30:37,693 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.411294 (1.4112939834594727 s / img per device, on 1 devices)
2020-12-13 04:30:37,693 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:30:37,788 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:30:37,788 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0479, 0.0271, 0.0011, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 8.]), 'best match scores': tensor([0.9040, 0.9873, 0.9674, 0.4765, 0.9997, 0.1393, 1.0000, 0.0914, 0.2106]), 'num_pos': 9}
2020-12-13 04:30:37,793 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.888889
2020-12-13 04:31:08,288 maskrcnn_benchmark.trainer INFO: eta: 17:08:37  iter: 620  loss: 8.3986 (9.6173)  loss_classifier: 0.1001 (0.3089)  loss_box_reg: 0.4027 (0.5428)  loss_objectness: 0.4918 (0.7158)  loss_rpn_box_reg: 7.3513 (8.0498)  time: 1.5231 (1.5672)  data: 0.0965 (0.1403)  lr: 0.000000  max mem: 986
2020-12-13 04:31:38,766 maskrcnn_benchmark.trainer INFO: eta: 17:07:13  iter: 640  loss: 8.3450 (9.5864)  loss_classifier: 0.1328 (0.3091)  loss_box_reg: 0.3956 (0.5409)  loss_objectness: 0.4481 (0.7087)  loss_rpn_box_reg: 7.3088 (8.0277)  time: 1.5233 (1.5659)  data: 0.0996 (0.1390)  lr: 0.000000  max mem: 986
2020-12-13 04:32:09,256 maskrcnn_benchmark.trainer INFO: eta: 17:05:52  iter: 660  loss: 8.4689 (9.5602)  loss_classifier: 0.1141 (0.3095)  loss_box_reg: 0.3877 (0.5388)  loss_objectness: 0.4504 (0.7013)  loss_rpn_box_reg: 7.4538 (8.0106)  time: 1.5244 (1.5646)  data: 0.0970 (0.1378)  lr: 0.000000  max mem: 986
2020-12-13 04:32:09,257 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:32:09,309 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:32:10,819 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.509663 (1.5096626281738281 s / img per device, on 1 devices)
2020-12-13 04:32:10,819 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.407629 (1.4076292514801025 s / img per device, on 1 devices)
2020-12-13 04:32:10,819 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:32:10,913 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:32:10,913 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1262, 0.1242, 0.0324, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  2., -1.,  2.,  2.,  2.,  2.,  7.,  2.]), 'best match scores': tensor([0.0000, 0.1330, 0.0000, 1.0000, 0.9956, 1.0000, 1.0000, 1.0000, 0.1753]), 'num_pos': 9}
2020-12-13 04:32:10,917 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 04:32:41,392 maskrcnn_benchmark.trainer INFO: eta: 17:06:09  iter: 680  loss: 8.1392 (9.5263)  loss_classifier: 0.0881 (0.3068)  loss_box_reg: 0.3826 (0.5355)  loss_objectness: 0.5029 (0.6953)  loss_rpn_box_reg: 7.1498 (7.9886)  time: 1.5236 (1.5659)  data: 0.0946 (0.1391)  lr: 0.000000  max mem: 986
2020-12-13 04:33:11,834 maskrcnn_benchmark.trainer INFO: eta: 17:04:49  iter: 700  loss: 8.1192 (9.4891)  loss_classifier: 0.1016 (0.3028)  loss_box_reg: 0.3668 (0.5304)  loss_objectness: 0.4660 (0.6893)  loss_rpn_box_reg: 7.1947 (7.9666)  time: 1.5210 (1.5646)  data: 0.0955 (0.1378)  lr: 0.000000  max mem: 986
2020-12-13 04:33:42,264 maskrcnn_benchmark.trainer INFO: eta: 17:03:31  iter: 720  loss: 8.1991 (9.4561)  loss_classifier: 0.0875 (0.2985)  loss_box_reg: 0.3423 (0.5263)  loss_objectness: 0.4855 (0.6838)  loss_rpn_box_reg: 7.1842 (7.9474)  time: 1.5196 (1.5634)  data: 0.0955 (0.1367)  lr: 0.000000  max mem: 986
2020-12-13 04:33:42,266 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:33:42,317 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:33:43,824 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.506381 (1.5063807964324951 s / img per device, on 1 devices)
2020-12-13 04:33:43,824 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.403582 (1.4035818576812744 s / img per device, on 1 devices)
2020-12-13 04:33:43,824 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:33:43,918 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:33:43,918 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0240, 0.0206, 0.0171, 0.0007, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 1., 2., 2., 2., 2., 2., 2., 2.]), 'best match scores': tensor([1.0000, 1.0000, 0.5690, 0.7202, 0.0848, 0.9123, 0.2763, 0.7827, 0.9941]), 'num_pos': 9}
2020-12-13 04:33:43,923 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.888889
2020-12-13 04:34:14,413 maskrcnn_benchmark.trainer INFO: eta: 17:03:46  iter: 740  loss: 8.1755 (9.4278)  loss_classifier: 0.0671 (0.2967)  loss_box_reg: 0.3553 (0.5231)  loss_objectness: 0.4614 (0.6781)  loss_rpn_box_reg: 7.2439 (7.9299)  time: 1.5248 (1.5646)  data: 0.0960 (0.1378)  lr: 0.000000  max mem: 986
2020-12-13 04:34:44,951 maskrcnn_benchmark.trainer INFO: eta: 17:02:36  iter: 760  loss: 8.1626 (9.4003)  loss_classifier: 0.0687 (0.2954)  loss_box_reg: 0.3261 (0.5195)  loss_objectness: 0.5057 (0.6734)  loss_rpn_box_reg: 7.1684 (7.9119)  time: 1.5280 (1.5636)  data: 0.1026 (0.1369)  lr: 0.000000  max mem: 986
2020-12-13 04:35:15,523 maskrcnn_benchmark.trainer INFO: eta: 17:01:29  iter: 780  loss: 7.9616 (9.3690)  loss_classifier: 0.0616 (0.2941)  loss_box_reg: 0.3503 (0.5167)  loss_objectness: 0.4583 (0.6680)  loss_rpn_box_reg: 7.0898 (7.8902)  time: 1.5295 (1.5627)  data: 0.1058 (0.1360)  lr: 0.000000  max mem: 986
2020-12-13 04:35:15,525 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:35:15,581 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:35:17,091 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.510509 (1.5105087757110596 s / img per device, on 1 devices)
2020-12-13 04:35:17,091 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.398886 (1.3988864421844482 s / img per device, on 1 devices)
2020-12-13 04:35:17,092 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:35:17,196 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:35:17,196 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1665, 0.0333, 0.0039, 0.0006, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 2.]), 'best match scores': tensor([0.9885, 0.9296, 0.9102, 0.9999, 0.9999, 1.0000, 0.9993, 0.9994, 0.2899]), 'num_pos': 9}
2020-12-13 04:35:17,200 maskrcnn_benchmark.trainer INFO: validation accuracy: 1.000000
2020-12-13 04:35:47,658 maskrcnn_benchmark.trainer INFO: eta: 17:01:41  iter: 800  loss: 7.9232 (9.3352)  loss_classifier: 0.1000 (0.2890)  loss_box_reg: 0.3409 (0.5118)  loss_objectness: 0.4831 (0.6636)  loss_rpn_box_reg: 7.0541 (7.8708)  time: 1.5221 (1.5638)  data: 0.0964 (0.1372)  lr: 0.000000  max mem: 986
2020-12-13 04:36:18,115 maskrcnn_benchmark.trainer INFO: eta: 17:00:31  iter: 820  loss: 8.1402 (9.3041)  loss_classifier: 0.0993 (0.2845)  loss_box_reg: 0.3346 (0.5075)  loss_objectness: 0.4656 (0.6590)  loss_rpn_box_reg: 7.0813 (7.8531)  time: 1.5202 (1.5628)  data: 0.0964 (0.1362)  lr: 0.000000  max mem: 986
2020-12-13 04:36:48,579 maskrcnn_benchmark.trainer INFO: eta: 16:59:23  iter: 840  loss: 7.9262 (9.2712)  loss_classifier: 0.0632 (0.2799)  loss_box_reg: 0.3293 (0.5032)  loss_objectness: 0.4562 (0.6541)  loss_rpn_box_reg: 7.0376 (7.8341)  time: 1.5236 (1.5619)  data: 0.0959 (0.1353)  lr: 0.000000  max mem: 986
2020-12-13 04:36:48,581 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:36:48,632 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:36:50,141 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.508483 (1.5084829330444336 s / img per device, on 1 devices)
2020-12-13 04:36:50,141 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.406743 (1.4067432880401611 s / img per device, on 1 devices)
2020-12-13 04:36:50,141 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:36:50,235 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:36:50,236 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0311, 0.0209, 0.0175, 0.0171, 0.0168, 0.0030, 0.0002, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 1., 2., 2., 2., 2., 2., 8.]), 'best match scores': tensor([0.9993, 0.2077, 1.0000, 0.9264, 0.9887, 1.0000, 0.9554, 0.9999, 1.0000]), 'num_pos': 9}
2020-12-13 04:36:50,241 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.777778
2020-12-13 04:37:20,734 maskrcnn_benchmark.trainer INFO: eta: 16:59:33  iter: 860  loss: 7.8488 (9.2389)  loss_classifier: 0.0611 (0.2749)  loss_box_reg: 0.3230 (0.4984)  loss_objectness: 0.4911 (0.6497)  loss_rpn_box_reg: 7.0603 (7.8159)  time: 1.5212 (1.5629)  data: 0.0963 (0.1364)  lr: 0.000000  max mem: 986
2020-12-13 04:37:51,194 maskrcnn_benchmark.trainer INFO: eta: 16:58:26  iter: 880  loss: 7.8080 (9.2117)  loss_classifier: 0.0697 (0.2728)  loss_box_reg: 0.3184 (0.4959)  loss_objectness: 0.4541 (0.6456)  loss_rpn_box_reg: 6.9490 (7.7975)  time: 1.5222 (1.5620)  data: 0.0962 (0.1355)  lr: 0.000000  max mem: 986
2020-12-13 04:38:21,617 maskrcnn_benchmark.trainer INFO: eta: 16:57:20  iter: 900  loss: 7.8795 (9.1857)  loss_classifier: 0.0653 (0.2697)  loss_box_reg: 0.3169 (0.4929)  loss_objectness: 0.4528 (0.6414)  loss_rpn_box_reg: 7.0522 (7.7817)  time: 1.5211 (1.5611)  data: 0.0955 (0.1346)  lr: 0.000000  max mem: 986
2020-12-13 04:38:21,619 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:38:21,668 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:38:23,179 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.511010 (1.5110101699829102 s / img per device, on 1 devices)
2020-12-13 04:38:23,179 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.410095 (1.410094976425171 s / img per device, on 1 devices)
2020-12-13 04:38:23,179 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:38:23,273 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:38:23,273 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0908, 0.0368, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 1.0000, 0.9995, 0.8934, 0.5825, 0.7686, 0.1518, 0.7463]), 'num_pos': 9}
2020-12-13 04:38:23,278 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.777778
2020-12-13 04:38:53,703 maskrcnn_benchmark.trainer INFO: eta: 16:57:25  iter: 920  loss: 7.8555 (9.1573)  loss_classifier: 0.0740 (0.2668)  loss_box_reg: 0.3045 (0.4891)  loss_objectness: 0.4704 (0.6374)  loss_rpn_box_reg: 6.9224 (7.7640)  time: 1.5206 (1.5621)  data: 0.0957 (0.1356)  lr: 0.000000  max mem: 986
2020-12-13 04:39:24,171 maskrcnn_benchmark.trainer INFO: eta: 16:56:22  iter: 940  loss: 7.9558 (9.1322)  loss_classifier: 0.0572 (0.2638)  loss_box_reg: 0.2958 (0.4862)  loss_objectness: 0.4679 (0.6338)  loss_rpn_box_reg: 7.0016 (7.7485)  time: 1.5226 (1.5612)  data: 0.0964 (0.1347)  lr: 0.000000  max mem: 986
2020-12-13 04:39:54,647 maskrcnn_benchmark.trainer INFO: eta: 16:55:20  iter: 960  loss: 7.7530 (9.1049)  loss_classifier: 0.0771 (0.2601)  loss_box_reg: 0.2874 (0.4823)  loss_objectness: 0.5010 (0.6310)  loss_rpn_box_reg: 6.8722 (7.7314)  time: 1.5223 (1.5605)  data: 0.0954 (0.1339)  lr: 0.000000  max mem: 986
2020-12-13 04:39:54,649 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:39:54,698 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:39:56,203 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.504980 (1.5049796104431152 s / img per device, on 1 devices)
2020-12-13 04:39:56,203 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.404830 (1.4048304557800293 s / img per device, on 1 devices)
2020-12-13 04:39:56,203 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:39:56,297 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:39:56,297 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0667, 0.0640, 0.0231, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.4763, 0.8319, 0.1157, 0.4972, 0.6086, 1.0000, 0.8384, 0.9996]), 'num_pos': 9}
2020-12-13 04:39:56,302 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.888889
2020-12-13 04:40:26,774 maskrcnn_benchmark.trainer INFO: eta: 16:55:25  iter: 980  loss: 7.6370 (9.0814)  loss_classifier: 0.0563 (0.2603)  loss_box_reg: 0.2865 (0.4811)  loss_objectness: 0.4474 (0.6271)  loss_rpn_box_reg: 6.8203 (7.7129)  time: 1.5235 (1.5614)  data: 0.0948 (0.1348)  lr: 0.000000  max mem: 986
2020-12-13 04:40:57,229 maskrcnn_benchmark.trainer INFO: eta: 16:54:24  iter: 1000  loss: 7.7774 (9.0619)  loss_classifier: 0.0887 (0.2621)  loss_box_reg: 0.3732 (0.4802)  loss_objectness: 0.4734 (0.6235)  loss_rpn_box_reg: 6.8459 (7.6961)  time: 1.5224 (1.5606)  data: 0.0951 (0.1340)  lr: 0.000000  max mem: 986
2020-12-13 04:41:27,734 maskrcnn_benchmark.trainer INFO: eta: 16:53:26  iter: 1020  loss: 7.6965 (9.0354)  loss_classifier: 0.0393 (0.2591)  loss_box_reg: 0.2661 (0.4762)  loss_objectness: 0.4396 (0.6201)  loss_rpn_box_reg: 6.8461 (7.6800)  time: 1.5223 (1.5599)  data: 0.0960 (0.1333)  lr: 0.000000  max mem: 986
2020-12-13 04:41:27,736 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:41:27,786 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:41:29,287 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.501475 (1.5014746189117432 s / img per device, on 1 devices)
2020-12-13 04:41:29,288 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.399773 (1.399773120880127 s / img per device, on 1 devices)
2020-12-13 04:41:29,288 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:41:29,381 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:41:29,381 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0834, 0.0560, 0.0188, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  2.,  2., -1., -1.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 1.0000, 0.9359, 0.0000, 0.0000, 1.0000, 0.2136, 0.7126, 0.9999]), 'num_pos': 9}
2020-12-13 04:41:29,387 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 04:41:59,908 maskrcnn_benchmark.trainer INFO: eta: 16:53:31  iter: 1040  loss: 7.6413 (9.0110)  loss_classifier: 0.0444 (0.2562)  loss_box_reg: 0.3482 (0.4738)  loss_objectness: 0.4609 (0.6172)  loss_rpn_box_reg: 6.7881 (7.6637)  time: 1.5231 (1.5609)  data: 0.0958 (0.1343)  lr: 0.000000  max mem: 986
2020-12-13 04:42:30,355 maskrcnn_benchmark.trainer INFO: eta: 16:52:31  iter: 1060  loss: 7.4158 (8.9826)  loss_classifier: 0.0421 (0.2523)  loss_box_reg: 0.1868 (0.4696)  loss_objectness: 0.4382 (0.6141)  loss_rpn_box_reg: 6.7063 (7.6466)  time: 1.5220 (1.5601)  data: 0.0955 (0.1335)  lr: 0.000000  max mem: 986
2020-12-13 04:43:00,841 maskrcnn_benchmark.trainer INFO: eta: 16:51:34  iter: 1080  loss: 7.7021 (8.9646)  loss_classifier: 0.1002 (0.2546)  loss_box_reg: 0.3303 (0.4696)  loss_objectness: 0.4191 (0.6106)  loss_rpn_box_reg: 6.7595 (7.6298)  time: 1.5243 (1.5595)  data: 0.0965 (0.1329)  lr: 0.000000  max mem: 986
2020-12-13 04:43:00,843 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:43:00,892 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:43:02,406 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.513660 (1.5136604309082031 s / img per device, on 1 devices)
2020-12-13 04:43:02,406 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.410454 (1.410454273223877 s / img per device, on 1 devices)
2020-12-13 04:43:02,406 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:43:02,501 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:43:02,501 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0555, 0.0209, 0.0007, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1.,  2.,  2.,  2.,  2.,  2.,  5.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 1.0000, 0.9997, 0.9987, 0.9173, 1.0000, 0.9956, 1.0000]), 'num_pos': 9}
2020-12-13 04:43:02,506 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 04:43:33,025 maskrcnn_benchmark.trainer INFO: eta: 16:51:38  iter: 1100  loss: 7.4359 (8.9415)  loss_classifier: 0.0496 (0.2528)  loss_box_reg: 0.2533 (0.4669)  loss_objectness: 0.4469 (0.6075)  loss_rpn_box_reg: 6.7205 (7.6143)  time: 1.5255 (1.5604)  data: 0.1047 (0.1338)  lr: 0.000000  max mem: 986
2020-12-13 04:44:03,573 maskrcnn_benchmark.trainer INFO: eta: 16:50:44  iter: 1120  loss: 7.6617 (8.9268)  loss_classifier: 0.0681 (0.2560)  loss_box_reg: 0.3041 (0.4664)  loss_objectness: 0.4138 (0.6043)  loss_rpn_box_reg: 6.7710 (7.6002)  time: 1.5268 (1.5598)  data: 0.1053 (0.1333)  lr: 0.000000  max mem: 986
2020-12-13 04:44:34,018 maskrcnn_benchmark.trainer INFO: eta: 16:49:48  iter: 1140  loss: 7.4459 (8.9012)  loss_classifier: 0.0793 (0.2529)  loss_box_reg: 0.2209 (0.4622)  loss_objectness: 0.4362 (0.6013)  loss_rpn_box_reg: 6.7348 (7.5848)  time: 1.5212 (1.5591)  data: 0.0963 (0.1327)  lr: 0.000000  max mem: 986
2020-12-13 04:44:34,020 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:44:34,084 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:44:35,618 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.534626 (1.5346260070800781 s / img per device, on 1 devices)
2020-12-13 04:44:35,619 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.411793 (1.4117932319641113 s / img per device, on 1 devices)
2020-12-13 04:44:35,619 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:44:35,713 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:44:35,714 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([2.0852e-02, 2.1323e-03, 1.6216e-04, 9.7543e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.1383, 1.0000, 1.0000, 0.9995, 0.7395, 1.0000]), 'num_pos': 9}
2020-12-13 04:44:35,719 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 04:45:06,162 maskrcnn_benchmark.trainer INFO: eta: 16:49:49  iter: 1160  loss: 7.4472 (8.8800)  loss_classifier: 0.0812 (0.2524)  loss_box_reg: 0.3360 (0.4611)  loss_objectness: 0.4230 (0.5982)  loss_rpn_box_reg: 6.5901 (7.5683)  time: 1.5204 (1.5600)  data: 0.0962 (0.1335)  lr: 0.000000  max mem: 986
2020-12-13 04:45:36,572 maskrcnn_benchmark.trainer INFO: eta: 16:48:51  iter: 1180  loss: 7.3845 (8.8620)  loss_classifier: 0.0478 (0.2535)  loss_box_reg: 0.2773 (0.4596)  loss_objectness: 0.4385 (0.5954)  loss_rpn_box_reg: 6.6252 (7.5534)  time: 1.5194 (1.5593)  data: 0.0960 (0.1329)  lr: 0.000000  max mem: 986
2020-12-13 04:46:07,099 maskrcnn_benchmark.trainer INFO: eta: 16:47:59  iter: 1200  loss: 7.3026 (8.8361)  loss_classifier: 0.0523 (0.2503)  loss_box_reg: 0.1660 (0.4553)  loss_objectness: 0.4134 (0.5923)  loss_rpn_box_reg: 6.5265 (7.5381)  time: 1.5239 (1.5587)  data: 0.0970 (0.1324)  lr: 0.000000  max mem: 986
2020-12-13 04:46:07,101 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:46:07,150 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:46:08,653 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.502675 (1.5026748180389404 s / img per device, on 1 devices)
2020-12-13 04:46:08,653 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.403367 (1.403367042541504 s / img per device, on 1 devices)
2020-12-13 04:46:08,654 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:46:08,747 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:46:08,747 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0013, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.9996, 0.8119, 1.0000, 0.8089, 0.9970, 1.0000]), 'num_pos': 9}
2020-12-13 04:46:08,752 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 04:46:39,198 maskrcnn_benchmark.trainer INFO: eta: 16:47:57  iter: 1220  loss: 7.3669 (8.8118)  loss_classifier: 0.0538 (0.2473)  loss_box_reg: 0.2216 (0.4519)  loss_objectness: 0.4542 (0.5902)  loss_rpn_box_reg: 6.6196 (7.5224)  time: 1.5216 (1.5595)  data: 0.0955 (0.1331)  lr: 0.000000  max mem: 986
2020-12-13 04:47:09,685 maskrcnn_benchmark.trainer INFO: eta: 16:47:04  iter: 1240  loss: 7.1616 (8.7868)  loss_classifier: 0.0482 (0.2443)  loss_box_reg: 0.2434 (0.4489)  loss_objectness: 0.4010 (0.5875)  loss_rpn_box_reg: 6.4441 (7.5061)  time: 1.5229 (1.5589)  data: 0.0957 (0.1326)  lr: 0.000000  max mem: 986
2020-12-13 04:47:40,118 maskrcnn_benchmark.trainer INFO: eta: 16:46:10  iter: 1260  loss: 7.2236 (8.7631)  loss_classifier: 0.0449 (0.2413)  loss_box_reg: 0.2076 (0.4454)  loss_objectness: 0.4183 (0.5849)  loss_rpn_box_reg: 6.5334 (7.4915)  time: 1.5198 (1.5583)  data: 0.0955 (0.1320)  lr: 0.000000  max mem: 986
2020-12-13 04:47:40,120 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:47:40,172 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:47:41,680 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.508123 (1.5081226825714111 s / img per device, on 1 devices)
2020-12-13 04:47:41,680 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.406608 (1.4066076278686523 s / img per device, on 1 devices)
2020-12-13 04:47:41,681 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:47:41,774 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:47:41,774 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0209, 0.0002, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1.,  2.,  2.,  2.,  2.,  4.,  7.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.9996, 0.9994, 0.0996, 0.9900, 1.0000, 0.9727, 1.0000]), 'num_pos': 9}
2020-12-13 04:47:41,779 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 04:48:12,235 maskrcnn_benchmark.trainer INFO: eta: 16:46:07  iter: 1280  loss: 7.2315 (8.7441)  loss_classifier: 0.0392 (0.2411)  loss_box_reg: 0.2356 (0.4430)  loss_objectness: 0.4218 (0.5826)  loss_rpn_box_reg: 6.5423 (7.4773)  time: 1.5230 (1.5591)  data: 0.0938 (0.1327)  lr: 0.000000  max mem: 986
2020-12-13 04:48:42,656 maskrcnn_benchmark.trainer INFO: eta: 16:45:14  iter: 1300  loss: 7.3166 (8.7235)  loss_classifier: 0.0518 (0.2399)  loss_box_reg: 0.2199 (0.4409)  loss_objectness: 0.4205 (0.5802)  loss_rpn_box_reg: 6.4843 (7.4625)  time: 1.5205 (1.5585)  data: 0.0936 (0.1321)  lr: 0.000000  max mem: 986
2020-12-13 04:49:13,141 maskrcnn_benchmark.trainer INFO: eta: 16:44:22  iter: 1320  loss: 7.2207 (8.7036)  loss_classifier: 0.0429 (0.2385)  loss_box_reg: 0.2741 (0.4390)  loss_objectness: 0.4310 (0.5779)  loss_rpn_box_reg: 6.4619 (7.4482)  time: 1.5239 (1.5580)  data: 0.0946 (0.1315)  lr: 0.000000  max mem: 986
2020-12-13 04:49:13,143 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:49:13,192 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:49:14,701 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.509723 (1.509723424911499 s / img per device, on 1 devices)
2020-12-13 04:49:14,702 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.410199 (1.41019868850708 s / img per device, on 1 devices)
2020-12-13 04:49:14,702 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:49:14,796 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:49:14,796 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1334, 0.0004, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2., -1., -1.,  2.,  2., -1.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.8760, 0.3118, 0.0000]), 'num_pos': 9}
2020-12-13 04:49:14,801 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 04:49:45,287 maskrcnn_benchmark.trainer INFO: eta: 16:44:20  iter: 1340  loss: 7.1968 (8.6849)  loss_classifier: 0.0424 (0.2381)  loss_box_reg: 0.1488 (0.4367)  loss_objectness: 0.4191 (0.5758)  loss_rpn_box_reg: 6.5500 (7.4344)  time: 1.5231 (1.5587)  data: 0.0944 (0.1322)  lr: 0.000000  max mem: 986
2020-12-13 04:50:15,750 maskrcnn_benchmark.trainer INFO: eta: 16:43:28  iter: 1360  loss: 7.1374 (8.6628)  loss_classifier: 0.0504 (0.2353)  loss_box_reg: 0.2479 (0.4339)  loss_objectness: 0.4418 (0.5738)  loss_rpn_box_reg: 6.4201 (7.4197)  time: 1.5222 (1.5582)  data: 0.0940 (0.1317)  lr: 0.000000  max mem: 986
2020-12-13 04:50:46,228 maskrcnn_benchmark.trainer INFO: eta: 16:42:38  iter: 1380  loss: 7.1397 (8.6410)  loss_classifier: 0.0293 (0.2332)  loss_box_reg: 0.1474 (0.4311)  loss_objectness: 0.4100 (0.5716)  loss_rpn_box_reg: 6.4130 (7.4051)  time: 1.5238 (1.5577)  data: 0.0946 (0.1311)  lr: 0.000000  max mem: 986
2020-12-13 04:50:46,230 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:50:46,280 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:50:47,788 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.507964 (1.5079643726348877 s / img per device, on 1 devices)
2020-12-13 04:50:47,788 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.405988 (1.4059879779815674 s / img per device, on 1 devices)
2020-12-13 04:50:47,789 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:50:47,885 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:50:47,885 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([2.0852e-02, 1.7123e-02, 1.5747e-02, 2.8408e-03, 9.2360e-05, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  8.]), 'best match scores': tensor([0.0000, 0.1763, 1.0000, 0.8385, 0.9954, 0.2394, 0.1186, 0.9033, 1.0000]), 'num_pos': 9}
2020-12-13 04:50:47,890 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.777778
2020-12-13 04:51:18,398 maskrcnn_benchmark.trainer INFO: eta: 16:42:35  iter: 1400  loss: 7.1311 (8.6237)  loss_classifier: 0.0670 (0.2339)  loss_box_reg: 0.2524 (0.4297)  loss_objectness: 0.4074 (0.5694)  loss_rpn_box_reg: 6.4022 (7.3907)  time: 1.5246 (1.5584)  data: 0.0956 (0.1318)  lr: 0.000000  max mem: 986
2020-12-13 04:51:48,858 maskrcnn_benchmark.trainer INFO: eta: 16:41:44  iter: 1420  loss: 7.2030 (8.6049)  loss_classifier: 0.0355 (0.2331)  loss_box_reg: 0.1833 (0.4267)  loss_objectness: 0.4059 (0.5673)  loss_rpn_box_reg: 6.4937 (7.3778)  time: 1.5235 (1.5579)  data: 0.0952 (0.1313)  lr: 0.000000  max mem: 986
2020-12-13 04:52:19,333 maskrcnn_benchmark.trainer INFO: eta: 16:40:55  iter: 1440  loss: 7.0181 (8.5841)  loss_classifier: 0.0470 (0.2315)  loss_box_reg: 0.1819 (0.4241)  loss_objectness: 0.4243 (0.5651)  loss_rpn_box_reg: 6.3276 (7.3634)  time: 1.5236 (1.5575)  data: 0.0957 (0.1308)  lr: 0.000000  max mem: 986
2020-12-13 04:52:19,335 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:52:19,384 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:52:20,882 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.497080 (1.4970803260803223 s / img per device, on 1 devices)
2020-12-13 04:52:20,882 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.398458 (1.3984577655792236 s / img per device, on 1 devices)
2020-12-13 04:52:20,882 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:52:20,978 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:52:20,978 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1369, 0.0838, 0.0569, 0.0296, 0.0171, 0.0007, 0.0005, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 2.]), 'best match scores': tensor([0.9414, 0.9774, 0.7821, 0.9996, 0.7642, 1.0000, 0.0824, 0.5572, 0.0886]), 'num_pos': 9}
2020-12-13 04:52:20,983 maskrcnn_benchmark.trainer INFO: validation accuracy: 1.000000
2020-12-13 04:52:51,444 maskrcnn_benchmark.trainer INFO: eta: 16:40:49  iter: 1460  loss: 7.0607 (8.5636)  loss_classifier: 0.0407 (0.2296)  loss_box_reg: 0.2154 (0.4221)  loss_objectness: 0.4055 (0.5631)  loss_rpn_box_reg: 6.2902 (7.3488)  time: 1.5228 (1.5581)  data: 0.0959 (0.1315)  lr: 0.000000  max mem: 986
2020-12-13 04:53:21,938 maskrcnn_benchmark.trainer INFO: eta: 16:40:01  iter: 1480  loss: 7.0748 (8.5440)  loss_classifier: 0.0558 (0.2279)  loss_box_reg: 0.1752 (0.4193)  loss_objectness: 0.4323 (0.5613)  loss_rpn_box_reg: 6.3587 (7.3354)  time: 1.5247 (1.5577)  data: 0.0976 (0.1311)  lr: 0.000000  max mem: 986
2020-12-13 04:53:52,489 maskrcnn_benchmark.trainer INFO: eta: 16:39:14  iter: 1500  loss: 7.0161 (8.5242)  loss_classifier: 0.0310 (0.2254)  loss_box_reg: 0.1743 (0.4164)  loss_objectness: 0.4097 (0.5596)  loss_rpn_box_reg: 6.4028 (7.3228)  time: 1.5291 (1.5573)  data: 0.1056 (0.1307)  lr: 0.000000  max mem: 986
2020-12-13 04:53:52,491 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:53:52,548 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:53:54,059 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.510784 (1.510784387588501 s / img per device, on 1 devices)
2020-12-13 04:53:54,059 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.399351 (1.3993513584136963 s / img per device, on 1 devices)
2020-12-13 04:53:54,059 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:53:54,166 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:53:54,166 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0362, 0.0084, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.2247, 0.9999, 0.1542, 0.6650, 0.6505]), 'num_pos': 9}
2020-12-13 04:53:54,171 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 04:54:24,695 maskrcnn_benchmark.trainer INFO: eta: 16:39:10  iter: 1520  loss: 7.1394 (8.5072)  loss_classifier: 0.0371 (0.2245)  loss_box_reg: 0.2135 (0.4142)  loss_objectness: 0.4272 (0.5581)  loss_rpn_box_reg: 6.3567 (7.3105)  time: 1.5250 (1.5580)  data: 0.0972 (0.1314)  lr: 0.000000  max mem: 986
2020-12-13 04:54:55,188 maskrcnn_benchmark.trainer INFO: eta: 16:38:22  iter: 1540  loss: 7.0333 (8.4886)  loss_classifier: 0.0205 (0.2225)  loss_box_reg: 0.1984 (0.4115)  loss_objectness: 0.4171 (0.5563)  loss_rpn_box_reg: 6.3440 (7.2982)  time: 1.5248 (1.5575)  data: 0.0953 (0.1309)  lr: 0.000000  max mem: 986
2020-12-13 04:55:25,680 maskrcnn_benchmark.trainer INFO: eta: 16:37:34  iter: 1560  loss: 6.9539 (8.4700)  loss_classifier: 0.0448 (0.2210)  loss_box_reg: 0.1769 (0.4089)  loss_objectness: 0.4062 (0.5544)  loss_rpn_box_reg: 6.2893 (7.2857)  time: 1.5236 (1.5571)  data: 0.0956 (0.1305)  lr: 0.000000  max mem: 986
2020-12-13 04:55:25,682 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:55:25,732 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:55:27,247 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.515610 (1.5156097412109375 s / img per device, on 1 devices)
2020-12-13 04:55:27,248 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.411525 (1.4115254878997803 s / img per device, on 1 devices)
2020-12-13 04:55:27,248 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:55:27,347 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:55:27,347 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0209, 0.0006, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 2.]), 'best match scores': tensor([1.0000, 0.7531, 0.1874, 0.9331, 0.2667, 0.9848, 0.9928, 1.0000, 0.9935]), 'num_pos': 9}
2020-12-13 04:55:27,352 maskrcnn_benchmark.trainer INFO: validation accuracy: 1.000000
2020-12-13 04:55:57,852 maskrcnn_benchmark.trainer INFO: eta: 16:37:28  iter: 1580  loss: 7.0456 (8.4526)  loss_classifier: 0.0700 (0.2204)  loss_box_reg: 0.2596 (0.4074)  loss_objectness: 0.3948 (0.5523)  loss_rpn_box_reg: 6.3700 (7.2725)  time: 1.5239 (1.5578)  data: 0.0961 (0.1311)  lr: 0.000000  max mem: 986
2020-12-13 04:56:28,323 maskrcnn_benchmark.trainer INFO: eta: 16:36:41  iter: 1600  loss: 6.9228 (8.4334)  loss_classifier: 0.0397 (0.2182)  loss_box_reg: 0.1631 (0.4045)  loss_objectness: 0.4106 (0.5507)  loss_rpn_box_reg: 6.2450 (7.2600)  time: 1.5236 (1.5573)  data: 0.0967 (0.1307)  lr: 0.000000  max mem: 986
2020-12-13 04:56:58,825 maskrcnn_benchmark.trainer INFO: eta: 16:35:54  iter: 1620  loss: 6.9146 (8.4153)  loss_classifier: 0.0578 (0.2163)  loss_box_reg: 0.2228 (0.4024)  loss_objectness: 0.4100 (0.5491)  loss_rpn_box_reg: 6.2618 (7.2475)  time: 1.5251 (1.5569)  data: 0.0978 (0.1303)  lr: 0.000000  max mem: 986
2020-12-13 04:56:58,827 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:56:58,875 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:57:00,391 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.516031 (1.5160305500030518 s / img per device, on 1 devices)
2020-12-13 04:57:00,392 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.413715 (1.41371488571167 s / img per device, on 1 devices)
2020-12-13 04:57:00,392 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:57:00,488 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:57:00,488 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000]), 'num_pos': 9}
2020-12-13 04:57:00,492 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 04:57:31,012 maskrcnn_benchmark.trainer INFO: eta: 16:35:48  iter: 1640  loss: 6.9158 (8.3989)  loss_classifier: 0.0492 (0.2165)  loss_box_reg: 0.1728 (0.4004)  loss_objectness: 0.4020 (0.5471)  loss_rpn_box_reg: 6.2049 (7.2349)  time: 1.5260 (1.5576)  data: 0.0972 (0.1309)  lr: 0.000000  max mem: 986
2020-12-13 04:58:01,575 maskrcnn_benchmark.trainer INFO: eta: 16:35:03  iter: 1660  loss: 6.7931 (8.3851)  loss_classifier: 0.0584 (0.2193)  loss_box_reg: 0.2272 (0.3997)  loss_objectness: 0.4212 (0.5456)  loss_rpn_box_reg: 6.0460 (7.2204)  time: 1.5282 (1.5572)  data: 0.1004 (0.1306)  lr: 0.000000  max mem: 986
2020-12-13 04:58:32,184 maskrcnn_benchmark.trainer INFO: eta: 16:34:20  iter: 1680  loss: 7.0818 (8.3772)  loss_classifier: 0.0797 (0.2246)  loss_box_reg: 0.3162 (0.4003)  loss_objectness: 0.3683 (0.5438)  loss_rpn_box_reg: 6.2085 (7.2085)  time: 1.5301 (1.5569)  data: 0.1082 (0.1303)  lr: 0.000000  max mem: 986
2020-12-13 04:58:32,187 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 04:58:32,244 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 04:58:33,756 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.511991 (1.5119905471801758 s / img per device, on 1 devices)
2020-12-13 04:58:33,756 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.397671 (1.3976705074310303 s / img per device, on 1 devices)
2020-12-13 04:58:33,756 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 04:58:33,867 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 04:58:33,867 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0232, 0.0089, 0.0023, 0.0021, 0.0006, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 2.]), 'best match scores': tensor([1.0000, 0.3118, 0.5148, 0.9524, 1.0000, 0.7021, 0.4228, 0.3671, 0.0591]), 'num_pos': 9}
2020-12-13 04:58:33,872 maskrcnn_benchmark.trainer INFO: validation accuracy: 1.000000
2020-12-13 04:59:04,375 maskrcnn_benchmark.trainer INFO: eta: 16:34:12  iter: 1700  loss: 6.6871 (8.3586)  loss_classifier: 0.0246 (0.2234)  loss_box_reg: 0.1012 (0.3978)  loss_objectness: 0.4210 (0.5424)  loss_rpn_box_reg: 6.0669 (7.1950)  time: 1.5244 (1.5575)  data: 0.0979 (0.1309)  lr: 0.000000  max mem: 986
2020-12-13 04:59:34,849 maskrcnn_benchmark.trainer INFO: eta: 16:33:26  iter: 1720  loss: 6.5687 (8.3379)  loss_classifier: 0.0125 (0.2211)  loss_box_reg: 0.1458 (0.3950)  loss_objectness: 0.3901 (0.5408)  loss_rpn_box_reg: 5.9347 (7.1810)  time: 1.5219 (1.5571)  data: 0.0975 (0.1305)  lr: 0.000000  max mem: 986
2020-12-13 05:00:05,336 maskrcnn_benchmark.trainer INFO: eta: 16:32:41  iter: 1740  loss: 6.6935 (8.3192)  loss_classifier: 0.0319 (0.2191)  loss_box_reg: 0.1431 (0.3923)  loss_objectness: 0.4293 (0.5394)  loss_rpn_box_reg: 5.9930 (7.1684)  time: 1.5230 (1.5567)  data: 0.0979 (0.1302)  lr: 0.000000  max mem: 986
2020-12-13 05:00:05,338 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:00:05,393 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:00:06,904 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.511226 (1.5112261772155762 s / img per device, on 1 devices)
2020-12-13 05:00:06,904 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.398156 (1.398155927658081 s / img per device, on 1 devices)
2020-12-13 05:00:06,904 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:00:07,018 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:00:07,018 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1851, 0.1219, 0.0557, 0.0134, 0.0007, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  2., -1.,  2., -1.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.1740, 0.0000, 0.9912, 0.0000, 0.1768, 1.0000, 0.9777, 0.9970]), 'num_pos': 9}
2020-12-13 05:00:07,023 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 05:00:37,626 maskrcnn_benchmark.trainer INFO: eta: 16:32:34  iter: 1760  loss: 6.6965 (8.3028)  loss_classifier: 0.0255 (0.2179)  loss_box_reg: 0.1388 (0.3896)  loss_objectness: 0.3827 (0.5376)  loss_rpn_box_reg: 6.1686 (7.1576)  time: 1.5303 (1.5574)  data: 0.1076 (0.1309)  lr: 0.000000  max mem: 986
2020-12-13 05:01:08,126 maskrcnn_benchmark.trainer INFO: eta: 16:31:49  iter: 1780  loss: 6.6199 (8.2862)  loss_classifier: 0.0407 (0.2176)  loss_box_reg: 0.1366 (0.3876)  loss_objectness: 0.3853 (0.5362)  loss_rpn_box_reg: 6.0360 (7.1448)  time: 1.5227 (1.5570)  data: 0.0980 (0.1305)  lr: 0.000000  max mem: 986
2020-12-13 05:01:38,613 maskrcnn_benchmark.trainer INFO: eta: 16:31:04  iter: 1800  loss: 6.4971 (8.2672)  loss_classifier: 0.0332 (0.2156)  loss_box_reg: 0.1317 (0.3846)  loss_objectness: 0.3666 (0.5343)  loss_rpn_box_reg: 6.0242 (7.1327)  time: 1.5244 (1.5567)  data: 0.0960 (0.1301)  lr: 0.000000  max mem: 986
2020-12-13 05:01:38,615 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:01:38,664 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:01:40,174 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.510480 (1.5104804039001465 s / img per device, on 1 devices)
2020-12-13 05:01:40,175 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.408521 (1.4085214138031006 s / img per device, on 1 devices)
2020-12-13 05:01:40,175 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:01:40,271 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:01:40,271 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0007, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2., -1., -1., -1., -1.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.9960, 0.0000, 0.0000, 0.0000, 0.0000, 0.5227]), 'num_pos': 9}
2020-12-13 05:01:40,275 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 05:02:10,791 maskrcnn_benchmark.trainer INFO: eta: 16:30:55  iter: 1820  loss: 6.7296 (8.2526)  loss_classifier: 0.0296 (0.2157)  loss_box_reg: 0.1308 (0.3830)  loss_objectness: 0.4157 (0.5330)  loss_rpn_box_reg: 6.1080 (7.1209)  time: 1.5250 (1.5572)  data: 0.0962 (0.1307)  lr: 0.000000  max mem: 986
2020-12-13 05:02:41,318 maskrcnn_benchmark.trainer INFO: eta: 16:30:11  iter: 1840  loss: 6.6250 (8.2377)  loss_classifier: 0.0331 (0.2157)  loss_box_reg: 0.1315 (0.3812)  loss_objectness: 0.4018 (0.5319)  loss_rpn_box_reg: 6.0331 (7.1089)  time: 1.5263 (1.5569)  data: 0.0961 (0.1303)  lr: 0.000000  max mem: 986
2020-12-13 05:03:11,841 maskrcnn_benchmark.trainer INFO: eta: 16:29:27  iter: 1860  loss: 6.6538 (8.2214)  loss_classifier: 0.0676 (0.2146)  loss_box_reg: 0.0862 (0.3786)  loss_objectness: 0.3866 (0.5305)  loss_rpn_box_reg: 6.0763 (7.0978)  time: 1.5250 (1.5566)  data: 0.0962 (0.1300)  lr: 0.000000  max mem: 986
2020-12-13 05:03:11,844 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:03:11,894 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:03:13,408 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.513212 (1.513211965560913 s / img per device, on 1 devices)
2020-12-13 05:03:13,408 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.410953 (1.4109525680541992 s / img per device, on 1 devices)
2020-12-13 05:03:13,408 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:03:13,505 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:03:13,506 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0676, 0.0660, 0.0549, 0.0043, 0.0003, 0.0001, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2.,  2.,  2.,  2.,  2., -1.,  2., -1., -1.]), 'best match scores': tensor([0.8349, 0.7455, 0.9923, 0.8052, 1.0000, 0.0000, 0.0707, 0.0000, 0.0000]), 'num_pos': 9}
2020-12-13 05:03:13,510 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 05:03:44,074 maskrcnn_benchmark.trainer INFO: eta: 16:29:19  iter: 1880  loss: 6.7727 (8.2098)  loss_classifier: 0.0447 (0.2161)  loss_box_reg: 0.1325 (0.3776)  loss_objectness: 0.3849 (0.5291)  loss_rpn_box_reg: 6.0680 (7.0872)  time: 1.5273 (1.5572)  data: 0.0972 (0.1305)  lr: 0.000000  max mem: 986
2020-12-13 05:04:14,589 maskrcnn_benchmark.trainer INFO: eta: 16:28:35  iter: 1900  loss: 6.5655 (8.1936)  loss_classifier: 0.0289 (0.2143)  loss_box_reg: 0.0854 (0.3752)  loss_objectness: 0.4097 (0.5280)  loss_rpn_box_reg: 5.9957 (7.0761)  time: 1.5264 (1.5568)  data: 0.0966 (0.1301)  lr: 0.000000  max mem: 986
2020-12-13 05:04:45,058 maskrcnn_benchmark.trainer INFO: eta: 16:27:51  iter: 1920  loss: 6.5168 (8.1800)  loss_classifier: 0.0473 (0.2150)  loss_box_reg: 0.1259 (0.3735)  loss_objectness: 0.3657 (0.5265)  loss_rpn_box_reg: 5.9640 (7.0649)  time: 1.5227 (1.5565)  data: 0.0970 (0.1298)  lr: 0.000000  max mem: 986
2020-12-13 05:04:45,060 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:04:45,114 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:04:46,626 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.512115 (1.5121145248413086 s / img per device, on 1 devices)
2020-12-13 05:04:46,626 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.397922 (1.3979215621948242 s / img per device, on 1 devices)
2020-12-13 05:04:46,626 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:04:46,739 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:04:46,740 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0006, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4427, 0.1465, 0.8669, 1.0000]), 'num_pos': 9}
2020-12-13 05:04:46,744 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.444444
2020-12-13 05:05:17,291 maskrcnn_benchmark.trainer INFO: eta: 16:27:41  iter: 1940  loss: 6.5513 (8.1649)  loss_classifier: 0.0480 (0.2146)  loss_box_reg: 0.1255 (0.3717)  loss_objectness: 0.4038 (0.5253)  loss_rpn_box_reg: 5.8413 (7.0532)  time: 1.5271 (1.5571)  data: 0.1000 (0.1304)  lr: 0.000000  max mem: 986
2020-12-13 05:05:47,813 maskrcnn_benchmark.trainer INFO: eta: 16:26:58  iter: 1960  loss: 6.4886 (8.1476)  loss_classifier: 0.0299 (0.2127)  loss_box_reg: 0.0809 (0.3690)  loss_objectness: 0.3658 (0.5236)  loss_rpn_box_reg: 5.9175 (7.0423)  time: 1.5258 (1.5567)  data: 0.1002 (0.1301)  lr: 0.000000  max mem: 986
2020-12-13 05:06:18,367 maskrcnn_benchmark.trainer INFO: eta: 16:26:16  iter: 1980  loss: 6.5266 (8.1322)  loss_classifier: 0.0663 (0.2117)  loss_box_reg: 0.1129 (0.3670)  loss_objectness: 0.3839 (0.5224)  loss_rpn_box_reg: 5.8857 (7.0310)  time: 1.5274 (1.5564)  data: 0.1002 (0.1298)  lr: 0.000000  max mem: 986
2020-12-13 05:06:18,369 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:06:18,424 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:06:19,934 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.510013 (1.5100128650665283 s / img per device, on 1 devices)
2020-12-13 05:06:19,935 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.403656 (1.4036564826965332 s / img per device, on 1 devices)
2020-12-13 05:06:19,935 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:06:20,038 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:06:20,038 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1214, 0.0209, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1.,  2., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.9998, 0.0000, 0.0000, 0.4124, 1.0000]), 'num_pos': 9}
2020-12-13 05:06:20,042 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 05:06:50,556 maskrcnn_benchmark.trainer INFO: eta: 16:26:05  iter: 2000  loss: 6.5072 (8.1174)  loss_classifier: 0.0418 (0.2114)  loss_box_reg: 0.1909 (0.3654)  loss_objectness: 0.3565 (0.5210)  loss_rpn_box_reg: 5.8984 (7.0196)  time: 1.5240 (1.5570)  data: 0.0996 (0.1303)  lr: 0.000000  max mem: 986
2020-12-13 05:07:21,113 maskrcnn_benchmark.trainer INFO: eta: 16:25:23  iter: 2020  loss: 6.4610 (8.1014)  loss_classifier: 0.0385 (0.2101)  loss_box_reg: 0.1166 (0.3630)  loss_objectness: 0.3783 (0.5197)  loss_rpn_box_reg: 5.8925 (7.0086)  time: 1.5278 (1.5567)  data: 0.0999 (0.1300)  lr: 0.000000  max mem: 986
2020-12-13 05:07:51,681 maskrcnn_benchmark.trainer INFO: eta: 16:24:41  iter: 2040  loss: 6.5073 (8.0874)  loss_classifier: 0.0387 (0.2095)  loss_box_reg: 0.1178 (0.3613)  loss_objectness: 0.3843 (0.5187)  loss_rpn_box_reg: 5.9166 (6.9980)  time: 1.5291 (1.5564)  data: 0.0989 (0.1297)  lr: 0.000000  max mem: 986
2020-12-13 05:07:51,683 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:07:51,739 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:07:53,257 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.517890 (1.517890453338623 s / img per device, on 1 devices)
2020-12-13 05:07:53,257 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.411143 (1.4111428260803223 s / img per device, on 1 devices)
2020-12-13 05:07:53,257 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:07:53,360 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:07:53,360 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0411, 0.0032, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 1.0000, 0.1063, 0.8808, 0.9993, 0.2216, 0.9981, 0.1244]), 'num_pos': 9}
2020-12-13 05:07:53,364 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.777778
2020-12-13 05:08:23,912 maskrcnn_benchmark.trainer INFO: eta: 16:24:30  iter: 2060  loss: 6.4141 (8.0743)  loss_classifier: 0.0671 (0.2101)  loss_box_reg: 0.1152 (0.3600)  loss_objectness: 0.3596 (0.5172)  loss_rpn_box_reg: 5.8559 (6.9870)  time: 1.5255 (1.5569)  data: 0.1010 (0.1303)  lr: 0.000000  max mem: 986
2020-12-13 05:08:54,558 maskrcnn_benchmark.trainer INFO: eta: 16:23:50  iter: 2080  loss: 6.6371 (8.0634)  loss_classifier: 0.0654 (0.2121)  loss_box_reg: 0.1623 (0.3593)  loss_objectness: 0.3770 (0.5159)  loss_rpn_box_reg: 5.8340 (6.9761)  time: 1.5316 (1.5567)  data: 0.1097 (0.1301)  lr: 0.000000  max mem: 986
2020-12-13 05:09:25,078 maskrcnn_benchmark.trainer INFO: eta: 16:23:08  iter: 2100  loss: 6.4896 (8.0520)  loss_classifier: 0.0335 (0.2134)  loss_box_reg: 0.1498 (0.3581)  loss_objectness: 0.3596 (0.5145)  loss_rpn_box_reg: 5.9568 (6.9660)  time: 1.5272 (1.5564)  data: 0.1001 (0.1298)  lr: 0.000000  max mem: 986
2020-12-13 05:09:25,080 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:09:25,137 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:09:26,652 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.514547 (1.5145471096038818 s / img per device, on 1 devices)
2020-12-13 05:09:26,652 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.408434 (1.4084341526031494 s / img per device, on 1 devices)
2020-12-13 05:09:26,652 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:09:26,755 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:09:26,755 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0006, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1., -1., -1., -1.,  2.,  2.,  2.]), 'best match scores': tensor([0.7333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6026, 0.1269, 0.9992]), 'num_pos': 9}
2020-12-13 05:09:26,760 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.444444
2020-12-13 05:09:57,201 maskrcnn_benchmark.trainer INFO: eta: 16:22:54  iter: 2120  loss: 6.3873 (8.0371)  loss_classifier: 0.0264 (0.2128)  loss_box_reg: 0.0726 (0.3561)  loss_objectness: 0.3491 (0.5132)  loss_rpn_box_reg: 5.7731 (6.9550)  time: 1.5207 (1.5569)  data: 0.0956 (0.1303)  lr: 0.000000  max mem: 986
2020-12-13 05:10:27,620 maskrcnn_benchmark.trainer INFO: eta: 16:22:10  iter: 2140  loss: 6.3759 (8.0217)  loss_classifier: 0.0094 (0.2109)  loss_box_reg: 0.1061 (0.3538)  loss_objectness: 0.3936 (0.5122)  loss_rpn_box_reg: 5.8325 (6.9448)  time: 1.5203 (1.5565)  data: 0.0957 (0.1300)  lr: 0.000000  max mem: 986
2020-12-13 05:10:58,039 maskrcnn_benchmark.trainer INFO: eta: 16:21:27  iter: 2160  loss: 6.4779 (8.0070)  loss_classifier: 0.0459 (0.2102)  loss_box_reg: 0.1106 (0.3520)  loss_objectness: 0.3771 (0.5110)  loss_rpn_box_reg: 5.7510 (6.9339)  time: 1.5189 (1.5562)  data: 0.0958 (0.1296)  lr: 0.000000  max mem: 986
2020-12-13 05:10:58,042 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:10:58,093 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:10:59,600 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.507291 (1.5072910785675049 s / img per device, on 1 devices)
2020-12-13 05:10:59,601 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.403751 (1.4037508964538574 s / img per device, on 1 devices)
2020-12-13 05:10:59,601 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:10:59,694 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:10:59,695 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2., -1., -1., -1., -1.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.4701, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]), 'num_pos': 9}
2020-12-13 05:10:59,699 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 05:11:30,129 maskrcnn_benchmark.trainer INFO: eta: 16:21:13  iter: 2180  loss: 6.3342 (7.9936)  loss_classifier: 0.0240 (0.2102)  loss_box_reg: 0.1038 (0.3505)  loss_objectness: 0.3629 (0.5097)  loss_rpn_box_reg: 5.7437 (6.9232)  time: 1.5215 (1.5567)  data: 0.0960 (0.1301)  lr: 0.000000  max mem: 986
2020-12-13 05:12:00,532 maskrcnn_benchmark.trainer INFO: eta: 16:20:29  iter: 2200  loss: 6.4221 (7.9806)  loss_classifier: 0.0410 (0.2101)  loss_box_reg: 0.1156 (0.3489)  loss_objectness: 0.3856 (0.5087)  loss_rpn_box_reg: 5.7632 (6.9129)  time: 1.5198 (1.5563)  data: 0.0957 (0.1298)  lr: 0.000000  max mem: 986
2020-12-13 05:12:31,016 maskrcnn_benchmark.trainer INFO: eta: 16:19:47  iter: 2220  loss: 6.3521 (7.9677)  loss_classifier: 0.0459 (0.2103)  loss_box_reg: 0.0994 (0.3476)  loss_objectness: 0.3919 (0.5076)  loss_rpn_box_reg: 5.6568 (6.9021)  time: 1.5235 (1.5560)  data: 0.0959 (0.1295)  lr: 0.000000  max mem: 986
2020-12-13 05:12:31,018 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:12:31,068 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:12:32,574 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.505634 (1.50563383102417 s / img per device, on 1 devices)
2020-12-13 05:12:32,574 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.406862 (1.4068617820739746 s / img per device, on 1 devices)
2020-12-13 05:12:32,574 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:12:32,666 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:12:32,667 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0571, 0.0127, 0.0009, 0.0006, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 2.]), 'best match scores': tensor([0.9848, 0.9446, 1.0000, 0.9972, 0.9915, 0.4436, 0.2658, 0.9871, 1.0000]), 'num_pos': 9}
2020-12-13 05:12:32,672 maskrcnn_benchmark.trainer INFO: validation accuracy: 1.000000
2020-12-13 05:13:03,172 maskrcnn_benchmark.trainer INFO: eta: 16:19:33  iter: 2240  loss: 6.3700 (7.9547)  loss_classifier: 0.0660 (0.2094)  loss_box_reg: 0.0950 (0.3459)  loss_objectness: 0.3482 (0.5065)  loss_rpn_box_reg: 5.8375 (6.8929)  time: 1.5219 (1.5565)  data: 0.0949 (0.1299)  lr: 0.000000  max mem: 986
2020-12-13 05:13:33,603 maskrcnn_benchmark.trainer INFO: eta: 16:18:50  iter: 2260  loss: 6.3867 (7.9414)  loss_classifier: 0.0540 (0.2087)  loss_box_reg: 0.1671 (0.3444)  loss_objectness: 0.4050 (0.5055)  loss_rpn_box_reg: 5.7956 (6.8827)  time: 1.5200 (1.5562)  data: 0.0955 (0.1296)  lr: 0.000000  max mem: 986
2020-12-13 05:14:04,050 maskrcnn_benchmark.trainer INFO: eta: 16:18:08  iter: 2280  loss: 6.2799 (7.9294)  loss_classifier: 0.0208 (0.2086)  loss_box_reg: 0.0920 (0.3431)  loss_objectness: 0.4209 (0.5047)  loss_rpn_box_reg: 5.7326 (6.8730)  time: 1.5205 (1.5559)  data: 0.0947 (0.1293)  lr: 0.000000  max mem: 986
2020-12-13 05:14:04,052 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:14:04,101 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:14:05,604 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.503267 (1.5032672882080078 s / img per device, on 1 devices)
2020-12-13 05:14:05,604 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.401811 (1.4018113613128662 s / img per device, on 1 devices)
2020-12-13 05:14:05,604 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:14:05,698 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:14:05,698 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  2., -1., -1., -1.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.3862, 0.7591, 1.0000, 0.0752]), 'num_pos': 9}
2020-12-13 05:14:05,703 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 05:14:36,127 maskrcnn_benchmark.trainer INFO: eta: 16:17:53  iter: 2300  loss: 6.3081 (7.9158)  loss_classifier: 0.0554 (0.2076)  loss_box_reg: 0.1337 (0.3415)  loss_objectness: 0.3880 (0.5037)  loss_rpn_box_reg: 5.7355 (6.8630)  time: 1.5212 (1.5563)  data: 0.0947 (0.1298)  lr: 0.000000  max mem: 986
2020-12-13 05:15:06,566 maskrcnn_benchmark.trainer INFO: eta: 16:17:10  iter: 2320  loss: 6.3070 (7.9034)  loss_classifier: 0.0426 (0.2074)  loss_box_reg: 0.1267 (0.3402)  loss_objectness: 0.3652 (0.5026)  loss_rpn_box_reg: 5.7036 (6.8532)  time: 1.5211 (1.5560)  data: 0.0961 (0.1295)  lr: 0.000000  max mem: 986
2020-12-13 05:15:36,982 maskrcnn_benchmark.trainer INFO: eta: 16:16:28  iter: 2340  loss: 6.2076 (7.8897)  loss_classifier: 0.0170 (0.2062)  loss_box_reg: 0.1441 (0.3387)  loss_objectness: 0.3373 (0.5014)  loss_rpn_box_reg: 5.6698 (6.8435)  time: 1.5200 (1.5557)  data: 0.0946 (0.1292)  lr: 0.000000  max mem: 986
2020-12-13 05:15:36,984 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:15:37,034 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:15:38,541 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.506208 (1.5062079429626465 s / img per device, on 1 devices)
2020-12-13 05:15:38,541 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.402424 (1.4024238586425781 s / img per device, on 1 devices)
2020-12-13 05:15:38,541 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:15:38,636 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:15:38,637 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.4452e-01, 1.0698e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  2., -1.,  2., -1., -1.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.4249, 0.0000, 0.0743, 0.0000, 0.0000, 1.0000, 0.1586, 0.9997]), 'num_pos': 9}
2020-12-13 05:15:38,642 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 05:16:09,149 maskrcnn_benchmark.trainer INFO: eta: 16:16:13  iter: 2360  loss: 6.3316 (7.8779)  loss_classifier: 0.0653 (0.2059)  loss_box_reg: 0.1480 (0.3375)  loss_objectness: 0.3649 (0.5005)  loss_rpn_box_reg: 5.7170 (6.8340)  time: 1.5260 (1.5562)  data: 0.0961 (0.1296)  lr: 0.000000  max mem: 986
2020-12-13 05:16:39,628 maskrcnn_benchmark.trainer INFO: eta: 16:15:32  iter: 2380  loss: 6.2481 (7.8658)  loss_classifier: 0.0645 (0.2058)  loss_box_reg: 0.0864 (0.3362)  loss_objectness: 0.3553 (0.4994)  loss_rpn_box_reg: 5.6299 (6.8244)  time: 1.5227 (1.5559)  data: 0.0963 (0.1294)  lr: 0.000000  max mem: 986
2020-12-13 05:17:10,048 maskrcnn_benchmark.trainer INFO: eta: 16:14:50  iter: 2400  loss: 6.2452 (7.8528)  loss_classifier: 0.0570 (0.2050)  loss_box_reg: 0.1346 (0.3346)  loss_objectness: 0.3639 (0.4984)  loss_rpn_box_reg: 5.6530 (6.8148)  time: 1.5209 (1.5556)  data: 0.0964 (0.1291)  lr: 0.000000  max mem: 986
2020-12-13 05:17:10,050 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:17:10,099 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:17:11,609 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.509568 (1.5095677375793457 s / img per device, on 1 devices)
2020-12-13 05:17:11,609 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.401700 (1.401700496673584 s / img per device, on 1 devices)
2020-12-13 05:17:11,609 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:17:11,703 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:17:11,703 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0769, 0.0204, 0.0019, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2., -1.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.9985, 0.1631, 0.0657, 0.9952]), 'num_pos': 9}
2020-12-13 05:17:11,707 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 05:17:42,177 maskrcnn_benchmark.trainer INFO: eta: 16:14:35  iter: 2420  loss: 6.1766 (7.8387)  loss_classifier: 0.0450 (0.2037)  loss_box_reg: 0.0979 (0.3328)  loss_objectness: 0.3728 (0.4972)  loss_rpn_box_reg: 5.6764 (6.8050)  time: 1.5225 (1.5560)  data: 0.0940 (0.1295)  lr: 0.000000  max mem: 986
2020-12-13 05:18:12,655 maskrcnn_benchmark.trainer INFO: eta: 16:13:54  iter: 2440  loss: 6.1985 (7.8250)  loss_classifier: 0.0459 (0.2025)  loss_box_reg: 0.1490 (0.3313)  loss_objectness: 0.3737 (0.4961)  loss_rpn_box_reg: 5.5068 (6.7952)  time: 1.5225 (1.5558)  data: 0.0943 (0.1292)  lr: 0.000000  max mem: 986
2020-12-13 05:18:43,127 maskrcnn_benchmark.trainer INFO: eta: 16:13:13  iter: 2460  loss: 6.3195 (7.8135)  loss_classifier: 0.0623 (0.2024)  loss_box_reg: 0.1341 (0.3302)  loss_objectness: 0.3695 (0.4952)  loss_rpn_box_reg: 5.6877 (6.7858)  time: 1.5226 (1.5555)  data: 0.0941 (0.1290)  lr: 0.000000  max mem: 986
2020-12-13 05:18:43,129 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:18:43,178 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:18:44,678 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.499925 (1.499924898147583 s / img per device, on 1 devices)
2020-12-13 05:18:44,678 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.401542 (1.4015419483184814 s / img per device, on 1 devices)
2020-12-13 05:18:44,678 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:18:44,768 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:18:44,768 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4626, 0.8827, 0.6354]), 'num_pos': 9}
2020-12-13 05:18:44,774 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 05:19:15,254 maskrcnn_benchmark.trainer INFO: eta: 16:12:57  iter: 2480  loss: 6.2464 (7.8033)  loss_classifier: 0.0389 (0.2034)  loss_box_reg: 0.1360 (0.3294)  loss_objectness: 0.3779 (0.4943)  loss_rpn_box_reg: 5.5783 (6.7762)  time: 1.5238 (1.5559)  data: 0.0941 (0.1294)  lr: 0.000000  max mem: 986
2020-12-13 05:19:45,717 maskrcnn_benchmark.trainer INFO: eta: 16:12:16  iter: 2500  loss: 6.1851 (7.7916)  loss_classifier: 0.0315 (0.2030)  loss_box_reg: 0.0803 (0.3279)  loss_objectness: 0.3639 (0.4932)  loss_rpn_box_reg: 5.5466 (6.7675)  time: 1.5227 (1.5556)  data: 0.0942 (0.1291)  lr: 0.000000  max mem: 986
2020-12-13 05:19:45,719 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./model_0002500.pth
2020-12-13 05:20:20,650 maskrcnn_benchmark.trainer INFO: eta: 16:12:42  iter: 2520  loss: 6.0155 (7.7776)  loss_classifier: 0.0315 (0.2017)  loss_box_reg: 0.0750 (0.3260)  loss_objectness: 0.3741 (0.4924)  loss_rpn_box_reg: 5.5147 (6.7575)  time: 1.5208 (1.5572)  data: 0.0950 (0.1306)  lr: 0.000000  max mem: 986
2020-12-13 05:20:20,652 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:20:20,701 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:20:22,205 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.504050 (1.50404953956604 s / img per device, on 1 devices)
2020-12-13 05:20:22,205 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.403414 (1.4034144878387451 s / img per device, on 1 devices)
2020-12-13 05:20:22,205 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:20:22,298 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:20:22,298 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1., -1., -1.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]), 'num_pos': 9}
2020-12-13 05:20:22,303 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.111111
2020-12-13 05:20:52,740 maskrcnn_benchmark.trainer INFO: eta: 16:12:25  iter: 2540  loss: 6.1264 (7.7653)  loss_classifier: 0.0115 (0.2009)  loss_box_reg: 0.0789 (0.3244)  loss_objectness: 0.4032 (0.4917)  loss_rpn_box_reg: 5.6172 (6.7483)  time: 1.5198 (1.5575)  data: 0.0955 (0.1310)  lr: 0.000000  max mem: 986
2020-12-13 05:21:23,156 maskrcnn_benchmark.trainer INFO: eta: 16:11:43  iter: 2560  loss: 6.0858 (7.7521)  loss_classifier: 0.0434 (0.1998)  loss_box_reg: 0.1211 (0.3230)  loss_objectness: 0.3635 (0.4907)  loss_rpn_box_reg: 5.4410 (6.7386)  time: 1.5209 (1.5572)  data: 0.0960 (0.1307)  lr: 0.000000  max mem: 986
2020-12-13 05:21:53,612 maskrcnn_benchmark.trainer INFO: eta: 16:11:02  iter: 2580  loss: 6.2557 (7.7421)  loss_classifier: 0.0674 (0.2001)  loss_box_reg: 0.1461 (0.3220)  loss_objectness: 0.3629 (0.4898)  loss_rpn_box_reg: 5.6357 (6.7302)  time: 1.5204 (1.5570)  data: 0.0959 (0.1305)  lr: 0.000000  max mem: 986
2020-12-13 05:21:53,614 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:21:53,664 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:21:55,163 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.498742 (1.498741865158081 s / img per device, on 1 devices)
2020-12-13 05:21:55,163 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.397877 (1.397876501083374 s / img per device, on 1 devices)
2020-12-13 05:21:55,163 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:21:55,256 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:21:55,256 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0689, 0.0647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2.,  2., -1., -1., -1., -1.,  2.,  2.,  2.]), 'best match scores': tensor([0.9978, 0.8844, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9997, 0.9998]), 'num_pos': 9}
2020-12-13 05:21:55,261 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 05:22:25,690 maskrcnn_benchmark.trainer INFO: eta: 16:10:44  iter: 2600  loss: 6.0387 (7.7302)  loss_classifier: 0.0221 (0.1999)  loss_box_reg: 0.0726 (0.3207)  loss_objectness: 0.3404 (0.4887)  loss_rpn_box_reg: 5.5631 (6.7210)  time: 1.5218 (1.5573)  data: 0.0957 (0.1308)  lr: 0.000000  max mem: 986
2020-12-13 05:22:56,133 maskrcnn_benchmark.trainer INFO: eta: 16:10:03  iter: 2620  loss: 6.1320 (7.7196)  loss_classifier: 0.0324 (0.2002)  loss_box_reg: 0.0725 (0.3195)  loss_objectness: 0.3546 (0.4878)  loss_rpn_box_reg: 5.5626 (6.7121)  time: 1.5234 (1.5571)  data: 0.0957 (0.1306)  lr: 0.000000  max mem: 986
2020-12-13 05:23:26,789 maskrcnn_benchmark.trainer INFO: eta: 16:09:25  iter: 2640  loss: 6.0848 (7.7100)  loss_classifier: 0.0583 (0.2014)  loss_box_reg: 0.1133 (0.3188)  loss_objectness: 0.3413 (0.4868)  loss_rpn_box_reg: 5.5001 (6.7030)  time: 1.5303 (1.5569)  data: 0.0997 (0.1304)  lr: 0.000000  max mem: 986
2020-12-13 05:23:26,792 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:23:26,844 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:23:28,365 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.521044 (1.5210444927215576 s / img per device, on 1 devices)
2020-12-13 05:23:28,365 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.412778 (1.4127776622772217 s / img per device, on 1 devices)
2020-12-13 05:23:28,366 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:23:28,458 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:23:28,458 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0167, 0.0082, 0.0067, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2.,  2.,  2., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.7800, 0.8805, 0.9991, 0.0000, 1.0000, 0.9999]), 'num_pos': 9}
2020-12-13 05:23:28,464 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 05:23:59,708 maskrcnn_benchmark.trainer INFO: eta: 16:09:19  iter: 2660  loss: 6.2593 (7.7011)  loss_classifier: 0.0557 (0.2021)  loss_box_reg: 0.1720 (0.3182)  loss_objectness: 0.3406 (0.4857)  loss_rpn_box_reg: 5.6666 (6.6951)  time: 1.5397 (1.5576)  data: 0.1095 (0.1310)  lr: 0.000000  max mem: 986
2020-12-13 05:24:31,839 maskrcnn_benchmark.trainer INFO: eta: 16:09:01  iter: 2680  loss: 6.1939 (7.6922)  loss_classifier: 0.1370 (0.2036)  loss_box_reg: 0.1687 (0.3177)  loss_objectness: 0.3525 (0.4847)  loss_rpn_box_reg: 5.5228 (6.6862)  time: 1.6376 (1.5579)  data: 0.1909 (0.1313)  lr: 0.000000  max mem: 986
2020-12-13 05:25:02,487 maskrcnn_benchmark.trainer INFO: eta: 16:08:23  iter: 2700  loss: 5.9952 (7.6807)  loss_classifier: 0.0475 (0.2030)  loss_box_reg: 0.0707 (0.3163)  loss_objectness: 0.3598 (0.4838)  loss_rpn_box_reg: 5.4781 (6.6776)  time: 1.5321 (1.5577)  data: 0.1045 (0.1311)  lr: 0.000000  max mem: 986
2020-12-13 05:25:02,610 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:25:02,715 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:25:04,229 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.514657 (1.5146570205688477 s / img per device, on 1 devices)
2020-12-13 05:25:04,230 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.412340 (1.4123401641845703 s / img per device, on 1 devices)
2020-12-13 05:25:04,230 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:25:04,323 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:25:04,421 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9995, 0.9937]), 'num_pos': 9}
2020-12-13 05:25:04,424 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 05:25:34,992 maskrcnn_benchmark.trainer INFO: eta: 16:08:10  iter: 2720  loss: 6.0820 (7.6689)  loss_classifier: 0.0081 (0.2017)  loss_box_reg: 0.0679 (0.3148)  loss_objectness: 0.3638 (0.4830)  loss_rpn_box_reg: 5.4780 (6.6694)  time: 1.5278 (1.5582)  data: 0.1014 (0.1316)  lr: 0.000000  max mem: 986
2020-12-13 05:26:05,608 maskrcnn_benchmark.trainer INFO: eta: 16:07:32  iter: 2740  loss: 5.9781 (7.6569)  loss_classifier: 0.0350 (0.2006)  loss_box_reg: 0.0838 (0.3135)  loss_objectness: 0.3616 (0.4822)  loss_rpn_box_reg: 5.4671 (6.6606)  time: 1.5292 (1.5580)  data: 0.1056 (0.1314)  lr: 0.000000  max mem: 986
2020-12-13 05:26:36,147 maskrcnn_benchmark.trainer INFO: eta: 16:06:52  iter: 2760  loss: 6.0120 (7.6451)  loss_classifier: 0.0428 (0.1998)  loss_box_reg: 0.0639 (0.3118)  loss_objectness: 0.3603 (0.4813)  loss_rpn_box_reg: 5.5001 (6.6522)  time: 1.5278 (1.5578)  data: 0.1001 (0.1312)  lr: 0.000000  max mem: 986
2020-12-13 05:26:36,149 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:26:36,213 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:26:37,720 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.506365 (1.5063648223876953 s / img per device, on 1 devices)
2020-12-13 05:26:37,720 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.405731 (1.4057307243347168 s / img per device, on 1 devices)
2020-12-13 05:26:37,720 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:26:37,815 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:26:37,816 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0083, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1457, 0.8082, 0.9998]), 'num_pos': 9}
2020-12-13 05:26:37,821 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 05:27:08,317 maskrcnn_benchmark.trainer INFO: eta: 16:06:35  iter: 2780  loss: 6.0210 (7.6343)  loss_classifier: 0.0271 (0.1992)  loss_box_reg: 0.0695 (0.3108)  loss_objectness: 0.3866 (0.4806)  loss_rpn_box_reg: 5.5121 (6.6438)  time: 1.5228 (1.5582)  data: 0.0942 (0.1315)  lr: 0.000000  max mem: 986
2020-12-13 05:27:38,774 maskrcnn_benchmark.trainer INFO: eta: 16:05:54  iter: 2800  loss: 5.9078 (7.6219)  loss_classifier: 0.0212 (0.1981)  loss_box_reg: 0.1086 (0.3095)  loss_objectness: 0.3841 (0.4798)  loss_rpn_box_reg: 5.3292 (6.6345)  time: 1.5229 (1.5579)  data: 0.0938 (0.1313)  lr: 0.000000  max mem: 986
2020-12-13 05:28:09,251 maskrcnn_benchmark.trainer INFO: eta: 16:05:14  iter: 2820  loss: 6.1539 (7.6121)  loss_classifier: 0.0569 (0.1981)  loss_box_reg: 0.2121 (0.3091)  loss_objectness: 0.3716 (0.4790)  loss_rpn_box_reg: 5.4695 (6.6259)  time: 1.5239 (1.5577)  data: 0.0943 (0.1310)  lr: 0.000000  max mem: 986
2020-12-13 05:28:09,253 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:28:09,302 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:28:10,806 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.503314 (1.5033137798309326 s / img per device, on 1 devices)
2020-12-13 05:28:10,806 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.404047 (1.4040470123291016 s / img per device, on 1 devices)
2020-12-13 05:28:10,807 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:28:10,898 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:28:10,899 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0929, 0.0209, 0.0085, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9780]), 'num_pos': 9}
2020-12-13 05:28:10,904 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 05:28:41,390 maskrcnn_benchmark.trainer INFO: eta: 16:04:56  iter: 2840  loss: 6.0817 (7.6030)  loss_classifier: 0.0764 (0.1986)  loss_box_reg: 0.1611 (0.3083)  loss_objectness: 0.3760 (0.4782)  loss_rpn_box_reg: 5.4471 (6.6179)  time: 1.5241 (1.5580)  data: 0.0945 (0.1313)  lr: 0.000000  max mem: 986
2020-12-13 05:29:11,860 maskrcnn_benchmark.trainer INFO: eta: 16:04:16  iter: 2860  loss: 5.9668 (7.5918)  loss_classifier: 0.0254 (0.1974)  loss_box_reg: 0.0618 (0.3071)  loss_objectness: 0.3624 (0.4775)  loss_rpn_box_reg: 5.4705 (6.6098)  time: 1.5245 (1.5578)  data: 0.0955 (0.1311)  lr: 0.000000  max mem: 986
2020-12-13 05:29:42,293 maskrcnn_benchmark.trainer INFO: eta: 16:03:35  iter: 2880  loss: 6.1766 (7.5830)  loss_classifier: 0.0226 (0.1980)  loss_box_reg: 0.1391 (0.3064)  loss_objectness: 0.3511 (0.4767)  loss_rpn_box_reg: 5.5151 (6.6019)  time: 1.5202 (1.5575)  data: 0.0953 (0.1308)  lr: 0.000000  max mem: 986
2020-12-13 05:29:42,296 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:29:42,345 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:29:43,854 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.508492 (1.5084919929504395 s / img per device, on 1 devices)
2020-12-13 05:29:43,854 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.406575 (1.4065747261047363 s / img per device, on 1 devices)
2020-12-13 05:29:43,854 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:29:43,948 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:29:43,949 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0748, 0.0011, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1.,  2., -1.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.8442, 0.0000, 0.5560, 0.0527, 1.0000, 1.0000, 0.9998]), 'num_pos': 9}
2020-12-13 05:29:43,954 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 05:30:14,413 maskrcnn_benchmark.trainer INFO: eta: 16:03:16  iter: 2900  loss: 5.9607 (7.5713)  loss_classifier: 0.0474 (0.1969)  loss_box_reg: 0.0935 (0.3052)  loss_objectness: 0.3576 (0.4759)  loss_rpn_box_reg: 5.2969 (6.5933)  time: 1.5207 (1.5579)  data: 0.0962 (0.1312)  lr: 0.000000  max mem: 986
2020-12-13 05:30:44,897 maskrcnn_benchmark.trainer INFO: eta: 16:02:37  iter: 2920  loss: 5.9134 (7.5617)  loss_classifier: 0.0389 (0.1972)  loss_box_reg: 0.0587 (0.3041)  loss_objectness: 0.3661 (0.4752)  loss_rpn_box_reg: 5.3985 (6.5852)  time: 1.5224 (1.5576)  data: 0.0959 (0.1310)  lr: 0.000000  max mem: 986
2020-12-13 05:31:15,347 maskrcnn_benchmark.trainer INFO: eta: 16:01:57  iter: 2940  loss: 5.9670 (7.5508)  loss_classifier: 0.0279 (0.1963)  loss_box_reg: 0.0822 (0.3029)  loss_objectness: 0.3529 (0.4744)  loss_rpn_box_reg: 5.3779 (6.5772)  time: 1.5202 (1.5574)  data: 0.0969 (0.1307)  lr: 0.000000  max mem: 986
2020-12-13 05:31:15,349 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:31:15,398 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:31:16,913 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.514904 (1.5149037837982178 s / img per device, on 1 devices)
2020-12-13 05:31:16,914 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.411727 (1.411726713180542 s / img per device, on 1 devices)
2020-12-13 05:31:16,914 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:31:17,007 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:31:17,007 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1., -1., -1.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9892]), 'num_pos': 9}
2020-12-13 05:31:17,012 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.111111
2020-12-13 05:31:47,481 maskrcnn_benchmark.trainer INFO: eta: 16:01:38  iter: 2960  loss: 6.0297 (7.5408)  loss_classifier: 0.0542 (0.1958)  loss_box_reg: 0.1245 (0.3017)  loss_objectness: 0.3483 (0.4736)  loss_rpn_box_reg: 5.4634 (6.5697)  time: 1.5228 (1.5577)  data: 0.0968 (0.1311)  lr: 0.000000  max mem: 986
2020-12-13 05:32:17,942 maskrcnn_benchmark.trainer INFO: eta: 16:00:58  iter: 2980  loss: 5.8334 (7.5309)  loss_classifier: 0.0305 (0.1955)  loss_box_reg: 0.1060 (0.3007)  loss_objectness: 0.3466 (0.4727)  loss_rpn_box_reg: 5.3887 (6.5620)  time: 1.5247 (1.5575)  data: 0.0952 (0.1308)  lr: 0.000000  max mem: 986
2020-12-13 05:32:48,407 maskrcnn_benchmark.trainer INFO: eta: 16:00:18  iter: 3000  loss: 5.7757 (7.5200)  loss_classifier: 0.0431 (0.1949)  loss_box_reg: 0.0865 (0.2993)  loss_objectness: 0.3360 (0.4719)  loss_rpn_box_reg: 5.2798 (6.5539)  time: 1.5241 (1.5573)  data: 0.0946 (0.1306)  lr: 0.000000  max mem: 986
2020-12-13 05:32:48,409 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:32:48,456 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:32:49,967 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.511256 (1.511256217956543 s / img per device, on 1 devices)
2020-12-13 05:32:49,967 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.408646 (1.4086456298828125 s / img per device, on 1 devices)
2020-12-13 05:32:49,968 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:32:50,059 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:32:50,059 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0209, 0.0202, 0.0022, 0.0005, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  2., -1., -1.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.6018, 0.0000, 0.0000, 1.0000, 0.1561, 0.8527, 0.9667, 0.9525]), 'num_pos': 9}
2020-12-13 05:32:50,064 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 05:33:20,609 maskrcnn_benchmark.trainer INFO: eta: 16:00:00  iter: 3020  loss: 5.9630 (7.5101)  loss_classifier: 0.0502 (0.1944)  loss_box_reg: 0.1436 (0.2984)  loss_objectness: 0.3692 (0.4712)  loss_rpn_box_reg: 5.3409 (6.5461)  time: 1.5269 (1.5576)  data: 0.0955 (0.1309)  lr: 0.000000  max mem: 986
2020-12-13 05:33:51,099 maskrcnn_benchmark.trainer INFO: eta: 15:59:21  iter: 3040  loss: 5.8465 (7.5008)  loss_classifier: 0.0268 (0.1945)  loss_box_reg: 0.1357 (0.2977)  loss_objectness: 0.2929 (0.4701)  loss_rpn_box_reg: 5.3555 (6.5385)  time: 1.5251 (1.5574)  data: 0.0948 (0.1307)  lr: 0.000000  max mem: 986
2020-12-13 05:34:21,585 maskrcnn_benchmark.trainer INFO: eta: 15:58:42  iter: 3060  loss: 5.9082 (7.4907)  loss_classifier: 0.0611 (0.1941)  loss_box_reg: 0.1231 (0.2967)  loss_objectness: 0.3633 (0.4694)  loss_rpn_box_reg: 5.3170 (6.5305)  time: 1.5238 (1.5572)  data: 0.0949 (0.1305)  lr: 0.000000  max mem: 986
2020-12-13 05:34:21,587 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:34:21,637 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:34:23,151 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.514176 (1.5141756534576416 s / img per device, on 1 devices)
2020-12-13 05:34:23,151 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.412119 (1.412118911743164 s / img per device, on 1 devices)
2020-12-13 05:34:23,151 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:34:23,246 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:34:23,246 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.2640, 0.1071, 0.0272, 0.0011, 0.0007, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.1116, 0.0000, 0.9993, 0.8106, 0.9998, 0.1356, 0.5582, 0.3357, 0.8451]), 'num_pos': 9}
2020-12-13 05:34:23,251 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.888889
2020-12-13 05:34:53,757 maskrcnn_benchmark.trainer INFO: eta: 15:58:23  iter: 3080  loss: 5.9519 (7.4820)  loss_classifier: 0.0926 (0.1945)  loss_box_reg: 0.1651 (0.2962)  loss_objectness: 0.3551 (0.4687)  loss_rpn_box_reg: 5.3302 (6.5227)  time: 1.5244 (1.5575)  data: 0.0955 (0.1308)  lr: 0.000000  max mem: 986
2020-12-13 05:35:24,241 maskrcnn_benchmark.trainer INFO: eta: 15:57:44  iter: 3100  loss: 5.8828 (7.4720)  loss_classifier: 0.0627 (0.1938)  loss_box_reg: 0.1177 (0.2950)  loss_objectness: 0.3423 (0.4679)  loss_rpn_box_reg: 5.3759 (6.5152)  time: 1.5242 (1.5573)  data: 0.0957 (0.1306)  lr: 0.000000  max mem: 986
2020-12-13 05:35:54,749 maskrcnn_benchmark.trainer INFO: eta: 15:57:05  iter: 3120  loss: 5.9282 (7.4619)  loss_classifier: 0.0378 (0.1930)  loss_box_reg: 0.0782 (0.2939)  loss_objectness: 0.3627 (0.4672)  loss_rpn_box_reg: 5.3038 (6.5078)  time: 1.5250 (1.5571)  data: 0.0962 (0.1304)  lr: 0.000000  max mem: 986
2020-12-13 05:35:54,751 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:35:54,799 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:35:56,297 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.497988 (1.4979875087738037 s / img per device, on 1 devices)
2020-12-13 05:35:56,298 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.396643 (1.3966426849365234 s / img per device, on 1 devices)
2020-12-13 05:35:56,298 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:35:56,391 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:35:56,391 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0212, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1.,  2., -1.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9582, 0.0000, 0.3693]), 'num_pos': 9}
2020-12-13 05:35:56,396 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 05:36:26,881 maskrcnn_benchmark.trainer INFO: eta: 15:56:46  iter: 3140  loss: 5.8730 (7.4523)  loss_classifier: 0.0234 (0.1925)  loss_box_reg: 0.1443 (0.2931)  loss_objectness: 0.3321 (0.4665)  loss_rpn_box_reg: 5.3012 (6.5002)  time: 1.5224 (1.5574)  data: 0.0965 (0.1307)  lr: 0.000000  max mem: 986
2020-12-13 05:36:57,339 maskrcnn_benchmark.trainer INFO: eta: 15:56:07  iter: 3160  loss: 5.8506 (7.4431)  loss_classifier: 0.0161 (0.1921)  loss_box_reg: 0.0943 (0.2922)  loss_objectness: 0.3301 (0.4657)  loss_rpn_box_reg: 5.3663 (6.4931)  time: 1.5211 (1.5572)  data: 0.0961 (0.1305)  lr: 0.000000  max mem: 986
2020-12-13 05:37:27,797 maskrcnn_benchmark.trainer INFO: eta: 15:55:27  iter: 3180  loss: 5.8052 (7.4328)  loss_classifier: 0.0403 (0.1911)  loss_box_reg: 0.0468 (0.2908)  loss_objectness: 0.3644 (0.4651)  loss_rpn_box_reg: 5.3095 (6.4857)  time: 1.5203 (1.5570)  data: 0.0964 (0.1303)  lr: 0.000000  max mem: 986
2020-12-13 05:37:27,799 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:37:27,849 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:37:29,351 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.501148 (1.5011484622955322 s / img per device, on 1 devices)
2020-12-13 05:37:29,351 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.398870 (1.398869514465332 s / img per device, on 1 devices)
2020-12-13 05:37:29,351 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:37:29,446 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:37:29,446 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0593, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1.,  2.,  2., -1., -1.,  2.,  2.,  5.]), 'best match scores': tensor([0.0000, 0.0000, 0.9999, 0.5122, 0.0000, 0.0000, 0.9750, 0.9921, 0.9999]), 'num_pos': 9}
2020-12-13 05:37:29,451 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.444444
2020-12-13 05:37:59,879 maskrcnn_benchmark.trainer INFO: eta: 15:55:07  iter: 3200  loss: 5.8154 (7.4236)  loss_classifier: 0.0598 (0.1910)  loss_box_reg: 0.1381 (0.2899)  loss_objectness: 0.3688 (0.4646)  loss_rpn_box_reg: 5.2501 (6.4780)  time: 1.5198 (1.5573)  data: 0.0960 (0.1306)  lr: 0.000000  max mem: 986
2020-12-13 05:38:30,305 maskrcnn_benchmark.trainer INFO: eta: 15:54:28  iter: 3220  loss: 6.0455 (7.4156)  loss_classifier: 0.0832 (0.1916)  loss_box_reg: 0.2615 (0.2897)  loss_objectness: 0.3655 (0.4640)  loss_rpn_box_reg: 5.2363 (6.4704)  time: 1.5202 (1.5571)  data: 0.0954 (0.1304)  lr: 0.000000  max mem: 986
2020-12-13 05:39:00,780 maskrcnn_benchmark.trainer INFO: eta: 15:53:49  iter: 3240  loss: 5.9081 (7.4069)  loss_classifier: 0.0599 (0.1916)  loss_box_reg: 0.1272 (0.2889)  loss_objectness: 0.3454 (0.4633)  loss_rpn_box_reg: 5.2381 (6.4631)  time: 1.5223 (1.5568)  data: 0.0954 (0.1301)  lr: 0.000000  max mem: 986
2020-12-13 05:39:00,782 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:39:00,831 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:39:02,340 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.509174 (1.50917387008667 s / img per device, on 1 devices)
2020-12-13 05:39:02,341 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.410411 (1.4104113578796387 s / img per device, on 1 devices)
2020-12-13 05:39:02,341 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:39:02,434 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:39:02,434 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0153, 0.0027, 0.0009, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1.,  2., -1., -1.,  2., -1.,  2.]), 'best match scores': tensor([0.4155, 0.0000, 0.0000, 0.9976, 0.0000, 0.0000, 0.1655, 0.0000, 0.1472]), 'num_pos': 9}
2020-12-13 05:39:02,439 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.444444
2020-12-13 05:39:32,923 maskrcnn_benchmark.trainer INFO: eta: 15:53:29  iter: 3260  loss: 5.8186 (7.3981)  loss_classifier: 0.0156 (0.1911)  loss_box_reg: 0.0437 (0.2880)  loss_objectness: 0.3830 (0.4627)  loss_rpn_box_reg: 5.2985 (6.4564)  time: 1.5233 (1.5572)  data: 0.0950 (0.1304)  lr: 0.000000  max mem: 986
2020-12-13 05:40:03,408 maskrcnn_benchmark.trainer INFO: eta: 15:52:51  iter: 3280  loss: 5.8561 (7.3887)  loss_classifier: 0.0642 (0.1907)  loss_box_reg: 0.1430 (0.2872)  loss_objectness: 0.3501 (0.4621)  loss_rpn_box_reg: 5.1727 (6.4488)  time: 1.5255 (1.5570)  data: 0.0944 (0.1302)  lr: 0.000000  max mem: 986
2020-12-13 05:40:33,875 maskrcnn_benchmark.trainer INFO: eta: 15:52:12  iter: 3300  loss: 5.6583 (7.3785)  loss_classifier: 0.0414 (0.1898)  loss_box_reg: 0.0420 (0.2860)  loss_objectness: 0.3279 (0.4613)  loss_rpn_box_reg: 5.2022 (6.4414)  time: 1.5223 (1.5567)  data: 0.0941 (0.1300)  lr: 0.000000  max mem: 986
2020-12-13 05:40:33,877 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:40:33,925 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:40:35,439 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.513855 (1.513855218887329 s / img per device, on 1 devices)
2020-12-13 05:40:35,440 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.411365 (1.4113645553588867 s / img per device, on 1 devices)
2020-12-13 05:40:35,440 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:40:35,531 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:40:35,531 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.1001]), 'num_pos': 9}
2020-12-13 05:40:35,536 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 05:41:06,006 maskrcnn_benchmark.trainer INFO: eta: 15:51:52  iter: 3320  loss: 5.7942 (7.3701)  loss_classifier: 0.0196 (0.1899)  loss_box_reg: 0.1273 (0.2852)  loss_objectness: 0.3368 (0.4605)  loss_rpn_box_reg: 5.2920 (6.4344)  time: 1.5235 (1.5570)  data: 0.0944 (0.1303)  lr: 0.000000  max mem: 986
2020-12-13 05:41:36,492 maskrcnn_benchmark.trainer INFO: eta: 15:51:14  iter: 3340  loss: 5.6959 (7.3616)  loss_classifier: 0.0459 (0.1901)  loss_box_reg: 0.0818 (0.2845)  loss_objectness: 0.3352 (0.4598)  loss_rpn_box_reg: 5.2457 (6.4272)  time: 1.5239 (1.5569)  data: 0.0950 (0.1301)  lr: 0.000000  max mem: 986
2020-12-13 05:42:06,930 maskrcnn_benchmark.trainer INFO: eta: 15:50:35  iter: 3360  loss: 5.6660 (7.3519)  loss_classifier: 0.0143 (0.1892)  loss_box_reg: 0.0726 (0.2835)  loss_objectness: 0.3308 (0.4590)  loss_rpn_box_reg: 5.2975 (6.4202)  time: 1.5210 (1.5566)  data: 0.0956 (0.1299)  lr: 0.000000  max mem: 986
2020-12-13 05:42:06,932 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:42:06,981 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:42:08,485 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.503615 (1.5036146640777588 s / img per device, on 1 devices)
2020-12-13 05:42:08,485 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.402528 (1.4025282859802246 s / img per device, on 1 devices)
2020-12-13 05:42:08,485 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:42:08,578 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:42:08,578 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1.,  2., -1.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9984, 0.0000, 1.0000]), 'num_pos': 9}
2020-12-13 05:42:08,584 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 05:42:39,016 maskrcnn_benchmark.trainer INFO: eta: 15:50:14  iter: 3380  loss: 5.8093 (7.3439)  loss_classifier: 0.0555 (0.1895)  loss_box_reg: 0.1139 (0.2828)  loss_objectness: 0.3382 (0.4584)  loss_rpn_box_reg: 5.2197 (6.4132)  time: 1.5203 (1.5569)  data: 0.0955 (0.1302)  lr: 0.000000  max mem: 986
2020-12-13 05:43:09,422 maskrcnn_benchmark.trainer INFO: eta: 15:49:35  iter: 3400  loss: 5.8964 (7.3361)  loss_classifier: 0.0355 (0.1896)  loss_box_reg: 0.1044 (0.2822)  loss_objectness: 0.3372 (0.4578)  loss_rpn_box_reg: 5.3134 (6.4066)  time: 1.5183 (1.5567)  data: 0.0961 (0.1300)  lr: 0.000000  max mem: 986
2020-12-13 05:43:39,877 maskrcnn_benchmark.trainer INFO: eta: 15:48:57  iter: 3420  loss: 5.7283 (7.3270)  loss_classifier: 0.0253 (0.1889)  loss_box_reg: 0.0346 (0.2810)  loss_objectness: 0.3534 (0.4572)  loss_rpn_box_reg: 5.2181 (6.3999)  time: 1.5232 (1.5565)  data: 0.0943 (0.1298)  lr: 0.000000  max mem: 986
2020-12-13 05:43:39,879 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:43:39,928 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:43:41,433 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.505241 (1.5052409172058105 s / img per device, on 1 devices)
2020-12-13 05:43:41,433 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.402751 (1.4027514457702637 s / img per device, on 1 devices)
2020-12-13 05:43:41,433 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:43:41,524 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:43:41,524 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0397, 0.0209, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1.,  2., -1.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.8364, 0.0000, 0.4775, 0.0712, 1.0000]), 'num_pos': 9}
2020-12-13 05:43:41,530 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.444444
2020-12-13 05:44:12,011 maskrcnn_benchmark.trainer INFO: eta: 15:48:36  iter: 3440  loss: 5.7149 (7.3178)  loss_classifier: 0.0196 (0.1886)  loss_box_reg: 0.0342 (0.2800)  loss_objectness: 0.3483 (0.4565)  loss_rpn_box_reg: 5.1687 (6.3926)  time: 1.5240 (1.5568)  data: 0.0943 (0.1300)  lr: 0.000000  max mem: 986
2020-12-13 05:44:42,486 maskrcnn_benchmark.trainer INFO: eta: 15:47:58  iter: 3460  loss: 5.8454 (7.3098)  loss_classifier: 0.0852 (0.1888)  loss_box_reg: 0.1063 (0.2792)  loss_objectness: 0.3361 (0.4560)  loss_rpn_box_reg: 5.1711 (6.3858)  time: 1.5243 (1.5566)  data: 0.0945 (0.1298)  lr: 0.000000  max mem: 986
2020-12-13 05:45:12,943 maskrcnn_benchmark.trainer INFO: eta: 15:47:20  iter: 3480  loss: 5.7896 (7.3009)  loss_classifier: 0.0382 (0.1882)  loss_box_reg: 0.0335 (0.2780)  loss_objectness: 0.3866 (0.4556)  loss_rpn_box_reg: 5.2335 (6.3791)  time: 1.5239 (1.5564)  data: 0.0943 (0.1296)  lr: 0.000000  max mem: 986
2020-12-13 05:45:12,945 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:45:12,995 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:45:14,504 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.507905 (1.5079054832458496 s / img per device, on 1 devices)
2020-12-13 05:45:14,504 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.408128 (1.4081275463104248 s / img per device, on 1 devices)
2020-12-13 05:45:14,504 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:45:14,595 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:45:14,596 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0101, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1., -1., -1., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.9970, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3033, 0.9974]), 'num_pos': 9}
2020-12-13 05:45:14,601 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 05:45:45,086 maskrcnn_benchmark.trainer INFO: eta: 15:46:59  iter: 3500  loss: 5.6778 (7.2920)  loss_classifier: 0.0459 (0.1879)  loss_box_reg: 0.1028 (0.2771)  loss_objectness: 0.3740 (0.4552)  loss_rpn_box_reg: 5.1176 (6.3719)  time: 1.5230 (1.5567)  data: 0.0944 (0.1299)  lr: 0.000000  max mem: 986
2020-12-13 05:46:15,564 maskrcnn_benchmark.trainer INFO: eta: 15:46:21  iter: 3520  loss: 5.6260 (7.2831)  loss_classifier: 0.0429 (0.1875)  loss_box_reg: 0.0681 (0.2760)  loss_objectness: 0.3325 (0.4545)  loss_rpn_box_reg: 5.1833 (6.3652)  time: 1.5230 (1.5565)  data: 0.0945 (0.1297)  lr: 0.000000  max mem: 986
2020-12-13 05:46:46,034 maskrcnn_benchmark.trainer INFO: eta: 15:45:44  iter: 3540  loss: 5.7416 (7.2754)  loss_classifier: 0.0786 (0.1876)  loss_box_reg: 0.1738 (0.2755)  loss_objectness: 0.3243 (0.4539)  loss_rpn_box_reg: 5.1765 (6.3584)  time: 1.5234 (1.5563)  data: 0.0941 (0.1295)  lr: 0.000000  max mem: 986
2020-12-13 05:46:46,036 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:46:46,085 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:46:47,597 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.511925 (1.511925220489502 s / img per device, on 1 devices)
2020-12-13 05:46:47,597 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.411886 (1.4118857383728027 s / img per device, on 1 devices)
2020-12-13 05:46:47,598 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:46:47,690 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:46:47,690 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0187, 0.0010, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2.,  2., -1.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.1590, 0.0952, 0.0000, 0.9887, 1.0000, 1.0000]), 'num_pos': 9}
2020-12-13 05:46:47,695 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 05:47:18,165 maskrcnn_benchmark.trainer INFO: eta: 15:45:23  iter: 3560  loss: 5.7447 (7.2673)  loss_classifier: 0.0658 (0.1875)  loss_box_reg: 0.1013 (0.2747)  loss_objectness: 0.3309 (0.4532)  loss_rpn_box_reg: 5.1403 (6.3518)  time: 1.5232 (1.5566)  data: 0.0943 (0.1298)  lr: 0.000000  max mem: 986
2020-12-13 05:47:48,632 maskrcnn_benchmark.trainer INFO: eta: 15:44:45  iter: 3580  loss: 5.4828 (7.2577)  loss_classifier: 0.0270 (0.1868)  loss_box_reg: 0.0291 (0.2735)  loss_objectness: 0.3179 (0.4526)  loss_rpn_box_reg: 5.0441 (6.3449)  time: 1.5231 (1.5564)  data: 0.0943 (0.1296)  lr: 0.000000  max mem: 986
2020-12-13 05:48:19,112 maskrcnn_benchmark.trainer INFO: eta: 15:44:07  iter: 3600  loss: 5.6670 (7.2506)  loss_classifier: 0.0230 (0.1873)  loss_box_reg: 0.0603 (0.2732)  loss_objectness: 0.3626 (0.4521)  loss_rpn_box_reg: 5.0488 (6.3380)  time: 1.5224 (1.5563)  data: 0.0950 (0.1294)  lr: 0.000000  max mem: 986
2020-12-13 05:48:19,114 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:48:19,165 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:48:20,670 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.504975 (1.5049753189086914 s / img per device, on 1 devices)
2020-12-13 05:48:20,670 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.404167 (1.4041671752929688 s / img per device, on 1 devices)
2020-12-13 05:48:20,670 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:48:20,763 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:48:20,764 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0859, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1.,  2.,  2.,  2.,  4.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9998, 1.0000, 0.9990, 0.9988]), 'num_pos': 9}
2020-12-13 05:48:20,769 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 05:48:51,239 maskrcnn_benchmark.trainer INFO: eta: 15:43:46  iter: 3620  loss: 5.6528 (7.2424)  loss_classifier: 0.0373 (0.1868)  loss_box_reg: 0.1019 (0.2724)  loss_objectness: 0.3627 (0.4516)  loss_rpn_box_reg: 5.1229 (6.3316)  time: 1.5227 (1.5565)  data: 0.0939 (0.1297)  lr: 0.000000  max mem: 986
2020-12-13 05:49:21,723 maskrcnn_benchmark.trainer INFO: eta: 15:43:08  iter: 3640  loss: 5.5830 (7.2339)  loss_classifier: 0.0596 (0.1863)  loss_box_reg: 0.1248 (0.2716)  loss_objectness: 0.3205 (0.4510)  loss_rpn_box_reg: 5.0964 (6.3250)  time: 1.5223 (1.5564)  data: 0.0949 (0.1295)  lr: 0.000000  max mem: 986
2020-12-13 05:49:52,223 maskrcnn_benchmark.trainer INFO: eta: 15:42:31  iter: 3660  loss: 5.6014 (7.2255)  loss_classifier: 0.0434 (0.1859)  loss_box_reg: 0.0777 (0.2707)  loss_objectness: 0.3462 (0.4505)  loss_rpn_box_reg: 5.1091 (6.3184)  time: 1.5239 (1.5562)  data: 0.0951 (0.1293)  lr: 0.000000  max mem: 986
2020-12-13 05:49:52,225 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:49:52,275 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:49:53,783 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.507323 (1.5073225498199463 s / img per device, on 1 devices)
2020-12-13 05:49:53,783 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.405202 (1.4052016735076904 s / img per device, on 1 devices)
2020-12-13 05:49:53,783 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:49:53,874 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:49:53,875 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1478, 0.0860, 0.0630, 0.0030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1.,  2., -1., -1.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.6273, 0.0000, 0.0000, 0.3014, 0.9993, 1.0000, 0.9427]), 'num_pos': 9}
2020-12-13 05:49:53,880 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 05:50:24,356 maskrcnn_benchmark.trainer INFO: eta: 15:42:10  iter: 3680  loss: 5.8564 (7.2185)  loss_classifier: 0.1445 (0.1864)  loss_box_reg: 0.1716 (0.2702)  loss_objectness: 0.3513 (0.4501)  loss_rpn_box_reg: 5.1566 (6.3118)  time: 1.5240 (1.5565)  data: 0.0943 (0.1296)  lr: 0.000000  max mem: 986
2020-12-13 05:50:54,818 maskrcnn_benchmark.trainer INFO: eta: 15:41:32  iter: 3700  loss: 5.7713 (7.2111)  loss_classifier: 0.0484 (0.1869)  loss_box_reg: 0.1407 (0.2697)  loss_objectness: 0.3199 (0.4494)  loss_rpn_box_reg: 5.0700 (6.3050)  time: 1.5226 (1.5563)  data: 0.0944 (0.1294)  lr: 0.000000  max mem: 986
2020-12-13 05:51:25,324 maskrcnn_benchmark.trainer INFO: eta: 15:40:55  iter: 3720  loss: 5.6979 (7.2032)  loss_classifier: 0.0840 (0.1870)  loss_box_reg: 0.1150 (0.2691)  loss_objectness: 0.3275 (0.4488)  loss_rpn_box_reg: 5.0504 (6.2983)  time: 1.5257 (1.5561)  data: 0.0952 (0.1292)  lr: 0.000000  max mem: 986
2020-12-13 05:51:25,327 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:51:25,377 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:51:26,887 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.510184 (1.5101840496063232 s / img per device, on 1 devices)
2020-12-13 05:51:26,887 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.408490 (1.4084904193878174 s / img per device, on 1 devices)
2020-12-13 05:51:26,888 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:51:26,985 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:51:26,985 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0897, 0.0687, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1.,  2.,  2.,  6.,  6.,  6.,  6.]), 'best match scores': tensor([0.6372, 0.0000, 0.0000, 1.0000, 0.0810, 0.0718, 0.0718, 0.0718, 0.0718]), 'num_pos': 9}
2020-12-13 05:51:26,989 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 05:51:57,487 maskrcnn_benchmark.trainer INFO: eta: 15:40:34  iter: 3740  loss: 5.7126 (7.1953)  loss_classifier: 0.0706 (0.1868)  loss_box_reg: 0.1108 (0.2684)  loss_objectness: 0.3701 (0.4485)  loss_rpn_box_reg: 5.0487 (6.2917)  time: 1.5250 (1.5564)  data: 0.0950 (0.1295)  lr: 0.000000  max mem: 986
2020-12-13 05:52:27,966 maskrcnn_benchmark.trainer INFO: eta: 15:39:57  iter: 3760  loss: 5.4204 (7.1873)  loss_classifier: 0.0563 (0.1866)  loss_box_reg: 0.1084 (0.2678)  loss_objectness: 0.3293 (0.4478)  loss_rpn_box_reg: 4.9537 (6.2851)  time: 1.5243 (1.5562)  data: 0.0945 (0.1293)  lr: 0.000000  max mem: 986
2020-12-13 05:52:58,464 maskrcnn_benchmark.trainer INFO: eta: 15:39:20  iter: 3780  loss: 5.5242 (7.1788)  loss_classifier: 0.0346 (0.1860)  loss_box_reg: 0.1034 (0.2669)  loss_objectness: 0.3424 (0.4474)  loss_rpn_box_reg: 5.0465 (6.2786)  time: 1.5248 (1.5560)  data: 0.0950 (0.1291)  lr: 0.000000  max mem: 986
2020-12-13 05:52:58,466 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:52:58,516 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:53:00,026 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.509911 (1.5099108219146729 s / img per device, on 1 devices)
2020-12-13 05:53:00,027 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.406974 (1.4069736003875732 s / img per device, on 1 devices)
2020-12-13 05:53:00,027 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:53:00,121 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:53:00,121 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0556, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  2., -1., -1.,  2.,  6.,  6.,  6.,  6.]), 'best match scores': tensor([0.0000, 0.1356, 0.0000, 0.0000, 0.9996, 0.0762, 0.0762, 0.0762, 0.0762]), 'num_pos': 9}
2020-12-13 05:53:00,125 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 05:53:30,631 maskrcnn_benchmark.trainer INFO: eta: 15:38:58  iter: 3800  loss: 5.5894 (7.1712)  loss_classifier: 0.0673 (0.1859)  loss_box_reg: 0.1060 (0.2663)  loss_objectness: 0.3500 (0.4469)  loss_rpn_box_reg: 5.0221 (6.2721)  time: 1.5246 (1.5563)  data: 0.0951 (0.1294)  lr: 0.000000  max mem: 986
2020-12-13 05:54:01,124 maskrcnn_benchmark.trainer INFO: eta: 15:38:21  iter: 3820  loss: 5.8727 (7.1649)  loss_classifier: 0.1690 (0.1866)  loss_box_reg: 0.1435 (0.2658)  loss_objectness: 0.3680 (0.4465)  loss_rpn_box_reg: 5.1120 (6.2661)  time: 1.5243 (1.5562)  data: 0.0945 (0.1292)  lr: 0.000000  max mem: 986
2020-12-13 05:54:31,634 maskrcnn_benchmark.trainer INFO: eta: 15:37:44  iter: 3840  loss: 5.5186 (7.1566)  loss_classifier: 0.0540 (0.1861)  loss_box_reg: 0.0977 (0.2649)  loss_objectness: 0.3489 (0.4460)  loss_rpn_box_reg: 5.0212 (6.2596)  time: 1.5232 (1.5560)  data: 0.0959 (0.1290)  lr: 0.000000  max mem: 986
2020-12-13 05:54:31,636 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:54:31,686 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:54:33,189 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.502890 (1.502889633178711 s / img per device, on 1 devices)
2020-12-13 05:54:33,190 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.401185 (1.4011847972869873 s / img per device, on 1 devices)
2020-12-13 05:54:33,190 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:54:33,285 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:54:33,285 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1155, 0.0394, 0.0209, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 6., 6., 6., 6., 2., 2.]), 'best match scores': tensor([0.1465, 0.7572, 0.1316, 0.1167, 0.1167, 0.1167, 0.1167, 0.6981, 0.9624]), 'num_pos': 9}
2020-12-13 05:54:33,289 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 05:55:03,796 maskrcnn_benchmark.trainer INFO: eta: 15:37:23  iter: 3860  loss: 5.5838 (7.1490)  loss_classifier: 0.0456 (0.1858)  loss_box_reg: 0.0549 (0.2642)  loss_objectness: 0.3446 (0.4454)  loss_rpn_box_reg: 5.0436 (6.2536)  time: 1.5245 (1.5563)  data: 0.0960 (0.1293)  lr: 0.000000  max mem: 986
2020-12-13 05:55:34,274 maskrcnn_benchmark.trainer INFO: eta: 15:36:46  iter: 3880  loss: 5.6536 (7.1414)  loss_classifier: 0.0468 (0.1855)  loss_box_reg: 0.1065 (0.2633)  loss_objectness: 0.3168 (0.4448)  loss_rpn_box_reg: 5.1216 (6.2478)  time: 1.5226 (1.5561)  data: 0.0950 (0.1291)  lr: 0.000000  max mem: 986
2020-12-13 05:56:04,756 maskrcnn_benchmark.trainer INFO: eta: 15:36:09  iter: 3900  loss: 5.5474 (7.1334)  loss_classifier: 0.0383 (0.1852)  loss_box_reg: 0.1230 (0.2625)  loss_objectness: 0.3145 (0.4442)  loss_rpn_box_reg: 5.0208 (6.2414)  time: 1.5228 (1.5559)  data: 0.0944 (0.1289)  lr: 0.000000  max mem: 986
2020-12-13 05:56:04,759 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:56:04,810 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:56:06,325 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.515443 (1.5154428482055664 s / img per device, on 1 devices)
2020-12-13 05:56:06,325 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.412163 (1.4121630191802979 s / img per device, on 1 devices)
2020-12-13 05:56:06,326 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:56:06,422 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:56:06,422 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1505, 0.0287, 0.0129, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 6., 6., 2., 6., 2., 2., 6.]), 'best match scores': tensor([0.9796, 0.9957, 0.0559, 0.0559, 0.9957, 0.0559, 0.9956, 1.0000, 0.0559]), 'num_pos': 9}
2020-12-13 05:56:06,426 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 05:56:36,941 maskrcnn_benchmark.trainer INFO: eta: 15:35:48  iter: 3920  loss: 5.5210 (7.1253)  loss_classifier: 0.0552 (0.1848)  loss_box_reg: 0.0765 (0.2617)  loss_objectness: 0.3711 (0.4438)  loss_rpn_box_reg: 5.0028 (6.2349)  time: 1.5257 (1.5562)  data: 0.0957 (0.1292)  lr: 0.000000  max mem: 986
2020-12-13 05:57:07,474 maskrcnn_benchmark.trainer INFO: eta: 15:35:11  iter: 3940  loss: 5.4383 (7.1169)  loss_classifier: 0.0195 (0.1843)  loss_box_reg: 0.0178 (0.2607)  loss_objectness: 0.3193 (0.4432)  loss_rpn_box_reg: 5.0014 (6.2287)  time: 1.5265 (1.5561)  data: 0.0959 (0.1290)  lr: 0.000000  max mem: 986
2020-12-13 05:57:37,975 maskrcnn_benchmark.trainer INFO: eta: 15:34:34  iter: 3960  loss: 5.6356 (7.1100)  loss_classifier: 0.0928 (0.1843)  loss_box_reg: 0.2026 (0.2605)  loss_objectness: 0.3272 (0.4427)  loss_rpn_box_reg: 4.9333 (6.2225)  time: 1.5247 (1.5559)  data: 0.0950 (0.1289)  lr: 0.000000  max mem: 986
2020-12-13 05:57:37,977 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:57:38,030 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:57:39,546 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.515468 (1.515467882156372 s / img per device, on 1 devices)
2020-12-13 05:57:39,546 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.411862 (1.4118618965148926 s / img per device, on 1 devices)
2020-12-13 05:57:39,546 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:57:39,640 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:57:39,640 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1330, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  2., -1., -1.,  2.,  6.,  6.,  6.,  6.]), 'best match scores': tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.9999, 0.0652, 0.0652, 0.0652, 0.0652]), 'num_pos': 9}
2020-12-13 05:57:39,644 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 05:58:10,143 maskrcnn_benchmark.trainer INFO: eta: 15:34:13  iter: 3980  loss: 5.5411 (7.1024)  loss_classifier: 0.0716 (0.1840)  loss_box_reg: 0.1509 (0.2601)  loss_objectness: 0.3336 (0.4422)  loss_rpn_box_reg: 4.9332 (6.2161)  time: 1.5259 (1.5562)  data: 0.0948 (0.1291)  lr: 0.000000  max mem: 986
2020-12-13 05:58:40,645 maskrcnn_benchmark.trainer INFO: eta: 15:33:36  iter: 4000  loss: 5.5873 (7.0949)  loss_classifier: 0.0416 (0.1837)  loss_box_reg: 0.1034 (0.2596)  loss_objectness: 0.3463 (0.4417)  loss_rpn_box_reg: 4.9763 (6.2098)  time: 1.5251 (1.5560)  data: 0.0951 (0.1289)  lr: 0.000000  max mem: 986
2020-12-13 05:59:11,118 maskrcnn_benchmark.trainer INFO: eta: 15:32:59  iter: 4020  loss: 5.6116 (7.0875)  loss_classifier: 0.1147 (0.1835)  loss_box_reg: 0.1847 (0.2591)  loss_objectness: 0.3168 (0.4412)  loss_rpn_box_reg: 4.8818 (6.2037)  time: 1.5247 (1.5558)  data: 0.0946 (0.1288)  lr: 0.000000  max mem: 986
2020-12-13 05:59:11,119 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 05:59:11,171 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 05:59:12,678 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.507210 (1.5072100162506104 s / img per device, on 1 devices)
2020-12-13 05:59:12,678 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.405320 (1.405320405960083 s / img per device, on 1 devices)
2020-12-13 05:59:12,678 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 05:59:12,772 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 05:59:12,773 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1046, 0.0283, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([4., 5., 2., 6., 6., 6., 6., 6., 2.]), 'best match scores': tensor([1.0000, 0.9981, 1.0000, 0.0662, 0.0662, 0.0662, 0.0662, 0.9381, 0.9724]), 'num_pos': 9}
2020-12-13 05:59:12,777 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 05:59:43,264 maskrcnn_benchmark.trainer INFO: eta: 15:32:37  iter: 4040  loss: 5.6331 (7.0805)  loss_classifier: 0.0885 (0.1835)  loss_box_reg: 0.2198 (0.2590)  loss_objectness: 0.3167 (0.4406)  loss_rpn_box_reg: 4.9161 (6.1975)  time: 1.5231 (1.5561)  data: 0.0947 (0.1290)  lr: 0.000000  max mem: 986
2020-12-13 06:00:13,741 maskrcnn_benchmark.trainer INFO: eta: 15:32:00  iter: 4060  loss: 5.6501 (7.0743)  loss_classifier: 0.2834 (0.1842)  loss_box_reg: 0.2102 (0.2589)  loss_objectness: 0.3106 (0.4401)  loss_rpn_box_reg: 4.9593 (6.1912)  time: 1.5228 (1.5559)  data: 0.0959 (0.1289)  lr: 0.000000  max mem: 986
2020-12-13 06:00:44,260 maskrcnn_benchmark.trainer INFO: eta: 15:31:24  iter: 4080  loss: 5.5049 (7.0665)  loss_classifier: 0.0576 (0.1837)  loss_box_reg: 0.1047 (0.2582)  loss_objectness: 0.3615 (0.4397)  loss_rpn_box_reg: 4.9006 (6.1849)  time: 1.5240 (1.5558)  data: 0.0952 (0.1287)  lr: 0.000000  max mem: 986
2020-12-13 06:00:44,262 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:00:44,314 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:00:45,822 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.507381 (1.507380723953247 s / img per device, on 1 devices)
2020-12-13 06:00:45,822 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.405746 (1.4057462215423584 s / img per device, on 1 devices)
2020-12-13 06:00:45,822 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:00:45,915 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:00:45,915 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1162, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1., -1., -1.,  2.,  2.,  4.,  6.]), 'best match scores': tensor([0.7091, 0.0000, 0.0000, 0.0000, 0.0000, 0.9894, 0.9964, 0.6557, 0.1143]), 'num_pos': 9}
2020-12-13 06:00:45,920 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 06:01:16,414 maskrcnn_benchmark.trainer INFO: eta: 15:31:02  iter: 4100  loss: 5.6053 (7.0594)  loss_classifier: 0.0860 (0.1838)  loss_box_reg: 0.1809 (0.2579)  loss_objectness: 0.3039 (0.4390)  loss_rpn_box_reg: 4.8965 (6.1787)  time: 1.5259 (1.5561)  data: 0.0950 (0.1289)  lr: 0.000000  max mem: 986
2020-12-13 06:01:46,890 maskrcnn_benchmark.trainer INFO: eta: 15:30:25  iter: 4120  loss: 5.5682 (7.0523)  loss_classifier: 0.0595 (0.1835)  loss_box_reg: 0.1499 (0.2576)  loss_objectness: 0.2972 (0.4385)  loss_rpn_box_reg: 4.9029 (6.1728)  time: 1.5236 (1.5559)  data: 0.0949 (0.1288)  lr: 0.000000  max mem: 986
2020-12-13 06:02:17,355 maskrcnn_benchmark.trainer INFO: eta: 15:29:48  iter: 4140  loss: 5.4419 (7.0446)  loss_classifier: 0.0395 (0.1830)  loss_box_reg: 0.1072 (0.2568)  loss_objectness: 0.3454 (0.4379)  loss_rpn_box_reg: 4.9461 (6.1669)  time: 1.5227 (1.5557)  data: 0.0954 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:02:17,357 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:02:17,408 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:02:18,922 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.513722 (1.5137224197387695 s / img per device, on 1 devices)
2020-12-13 06:02:18,922 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.410872 (1.410872220993042 s / img per device, on 1 devices)
2020-12-13 06:02:18,922 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:02:19,016 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:02:19,017 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1203, 0.0004, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1.,  2., -1., -1.,  2.,  2.,  6.]), 'best match scores': tensor([0.9998, 0.0000, 0.0000, 0.0583, 0.0000, 0.0000, 0.9402, 0.4025, 0.0861]), 'num_pos': 9}
2020-12-13 06:02:19,021 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.444444
2020-12-13 06:02:49,528 maskrcnn_benchmark.trainer INFO: eta: 15:29:26  iter: 4160  loss: 5.7657 (7.0384)  loss_classifier: 0.2650 (0.1834)  loss_box_reg: 0.2468 (0.2567)  loss_objectness: 0.3333 (0.4375)  loss_rpn_box_reg: 4.8712 (6.1609)  time: 1.5273 (1.5560)  data: 0.0959 (0.1289)  lr: 0.000000  max mem: 986
2020-12-13 06:03:20,010 maskrcnn_benchmark.trainer INFO: eta: 15:28:50  iter: 4180  loss: 5.5686 (7.0314)  loss_classifier: 0.0931 (0.1832)  loss_box_reg: 0.1813 (0.2563)  loss_objectness: 0.3106 (0.4369)  loss_rpn_box_reg: 4.9033 (6.1550)  time: 1.5260 (1.5558)  data: 0.0974 (0.1287)  lr: 0.000000  max mem: 986
2020-12-13 06:03:50,516 maskrcnn_benchmark.trainer INFO: eta: 15:28:13  iter: 4200  loss: 5.5472 (7.0244)  loss_classifier: 0.1416 (0.1831)  loss_box_reg: 0.1695 (0.2560)  loss_objectness: 0.3167 (0.4365)  loss_rpn_box_reg: 4.8503 (6.1489)  time: 1.5256 (1.5557)  data: 0.0956 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:03:50,518 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:03:50,572 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:03:52,078 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.505980 (1.5059804916381836 s / img per device, on 1 devices)
2020-12-13 06:03:52,078 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.402802 (1.402801513671875 s / img per device, on 1 devices)
2020-12-13 06:03:52,079 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:03:52,181 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:03:52,181 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1.,  2.,  2.,  6.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9892, 0.6116, 0.1114]), 'num_pos': 9}
2020-12-13 06:03:52,185 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 06:04:22,689 maskrcnn_benchmark.trainer INFO: eta: 15:27:51  iter: 4220  loss: 5.5371 (7.0177)  loss_classifier: 0.1108 (0.1829)  loss_box_reg: 0.2151 (0.2557)  loss_objectness: 0.3011 (0.4359)  loss_rpn_box_reg: 4.9375 (6.1432)  time: 1.5263 (1.5559)  data: 0.0953 (0.1288)  lr: 0.000000  max mem: 986
2020-12-13 06:04:53,168 maskrcnn_benchmark.trainer INFO: eta: 15:27:15  iter: 4240  loss: 5.4209 (7.0102)  loss_classifier: 0.0611 (0.1824)  loss_box_reg: 0.1158 (0.2551)  loss_objectness: 0.3247 (0.4354)  loss_rpn_box_reg: 4.9037 (6.1372)  time: 1.5219 (1.5558)  data: 0.0960 (0.1287)  lr: 0.000000  max mem: 986
2020-12-13 06:05:23,668 maskrcnn_benchmark.trainer INFO: eta: 15:26:38  iter: 4260  loss: 5.3566 (7.0026)  loss_classifier: 0.0619 (0.1821)  loss_box_reg: 0.1468 (0.2547)  loss_objectness: 0.3036 (0.4349)  loss_rpn_box_reg: 4.8638 (6.1310)  time: 1.5237 (1.5556)  data: 0.0958 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:05:23,670 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:05:23,722 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:05:25,236 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.514124 (1.5141241550445557 s / img per device, on 1 devices)
2020-12-13 06:05:25,236 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.411085 (1.4110848903656006 s / img per device, on 1 devices)
2020-12-13 06:05:25,237 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:05:25,331 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:05:25,331 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1579, 0.0768, 0.0209, 0.0081, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 4., 2., 6., 2.]), 'best match scores': tensor([0.9908, 0.9976, 0.0571, 0.2890, 0.9870, 0.9004, 0.8410, 0.0514, 0.9927]), 'num_pos': 9}
2020-12-13 06:05:25,336 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.777778
2020-12-13 06:05:55,859 maskrcnn_benchmark.trainer INFO: eta: 15:26:16  iter: 4280  loss: 5.4130 (6.9954)  loss_classifier: 0.0500 (0.1818)  loss_box_reg: 0.0975 (0.2540)  loss_objectness: 0.3285 (0.4344)  loss_rpn_box_reg: 4.9016 (6.1252)  time: 1.5256 (1.5559)  data: 0.0969 (0.1288)  lr: 0.000000  max mem: 986
2020-12-13 06:06:26,401 maskrcnn_benchmark.trainer INFO: eta: 15:25:40  iter: 4300  loss: 5.4013 (6.9881)  loss_classifier: 0.0838 (0.1814)  loss_box_reg: 0.1539 (0.2536)  loss_objectness: 0.3173 (0.4339)  loss_rpn_box_reg: 4.7878 (6.1193)  time: 1.5249 (1.5558)  data: 0.0975 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:06:56,960 maskrcnn_benchmark.trainer INFO: eta: 15:25:05  iter: 4320  loss: 5.4230 (6.9809)  loss_classifier: 0.0960 (0.1812)  loss_box_reg: 0.0839 (0.2529)  loss_objectness: 0.3380 (0.4334)  loss_rpn_box_reg: 4.8965 (6.1134)  time: 1.5275 (1.5556)  data: 0.1046 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:06:56,963 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:06:57,021 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:06:58,532 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.510375 (1.5103750228881836 s / img per device, on 1 devices)
2020-12-13 06:06:58,532 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.398041 (1.398041009902954 s / img per device, on 1 devices)
2020-12-13 06:06:58,532 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:06:58,635 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:06:58,636 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1.,  2.,  2.,  6.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000]), 'num_pos': 9}
2020-12-13 06:06:58,639 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 06:07:29,253 maskrcnn_benchmark.trainer INFO: eta: 15:24:43  iter: 4340  loss: 5.6235 (6.9745)  loss_classifier: 0.1672 (0.1813)  loss_box_reg: 0.2310 (0.2528)  loss_objectness: 0.3005 (0.4328)  loss_rpn_box_reg: 4.8513 (6.1076)  time: 1.5309 (1.5559)  data: 0.1062 (0.1288)  lr: 0.000000  max mem: 986
2020-12-13 06:07:59,840 maskrcnn_benchmark.trainer INFO: eta: 15:24:08  iter: 4360  loss: 5.3073 (6.9672)  loss_classifier: 0.0809 (0.1810)  loss_box_reg: 0.0953 (0.2523)  loss_objectness: 0.3346 (0.4324)  loss_rpn_box_reg: 4.8045 (6.1016)  time: 1.5292 (1.5558)  data: 0.1054 (0.1287)  lr: 0.000000  max mem: 986
2020-12-13 06:08:30,452 maskrcnn_benchmark.trainer INFO: eta: 15:23:33  iter: 4380  loss: 5.3342 (6.9597)  loss_classifier: 0.1002 (0.1807)  loss_box_reg: 0.0901 (0.2516)  loss_objectness: 0.3071 (0.4319)  loss_rpn_box_reg: 4.7799 (6.0956)  time: 1.5317 (1.5557)  data: 0.1064 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:08:30,454 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:08:30,511 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:08:32,023 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.511075 (1.511075496673584 s / img per device, on 1 devices)
2020-12-13 06:08:32,023 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.398145 (1.3981449604034424 s / img per device, on 1 devices)
2020-12-13 06:08:32,023 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:08:32,128 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:08:32,128 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1., -1.,  2.,  4.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.3242]), 'num_pos': 9}
2020-12-13 06:08:32,132 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.111111
2020-12-13 06:09:02,619 maskrcnn_benchmark.trainer INFO: eta: 15:23:10  iter: 4400  loss: 5.4008 (6.9530)  loss_classifier: 0.0635 (0.1803)  loss_box_reg: 0.1752 (0.2512)  loss_objectness: 0.3360 (0.4314)  loss_rpn_box_reg: 4.8777 (6.0900)  time: 1.5231 (1.5559)  data: 0.0958 (0.1288)  lr: 0.000000  max mem: 986
2020-12-13 06:09:33,071 maskrcnn_benchmark.trainer INFO: eta: 15:22:34  iter: 4420  loss: 5.5546 (6.9467)  loss_classifier: 0.1442 (0.1805)  loss_box_reg: 0.2183 (0.2512)  loss_objectness: 0.3272 (0.4309)  loss_rpn_box_reg: 4.7856 (6.0842)  time: 1.5224 (1.5558)  data: 0.0963 (0.1287)  lr: 0.000000  max mem: 986
2020-12-13 06:10:03,544 maskrcnn_benchmark.trainer INFO: eta: 15:21:57  iter: 4440  loss: 5.3124 (6.9396)  loss_classifier: 0.0380 (0.1800)  loss_box_reg: 0.0744 (0.2506)  loss_objectness: 0.3481 (0.4306)  loss_rpn_box_reg: 4.7934 (6.0785)  time: 1.5227 (1.5556)  data: 0.0988 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:10:03,546 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:10:03,604 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:10:05,115 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.510068 (1.5100677013397217 s / img per device, on 1 devices)
2020-12-13 06:10:05,115 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.399001 (1.399000644683838 s / img per device, on 1 devices)
2020-12-13 06:10:05,115 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:10:05,221 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:10:05,221 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0844, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2., -1., -1.,  2.,  2.,  7.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.9761, 0.0000, 0.0000, 0.9719, 0.9996, 1.0000]), 'num_pos': 9}
2020-12-13 06:10:05,225 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 06:10:35,818 maskrcnn_benchmark.trainer INFO: eta: 15:21:35  iter: 4460  loss: 5.3291 (6.9328)  loss_classifier: 0.0706 (0.1796)  loss_box_reg: 0.1426 (0.2502)  loss_objectness: 0.3208 (0.4301)  loss_rpn_box_reg: 4.7987 (6.0729)  time: 1.5286 (1.5559)  data: 0.1053 (0.1288)  lr: 0.000000  max mem: 986
2020-12-13 06:11:06,261 maskrcnn_benchmark.trainer INFO: eta: 15:20:59  iter: 4480  loss: 5.3828 (6.9259)  loss_classifier: 0.0651 (0.1792)  loss_box_reg: 0.1159 (0.2498)  loss_objectness: 0.3432 (0.4297)  loss_rpn_box_reg: 4.7539 (6.0672)  time: 1.5211 (1.5557)  data: 0.0959 (0.1287)  lr: 0.000000  max mem: 986
2020-12-13 06:11:36,744 maskrcnn_benchmark.trainer INFO: eta: 15:20:23  iter: 4500  loss: 5.2878 (6.9186)  loss_classifier: 0.0715 (0.1789)  loss_box_reg: 0.1043 (0.2492)  loss_objectness: 0.3074 (0.4291)  loss_rpn_box_reg: 4.7610 (6.0614)  time: 1.5245 (1.5556)  data: 0.0955 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:11:36,747 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:11:36,800 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:11:38,312 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.511756 (1.511756181716919 s / img per device, on 1 devices)
2020-12-13 06:11:38,312 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.409018 (1.40901780128479 s / img per device, on 1 devices)
2020-12-13 06:11:38,312 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:11:38,408 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:11:38,408 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.3165, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1.,  2., -1., -1., -1., -1.,  2.,  5.]), 'best match scores': tensor([0.0000, 0.0000, 0.9925, 0.0000, 0.0000, 0.0000, 0.0000, 0.9999, 0.2213]), 'num_pos': 9}
2020-12-13 06:11:38,412 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 06:12:08,927 maskrcnn_benchmark.trainer INFO: eta: 15:20:00  iter: 4520  loss: 5.3192 (6.9120)  loss_classifier: 0.1179 (0.1788)  loss_box_reg: 0.1522 (0.2487)  loss_objectness: 0.3241 (0.4287)  loss_rpn_box_reg: 4.7569 (6.0558)  time: 1.5244 (1.5558)  data: 0.0953 (0.1288)  lr: 0.000000  max mem: 986
2020-12-13 06:12:39,377 maskrcnn_benchmark.trainer INFO: eta: 15:19:24  iter: 4540  loss: 5.3007 (6.9052)  loss_classifier: 0.0792 (0.1786)  loss_box_reg: 0.1187 (0.2482)  loss_objectness: 0.3008 (0.4283)  loss_rpn_box_reg: 4.7927 (6.0502)  time: 1.5206 (1.5557)  data: 0.0952 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:13:09,841 maskrcnn_benchmark.trainer INFO: eta: 15:18:48  iter: 4560  loss: 5.1858 (6.8978)  loss_classifier: 0.0351 (0.1781)  loss_box_reg: 0.1086 (0.2477)  loss_objectness: 0.3431 (0.4279)  loss_rpn_box_reg: 4.7179 (6.0441)  time: 1.5235 (1.5555)  data: 0.0955 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:13:09,843 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:13:09,893 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:13:11,407 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.513781 (1.5137810707092285 s / img per device, on 1 devices)
2020-12-13 06:13:11,407 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.412835 (1.412834882736206 s / img per device, on 1 devices)
2020-12-13 06:13:11,407 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:13:11,504 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:13:11,504 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2850, 0.6713]), 'num_pos': 9}
2020-12-13 06:13:11,508 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 06:13:41,980 maskrcnn_benchmark.trainer INFO: eta: 15:18:24  iter: 4580  loss: 5.1774 (6.8906)  loss_classifier: 0.0847 (0.1777)  loss_box_reg: 0.1191 (0.2471)  loss_objectness: 0.3011 (0.4274)  loss_rpn_box_reg: 4.7172 (6.0385)  time: 1.5228 (1.5558)  data: 0.0953 (0.1287)  lr: 0.000000  max mem: 986
2020-12-13 06:14:12,437 maskrcnn_benchmark.trainer INFO: eta: 15:17:48  iter: 4600  loss: 5.3584 (6.8843)  loss_classifier: 0.1863 (0.1777)  loss_box_reg: 0.1670 (0.2469)  loss_objectness: 0.3069 (0.4269)  loss_rpn_box_reg: 4.7082 (6.0328)  time: 1.5218 (1.5556)  data: 0.0956 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:14:42,887 maskrcnn_benchmark.trainer INFO: eta: 15:17:12  iter: 4620  loss: 5.3704 (6.8780)  loss_classifier: 0.0929 (0.1775)  loss_box_reg: 0.0949 (0.2465)  loss_objectness: 0.2988 (0.4264)  loss_rpn_box_reg: 4.8883 (6.0277)  time: 1.5228 (1.5555)  data: 0.0957 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:14:42,889 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:14:42,939 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:14:44,443 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.503891 (1.5038907527923584 s / img per device, on 1 devices)
2020-12-13 06:14:44,443 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.402871 (1.4028708934783936 s / img per device, on 1 devices)
2020-12-13 06:14:44,443 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:14:44,536 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:14:44,536 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1206, 0.0576, 0.0171, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  1., -1., -1., -1.,  2.,  2.,  4.,  2.]), 'best match scores': tensor([0.0000, 0.2960, 0.0000, 0.0000, 0.0000, 0.3202, 0.0731, 1.0000, 0.9993]), 'num_pos': 9}
2020-12-13 06:14:44,541 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 06:15:15,008 maskrcnn_benchmark.trainer INFO: eta: 15:16:49  iter: 4640  loss: 5.2463 (6.8712)  loss_classifier: 0.0719 (0.1771)  loss_box_reg: 0.1297 (0.2460)  loss_objectness: 0.3201 (0.4260)  loss_rpn_box_reg: 4.7409 (6.0222)  time: 1.5241 (1.5557)  data: 0.0957 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:15:45,453 maskrcnn_benchmark.trainer INFO: eta: 15:16:13  iter: 4660  loss: 5.4338 (6.8650)  loss_classifier: 0.1180 (0.1769)  loss_box_reg: 0.1553 (0.2456)  loss_objectness: 0.3267 (0.4256)  loss_rpn_box_reg: 4.7999 (6.0169)  time: 1.5225 (1.5555)  data: 0.0957 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:16:16,014 maskrcnn_benchmark.trainer INFO: eta: 15:15:37  iter: 4680  loss: 5.1640 (6.8579)  loss_classifier: 0.0419 (0.1764)  loss_box_reg: 0.0036 (0.2449)  loss_objectness: 0.3263 (0.4251)  loss_rpn_box_reg: 4.7370 (6.0114)  time: 1.5291 (1.5554)  data: 0.1049 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:16:16,016 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:16:16,071 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:16:17,580 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.508819 (1.5088186264038086 s / img per device, on 1 devices)
2020-12-13 06:16:17,581 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.398676 (1.3986756801605225 s / img per device, on 1 devices)
2020-12-13 06:16:17,581 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:16:17,686 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:16:17,686 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9498]), 'num_pos': 9}
2020-12-13 06:16:17,690 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 06:16:48,257 maskrcnn_benchmark.trainer INFO: eta: 15:15:15  iter: 4700  loss: 5.3142 (6.8520)  loss_classifier: 0.1041 (0.1765)  loss_box_reg: 0.1622 (0.2447)  loss_objectness: 0.3402 (0.4248)  loss_rpn_box_reg: 4.7093 (6.0059)  time: 1.5271 (1.5557)  data: 0.0987 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:17:18,728 maskrcnn_benchmark.trainer INFO: eta: 15:14:39  iter: 4720  loss: 5.3151 (6.8454)  loss_classifier: 0.0740 (0.1761)  loss_box_reg: 0.1526 (0.2445)  loss_objectness: 0.3145 (0.4244)  loss_rpn_box_reg: 4.7379 (6.0004)  time: 1.5232 (1.5555)  data: 0.0955 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:17:49,218 maskrcnn_benchmark.trainer INFO: eta: 15:14:03  iter: 4740  loss: 5.2235 (6.8388)  loss_classifier: 0.1911 (0.1761)  loss_box_reg: 0.0954 (0.2440)  loss_objectness: 0.2944 (0.4239)  loss_rpn_box_reg: 4.6904 (5.9948)  time: 1.5235 (1.5554)  data: 0.0961 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:17:49,220 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:17:49,269 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:17:50,780 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.510298 (1.510298490524292 s / img per device, on 1 devices)
2020-12-13 06:17:50,780 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.409724 (1.409724473953247 s / img per device, on 1 devices)
2020-12-13 06:17:50,780 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:17:50,877 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:17:50,878 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.1153, 1.0000, 0.3095, 0.2883]), 'num_pos': 9}
2020-12-13 06:17:50,882 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 06:18:21,346 maskrcnn_benchmark.trainer INFO: eta: 15:13:39  iter: 4760  loss: 5.2879 (6.8324)  loss_classifier: 0.0911 (0.1758)  loss_box_reg: 0.0881 (0.2435)  loss_objectness: 0.3378 (0.4235)  loss_rpn_box_reg: 4.7134 (5.9896)  time: 1.5223 (1.5556)  data: 0.0961 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:18:51,895 maskrcnn_benchmark.trainer INFO: eta: 15:13:04  iter: 4780  loss: 5.1318 (6.8254)  loss_classifier: 0.0568 (0.1754)  loss_box_reg: 0.0619 (0.2427)  loss_objectness: 0.2982 (0.4230)  loss_rpn_box_reg: 4.7277 (5.9842)  time: 1.5260 (1.5555)  data: 0.1045 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:19:22,372 maskrcnn_benchmark.trainer INFO: eta: 15:12:28  iter: 4800  loss: 5.1762 (6.8192)  loss_classifier: 0.0676 (0.1753)  loss_box_reg: 0.1226 (0.2424)  loss_objectness: 0.3078 (0.4226)  loss_rpn_box_reg: 4.6806 (5.9789)  time: 1.5239 (1.5554)  data: 0.0960 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:19:22,374 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:19:22,424 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:19:23,938 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.513019 (1.5130186080932617 s / img per device, on 1 devices)
2020-12-13 06:19:23,938 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.411335 (1.4113352298736572 s / img per device, on 1 devices)
2020-12-13 06:19:23,938 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:19:24,032 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:19:24,032 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0780, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.9943, 0.9801, 0.1448, 0.3160, 0.9870, 0.7284]), 'num_pos': 9}
2020-12-13 06:19:24,037 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 06:19:54,538 maskrcnn_benchmark.trainer INFO: eta: 15:12:05  iter: 4820  loss: 5.2984 (6.8128)  loss_classifier: 0.0745 (0.1750)  loss_box_reg: 0.1064 (0.2418)  loss_objectness: 0.3155 (0.4223)  loss_rpn_box_reg: 4.7668 (5.9737)  time: 1.5252 (1.5556)  data: 0.0956 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:20:25,022 maskrcnn_benchmark.trainer INFO: eta: 15:11:29  iter: 4840  loss: 5.1053 (6.8060)  loss_classifier: 0.0629 (0.1747)  loss_box_reg: 0.1127 (0.2414)  loss_objectness: 0.3192 (0.4219)  loss_rpn_box_reg: 4.6582 (5.9680)  time: 1.5232 (1.5555)  data: 0.0962 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:20:55,496 maskrcnn_benchmark.trainer INFO: eta: 15:10:54  iter: 4860  loss: 5.1599 (6.7994)  loss_classifier: 0.0799 (0.1745)  loss_box_reg: 0.0761 (0.2408)  loss_objectness: 0.3220 (0.4215)  loss_rpn_box_reg: 4.6528 (5.9626)  time: 1.5235 (1.5553)  data: 0.0963 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 06:20:55,498 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:20:55,548 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:20:57,051 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.503292 (1.5032923221588135 s / img per device, on 1 devices)
2020-12-13 06:20:57,052 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.403036 (1.40303635597229 s / img per device, on 1 devices)
2020-12-13 06:20:57,052 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:20:57,148 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:20:57,148 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0414, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1.,  2., -1., -1., -1., -1.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.4821, 0.0000, 0.0000, 0.0000, 0.0000]), 'num_pos': 9}
2020-12-13 06:20:57,152 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.111111
2020-12-13 06:21:27,625 maskrcnn_benchmark.trainer INFO: eta: 15:10:30  iter: 4880  loss: 5.1295 (6.7927)  loss_classifier: 0.0509 (0.1741)  loss_box_reg: 0.1046 (0.2402)  loss_objectness: 0.3429 (0.4212)  loss_rpn_box_reg: 4.6246 (5.9572)  time: 1.5225 (1.5555)  data: 0.0958 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:21:58,114 maskrcnn_benchmark.trainer INFO: eta: 15:09:54  iter: 4900  loss: 5.1545 (6.7865)  loss_classifier: 0.0817 (0.1739)  loss_box_reg: 0.1743 (0.2399)  loss_objectness: 0.3136 (0.4208)  loss_rpn_box_reg: 4.6937 (5.9520)  time: 1.5233 (1.5554)  data: 0.0955 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:22:28,575 maskrcnn_benchmark.trainer INFO: eta: 15:09:19  iter: 4920  loss: 5.2638 (6.7807)  loss_classifier: 0.2261 (0.1741)  loss_box_reg: 0.1914 (0.2397)  loss_objectness: 0.3200 (0.4204)  loss_rpn_box_reg: 4.5747 (5.9465)  time: 1.5210 (1.5553)  data: 0.0956 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 06:22:28,578 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:22:28,627 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:22:30,139 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.512253 (1.5122530460357666 s / img per device, on 1 devices)
2020-12-13 06:22:30,140 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.409381 (1.4093811511993408 s / img per device, on 1 devices)
2020-12-13 06:22:30,140 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:22:30,238 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:22:30,239 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([3.2867e-04, 2.2192e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1.,  2., -1., -1.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.9489, 0.9959, 0.0542, 1.0000]), 'num_pos': 9}
2020-12-13 06:22:30,243 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 06:23:00,760 maskrcnn_benchmark.trainer INFO: eta: 15:08:55  iter: 4940  loss: 5.1147 (6.7744)  loss_classifier: 0.0636 (0.1738)  loss_box_reg: 0.1300 (0.2394)  loss_objectness: 0.3081 (0.4200)  loss_rpn_box_reg: 4.5948 (5.9412)  time: 1.5248 (1.5555)  data: 0.0978 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:23:31,269 maskrcnn_benchmark.trainer INFO: eta: 15:08:20  iter: 4960  loss: 5.1089 (6.7679)  loss_classifier: 0.0564 (0.1734)  loss_box_reg: 0.0986 (0.2389)  loss_objectness: 0.3072 (0.4195)  loss_rpn_box_reg: 4.6772 (5.9361)  time: 1.5246 (1.5554)  data: 0.0976 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 06:24:01,782 maskrcnn_benchmark.trainer INFO: eta: 15:07:45  iter: 4980  loss: 4.9489 (6.7610)  loss_classifier: 0.0351 (0.1731)  loss_box_reg: 0.0606 (0.2383)  loss_objectness: 0.3150 (0.4191)  loss_rpn_box_reg: 4.5383 (5.9306)  time: 1.5250 (1.5553)  data: 0.0975 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 06:24:01,784 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:24:01,834 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:24:03,339 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.505042 (1.5050418376922607 s / img per device, on 1 devices)
2020-12-13 06:24:03,340 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.399638 (1.3996384143829346 s / img per device, on 1 devices)
2020-12-13 06:24:03,340 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:24:03,442 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:24:03,443 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0633, 0.9797]), 'num_pos': 9}
2020-12-13 06:24:03,447 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 06:24:33,967 maskrcnn_benchmark.trainer INFO: eta: 15:07:21  iter: 5000  loss: 5.0427 (6.7545)  loss_classifier: 0.0939 (0.1728)  loss_box_reg: 0.1191 (0.2378)  loss_objectness: 0.3401 (0.4188)  loss_rpn_box_reg: 4.5192 (5.9251)  time: 1.5259 (1.5555)  data: 0.0974 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:24:33,969 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./model_0005000.pth
2020-12-13 06:25:05,653 maskrcnn_benchmark.trainer INFO: eta: 15:06:54  iter: 5020  loss: 5.3298 (6.7488)  loss_classifier: 0.1589 (0.1728)  loss_box_reg: 0.1691 (0.2377)  loss_objectness: 0.3220 (0.4184)  loss_rpn_box_reg: 4.6160 (5.9199)  time: 1.5253 (1.5556)  data: 0.0978 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:25:36,170 maskrcnn_benchmark.trainer INFO: eta: 15:06:19  iter: 5040  loss: 5.1420 (6.7426)  loss_classifier: 0.0759 (0.1726)  loss_box_reg: 0.1301 (0.2374)  loss_objectness: 0.2899 (0.4179)  loss_rpn_box_reg: 4.5985 (5.9146)  time: 1.5256 (1.5555)  data: 0.0976 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:25:36,171 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:25:36,221 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:25:37,727 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.506167 (1.506166696548462 s / img per device, on 1 devices)
2020-12-13 06:25:37,728 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.402840 (1.4028398990631104 s / img per device, on 1 devices)
2020-12-13 06:25:37,728 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:25:37,826 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:25:37,826 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1274, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  2., -1., -1., -1.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.2963, 0.7919, 0.9980, 0.3979]), 'num_pos': 9}
2020-12-13 06:25:37,830 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 06:26:08,379 maskrcnn_benchmark.trainer INFO: eta: 15:05:55  iter: 5060  loss: 5.1407 (6.7360)  loss_classifier: 0.0665 (0.1722)  loss_box_reg: 0.0910 (0.2369)  loss_objectness: 0.2877 (0.4175)  loss_rpn_box_reg: 4.5822 (5.9094)  time: 1.5262 (1.5557)  data: 0.0978 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:26:38,883 maskrcnn_benchmark.trainer INFO: eta: 15:05:20  iter: 5080  loss: 5.2429 (6.7301)  loss_classifier: 0.1408 (0.1722)  loss_box_reg: 0.1312 (0.2365)  loss_objectness: 0.3057 (0.4171)  loss_rpn_box_reg: 4.5916 (5.9043)  time: 1.5241 (1.5556)  data: 0.0978 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:27:09,385 maskrcnn_benchmark.trainer INFO: eta: 15:04:45  iter: 5100  loss: 5.0140 (6.7235)  loss_classifier: 0.0350 (0.1718)  loss_box_reg: 0.0016 (0.2359)  loss_objectness: 0.3335 (0.4168)  loss_rpn_box_reg: 4.5440 (5.8990)  time: 1.5250 (1.5554)  data: 0.0978 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:27:09,387 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:27:09,437 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:27:10,949 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.511570 (1.5115704536437988 s / img per device, on 1 devices)
2020-12-13 06:27:10,949 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.406707 (1.4067072868347168 s / img per device, on 1 devices)
2020-12-13 06:27:10,950 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:27:11,047 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:27:11,048 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.9594]), 'num_pos': 9}
2020-12-13 06:27:11,051 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 06:27:41,571 maskrcnn_benchmark.trainer INFO: eta: 15:04:21  iter: 5120  loss: 5.1749 (6.7177)  loss_classifier: 0.0835 (0.1717)  loss_box_reg: 0.1682 (0.2355)  loss_objectness: 0.3437 (0.4165)  loss_rpn_box_reg: 4.5663 (5.8940)  time: 1.5245 (1.5557)  data: 0.0971 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:28:12,113 maskrcnn_benchmark.trainer INFO: eta: 15:03:46  iter: 5140  loss: 5.1646 (6.7118)  loss_classifier: 0.0668 (0.1714)  loss_box_reg: 0.0936 (0.2351)  loss_objectness: 0.2973 (0.4161)  loss_rpn_box_reg: 4.6668 (5.8892)  time: 1.5265 (1.5555)  data: 0.0986 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:28:42,606 maskrcnn_benchmark.trainer INFO: eta: 15:03:11  iter: 5160  loss: 5.0958 (6.7055)  loss_classifier: 0.0407 (0.1711)  loss_box_reg: 0.0971 (0.2347)  loss_objectness: 0.3333 (0.4157)  loss_rpn_box_reg: 4.5927 (5.8840)  time: 1.5236 (1.5554)  data: 0.0980 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:28:42,608 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:28:42,658 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:28:44,171 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.513065 (1.5130646228790283 s / img per device, on 1 devices)
2020-12-13 06:28:44,171 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.408862 (1.4088616371154785 s / img per device, on 1 devices)
2020-12-13 06:28:44,171 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:28:44,264 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:28:44,265 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0329, 0.0012, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.9735, 0.3719, 0.9667, 0.9739, 1.0000, 0.9285, 0.9807]), 'num_pos': 9}
2020-12-13 06:28:44,269 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.777778
2020-12-13 06:29:14,789 maskrcnn_benchmark.trainer INFO: eta: 15:02:47  iter: 5180  loss: 5.1409 (6.6995)  loss_classifier: 0.0717 (0.1708)  loss_box_reg: 0.1453 (0.2343)  loss_objectness: 0.3159 (0.4154)  loss_rpn_box_reg: 4.5971 (5.8791)  time: 1.5264 (1.5556)  data: 0.0980 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:29:45,444 maskrcnn_benchmark.trainer INFO: eta: 15:02:13  iter: 5200  loss: 5.2516 (6.6940)  loss_classifier: 0.1075 (0.1707)  loss_box_reg: 0.1485 (0.2342)  loss_objectness: 0.2980 (0.4149)  loss_rpn_box_reg: 4.5758 (5.8742)  time: 1.5328 (1.5555)  data: 0.1084 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:30:16,067 maskrcnn_benchmark.trainer INFO: eta: 15:01:38  iter: 5220  loss: 5.1829 (6.6880)  loss_classifier: 0.1025 (0.1704)  loss_box_reg: 0.1563 (0.2340)  loss_objectness: 0.3272 (0.4146)  loss_rpn_box_reg: 4.4990 (5.8690)  time: 1.5308 (1.5555)  data: 0.1079 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:30:16,069 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:30:16,124 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:30:17,636 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.512167 (1.5121665000915527 s / img per device, on 1 devices)
2020-12-13 06:30:17,636 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.397922 (1.3979222774505615 s / img per device, on 1 devices)
2020-12-13 06:30:17,636 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:30:17,728 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:30:17,728 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([2.6391e-02, 3.5788e-11, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1.,  2., -1., -1., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7386, 1.0000]), 'num_pos': 9}
2020-12-13 06:30:17,732 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 06:30:48,242 maskrcnn_benchmark.trainer INFO: eta: 15:01:14  iter: 5240  loss: 5.1639 (6.6820)  loss_classifier: 0.1255 (0.1703)  loss_box_reg: 0.1400 (0.2337)  loss_objectness: 0.3387 (0.4143)  loss_rpn_box_reg: 4.4713 (5.8638)  time: 1.5248 (1.5557)  data: 0.0978 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:31:18,760 maskrcnn_benchmark.trainer INFO: eta: 15:00:39  iter: 5260  loss: 5.2363 (6.6764)  loss_classifier: 0.1167 (0.1702)  loss_box_reg: 0.1629 (0.2335)  loss_objectness: 0.3015 (0.4139)  loss_rpn_box_reg: 4.4910 (5.8588)  time: 1.5257 (1.5555)  data: 0.0982 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:31:49,274 maskrcnn_benchmark.trainer INFO: eta: 15:00:04  iter: 5280  loss: 5.2822 (6.6712)  loss_classifier: 0.0783 (0.1701)  loss_box_reg: 0.2262 (0.2335)  loss_objectness: 0.3255 (0.4135)  loss_rpn_box_reg: 4.5968 (5.8541)  time: 1.5258 (1.5554)  data: 0.0979 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:31:49,276 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:31:49,328 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:31:50,837 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.508687 (1.5086865425109863 s / img per device, on 1 devices)
2020-12-13 06:31:50,837 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.406499 (1.406498908996582 s / img per device, on 1 devices)
2020-12-13 06:31:50,837 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:31:50,931 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:31:50,932 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([6.8625e-02, 2.0852e-02, 6.8645e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 2.]), 'best match scores': tensor([0.7521, 0.7081, 0.8996, 0.9246, 0.9285, 1.0000, 0.9999, 0.9978, 0.9997]), 'num_pos': 9}
2020-12-13 06:31:50,937 maskrcnn_benchmark.trainer INFO: validation accuracy: 1.000000
2020-12-13 06:32:21,450 maskrcnn_benchmark.trainer INFO: eta: 14:59:40  iter: 5300  loss: 5.0943 (6.6656)  loss_classifier: 0.1401 (0.1700)  loss_box_reg: 0.2534 (0.2336)  loss_objectness: 0.3327 (0.4132)  loss_rpn_box_reg: 4.4256 (5.8488)  time: 1.5229 (1.5556)  data: 0.0960 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:32:52,011 maskrcnn_benchmark.trainer INFO: eta: 14:59:05  iter: 5320  loss: 5.2558 (6.6603)  loss_classifier: 0.1679 (0.1699)  loss_box_reg: 0.1170 (0.2334)  loss_objectness: 0.2954 (0.4128)  loss_rpn_box_reg: 4.5638 (5.8441)  time: 1.5271 (1.5555)  data: 0.1034 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:33:22,571 maskrcnn_benchmark.trainer INFO: eta: 14:58:31  iter: 5340  loss: 5.1594 (6.6546)  loss_classifier: 0.0836 (0.1697)  loss_box_reg: 0.1896 (0.2333)  loss_objectness: 0.3144 (0.4124)  loss_rpn_box_reg: 4.4962 (5.8391)  time: 1.5268 (1.5554)  data: 0.1039 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:33:22,573 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:33:22,627 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:33:24,141 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.513561 (1.5135605335235596 s / img per device, on 1 devices)
2020-12-13 06:33:24,141 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.402028 (1.4020280838012695 s / img per device, on 1 devices)
2020-12-13 06:33:24,141 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:33:24,244 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:33:24,245 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.8075e-01, 6.0257e-03, 2.1104e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1.,  2.,  2., -1.,  2., -1., -1.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.3471, 0.8456, 0.0000, 0.8414, 0.0000, 0.0000, 0.1906]), 'num_pos': 9}
2020-12-13 06:33:24,249 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.444444
2020-12-13 06:33:54,784 maskrcnn_benchmark.trainer INFO: eta: 14:58:07  iter: 5360  loss: 5.0559 (6.6488)  loss_classifier: 0.0870 (0.1694)  loss_box_reg: 0.0832 (0.2329)  loss_objectness: 0.3556 (0.4122)  loss_rpn_box_reg: 4.4878 (5.8342)  time: 1.5267 (1.5556)  data: 0.0967 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:34:25,386 maskrcnn_benchmark.trainer INFO: eta: 14:57:32  iter: 5380  loss: 5.1736 (6.6433)  loss_classifier: 0.0921 (0.1692)  loss_box_reg: 0.1658 (0.2327)  loss_objectness: 0.3176 (0.4118)  loss_rpn_box_reg: 4.5873 (5.8296)  time: 1.5287 (1.5555)  data: 0.1060 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:34:55,815 maskrcnn_benchmark.trainer INFO: eta: 14:56:57  iter: 5400  loss: 5.1193 (6.6379)  loss_classifier: 0.1764 (0.1695)  loss_box_reg: 0.1112 (0.2324)  loss_objectness: 0.3210 (0.4115)  loss_rpn_box_reg: 4.4569 (5.8245)  time: 1.5215 (1.5554)  data: 0.0959 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:34:55,817 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:34:55,866 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:34:57,375 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.509078 (1.509077548980713 s / img per device, on 1 devices)
2020-12-13 06:34:57,376 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.403801 (1.4038012027740479 s / img per device, on 1 devices)
2020-12-13 06:34:57,376 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:34:57,473 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:34:57,473 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9833, 0.1565, 0.8326]), 'num_pos': 9}
2020-12-13 06:34:57,477 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 06:35:28,043 maskrcnn_benchmark.trainer INFO: eta: 14:56:33  iter: 5420  loss: 5.0522 (6.6323)  loss_classifier: 0.0896 (0.1692)  loss_box_reg: 0.1384 (0.2322)  loss_objectness: 0.3288 (0.4112)  loss_rpn_box_reg: 4.5284 (5.8197)  time: 1.5288 (1.5556)  data: 0.1059 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:35:58,639 maskrcnn_benchmark.trainer INFO: eta: 14:55:58  iter: 5440  loss: 4.9936 (6.6265)  loss_classifier: 0.1062 (0.1691)  loss_box_reg: 0.1692 (0.2320)  loss_objectness: 0.3208 (0.4109)  loss_rpn_box_reg: 4.4397 (5.8146)  time: 1.5293 (1.5555)  data: 0.1069 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:36:29,112 maskrcnn_benchmark.trainer INFO: eta: 14:55:23  iter: 5460  loss: 5.0607 (6.6207)  loss_classifier: 0.0688 (0.1688)  loss_box_reg: 0.0885 (0.2315)  loss_objectness: 0.3265 (0.4106)  loss_rpn_box_reg: 4.4332 (5.8098)  time: 1.5215 (1.5554)  data: 0.0964 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:36:29,113 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:36:29,166 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:36:30,671 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.505215 (1.5052154064178467 s / img per device, on 1 devices)
2020-12-13 06:36:30,671 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.400509 (1.4005086421966553 s / img per device, on 1 devices)
2020-12-13 06:36:30,671 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:36:30,766 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:36:30,766 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1364, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3406, 0.9998]), 'num_pos': 9}
2020-12-13 06:36:30,770 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 06:37:01,253 maskrcnn_benchmark.trainer INFO: eta: 14:54:59  iter: 5480  loss: 4.9948 (6.6149)  loss_classifier: 0.1276 (0.1686)  loss_box_reg: 0.1351 (0.2313)  loss_objectness: 0.2989 (0.4102)  loss_rpn_box_reg: 4.3870 (5.8048)  time: 1.5217 (1.5556)  data: 0.0972 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:37:31,730 maskrcnn_benchmark.trainer INFO: eta: 14:54:23  iter: 5500  loss: 5.2304 (6.6099)  loss_classifier: 0.1692 (0.1687)  loss_box_reg: 0.1797 (0.2312)  loss_objectness: 0.3011 (0.4099)  loss_rpn_box_reg: 4.5171 (5.8002)  time: 1.5236 (1.5555)  data: 0.0960 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:38:02,218 maskrcnn_benchmark.trainer INFO: eta: 14:53:48  iter: 5520  loss: 5.1036 (6.6046)  loss_classifier: 0.1074 (0.1686)  loss_box_reg: 0.1997 (0.2311)  loss_objectness: 0.2887 (0.4095)  loss_rpn_box_reg: 4.4460 (5.7954)  time: 1.5238 (1.5554)  data: 0.0961 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:38:02,221 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:38:02,273 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:38:03,778 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.505346 (1.5053462982177734 s / img per device, on 1 devices)
2020-12-13 06:38:03,779 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.401900 (1.401900291442871 s / img per device, on 1 devices)
2020-12-13 06:38:03,779 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:38:03,873 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:38:03,873 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6053, 0.9589]), 'num_pos': 9}
2020-12-13 06:38:03,877 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 06:38:34,378 maskrcnn_benchmark.trainer INFO: eta: 14:53:24  iter: 5540  loss: 5.0677 (6.5991)  loss_classifier: 0.1491 (0.1685)  loss_box_reg: 0.2063 (0.2311)  loss_objectness: 0.2977 (0.4091)  loss_rpn_box_reg: 4.4594 (5.7904)  time: 1.5260 (1.5556)  data: 0.0956 (0.1286)  lr: 0.000000  max mem: 986
2020-12-13 06:39:04,862 maskrcnn_benchmark.trainer INFO: eta: 14:52:49  iter: 5560  loss: 5.0373 (6.5936)  loss_classifier: 0.1372 (0.1685)  loss_box_reg: 0.1024 (0.2308)  loss_objectness: 0.2939 (0.4087)  loss_rpn_box_reg: 4.4314 (5.7857)  time: 1.5253 (1.5554)  data: 0.0957 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:39:35,344 maskrcnn_benchmark.trainer INFO: eta: 14:52:14  iter: 5580  loss: 4.8556 (6.5874)  loss_classifier: 0.0448 (0.1682)  loss_box_reg: 0.0761 (0.2303)  loss_objectness: 0.3033 (0.4083)  loss_rpn_box_reg: 4.3993 (5.7807)  time: 1.5237 (1.5553)  data: 0.0956 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 06:39:35,346 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:39:35,398 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:39:36,907 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.508607 (1.5086073875427246 s / img per device, on 1 devices)
2020-12-13 06:39:36,907 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.406066 (1.4060661792755127 s / img per device, on 1 devices)
2020-12-13 06:39:36,908 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:39:37,002 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:39:37,002 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.1857, 0.1947, 0.0927, 1.0000, 0.1456]), 'num_pos': 9}
2020-12-13 06:39:37,006 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 06:40:07,518 maskrcnn_benchmark.trainer INFO: eta: 14:51:49  iter: 5600  loss: 4.8366 (6.5815)  loss_classifier: 0.0923 (0.1679)  loss_box_reg: 0.1339 (0.2300)  loss_objectness: 0.3108 (0.4079)  loss_rpn_box_reg: 4.3240 (5.7757)  time: 1.5267 (1.5555)  data: 0.0958 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:40:38,004 maskrcnn_benchmark.trainer INFO: eta: 14:51:14  iter: 5620  loss: 4.9666 (6.5760)  loss_classifier: 0.0968 (0.1677)  loss_box_reg: 0.1772 (0.2297)  loss_objectness: 0.3249 (0.4076)  loss_rpn_box_reg: 4.4155 (5.7709)  time: 1.5227 (1.5554)  data: 0.0960 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:41:08,475 maskrcnn_benchmark.trainer INFO: eta: 14:50:39  iter: 5640  loss: 5.0170 (6.5707)  loss_classifier: 0.0748 (0.1674)  loss_box_reg: 0.1645 (0.2296)  loss_objectness: 0.3025 (0.4073)  loss_rpn_box_reg: 4.5100 (5.7663)  time: 1.5231 (1.5553)  data: 0.0953 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 06:41:08,477 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:41:08,530 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:41:10,039 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.508838 (1.5088379383087158 s / img per device, on 1 devices)
2020-12-13 06:41:10,040 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.406141 (1.4061412811279297 s / img per device, on 1 devices)
2020-12-13 06:41:10,040 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:41:10,137 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:41:10,137 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0007, 0.0005, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.2008, 0.8584, 0.8188, 1.0000, 0.9142, 1.0000, 0.6596, 1.0000]), 'num_pos': 9}
2020-12-13 06:41:10,142 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.888889
2020-12-13 06:41:40,708 maskrcnn_benchmark.trainer INFO: eta: 14:50:15  iter: 5660  loss: 5.0244 (6.5653)  loss_classifier: 0.0781 (0.1672)  loss_box_reg: 0.1400 (0.2294)  loss_objectness: 0.2904 (0.4069)  loss_rpn_box_reg: 4.4345 (5.7618)  time: 1.5271 (1.5555)  data: 0.1007 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:42:11,296 maskrcnn_benchmark.trainer INFO: eta: 14:49:41  iter: 5680  loss: 4.9677 (6.5597)  loss_classifier: 0.0792 (0.1669)  loss_box_reg: 0.1476 (0.2292)  loss_objectness: 0.2770 (0.4065)  loss_rpn_box_reg: 4.4270 (5.7570)  time: 1.5283 (1.5554)  data: 0.1055 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:42:41,885 maskrcnn_benchmark.trainer INFO: eta: 14:49:07  iter: 5700  loss: 4.9723 (6.5544)  loss_classifier: 0.1264 (0.1668)  loss_box_reg: 0.1602 (0.2290)  loss_objectness: 0.3268 (0.4062)  loss_rpn_box_reg: 4.3734 (5.7523)  time: 1.5279 (1.5553)  data: 0.1050 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 06:42:41,887 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:42:41,939 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:42:43,443 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.503222 (1.5032219886779785 s / img per device, on 1 devices)
2020-12-13 06:42:43,443 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.397722 (1.3977220058441162 s / img per device, on 1 devices)
2020-12-13 06:42:43,443 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:42:43,539 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:42:43,539 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9211, 1.0000]), 'num_pos': 9}
2020-12-13 06:42:43,543 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 06:43:14,140 maskrcnn_benchmark.trainer INFO: eta: 14:48:42  iter: 5720  loss: 4.9171 (6.5488)  loss_classifier: 0.0515 (0.1666)  loss_box_reg: 0.1583 (0.2288)  loss_objectness: 0.2954 (0.4059)  loss_rpn_box_reg: 4.3119 (5.7476)  time: 1.5303 (1.5555)  data: 0.1060 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:43:44,691 maskrcnn_benchmark.trainer INFO: eta: 14:48:08  iter: 5740  loss: 4.9278 (6.5437)  loss_classifier: 0.1286 (0.1665)  loss_box_reg: 0.1423 (0.2286)  loss_objectness: 0.2920 (0.4056)  loss_rpn_box_reg: 4.4232 (5.7429)  time: 1.5272 (1.5554)  data: 0.1001 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:44:15,239 maskrcnn_benchmark.trainer INFO: eta: 14:47:34  iter: 5760  loss: 5.0544 (6.5390)  loss_classifier: 0.1721 (0.1666)  loss_box_reg: 0.1897 (0.2288)  loss_objectness: 0.3394 (0.4053)  loss_rpn_box_reg: 4.3738 (5.7382)  time: 1.5271 (1.5553)  data: 0.0952 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 06:44:15,240 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:44:15,294 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:44:16,803 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.509096 (1.5090956687927246 s / img per device, on 1 devices)
2020-12-13 06:44:16,803 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.406700 (1.4066996574401855 s / img per device, on 1 devices)
2020-12-13 06:44:16,803 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:44:16,896 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:44:16,897 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2., -1.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.7973, 0.0000, 0.6443, 0.2764, 0.5949, 0.5829]), 'num_pos': 9}
2020-12-13 06:44:16,902 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 06:44:47,403 maskrcnn_benchmark.trainer INFO: eta: 14:47:09  iter: 5780  loss: 5.0488 (6.5339)  loss_classifier: 0.1146 (0.1665)  loss_box_reg: 0.1988 (0.2287)  loss_objectness: 0.3046 (0.4050)  loss_rpn_box_reg: 4.4037 (5.7336)  time: 1.5251 (1.5555)  data: 0.0986 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:45:17,883 maskrcnn_benchmark.trainer INFO: eta: 14:46:34  iter: 5800  loss: 4.9033 (6.5285)  loss_classifier: 0.1349 (0.1665)  loss_box_reg: 0.1563 (0.2285)  loss_objectness: 0.2901 (0.4047)  loss_rpn_box_reg: 4.3355 (5.7288)  time: 1.5238 (1.5554)  data: 0.0964 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:45:48,377 maskrcnn_benchmark.trainer INFO: eta: 14:45:59  iter: 5820  loss: 5.0308 (6.5234)  loss_classifier: 0.1239 (0.1665)  loss_box_reg: 0.1588 (0.2283)  loss_objectness: 0.3226 (0.4044)  loss_rpn_box_reg: 4.4003 (5.7242)  time: 1.5251 (1.5553)  data: 0.0954 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 06:45:48,379 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:45:48,429 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:45:49,943 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.513473 (1.5134730339050293 s / img per device, on 1 devices)
2020-12-13 06:45:49,943 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.412727 (1.4127271175384521 s / img per device, on 1 devices)
2020-12-13 06:45:49,943 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:45:50,041 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:45:50,041 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.6651e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.5828, 1.0000, 0.4819, 0.2722]), 'num_pos': 9}
2020-12-13 06:45:50,045 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 06:46:20,562 maskrcnn_benchmark.trainer INFO: eta: 14:45:34  iter: 5840  loss: 4.9018 (6.5178)  loss_classifier: 0.0494 (0.1662)  loss_box_reg: 0.1101 (0.2280)  loss_objectness: 0.2760 (0.4040)  loss_rpn_box_reg: 4.3941 (5.7196)  time: 1.5252 (1.5555)  data: 0.0964 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:46:51,049 maskrcnn_benchmark.trainer INFO: eta: 14:45:00  iter: 5860  loss: 5.1130 (6.5130)  loss_classifier: 0.2094 (0.1663)  loss_box_reg: 0.2154 (0.2280)  loss_objectness: 0.3386 (0.4038)  loss_rpn_box_reg: 4.3703 (5.7150)  time: 1.5237 (1.5554)  data: 0.0965 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:47:21,618 maskrcnn_benchmark.trainer INFO: eta: 14:44:25  iter: 5880  loss: 4.8989 (6.5076)  loss_classifier: 0.0812 (0.1660)  loss_box_reg: 0.1167 (0.2277)  loss_objectness: 0.2886 (0.4034)  loss_rpn_box_reg: 4.3356 (5.7105)  time: 1.5278 (1.5553)  data: 0.1053 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 06:47:21,620 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:47:21,675 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:47:23,188 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.512688 (1.512688159942627 s / img per device, on 1 devices)
2020-12-13 06:47:23,188 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.402541 (1.402541160583496 s / img per device, on 1 devices)
2020-12-13 06:47:23,188 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:47:23,291 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:47:23,291 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.3064, 0.0489, 0.0377, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1., -1.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([1.0000, 0.0000, 0.0000, 0.0000, 0.8082, 0.6961, 0.2024, 0.9916, 0.9998]), 'num_pos': 9}
2020-12-13 06:47:23,296 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 06:47:53,842 maskrcnn_benchmark.trainer INFO: eta: 14:44:01  iter: 5900  loss: 4.9698 (6.5025)  loss_classifier: 0.1435 (0.1659)  loss_box_reg: 0.1252 (0.2275)  loss_objectness: 0.3088 (0.4031)  loss_rpn_box_reg: 4.4030 (5.7060)  time: 1.5290 (1.5555)  data: 0.1050 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:48:24,373 maskrcnn_benchmark.trainer INFO: eta: 14:43:26  iter: 5920  loss: 4.8666 (6.4972)  loss_classifier: 0.0919 (0.1658)  loss_box_reg: 0.1304 (0.2273)  loss_objectness: 0.2979 (0.4028)  loss_rpn_box_reg: 4.3829 (5.7014)  time: 1.5267 (1.5554)  data: 0.0995 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:48:54,910 maskrcnn_benchmark.trainer INFO: eta: 14:42:52  iter: 5940  loss: 4.9166 (6.4920)  loss_classifier: 0.0683 (0.1655)  loss_box_reg: 0.1410 (0.2271)  loss_objectness: 0.2992 (0.4025)  loss_rpn_box_reg: 4.3687 (5.6969)  time: 1.5254 (1.5553)  data: 0.0968 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 06:48:54,912 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:48:54,962 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:48:56,464 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.502073 (1.502072811126709 s / img per device, on 1 devices)
2020-12-13 06:48:56,465 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.401096 (1.4010963439941406 s / img per device, on 1 devices)
2020-12-13 06:48:56,465 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:48:56,566 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:48:56,566 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.9128e-02, 1.7197e-03, 2.7960e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1.,  2., -1.,  2., -1.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0717, 0.0000, 0.0665, 0.0000, 0.9999]), 'num_pos': 9}
2020-12-13 06:48:56,571 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 06:49:27,150 maskrcnn_benchmark.trainer INFO: eta: 14:42:27  iter: 5960  loss: 4.8994 (6.4870)  loss_classifier: 0.2140 (0.1656)  loss_box_reg: 0.1996 (0.2270)  loss_objectness: 0.2985 (0.4021)  loss_rpn_box_reg: 4.3550 (5.6923)  time: 1.5279 (1.5555)  data: 0.1055 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:49:57,720 maskrcnn_benchmark.trainer INFO: eta: 14:41:53  iter: 5980  loss: 4.8743 (6.4819)  loss_classifier: 0.0815 (0.1656)  loss_box_reg: 0.0946 (0.2268)  loss_objectness: 0.3050 (0.4018)  loss_rpn_box_reg: 4.3206 (5.6877)  time: 1.5280 (1.5554)  data: 0.1054 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:50:28,287 maskrcnn_benchmark.trainer INFO: eta: 14:41:19  iter: 6000  loss: 4.7464 (6.4762)  loss_classifier: 0.0314 (0.1653)  loss_box_reg: 0.0827 (0.2264)  loss_objectness: 0.2956 (0.4015)  loss_rpn_box_reg: 4.2978 (5.6830)  time: 1.5290 (1.5553)  data: 0.1050 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 06:50:28,289 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:50:28,344 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:50:29,851 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.506431 (1.5064306259155273 s / img per device, on 1 devices)
2020-12-13 06:50:29,851 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.396290 (1.3962903022766113 s / img per device, on 1 devices)
2020-12-13 06:50:29,851 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:50:29,957 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:50:29,957 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0311, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9974, 0.9988, 0.9472]), 'num_pos': 9}
2020-12-13 06:50:29,961 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 06:51:00,562 maskrcnn_benchmark.trainer INFO: eta: 14:40:55  iter: 6020  loss: 4.9717 (6.4712)  loss_classifier: 0.2009 (0.1654)  loss_box_reg: 0.1773 (0.2262)  loss_objectness: 0.2831 (0.4012)  loss_rpn_box_reg: 4.2869 (5.6784)  time: 1.5293 (1.5555)  data: 0.1060 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:51:31,057 maskrcnn_benchmark.trainer INFO: eta: 14:40:20  iter: 6040  loss: 4.9097 (6.4660)  loss_classifier: 0.0666 (0.1653)  loss_box_reg: 0.1317 (0.2259)  loss_objectness: 0.3114 (0.4009)  loss_rpn_box_reg: 4.3142 (5.6738)  time: 1.5240 (1.5554)  data: 0.0974 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:52:01,521 maskrcnn_benchmark.trainer INFO: eta: 14:39:45  iter: 6060  loss: 4.7672 (6.4606)  loss_classifier: 0.1161 (0.1653)  loss_box_reg: 0.1147 (0.2256)  loss_objectness: 0.3012 (0.4006)  loss_rpn_box_reg: 4.1798 (5.6690)  time: 1.5227 (1.5553)  data: 0.0963 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 06:52:01,522 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:52:01,571 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:52:03,082 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.510293 (1.5102934837341309 s / img per device, on 1 devices)
2020-12-13 06:52:03,082 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.409926 (1.409925937652588 s / img per device, on 1 devices)
2020-12-13 06:52:03,082 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:52:03,178 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:52:03,179 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0514, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2.,  2., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.9525, 0.4732, 0.0000, 0.0000, 0.9292, 0.6728]), 'num_pos': 9}
2020-12-13 06:52:03,183 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.444444
2020-12-13 06:52:33,667 maskrcnn_benchmark.trainer INFO: eta: 14:39:20  iter: 6080  loss: 5.0088 (6.4557)  loss_classifier: 0.0991 (0.1652)  loss_box_reg: 0.1624 (0.2256)  loss_objectness: 0.3114 (0.4003)  loss_rpn_box_reg: 4.2731 (5.6646)  time: 1.5237 (1.5554)  data: 0.0960 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:53:04,138 maskrcnn_benchmark.trainer INFO: eta: 14:38:45  iter: 6100  loss: 4.8380 (6.4504)  loss_classifier: 0.1055 (0.1650)  loss_box_reg: 0.1539 (0.2255)  loss_objectness: 0.2815 (0.3999)  loss_rpn_box_reg: 4.2299 (5.6599)  time: 1.5223 (1.5553)  data: 0.0967 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:53:34,607 maskrcnn_benchmark.trainer INFO: eta: 14:38:11  iter: 6120  loss: 4.8660 (6.4457)  loss_classifier: 0.2250 (0.1652)  loss_box_reg: 0.1489 (0.2254)  loss_objectness: 0.2750 (0.3996)  loss_rpn_box_reg: 4.3506 (5.6555)  time: 1.5220 (1.5552)  data: 0.0962 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 06:53:34,609 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:53:34,658 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:53:36,163 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.505107 (1.5051074028015137 s / img per device, on 1 devices)
2020-12-13 06:53:36,163 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.404450 (1.404449701309204 s / img per device, on 1 devices)
2020-12-13 06:53:36,164 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:53:36,260 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:53:36,260 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1.,  2., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1407, 0.0000, 0.9952, 1.0000]), 'num_pos': 9}
2020-12-13 06:53:36,264 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 06:54:06,779 maskrcnn_benchmark.trainer INFO: eta: 14:37:45  iter: 6140  loss: 4.8428 (6.4405)  loss_classifier: 0.1219 (0.1651)  loss_box_reg: 0.1782 (0.2253)  loss_objectness: 0.2917 (0.3993)  loss_rpn_box_reg: 4.2518 (5.6509)  time: 1.5239 (1.5554)  data: 0.0975 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:54:37,238 maskrcnn_benchmark.trainer INFO: eta: 14:37:11  iter: 6160  loss: 4.9392 (6.4359)  loss_classifier: 0.1378 (0.1651)  loss_box_reg: 0.3365 (0.2256)  loss_objectness: 0.2924 (0.3990)  loss_rpn_box_reg: 4.1913 (5.6462)  time: 1.5207 (1.5553)  data: 0.0960 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:55:07,723 maskrcnn_benchmark.trainer INFO: eta: 14:36:36  iter: 6180  loss: 4.7495 (6.4306)  loss_classifier: 0.0780 (0.1649)  loss_box_reg: 0.0901 (0.2251)  loss_objectness: 0.2884 (0.3987)  loss_rpn_box_reg: 4.2952 (5.6419)  time: 1.5234 (1.5552)  data: 0.0969 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 06:55:07,725 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:55:07,775 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:55:09,276 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.500951 (1.500950574874878 s / img per device, on 1 devices)
2020-12-13 06:55:09,277 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.400618 (1.400618314743042 s / img per device, on 1 devices)
2020-12-13 06:55:09,277 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:55:09,373 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:55:09,373 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0013, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  2., -1., -1., -1., -1., -1., -1.,  2.]), 'best match scores': tensor([0.0000, 0.8735, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0555]), 'num_pos': 9}
2020-12-13 06:55:09,377 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 06:55:39,899 maskrcnn_benchmark.trainer INFO: eta: 14:36:11  iter: 6200  loss: 4.7858 (6.4257)  loss_classifier: 0.1258 (0.1648)  loss_box_reg: 0.1678 (0.2250)  loss_objectness: 0.2952 (0.3984)  loss_rpn_box_reg: 4.2533 (5.6374)  time: 1.5230 (1.5554)  data: 0.0968 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:56:10,453 maskrcnn_benchmark.trainer INFO: eta: 14:35:37  iter: 6220  loss: 4.8145 (6.4203)  loss_classifier: 0.0743 (0.1646)  loss_box_reg: 0.0961 (0.2247)  loss_objectness: 0.2964 (0.3981)  loss_rpn_box_reg: 4.1976 (5.6329)  time: 1.5268 (1.5553)  data: 0.0988 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:56:40,956 maskrcnn_benchmark.trainer INFO: eta: 14:35:03  iter: 6240  loss: 4.8432 (6.4154)  loss_classifier: 0.1349 (0.1646)  loss_box_reg: 0.1661 (0.2246)  loss_objectness: 0.3149 (0.3978)  loss_rpn_box_reg: 4.1706 (5.6284)  time: 1.5241 (1.5552)  data: 0.0966 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 06:56:40,958 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:56:41,014 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:56:42,522 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.507844 (1.5078437328338623 s / img per device, on 1 devices)
2020-12-13 06:56:42,522 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.397178 (1.3971776962280273 s / img per device, on 1 devices)
2020-12-13 06:56:42,522 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:56:42,628 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:56:42,628 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0266, 0.0042, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1.,  2., -1.,  2., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.9977, 0.0000, 0.9275, 0.0000, 0.0000, 0.1928, 0.0876]), 'num_pos': 9}
2020-12-13 06:56:42,633 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.444444
2020-12-13 06:57:13,220 maskrcnn_benchmark.trainer INFO: eta: 14:34:38  iter: 6260  loss: 5.0431 (6.4111)  loss_classifier: 0.2435 (0.1649)  loss_box_reg: 0.2682 (0.2248)  loss_objectness: 0.3069 (0.3975)  loss_rpn_box_reg: 4.2296 (5.6239)  time: 1.5286 (1.5554)  data: 0.1067 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:57:43,783 maskrcnn_benchmark.trainer INFO: eta: 14:34:04  iter: 6280  loss: 4.7109 (6.4058)  loss_classifier: 0.0492 (0.1646)  loss_box_reg: 0.1152 (0.2244)  loss_objectness: 0.3146 (0.3972)  loss_rpn_box_reg: 4.2140 (5.6196)  time: 1.5271 (1.5553)  data: 0.1040 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:58:14,283 maskrcnn_benchmark.trainer INFO: eta: 14:33:29  iter: 6300  loss: 4.8435 (6.4010)  loss_classifier: 0.0680 (0.1644)  loss_box_reg: 0.1419 (0.2242)  loss_objectness: 0.3173 (0.3970)  loss_rpn_box_reg: 4.2588 (5.6153)  time: 1.5262 (1.5552)  data: 0.0966 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 06:58:14,285 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:58:14,335 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:58:15,844 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.509190 (1.5091900825500488 s / img per device, on 1 devices)
2020-12-13 06:58:15,844 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.409261 (1.4092607498168945 s / img per device, on 1 devices)
2020-12-13 06:58:15,845 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:58:15,941 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:58:15,941 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0494, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.1978]), 'num_pos': 9}
2020-12-13 06:58:15,945 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 06:58:46,463 maskrcnn_benchmark.trainer INFO: eta: 14:33:04  iter: 6320  loss: 4.8218 (6.3960)  loss_classifier: 0.0763 (0.1643)  loss_box_reg: 0.1487 (0.2241)  loss_objectness: 0.2978 (0.3967)  loss_rpn_box_reg: 4.2343 (5.6109)  time: 1.5239 (1.5554)  data: 0.0951 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 06:59:16,936 maskrcnn_benchmark.trainer INFO: eta: 14:32:29  iter: 6340  loss: 4.9368 (6.3915)  loss_classifier: 0.1503 (0.1643)  loss_box_reg: 0.2360 (0.2242)  loss_objectness: 0.3038 (0.3964)  loss_rpn_box_reg: 4.2250 (5.6066)  time: 1.5235 (1.5553)  data: 0.0957 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 06:59:47,442 maskrcnn_benchmark.trainer INFO: eta: 14:31:55  iter: 6360  loss: 4.9195 (6.3870)  loss_classifier: 0.1297 (0.1643)  loss_box_reg: 0.2500 (0.2243)  loss_objectness: 0.3148 (0.3961)  loss_rpn_box_reg: 4.2302 (5.6023)  time: 1.5237 (1.5552)  data: 0.0954 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 06:59:47,444 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 06:59:47,493 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 06:59:49,006 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.511970 (1.511970043182373 s / img per device, on 1 devices)
2020-12-13 06:59:49,006 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.409229 (1.4092285633087158 s / img per device, on 1 devices)
2020-12-13 06:59:49,006 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 06:59:49,103 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 06:59:49,103 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([6.6848e-02, 4.1025e-02, 9.1170e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2.,  2., -1.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.4071, 0.9295, 0.0000, 0.1646, 0.7183, 0.4648]), 'num_pos': 9}
2020-12-13 06:59:49,107 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 07:00:19,587 maskrcnn_benchmark.trainer INFO: eta: 14:31:30  iter: 6380  loss: 4.8342 (6.3821)  loss_classifier: 0.1128 (0.1642)  loss_box_reg: 0.1889 (0.2242)  loss_objectness: 0.2726 (0.3958)  loss_rpn_box_reg: 4.1871 (5.5978)  time: 1.5233 (1.5553)  data: 0.0963 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 07:00:50,096 maskrcnn_benchmark.trainer INFO: eta: 14:30:55  iter: 6400  loss: 4.7112 (6.3770)  loss_classifier: 0.0753 (0.1641)  loss_box_reg: 0.1364 (0.2240)  loss_objectness: 0.3114 (0.3956)  loss_rpn_box_reg: 4.1626 (5.5933)  time: 1.5251 (1.5552)  data: 0.0974 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:01:20,589 maskrcnn_benchmark.trainer INFO: eta: 14:30:21  iter: 6420  loss: 4.8547 (6.3723)  loss_classifier: 0.1279 (0.1641)  loss_box_reg: 0.1618 (0.2240)  loss_objectness: 0.3244 (0.3953)  loss_rpn_box_reg: 4.1684 (5.5889)  time: 1.5245 (1.5551)  data: 0.0961 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:01:20,591 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:01:20,640 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:01:22,138 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.497675 (1.4976747035980225 s / img per device, on 1 devices)
2020-12-13 07:01:22,138 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.396513 (1.3965134620666504 s / img per device, on 1 devices)
2020-12-13 07:01:22,139 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:01:22,235 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:01:22,235 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.1956e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1., -1., -1., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.7559, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6342, 0.0806]), 'num_pos': 9}
2020-12-13 07:01:22,240 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 07:01:52,758 maskrcnn_benchmark.trainer INFO: eta: 14:29:55  iter: 6440  loss: 5.0048 (6.3681)  loss_classifier: 0.1899 (0.1642)  loss_box_reg: 0.2615 (0.2241)  loss_objectness: 0.3072 (0.3951)  loss_rpn_box_reg: 4.2422 (5.5848)  time: 1.5251 (1.5553)  data: 0.0990 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 07:02:23,333 maskrcnn_benchmark.trainer INFO: eta: 14:29:22  iter: 6460  loss: 4.7499 (6.3633)  loss_classifier: 0.1443 (0.1641)  loss_box_reg: 0.1673 (0.2241)  loss_objectness: 0.2750 (0.3948)  loss_rpn_box_reg: 4.1215 (5.5803)  time: 1.5290 (1.5552)  data: 0.1045 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:02:53,826 maskrcnn_benchmark.trainer INFO: eta: 14:28:47  iter: 6480  loss: 4.7869 (6.3584)  loss_classifier: 0.0599 (0.1639)  loss_box_reg: 0.1700 (0.2239)  loss_objectness: 0.3163 (0.3945)  loss_rpn_box_reg: 4.2224 (5.5760)  time: 1.5258 (1.5551)  data: 0.0988 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:02:53,828 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:02:53,877 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:02:55,379 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.501189 (1.5011885166168213 s / img per device, on 1 devices)
2020-12-13 07:02:55,379 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.400539 (1.4005389213562012 s / img per device, on 1 devices)
2020-12-13 07:02:55,379 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:02:55,477 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:02:55,477 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([9.0884e-02, 3.4667e-03, 3.3349e-04, 2.5015e-07, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1.,  2.,  2.,  2.,  2.,  2.,  2.,  4.]), 'best match scores': tensor([1.0000, 0.0000, 0.3152, 0.2619, 0.1368, 0.9997, 0.9991, 0.9998, 0.1865]), 'num_pos': 9}
2020-12-13 07:02:55,482 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.777778
2020-12-13 07:03:26,076 maskrcnn_benchmark.trainer INFO: eta: 14:28:22  iter: 6500  loss: 4.7943 (6.3535)  loss_classifier: 0.0582 (0.1636)  loss_box_reg: 0.1581 (0.2238)  loss_objectness: 0.2894 (0.3943)  loss_rpn_box_reg: 4.2322 (5.5719)  time: 1.5290 (1.5553)  data: 0.1054 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 07:03:56,578 maskrcnn_benchmark.trainer INFO: eta: 14:27:48  iter: 6520  loss: 4.6842 (6.3489)  loss_classifier: 0.1071 (0.1636)  loss_box_reg: 0.2044 (0.2238)  loss_objectness: 0.2856 (0.3940)  loss_rpn_box_reg: 4.1055 (5.5675)  time: 1.5218 (1.5552)  data: 0.0965 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:04:27,140 maskrcnn_benchmark.trainer INFO: eta: 14:27:14  iter: 6540  loss: 4.9363 (6.3446)  loss_classifier: 0.1961 (0.1638)  loss_box_reg: 0.2270 (0.2238)  loss_objectness: 0.2758 (0.3937)  loss_rpn_box_reg: 4.1799 (5.5633)  time: 1.5274 (1.5551)  data: 0.1055 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:04:27,142 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:04:27,191 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:04:28,702 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.510393 (1.5103933811187744 s / img per device, on 1 devices)
2020-12-13 07:04:28,702 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.408430 (1.4084298610687256 s / img per device, on 1 devices)
2020-12-13 07:04:28,702 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:04:28,800 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:04:28,800 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([7.9167e-03, 1.4988e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 1.0000, 0.9988, 0.1340, 1.0000, 1.0000, 0.0966]), 'num_pos': 9}
2020-12-13 07:04:28,804 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 07:04:59,313 maskrcnn_benchmark.trainer INFO: eta: 14:26:48  iter: 6560  loss: 4.7291 (6.3396)  loss_classifier: 0.0754 (0.1636)  loss_box_reg: 0.0901 (0.2236)  loss_objectness: 0.2979 (0.3933)  loss_rpn_box_reg: 4.1465 (5.5591)  time: 1.5223 (1.5553)  data: 0.0969 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 07:05:29,789 maskrcnn_benchmark.trainer INFO: eta: 14:26:14  iter: 6580  loss: 4.6313 (6.3347)  loss_classifier: 0.1305 (0.1635)  loss_box_reg: 0.1399 (0.2234)  loss_objectness: 0.3085 (0.3931)  loss_rpn_box_reg: 4.1201 (5.5547)  time: 1.5212 (1.5552)  data: 0.0961 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:06:00,253 maskrcnn_benchmark.trainer INFO: eta: 14:25:40  iter: 6600  loss: 4.6384 (6.3300)  loss_classifier: 0.1244 (0.1634)  loss_box_reg: 0.2249 (0.2234)  loss_objectness: 0.2959 (0.3928)  loss_rpn_box_reg: 4.1201 (5.5503)  time: 1.5225 (1.5551)  data: 0.0968 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:06:00,255 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:06:00,305 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:06:01,818 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.512710 (1.5127103328704834 s / img per device, on 1 devices)
2020-12-13 07:06:01,818 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.410222 (1.4102222919464111 s / img per device, on 1 devices)
2020-12-13 07:06:01,818 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:06:01,913 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:06:01,913 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([3.6679e-03, 9.3864e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1.,  2., -1.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.9027, 0.0000, 0.0000, 0.2738, 0.0000, 0.2006, 0.1301, 0.9994, 0.3800]), 'num_pos': 9}
2020-12-13 07:06:01,918 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 07:06:32,427 maskrcnn_benchmark.trainer INFO: eta: 14:25:14  iter: 6620  loss: 4.7419 (6.3251)  loss_classifier: 0.0770 (0.1632)  loss_box_reg: 0.1328 (0.2232)  loss_objectness: 0.3088 (0.3925)  loss_rpn_box_reg: 4.1402 (5.5462)  time: 1.5238 (1.5553)  data: 0.1001 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 07:07:02,940 maskrcnn_benchmark.trainer INFO: eta: 14:24:40  iter: 6640  loss: 4.8557 (6.3205)  loss_classifier: 0.1850 (0.1633)  loss_box_reg: 0.2270 (0.2233)  loss_objectness: 0.2828 (0.3922)  loss_rpn_box_reg: 4.0510 (5.5416)  time: 1.5249 (1.5552)  data: 0.0965 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:07:33,370 maskrcnn_benchmark.trainer INFO: eta: 14:24:06  iter: 6660  loss: 4.7584 (6.3157)  loss_classifier: 0.1240 (0.1632)  loss_box_reg: 0.1774 (0.2231)  loss_objectness: 0.3093 (0.3920)  loss_rpn_box_reg: 4.1437 (5.5374)  time: 1.5208 (1.5551)  data: 0.0954 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:07:33,372 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:07:33,421 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:07:34,920 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.498961 (1.4989607334136963 s / img per device, on 1 devices)
2020-12-13 07:07:34,920 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.398784 (1.3987843990325928 s / img per device, on 1 devices)
2020-12-13 07:07:34,920 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:07:35,016 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:07:35,016 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([2.3784e-02, 2.9660e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1., -1., -1., -1., -1., -1.,  2.]), 'best match scores': tensor([1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4178]), 'num_pos': 9}
2020-12-13 07:07:35,020 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 07:08:05,481 maskrcnn_benchmark.trainer INFO: eta: 14:23:39  iter: 6680  loss: 4.7438 (6.3111)  loss_classifier: 0.1348 (0.1631)  loss_box_reg: 0.1893 (0.2230)  loss_objectness: 0.2646 (0.3917)  loss_rpn_box_reg: 4.1191 (5.5332)  time: 1.5233 (1.5552)  data: 0.0954 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 07:08:35,953 maskrcnn_benchmark.trainer INFO: eta: 14:23:05  iter: 6700  loss: 4.7086 (6.3062)  loss_classifier: 0.1037 (0.1629)  loss_box_reg: 0.2262 (0.2231)  loss_objectness: 0.2593 (0.3914)  loss_rpn_box_reg: 4.0700 (5.5288)  time: 1.5221 (1.5551)  data: 0.0964 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:09:06,399 maskrcnn_benchmark.trainer INFO: eta: 14:22:31  iter: 6720  loss: 4.6484 (6.3014)  loss_classifier: 0.0918 (0.1628)  loss_box_reg: 0.1308 (0.2230)  loss_objectness: 0.2917 (0.3911)  loss_rpn_box_reg: 4.0989 (5.5245)  time: 1.5219 (1.5550)  data: 0.0967 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:09:06,401 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:09:06,451 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:09:07,957 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.505801 (1.505800724029541 s / img per device, on 1 devices)
2020-12-13 07:09:07,958 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.400488 (1.4004881381988525 s / img per device, on 1 devices)
2020-12-13 07:09:07,958 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:09:08,084 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:09:08,084 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0117, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  2., -1., -1., -1., -1., -1., -1., -1.]), 'best match scores': tensor([0.0000, 0.7207, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'num_pos': 9}
2020-12-13 07:09:08,088 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.111111
2020-12-13 07:09:38,660 maskrcnn_benchmark.trainer INFO: eta: 14:22:05  iter: 6740  loss: 4.7040 (6.2967)  loss_classifier: 0.0944 (0.1626)  loss_box_reg: 0.1749 (0.2228)  loss_objectness: 0.2654 (0.3908)  loss_rpn_box_reg: 4.2377 (5.5206)  time: 1.5270 (1.5552)  data: 0.0991 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 07:10:09,141 maskrcnn_benchmark.trainer INFO: eta: 14:21:31  iter: 6760  loss: 4.6673 (6.2918)  loss_classifier: 0.0845 (0.1624)  loss_box_reg: 0.1643 (0.2225)  loss_objectness: 0.2463 (0.3904)  loss_rpn_box_reg: 4.1034 (5.5164)  time: 1.5232 (1.5551)  data: 0.0979 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:10:39,632 maskrcnn_benchmark.trainer INFO: eta: 14:20:57  iter: 6780  loss: 4.6734 (6.2873)  loss_classifier: 0.0762 (0.1624)  loss_box_reg: 0.1919 (0.2225)  loss_objectness: 0.2890 (0.3902)  loss_rpn_box_reg: 4.1499 (5.5122)  time: 1.5228 (1.5550)  data: 0.0982 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:10:39,634 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:10:39,683 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:10:41,188 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.504812 (1.504812479019165 s / img per device, on 1 devices)
2020-12-13 07:10:41,188 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.400298 (1.4002983570098877 s / img per device, on 1 devices)
2020-12-13 07:10:41,188 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:10:41,292 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:10:41,292 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([8.6996e-09, 9.4314e-11, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.7487, 0.0000, 0.3046, 0.9118, 0.1705, 0.9986, 1.0000, 0.9999, 1.0000]), 'num_pos': 9}
2020-12-13 07:10:41,296 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.888889
2020-12-13 07:11:11,769 maskrcnn_benchmark.trainer INFO: eta: 14:20:31  iter: 6800  loss: 4.7513 (6.2830)  loss_classifier: 0.1563 (0.1625)  loss_box_reg: 0.2082 (0.2225)  loss_objectness: 0.2918 (0.3899)  loss_rpn_box_reg: 4.1037 (5.5080)  time: 1.5233 (1.5552)  data: 0.0981 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 07:11:42,255 maskrcnn_benchmark.trainer INFO: eta: 14:19:57  iter: 6820  loss: 4.8187 (6.2788)  loss_classifier: 0.1488 (0.1625)  loss_box_reg: 0.1847 (0.2226)  loss_objectness: 0.2988 (0.3897)  loss_rpn_box_reg: 4.1255 (5.5039)  time: 1.5246 (1.5551)  data: 0.0982 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:12:12,802 maskrcnn_benchmark.trainer INFO: eta: 14:19:23  iter: 6840  loss: 4.5817 (6.2741)  loss_classifier: 0.0997 (0.1624)  loss_box_reg: 0.1538 (0.2225)  loss_objectness: 0.2733 (0.3894)  loss_rpn_box_reg: 4.0610 (5.4998)  time: 1.5280 (1.5550)  data: 0.0973 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:12:12,804 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:12:12,853 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:12:14,361 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.507194 (1.5071940422058105 s / img per device, on 1 devices)
2020-12-13 07:12:14,361 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.403825 (1.4038245677947998 s / img per device, on 1 devices)
2020-12-13 07:12:14,361 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:12:14,463 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:12:14,463 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([3.8194e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1., -1., -1.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.9959, 0.0000, 0.0000, 0.0000, 0.0000, 0.6509, 0.4251, 1.0000, 0.5159]), 'num_pos': 9}
2020-12-13 07:12:14,468 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 07:12:44,994 maskrcnn_benchmark.trainer INFO: eta: 14:18:57  iter: 6860  loss: 4.6564 (6.2695)  loss_classifier: 0.1030 (0.1623)  loss_box_reg: 0.1942 (0.2224)  loss_objectness: 0.2876 (0.3892)  loss_rpn_box_reg: 4.0614 (5.4956)  time: 1.5249 (1.5552)  data: 0.0969 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:13:15,485 maskrcnn_benchmark.trainer INFO: eta: 14:18:23  iter: 6880  loss: 4.4929 (6.2647)  loss_classifier: 0.0559 (0.1621)  loss_box_reg: 0.0978 (0.2221)  loss_objectness: 0.2928 (0.3890)  loss_rpn_box_reg: 4.0401 (5.4915)  time: 1.5246 (1.5551)  data: 0.0974 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:13:46,012 maskrcnn_benchmark.trainer INFO: eta: 14:17:50  iter: 6900  loss: 4.6022 (6.2599)  loss_classifier: 0.0744 (0.1619)  loss_box_reg: 0.1293 (0.2219)  loss_objectness: 0.2903 (0.3887)  loss_rpn_box_reg: 4.0622 (5.4874)  time: 1.5259 (1.5550)  data: 0.0975 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:13:46,014 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:13:46,064 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:13:47,579 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.514808 (1.5148084163665771 s / img per device, on 1 devices)
2020-12-13 07:13:47,580 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.408739 (1.408738613128662 s / img per device, on 1 devices)
2020-12-13 07:13:47,580 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:13:47,684 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:13:47,684 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1079, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2., -1., -1., -1., -1.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.9304, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]), 'num_pos': 9}
2020-12-13 07:13:47,688 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 07:14:18,208 maskrcnn_benchmark.trainer INFO: eta: 14:17:24  iter: 6920  loss: 4.7004 (6.2554)  loss_classifier: 0.1151 (0.1618)  loss_box_reg: 0.1765 (0.2219)  loss_objectness: 0.3044 (0.3884)  loss_rpn_box_reg: 4.0859 (5.4833)  time: 1.5250 (1.5551)  data: 0.0976 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:14:48,717 maskrcnn_benchmark.trainer INFO: eta: 14:16:50  iter: 6940  loss: 4.6883 (6.2510)  loss_classifier: 0.1427 (0.1617)  loss_box_reg: 0.1154 (0.2218)  loss_objectness: 0.2534 (0.3881)  loss_rpn_box_reg: 4.1020 (5.4794)  time: 1.5256 (1.5551)  data: 0.0976 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:15:19,215 maskrcnn_benchmark.trainer INFO: eta: 14:16:16  iter: 6960  loss: 4.5686 (6.2463)  loss_classifier: 0.0723 (0.1616)  loss_box_reg: 0.1633 (0.2217)  loss_objectness: 0.2846 (0.3878)  loss_rpn_box_reg: 3.9668 (5.4751)  time: 1.5232 (1.5550)  data: 0.0973 (0.1281)  lr: 0.000000  max mem: 986
2020-12-13 07:15:19,217 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:15:19,266 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:15:20,781 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.514377 (1.5143773555755615 s / img per device, on 1 devices)
2020-12-13 07:15:20,781 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.410184 (1.410184383392334 s / img per device, on 1 devices)
2020-12-13 07:15:20,781 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:15:20,885 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:15:20,886 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1432, 0.1160, 0.0011, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.9913, 0.4869, 0.8698, 0.9958, 0.9825, 1.0000]), 'num_pos': 9}
2020-12-13 07:15:20,890 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 07:15:51,428 maskrcnn_benchmark.trainer INFO: eta: 14:15:50  iter: 6980  loss: 4.7382 (6.2419)  loss_classifier: 0.1457 (0.1616)  loss_box_reg: 0.2259 (0.2217)  loss_objectness: 0.2762 (0.3875)  loss_rpn_box_reg: 4.0073 (5.4710)  time: 1.5279 (1.5551)  data: 0.0994 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:16:21,980 maskrcnn_benchmark.trainer INFO: eta: 14:15:16  iter: 7000  loss: 4.6195 (6.2373)  loss_classifier: 0.0977 (0.1615)  loss_box_reg: 0.1446 (0.2216)  loss_objectness: 0.2899 (0.3873)  loss_rpn_box_reg: 4.0051 (5.4669)  time: 1.5283 (1.5551)  data: 0.0998 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:16:52,525 maskrcnn_benchmark.trainer INFO: eta: 14:14:43  iter: 7020  loss: 4.6170 (6.2327)  loss_classifier: 0.0590 (0.1613)  loss_box_reg: 0.1384 (0.2213)  loss_objectness: 0.2863 (0.3870)  loss_rpn_box_reg: 4.0817 (5.4630)  time: 1.5259 (1.5550)  data: 0.0998 (0.1281)  lr: 0.000000  max mem: 986
2020-12-13 07:16:52,527 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:16:52,581 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:16:54,083 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.501684 (1.5016837120056152 s / img per device, on 1 devices)
2020-12-13 07:16:54,083 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.394504 (1.3945035934448242 s / img per device, on 1 devices)
2020-12-13 07:16:54,084 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:16:54,186 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:16:54,186 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1., -1.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9627, 1.0000]), 'num_pos': 9}
2020-12-13 07:16:54,190 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 07:17:24,737 maskrcnn_benchmark.trainer INFO: eta: 14:14:17  iter: 7040  loss: 4.4253 (6.2277)  loss_classifier: 0.0449 (0.1610)  loss_box_reg: 0.0670 (0.2210)  loss_objectness: 0.2708 (0.3867)  loss_rpn_box_reg: 3.9682 (5.4589)  time: 1.5255 (1.5551)  data: 0.0992 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:17:55,288 maskrcnn_benchmark.trainer INFO: eta: 14:13:43  iter: 7060  loss: 4.4947 (6.2229)  loss_classifier: 0.0559 (0.1608)  loss_box_reg: 0.1131 (0.2207)  loss_objectness: 0.3022 (0.3865)  loss_rpn_box_reg: 4.0135 (5.4548)  time: 1.5247 (1.5551)  data: 0.1006 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:18:25,878 maskrcnn_benchmark.trainer INFO: eta: 14:13:10  iter: 7080  loss: 4.6447 (6.2184)  loss_classifier: 0.0592 (0.1606)  loss_box_reg: 0.2702 (0.2208)  loss_objectness: 0.2715 (0.3862)  loss_rpn_box_reg: 3.9982 (5.4508)  time: 1.5281 (1.5550)  data: 0.0994 (0.1281)  lr: 0.000000  max mem: 986
2020-12-13 07:18:25,880 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:18:25,937 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:18:27,452 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.515108 (1.5151078701019287 s / img per device, on 1 devices)
2020-12-13 07:18:27,452 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.407158 (1.407158374786377 s / img per device, on 1 devices)
2020-12-13 07:18:27,453 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:18:27,556 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:18:27,556 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.5643e-03, 1.7311e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2.,  2., -1., -1., -1., -1., -1., -1.,  2.]), 'best match scores': tensor([0.9295, 0.0777, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3662]), 'num_pos': 9}
2020-12-13 07:18:27,560 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 07:18:58,129 maskrcnn_benchmark.trainer INFO: eta: 14:12:44  iter: 7100  loss: 4.6484 (6.2141)  loss_classifier: 0.1556 (0.1606)  loss_box_reg: 0.1960 (0.2208)  loss_objectness: 0.2924 (0.3859)  loss_rpn_box_reg: 4.0712 (5.4467)  time: 1.5287 (1.5551)  data: 0.1004 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:19:28,711 maskrcnn_benchmark.trainer INFO: eta: 14:12:10  iter: 7120  loss: 4.4947 (6.2094)  loss_classifier: 0.1407 (0.1606)  loss_box_reg: 0.1118 (0.2206)  loss_objectness: 0.2992 (0.3857)  loss_rpn_box_reg: 3.9444 (5.4425)  time: 1.5299 (1.5551)  data: 0.1000 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:19:59,314 maskrcnn_benchmark.trainer INFO: eta: 14:11:37  iter: 7140  loss: 4.6276 (6.2051)  loss_classifier: 0.1077 (0.1605)  loss_box_reg: 0.1706 (0.2207)  loss_objectness: 0.2924 (0.3854)  loss_rpn_box_reg: 4.0388 (5.4385)  time: 1.5303 (1.5550)  data: 0.1052 (0.1281)  lr: 0.000000  max mem: 986
2020-12-13 07:19:59,315 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:19:59,371 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:20:00,886 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.515230 (1.5152299404144287 s / img per device, on 1 devices)
2020-12-13 07:20:00,887 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.408121 (1.4081206321716309 s / img per device, on 1 devices)
2020-12-13 07:20:00,887 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:20:00,990 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:20:00,990 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1439, 0.0766, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1., -1., -1., -1., -1.,  2., -1.]), 'best match scores': tensor([0.5267, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0840, 0.0000]), 'num_pos': 9}
2020-12-13 07:20:00,995 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 07:20:31,548 maskrcnn_benchmark.trainer INFO: eta: 14:11:11  iter: 7160  loss: 4.4998 (6.2005)  loss_classifier: 0.0841 (0.1603)  loss_box_reg: 0.0770 (0.2204)  loss_objectness: 0.2703 (0.3852)  loss_rpn_box_reg: 4.0278 (5.4346)  time: 1.5272 (1.5552)  data: 0.0985 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:21:02,108 maskrcnn_benchmark.trainer INFO: eta: 14:10:37  iter: 7180  loss: 4.5563 (6.1961)  loss_classifier: 0.0637 (0.1601)  loss_box_reg: 0.1824 (0.2204)  loss_objectness: 0.2863 (0.3849)  loss_rpn_box_reg: 4.0430 (5.4307)  time: 1.5262 (1.5551)  data: 0.0994 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:21:32,673 maskrcnn_benchmark.trainer INFO: eta: 14:10:04  iter: 7200  loss: 4.6071 (6.1918)  loss_classifier: 0.1054 (0.1601)  loss_box_reg: 0.1540 (0.2202)  loss_objectness: 0.3134 (0.3847)  loss_rpn_box_reg: 4.0217 (5.4267)  time: 1.5288 (1.5550)  data: 0.0983 (0.1281)  lr: 0.000000  max mem: 986
2020-12-13 07:21:32,676 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:21:32,731 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:21:34,242 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.510893 (1.5108933448791504 s / img per device, on 1 devices)
2020-12-13 07:21:34,242 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.405746 (1.4057462215423584 s / img per device, on 1 devices)
2020-12-13 07:21:34,242 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:21:34,344 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:21:34,344 maskrcnn_benchmark.inference INFO: {'ar': 0, 'recalls': 0, 'thresholds': 0, 'gt_overlaps': 0, 'gt_labels': tensor([]), 'best match labels': tensor([]), 'best match scores': tensor([]), 'num_pos': 0}
2020-12-13 07:21:34,345 maskrcnn_benchmark.trainer INFO: validation accuracy: -1.000000
2020-12-13 07:22:04,949 maskrcnn_benchmark.trainer INFO: eta: 14:09:38  iter: 7220  loss: 4.5326 (6.1872)  loss_classifier: 0.1123 (0.1600)  loss_box_reg: 0.1600 (0.2201)  loss_objectness: 0.2875 (0.3844)  loss_rpn_box_reg: 3.9344 (5.4227)  time: 1.5291 (1.5552)  data: 0.0988 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:22:35,609 maskrcnn_benchmark.trainer INFO: eta: 14:09:05  iter: 7240  loss: 4.5455 (6.1827)  loss_classifier: 0.0979 (0.1598)  loss_box_reg: 0.1528 (0.2200)  loss_objectness: 0.3112 (0.3842)  loss_rpn_box_reg: 3.9416 (5.4186)  time: 1.5339 (1.5551)  data: 0.1097 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:23:06,168 maskrcnn_benchmark.trainer INFO: eta: 14:08:31  iter: 7260  loss: 4.4778 (6.1781)  loss_classifier: 0.1198 (0.1598)  loss_box_reg: 0.1464 (0.2199)  loss_objectness: 0.2548 (0.3840)  loss_rpn_box_reg: 3.9060 (5.4145)  time: 1.5267 (1.5550)  data: 0.1010 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:23:06,170 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:23:06,226 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:23:07,742 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.515845 (1.5158448219299316 s / img per device, on 1 devices)
2020-12-13 07:23:07,742 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.408079 (1.408078908920288 s / img per device, on 1 devices)
2020-12-13 07:23:07,742 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:23:07,846 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:23:07,846 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1405, 0.0576, 0.0567, 0.0067, 0.0047, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2.,  2., -1.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.9739, 0.4314, 0.0000, 0.1494, 0.2710, 0.6913, 1.0000, 0.3218, 0.9996]), 'num_pos': 9}
2020-12-13 07:23:07,851 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.888889
2020-12-13 07:23:38,378 maskrcnn_benchmark.trainer INFO: eta: 14:08:05  iter: 7280  loss: 4.5286 (6.1738)  loss_classifier: 0.1065 (0.1596)  loss_box_reg: 0.1556 (0.2198)  loss_objectness: 0.3197 (0.3838)  loss_rpn_box_reg: 4.0131 (5.4106)  time: 1.5256 (1.5552)  data: 0.1007 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:24:08,968 maskrcnn_benchmark.trainer INFO: eta: 14:07:32  iter: 7300  loss: 4.5326 (6.1693)  loss_classifier: 0.0842 (0.1595)  loss_box_reg: 0.1471 (0.2196)  loss_objectness: 0.2669 (0.3835)  loss_rpn_box_reg: 4.0084 (5.4067)  time: 1.5276 (1.5551)  data: 0.1012 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:24:39,546 maskrcnn_benchmark.trainer INFO: eta: 14:06:58  iter: 7320  loss: 4.5592 (6.1650)  loss_classifier: 0.1001 (0.1594)  loss_box_reg: 0.1917 (0.2195)  loss_objectness: 0.2998 (0.3833)  loss_rpn_box_reg: 4.0342 (5.4029)  time: 1.5261 (1.5550)  data: 0.1010 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:24:39,548 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:24:39,602 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:24:41,115 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.512794 (1.512794017791748 s / img per device, on 1 devices)
2020-12-13 07:24:41,116 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.404941 (1.4049410820007324 s / img per device, on 1 devices)
2020-12-13 07:24:41,116 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:24:41,240 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:24:41,241 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9965, 0.9997, 0.8716, 0.2097]), 'num_pos': 9}
2020-12-13 07:24:41,245 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.444444
2020-12-13 07:25:11,782 maskrcnn_benchmark.trainer INFO: eta: 14:06:32  iter: 7340  loss: 4.4654 (6.1606)  loss_classifier: 0.0799 (0.1592)  loss_box_reg: 0.1037 (0.2194)  loss_objectness: 0.2858 (0.3830)  loss_rpn_box_reg: 4.0014 (5.3989)  time: 1.5265 (1.5552)  data: 0.1006 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:25:42,321 maskrcnn_benchmark.trainer INFO: eta: 14:05:59  iter: 7360  loss: 4.4732 (6.1560)  loss_classifier: 0.0691 (0.1590)  loss_box_reg: 0.1637 (0.2193)  loss_objectness: 0.2984 (0.3828)  loss_rpn_box_reg: 3.9655 (5.3950)  time: 1.5247 (1.5551)  data: 0.1011 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:26:12,919 maskrcnn_benchmark.trainer INFO: eta: 14:05:25  iter: 7380  loss: 4.5619 (6.1519)  loss_classifier: 0.1021 (0.1590)  loss_box_reg: 0.2521 (0.2193)  loss_objectness: 0.2712 (0.3825)  loss_rpn_box_reg: 3.9737 (5.3911)  time: 1.5261 (1.5551)  data: 0.1002 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:26:12,920 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:26:12,976 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:26:14,487 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.510617 (1.5106172561645508 s / img per device, on 1 devices)
2020-12-13 07:26:14,487 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.403075 (1.4030749797821045 s / img per device, on 1 devices)
2020-12-13 07:26:14,487 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:26:14,590 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:26:14,591 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([3.2854e-03, 2.3754e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1.,  2., -1.,  6.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3654, 0.0000, 0.1297, 0.7999]), 'num_pos': 9}
2020-12-13 07:26:14,595 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 07:26:45,147 maskrcnn_benchmark.trainer INFO: eta: 14:04:59  iter: 7400  loss: 4.4249 (6.1472)  loss_classifier: 0.0734 (0.1587)  loss_box_reg: 0.1403 (0.2191)  loss_objectness: 0.2593 (0.3822)  loss_rpn_box_reg: 3.9251 (5.3872)  time: 1.5276 (1.5552)  data: 0.1015 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:27:15,683 maskrcnn_benchmark.trainer INFO: eta: 14:04:26  iter: 7420  loss: 4.5475 (6.1430)  loss_classifier: 0.0844 (0.1586)  loss_box_reg: 0.1802 (0.2191)  loss_objectness: 0.2757 (0.3819)  loss_rpn_box_reg: 3.9668 (5.3834)  time: 1.5273 (1.5551)  data: 0.1012 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:27:46,181 maskrcnn_benchmark.trainer INFO: eta: 14:03:52  iter: 7440  loss: 4.5357 (6.1386)  loss_classifier: 0.0921 (0.1584)  loss_box_reg: 0.1300 (0.2190)  loss_objectness: 0.2825 (0.3816)  loss_rpn_box_reg: 3.9660 (5.3796)  time: 1.5234 (1.5551)  data: 0.1007 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:27:46,183 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:27:46,240 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:27:47,744 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.503560 (1.5035603046417236 s / img per device, on 1 devices)
2020-12-13 07:27:47,744 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.396825 (1.396824598312378 s / img per device, on 1 devices)
2020-12-13 07:27:47,744 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:27:47,847 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:27:47,848 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1674, 0.0909, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.7362, 0.1462, 0.9444, 0.5859, 0.6805, 0.9620]), 'num_pos': 9}
2020-12-13 07:27:47,852 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 07:28:18,318 maskrcnn_benchmark.trainer INFO: eta: 14:03:25  iter: 7460  loss: 4.4946 (6.1342)  loss_classifier: 0.1268 (0.1583)  loss_box_reg: 0.1635 (0.2188)  loss_objectness: 0.2950 (0.3814)  loss_rpn_box_reg: 3.8914 (5.3756)  time: 1.5211 (1.5552)  data: 0.0963 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:28:48,771 maskrcnn_benchmark.trainer INFO: eta: 14:02:51  iter: 7480  loss: 4.4693 (6.1299)  loss_classifier: 0.0836 (0.1582)  loss_box_reg: 0.1862 (0.2187)  loss_objectness: 0.3235 (0.3812)  loss_rpn_box_reg: 3.9586 (5.3718)  time: 1.5205 (1.5551)  data: 0.0953 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:29:19,229 maskrcnn_benchmark.trainer INFO: eta: 14:02:18  iter: 7500  loss: 4.5094 (6.1257)  loss_classifier: 0.0638 (0.1581)  loss_box_reg: 0.2070 (0.2187)  loss_objectness: 0.2628 (0.3809)  loss_rpn_box_reg: 3.9592 (5.3680)  time: 1.5235 (1.5550)  data: 0.0954 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:29:19,231 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./model_0007500.pth
2020-12-13 07:29:20,424 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:29:20,497 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:29:22,006 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.508342 (1.5083422660827637 s / img per device, on 1 devices)
2020-12-13 07:29:22,006 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.406116 (1.406116008758545 s / img per device, on 1 devices)
2020-12-13 07:29:22,006 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:29:22,101 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:29:22,101 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1660, 0.0560, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1.,  2., -1.,  2., -1.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.9998, 0.0000, 0.9866, 0.0000, 0.3280, 0.5159, 0.9702]), 'num_pos': 9}
2020-12-13 07:29:22,106 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 07:29:52,566 maskrcnn_benchmark.trainer INFO: eta: 14:01:56  iter: 7520  loss: 4.4518 (6.1214)  loss_classifier: 0.0490 (0.1579)  loss_box_reg: 0.1566 (0.2185)  loss_objectness: 0.2620 (0.3807)  loss_rpn_box_reg: 3.9724 (5.3643)  time: 1.5189 (1.5553)  data: 0.0957 (0.1285)  lr: 0.000000  max mem: 986
2020-12-13 07:30:23,031 maskrcnn_benchmark.trainer INFO: eta: 14:01:22  iter: 7540  loss: 4.6257 (6.1175)  loss_classifier: 0.1252 (0.1578)  loss_box_reg: 0.2373 (0.2187)  loss_objectness: 0.2720 (0.3804)  loss_rpn_box_reg: 3.9191 (5.3605)  time: 1.5224 (1.5552)  data: 0.0956 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 07:30:53,480 maskrcnn_benchmark.trainer INFO: eta: 14:00:48  iter: 7560  loss: 4.3658 (6.1128)  loss_classifier: 0.0723 (0.1576)  loss_box_reg: 0.1149 (0.2186)  loss_objectness: 0.2805 (0.3802)  loss_rpn_box_reg: 3.8267 (5.3564)  time: 1.5207 (1.5551)  data: 0.0950 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:30:53,482 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:30:53,532 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:30:55,039 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.507071 (1.5070710182189941 s / img per device, on 1 devices)
2020-12-13 07:30:55,039 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.405289 (1.4052886962890625 s / img per device, on 1 devices)
2020-12-13 07:30:55,039 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:30:55,134 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:30:55,134 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.2056, 0.1405, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.3934, 0.8679, 1.0000, 0.4234, 0.9809, 0.9987, 0.9968]), 'num_pos': 9}
2020-12-13 07:30:55,139 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.777778
2020-12-13 07:31:25,617 maskrcnn_benchmark.trainer INFO: eta: 14:00:22  iter: 7580  loss: 4.5530 (6.1086)  loss_classifier: 0.1017 (0.1575)  loss_box_reg: 0.2701 (0.2187)  loss_objectness: 0.2497 (0.3799)  loss_rpn_box_reg: 3.8814 (5.3524)  time: 1.5234 (1.5553)  data: 0.0960 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 07:31:56,066 maskrcnn_benchmark.trainer INFO: eta: 13:59:48  iter: 7600  loss: 4.5947 (6.1046)  loss_classifier: 0.1329 (0.1575)  loss_box_reg: 0.2162 (0.2187)  loss_objectness: 0.2829 (0.3797)  loss_rpn_box_reg: 3.9097 (5.3487)  time: 1.5241 (1.5552)  data: 0.0954 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:32:26,527 maskrcnn_benchmark.trainer INFO: eta: 13:59:14  iter: 7620  loss: 4.6184 (6.1008)  loss_classifier: 0.1873 (0.1576)  loss_box_reg: 0.3033 (0.2190)  loss_objectness: 0.2994 (0.3795)  loss_rpn_box_reg: 3.8473 (5.3448)  time: 1.5237 (1.5551)  data: 0.0955 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:32:26,528 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:32:26,577 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:32:28,082 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.505453 (1.5054526329040527 s / img per device, on 1 devices)
2020-12-13 07:32:28,083 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.403000 (1.4029998779296875 s / img per device, on 1 devices)
2020-12-13 07:32:28,083 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:32:28,177 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:32:28,177 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1277, 0.0733, 0.0465, 0.0463, 0.0077, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 2.]), 'best match scores': tensor([0.9955, 0.1056, 0.5069, 1.0000, 0.9999, 0.7511, 0.0952, 0.0684, 0.9837]), 'num_pos': 9}
2020-12-13 07:32:28,183 maskrcnn_benchmark.trainer INFO: validation accuracy: 1.000000
2020-12-13 07:32:58,671 maskrcnn_benchmark.trainer INFO: eta: 13:58:47  iter: 7640  loss: 4.4857 (6.0968)  loss_classifier: 0.1125 (0.1576)  loss_box_reg: 0.1175 (0.2190)  loss_objectness: 0.2763 (0.3792)  loss_rpn_box_reg: 3.9265 (5.3410)  time: 1.5237 (1.5552)  data: 0.0966 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 07:33:29,138 maskrcnn_benchmark.trainer INFO: eta: 13:58:13  iter: 7660  loss: 4.4296 (6.0927)  loss_classifier: 0.1301 (0.1576)  loss_box_reg: 0.1656 (0.2189)  loss_objectness: 0.2856 (0.3790)  loss_rpn_box_reg: 3.8714 (5.3371)  time: 1.5230 (1.5552)  data: 0.0960 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:33:59,608 maskrcnn_benchmark.trainer INFO: eta: 13:57:40  iter: 7680  loss: 4.5269 (6.0885)  loss_classifier: 0.1011 (0.1575)  loss_box_reg: 0.2271 (0.2189)  loss_objectness: 0.2984 (0.3787)  loss_rpn_box_reg: 3.8356 (5.3333)  time: 1.5245 (1.5551)  data: 0.0959 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:33:59,610 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:33:59,660 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:34:01,165 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.504704 (1.504704236984253 s / img per device, on 1 devices)
2020-12-13 07:34:01,165 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.403315 (1.4033153057098389 s / img per device, on 1 devices)
2020-12-13 07:34:01,165 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:34:01,259 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:34:01,260 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0450, 0.0385, 0.0022, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1.,  2.,  7.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.9996, 0.9988, 1.0000, 0.9585, 0.9929]), 'num_pos': 9}
2020-12-13 07:34:01,265 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.444444
2020-12-13 07:34:31,815 maskrcnn_benchmark.trainer INFO: eta: 13:57:13  iter: 7700  loss: 4.3947 (6.0843)  loss_classifier: 0.0864 (0.1574)  loss_box_reg: 0.2184 (0.2189)  loss_objectness: 0.2726 (0.3785)  loss_rpn_box_reg: 3.8569 (5.3295)  time: 1.5260 (1.5552)  data: 0.1021 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 07:35:02,306 maskrcnn_benchmark.trainer INFO: eta: 13:56:40  iter: 7720  loss: 4.4328 (6.0802)  loss_classifier: 0.1629 (0.1575)  loss_box_reg: 0.1357 (0.2189)  loss_objectness: 0.2569 (0.3782)  loss_rpn_box_reg: 3.8383 (5.3257)  time: 1.5239 (1.5551)  data: 0.1004 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:35:32,775 maskrcnn_benchmark.trainer INFO: eta: 13:56:06  iter: 7740  loss: 4.5658 (6.0764)  loss_classifier: 0.1380 (0.1574)  loss_box_reg: 0.2160 (0.2188)  loss_objectness: 0.2968 (0.3780)  loss_rpn_box_reg: 3.9409 (5.3221)  time: 1.5236 (1.5551)  data: 0.0973 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:35:32,777 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:35:32,826 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:35:34,330 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.504058 (1.5040578842163086 s / img per device, on 1 devices)
2020-12-13 07:35:34,330 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.402268 (1.4022681713104248 s / img per device, on 1 devices)
2020-12-13 07:35:34,330 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:35:34,423 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:35:34,423 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([5.1643e-02, 1.6190e-02, 5.1857e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1., -1., -1.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.2113, 0.0000, 0.0000, 0.0000, 0.0000, 0.2938, 0.8591, 0.0802, 0.9206]), 'num_pos': 9}
2020-12-13 07:35:34,429 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 07:36:04,877 maskrcnn_benchmark.trainer INFO: eta: 13:55:39  iter: 7760  loss: 4.4581 (6.0723)  loss_classifier: 0.0815 (0.1573)  loss_box_reg: 0.1904 (0.2188)  loss_objectness: 0.2775 (0.3778)  loss_rpn_box_reg: 3.8662 (5.3184)  time: 1.5193 (1.5552)  data: 0.0954 (0.1284)  lr: 0.000000  max mem: 986
2020-12-13 07:36:35,308 maskrcnn_benchmark.trainer INFO: eta: 13:55:05  iter: 7780  loss: 4.3692 (6.0679)  loss_classifier: 0.0909 (0.1572)  loss_box_reg: 0.1337 (0.2187)  loss_objectness: 0.2661 (0.3775)  loss_rpn_box_reg: 3.8046 (5.3146)  time: 1.5204 (1.5551)  data: 0.0956 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:37:05,775 maskrcnn_benchmark.trainer INFO: eta: 13:54:31  iter: 7800  loss: 4.3702 (6.0636)  loss_classifier: 0.0849 (0.1571)  loss_box_reg: 0.1184 (0.2185)  loss_objectness: 0.2895 (0.3773)  loss_rpn_box_reg: 3.7799 (5.3107)  time: 1.5211 (1.5550)  data: 0.0946 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:37:05,777 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:37:05,828 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:37:07,338 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.510149 (1.5101492404937744 s / img per device, on 1 devices)
2020-12-13 07:37:07,338 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.408382 (1.4083824157714844 s / img per device, on 1 devices)
2020-12-13 07:37:07,338 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:37:07,428 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:37:07,428 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.0184e-01, 4.0932e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1.,  2., -1., -1., -1., -1., -1.]), 'best match scores': tensor([0.1151, 0.0000, 0.0000, 0.9955, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'num_pos': 9}
2020-12-13 07:37:07,433 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 07:37:37,944 maskrcnn_benchmark.trainer INFO: eta: 13:54:04  iter: 7820  loss: 4.4279 (6.0595)  loss_classifier: 0.1127 (0.1570)  loss_box_reg: 0.2326 (0.2186)  loss_objectness: 0.2640 (0.3770)  loss_rpn_box_reg: 3.7732 (5.3069)  time: 1.5258 (1.5552)  data: 0.0943 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:38:08,460 maskrcnn_benchmark.trainer INFO: eta: 13:53:31  iter: 7840  loss: 4.5165 (6.0556)  loss_classifier: 0.1626 (0.1571)  loss_box_reg: 0.2546 (0.2188)  loss_objectness: 0.2533 (0.3767)  loss_rpn_box_reg: 3.7527 (5.3030)  time: 1.5265 (1.5551)  data: 0.0946 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:38:38,973 maskrcnn_benchmark.trainer INFO: eta: 13:52:57  iter: 7860  loss: 4.2947 (6.0513)  loss_classifier: 0.0529 (0.1569)  loss_box_reg: 0.0942 (0.2186)  loss_objectness: 0.2971 (0.3765)  loss_rpn_box_reg: 3.8203 (5.2993)  time: 1.5271 (1.5550)  data: 0.0956 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:38:38,975 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:38:39,024 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:38:40,529 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.504604 (1.5046038627624512 s / img per device, on 1 devices)
2020-12-13 07:38:40,529 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.403445 (1.403444528579712 s / img per device, on 1 devices)
2020-12-13 07:38:40,529 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:38:40,625 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:38:40,625 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0073, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.1695, 0.0840]), 'num_pos': 9}
2020-12-13 07:38:40,630 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 07:39:11,188 maskrcnn_benchmark.trainer INFO: eta: 13:52:31  iter: 7880  loss: 4.4953 (6.0475)  loss_classifier: 0.0980 (0.1569)  loss_box_reg: 0.1930 (0.2187)  loss_objectness: 0.2726 (0.3762)  loss_rpn_box_reg: 3.8726 (5.2957)  time: 1.5254 (1.5552)  data: 0.1023 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:39:41,633 maskrcnn_benchmark.trainer INFO: eta: 13:51:57  iter: 7900  loss: 4.3920 (6.0435)  loss_classifier: 0.0791 (0.1567)  loss_box_reg: 0.1126 (0.2186)  loss_objectness: 0.2884 (0.3760)  loss_rpn_box_reg: 3.8865 (5.2922)  time: 1.5204 (1.5551)  data: 0.0958 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:40:12,114 maskrcnn_benchmark.trainer INFO: eta: 13:51:24  iter: 7920  loss: 4.6231 (6.0399)  loss_classifier: 0.1542 (0.1567)  loss_box_reg: 0.3451 (0.2188)  loss_objectness: 0.2953 (0.3758)  loss_rpn_box_reg: 3.8360 (5.2885)  time: 1.5228 (1.5550)  data: 0.0959 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:40:12,117 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:40:12,166 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:40:13,665 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.499087 (1.4990870952606201 s / img per device, on 1 devices)
2020-12-13 07:40:13,666 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.397793 (1.3977932929992676 s / img per device, on 1 devices)
2020-12-13 07:40:13,666 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:40:13,759 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:40:13,759 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0043, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1., -1., -1., -1., -1., -1.,  2.]), 'best match scores': tensor([0.9935, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9562]), 'num_pos': 9}
2020-12-13 07:40:13,764 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.222222
2020-12-13 07:40:44,220 maskrcnn_benchmark.trainer INFO: eta: 13:50:56  iter: 7940  loss: 4.5306 (6.0361)  loss_classifier: 0.1213 (0.1566)  loss_box_reg: 0.2539 (0.2190)  loss_objectness: 0.2786 (0.3756)  loss_rpn_box_reg: 3.8535 (5.2849)  time: 1.5227 (1.5551)  data: 0.0969 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:41:14,655 maskrcnn_benchmark.trainer INFO: eta: 13:50:23  iter: 7960  loss: 4.4811 (6.0324)  loss_classifier: 0.1736 (0.1567)  loss_box_reg: 0.2663 (0.2191)  loss_objectness: 0.2824 (0.3754)  loss_rpn_box_reg: 3.7946 (5.2812)  time: 1.5205 (1.5550)  data: 0.0963 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:41:45,098 maskrcnn_benchmark.trainer INFO: eta: 13:49:49  iter: 7980  loss: 4.4649 (6.0285)  loss_classifier: 0.1114 (0.1566)  loss_box_reg: 0.1986 (0.2191)  loss_objectness: 0.2637 (0.3752)  loss_rpn_box_reg: 3.8354 (5.2776)  time: 1.5214 (1.5549)  data: 0.0959 (0.1281)  lr: 0.000000  max mem: 986
2020-12-13 07:41:45,100 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:41:45,149 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:41:46,655 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.506241 (1.5062413215637207 s / img per device, on 1 devices)
2020-12-13 07:41:46,655 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.405110 (1.4051096439361572 s / img per device, on 1 devices)
2020-12-13 07:41:46,655 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:41:46,748 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:41:46,749 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([1.5824e-04, 6.3163e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1.,  2., -1., -1., -1., -1.,  2.]), 'best match scores': tensor([1.0000, 0.0000, 0.0000, 0.3519, 0.0000, 0.0000, 0.0000, 0.0000, 0.6425]), 'num_pos': 9}
2020-12-13 07:41:46,754 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 07:42:17,225 maskrcnn_benchmark.trainer INFO: eta: 13:49:22  iter: 8000  loss: 4.4219 (6.0247)  loss_classifier: 0.1110 (0.1566)  loss_box_reg: 0.2237 (0.2193)  loss_objectness: 0.2630 (0.3749)  loss_rpn_box_reg: 3.8157 (5.2739)  time: 1.5214 (1.5551)  data: 0.0962 (0.1283)  lr: 0.000000  max mem: 986
2020-12-13 07:42:47,660 maskrcnn_benchmark.trainer INFO: eta: 13:48:48  iter: 8020  loss: 4.3854 (6.0208)  loss_classifier: 0.0964 (0.1565)  loss_box_reg: 0.2015 (0.2193)  loss_objectness: 0.2637 (0.3747)  loss_rpn_box_reg: 3.8432 (5.2703)  time: 1.5209 (1.5550)  data: 0.0958 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:43:18,102 maskrcnn_benchmark.trainer INFO: eta: 13:48:15  iter: 8040  loss: 4.4286 (6.0170)  loss_classifier: 0.1313 (0.1565)  loss_box_reg: 0.2919 (0.2195)  loss_objectness: 0.2910 (0.3744)  loss_rpn_box_reg: 3.8003 (5.2666)  time: 1.5209 (1.5549)  data: 0.0957 (0.1281)  lr: 0.000000  max mem: 986
2020-12-13 07:43:18,104 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:43:18,154 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:43:19,662 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.507173 (1.5071725845336914 s / img per device, on 1 devices)
2020-12-13 07:43:19,662 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.403018 (1.4030182361602783 s / img per device, on 1 devices)
2020-12-13 07:43:19,662 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:43:19,756 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:43:19,756 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1588, 0.1361, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.1435, 0.9989, 0.9794, 0.9972, 0.9922, 0.3268]), 'num_pos': 9}
2020-12-13 07:43:19,761 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 07:43:50,189 maskrcnn_benchmark.trainer INFO: eta: 13:47:47  iter: 8060  loss: 4.3054 (6.0128)  loss_classifier: 0.0951 (0.1564)  loss_box_reg: 0.1581 (0.2194)  loss_objectness: 0.2618 (0.3742)  loss_rpn_box_reg: 3.7954 (5.2628)  time: 1.5211 (1.5550)  data: 0.0954 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:44:20,643 maskrcnn_benchmark.trainer INFO: eta: 13:47:14  iter: 8080  loss: 4.3067 (6.0085)  loss_classifier: 0.0602 (0.1562)  loss_box_reg: 0.1560 (0.2193)  loss_objectness: 0.2748 (0.3739)  loss_rpn_box_reg: 3.7626 (5.2592)  time: 1.5218 (1.5550)  data: 0.0961 (0.1281)  lr: 0.000000  max mem: 986
2020-12-13 07:44:51,098 maskrcnn_benchmark.trainer INFO: eta: 13:46:40  iter: 8100  loss: 4.4346 (6.0047)  loss_classifier: 0.1213 (0.1561)  loss_box_reg: 0.2624 (0.2193)  loss_objectness: 0.2653 (0.3737)  loss_rpn_box_reg: 3.7761 (5.2556)  time: 1.5235 (1.5549)  data: 0.0956 (0.1281)  lr: 0.000000  max mem: 986
2020-12-13 07:44:51,100 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:44:51,150 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:44:52,657 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.507353 (1.507352590560913 s / img per device, on 1 devices)
2020-12-13 07:44:52,657 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.402923 (1.4029231071472168 s / img per device, on 1 devices)
2020-12-13 07:44:52,658 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:44:52,751 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:44:52,752 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([9.1416e-02, 1.3692e-03, 2.3762e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1., -1., -1., -1.,  2.,  2.,  2.]), 'best match scores': tensor([0.0546, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9999, 0.5870, 1.0000]), 'num_pos': 9}
2020-12-13 07:44:52,756 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.444444
2020-12-13 07:45:23,205 maskrcnn_benchmark.trainer INFO: eta: 13:46:13  iter: 8120  loss: 4.2136 (6.0004)  loss_classifier: 0.0564 (0.1559)  loss_box_reg: 0.1211 (0.2191)  loss_objectness: 0.2435 (0.3734)  loss_rpn_box_reg: 3.8021 (5.2519)  time: 1.5221 (1.5550)  data: 0.0955 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:45:53,645 maskrcnn_benchmark.trainer INFO: eta: 13:45:39  iter: 8140  loss: 4.4205 (5.9966)  loss_classifier: 0.1263 (0.1559)  loss_box_reg: 0.2391 (0.2192)  loss_objectness: 0.3267 (0.3733)  loss_rpn_box_reg: 3.7231 (5.2482)  time: 1.5209 (1.5549)  data: 0.0962 (0.1281)  lr: 0.000000  max mem: 986
2020-12-13 07:46:24,152 maskrcnn_benchmark.trainer INFO: eta: 13:45:06  iter: 8160  loss: 4.4529 (5.9927)  loss_classifier: 0.1134 (0.1558)  loss_box_reg: 0.2466 (0.2192)  loss_objectness: 0.2922 (0.3731)  loss_rpn_box_reg: 3.8155 (5.2447)  time: 1.5244 (1.5548)  data: 0.0950 (0.1280)  lr: 0.000000  max mem: 986
2020-12-13 07:46:24,154 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:46:24,204 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:46:25,713 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.508936 (1.5089359283447266 s / img per device, on 1 devices)
2020-12-13 07:46:25,713 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.406929 (1.4069292545318604 s / img per device, on 1 devices)
2020-12-13 07:46:25,713 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:46:25,808 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:46:25,808 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0913, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1., -1.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0952, 0.8561, 0.0708]), 'num_pos': 9}
2020-12-13 07:46:25,812 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 07:46:56,359 maskrcnn_benchmark.trainer INFO: eta: 13:44:39  iter: 8180  loss: 4.2582 (5.9886)  loss_classifier: 0.1152 (0.1557)  loss_box_reg: 0.2254 (0.2192)  loss_objectness: 0.2787 (0.3728)  loss_rpn_box_reg: 3.6852 (5.2409)  time: 1.5270 (1.5550)  data: 0.0965 (0.1282)  lr: 0.000000  max mem: 986
2020-12-13 07:47:26,873 maskrcnn_benchmark.trainer INFO: eta: 13:44:06  iter: 8200  loss: 4.2565 (5.9846)  loss_classifier: 0.0891 (0.1555)  loss_box_reg: 0.1380 (0.2192)  loss_objectness: 0.2684 (0.3726)  loss_rpn_box_reg: 3.7641 (5.2372)  time: 1.5240 (1.5549)  data: 0.0966 (0.1281)  lr: 0.000000  max mem: 986
2020-12-13 07:47:57,357 maskrcnn_benchmark.trainer INFO: eta: 13:43:32  iter: 8220  loss: 4.3947 (5.9808)  loss_classifier: 0.1308 (0.1556)  loss_box_reg: 0.1618 (0.2191)  loss_objectness: 0.2750 (0.3724)  loss_rpn_box_reg: 3.7801 (5.2337)  time: 1.5221 (1.5548)  data: 0.0946 (0.1280)  lr: 0.000000  max mem: 986
2020-12-13 07:47:57,358 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:47:57,407 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:47:58,920 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.513085 (1.5130846500396729 s / img per device, on 1 devices)
2020-12-13 07:47:58,920 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.408761 (1.4087607860565186 s / img per device, on 1 devices)
2020-12-13 07:47:58,921 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:47:59,014 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:47:59,014 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.1538, 0.1260, 0.1182, 0.0502, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 2.]), 'best match scores': tensor([0.9971, 0.2061, 0.6397, 0.3992, 0.0773, 0.9164, 0.9186, 0.9974, 0.9985]), 'num_pos': 9}
2020-12-13 07:47:59,019 maskrcnn_benchmark.trainer INFO: validation accuracy: 1.000000
2020-12-13 07:48:29,514 maskrcnn_benchmark.trainer INFO: eta: 13:43:05  iter: 8240  loss: 4.4886 (5.9771)  loss_classifier: 0.0917 (0.1555)  loss_box_reg: 0.2813 (0.2193)  loss_objectness: 0.2572 (0.3722)  loss_rpn_box_reg: 3.8012 (5.2302)  time: 1.5231 (1.5550)  data: 0.0950 (0.1281)  lr: 0.000000  max mem: 986
2020-12-13 07:48:59,953 maskrcnn_benchmark.trainer INFO: eta: 13:42:32  iter: 8260  loss: 4.3669 (5.9732)  loss_classifier: 0.1178 (0.1554)  loss_box_reg: 0.2283 (0.2194)  loss_objectness: 0.2683 (0.3719)  loss_rpn_box_reg: 3.7429 (5.2266)  time: 1.5205 (1.5549)  data: 0.0961 (0.1281)  lr: 0.000000  max mem: 986
2020-12-13 07:49:30,388 maskrcnn_benchmark.trainer INFO: eta: 13:41:58  iter: 8280  loss: 4.3786 (5.9696)  loss_classifier: 0.1277 (0.1553)  loss_box_reg: 0.2219 (0.2195)  loss_objectness: 0.3101 (0.3717)  loss_rpn_box_reg: 3.7789 (5.2231)  time: 1.5215 (1.5548)  data: 0.0954 (0.1280)  lr: 0.000000  max mem: 986
2020-12-13 07:49:30,389 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:49:30,439 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:49:31,945 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.506237 (1.5062365531921387 s / img per device, on 1 devices)
2020-12-13 07:49:31,945 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.402503 (1.402503252029419 s / img per device, on 1 devices)
2020-12-13 07:49:31,946 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:49:32,039 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:49:32,039 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0113, 0.0103, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1., -1., -1., -1., -1.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1882, 0.1160, 0.9961, 0.1598]), 'num_pos': 9}
2020-12-13 07:49:32,043 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.444444
2020-12-13 07:50:02,478 maskrcnn_benchmark.trainer INFO: eta: 13:41:31  iter: 8300  loss: 4.5288 (5.9661)  loss_classifier: 0.1463 (0.1554)  loss_box_reg: 0.2927 (0.2196)  loss_objectness: 0.2763 (0.3715)  loss_rpn_box_reg: 3.7910 (5.2196)  time: 1.5227 (1.5549)  data: 0.0960 (0.1281)  lr: 0.000000  max mem: 986
2020-12-13 07:50:32,920 maskrcnn_benchmark.trainer INFO: eta: 13:40:57  iter: 8320  loss: 4.2541 (5.9622)  loss_classifier: 0.1031 (0.1553)  loss_box_reg: 0.1729 (0.2196)  loss_objectness: 0.2745 (0.3713)  loss_rpn_box_reg: 3.6948 (5.2160)  time: 1.5214 (1.5548)  data: 0.0959 (0.1280)  lr: 0.000000  max mem: 986
2020-12-13 07:51:03,376 maskrcnn_benchmark.trainer INFO: eta: 13:40:23  iter: 8340  loss: 4.3494 (5.9583)  loss_classifier: 0.0915 (0.1551)  loss_box_reg: 0.2272 (0.2196)  loss_objectness: 0.2754 (0.3710)  loss_rpn_box_reg: 3.7527 (5.2125)  time: 1.5228 (1.5548)  data: 0.0960 (0.1279)  lr: 0.000000  max mem: 986
2020-12-13 07:51:03,378 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:51:03,428 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:51:04,929 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.501045 (1.5010454654693604 s / img per device, on 1 devices)
2020-12-13 07:51:04,929 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.396209 (1.3962092399597168 s / img per device, on 1 devices)
2020-12-13 07:51:04,929 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:51:05,024 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:51:05,024 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0850, 0.0471, 0.0019, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1., -1., -1.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.5052, 0.0000, 0.0000, 0.0000, 0.0000, 0.7757, 0.2273, 0.2376, 1.0000]), 'num_pos': 9}
2020-12-13 07:51:05,028 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.555556
2020-12-13 07:51:35,539 maskrcnn_benchmark.trainer INFO: eta: 13:39:56  iter: 8360  loss: 4.3560 (5.9545)  loss_classifier: 0.0984 (0.1550)  loss_box_reg: 0.2493 (0.2196)  loss_objectness: 0.2847 (0.3709)  loss_rpn_box_reg: 3.6991 (5.2090)  time: 1.5237 (1.5549)  data: 0.0961 (0.1281)  lr: 0.000000  max mem: 986
2020-12-13 07:52:06,558 maskrcnn_benchmark.trainer INFO: eta: 13:39:25  iter: 8380  loss: 4.3208 (5.9507)  loss_classifier: 0.1041 (0.1550)  loss_box_reg: 0.2099 (0.2197)  loss_objectness: 0.2839 (0.3707)  loss_rpn_box_reg: 3.6952 (5.2054)  time: 1.5348 (1.5549)  data: 0.1001 (0.1280)  lr: 0.000000  max mem: 986
2020-12-13 07:52:37,171 maskrcnn_benchmark.trainer INFO: eta: 13:38:52  iter: 8400  loss: 4.1311 (5.9467)  loss_classifier: 0.0670 (0.1548)  loss_box_reg: 0.1306 (0.2196)  loss_objectness: 0.2817 (0.3705)  loss_rpn_box_reg: 3.6731 (5.2018)  time: 1.5264 (1.5548)  data: 0.0975 (0.1279)  lr: 0.000000  max mem: 986
2020-12-13 07:52:37,174 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:52:37,226 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:52:38,735 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.509498 (1.509497880935669 s / img per device, on 1 devices)
2020-12-13 07:52:38,735 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.402897 (1.4028971195220947 s / img per device, on 1 devices)
2020-12-13 07:52:38,736 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:52:38,831 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:52:38,831 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.2202, 0.0747, 0.0286, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  2., -1., -1.,  2.,  2., -1., -1., -1.]), 'best match scores': tensor([0.0000, 0.2432, 0.0000, 0.0000, 0.9476, 0.1322, 0.0000, 0.0000, 0.0000]), 'num_pos': 9}
2020-12-13 07:52:38,836 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.333333
2020-12-13 07:53:09,477 maskrcnn_benchmark.trainer INFO: eta: 13:38:26  iter: 8420  loss: 4.3244 (5.9429)  loss_classifier: 0.1107 (0.1547)  loss_box_reg: 0.1928 (0.2196)  loss_objectness: 0.2859 (0.3702)  loss_rpn_box_reg: 3.7383 (5.1983)  time: 1.5305 (1.5550)  data: 0.0973 (0.1281)  lr: 0.000000  max mem: 986
2020-12-13 07:53:40,139 maskrcnn_benchmark.trainer INFO: eta: 13:37:53  iter: 8440  loss: 4.4526 (5.9395)  loss_classifier: 0.1970 (0.1548)  loss_box_reg: 0.2935 (0.2198)  loss_objectness: 0.2718 (0.3700)  loss_rpn_box_reg: 3.7233 (5.1948)  time: 1.5291 (1.5549)  data: 0.0956 (0.1280)  lr: 0.000000  max mem: 986
2020-12-13 07:54:12,013 maskrcnn_benchmark.trainer INFO: eta: 13:37:25  iter: 8460  loss: 4.3257 (5.9358)  loss_classifier: 0.1190 (0.1548)  loss_box_reg: 0.2901 (0.2201)  loss_objectness: 0.2677 (0.3698)  loss_rpn_box_reg: 3.6154 (5.1911)  time: 1.5729 (1.5550)  data: 0.0997 (0.1279)  lr: 0.000000  max mem: 986
2020-12-13 07:54:12,015 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:54:12,066 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:54:13,622 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.556136 (1.556135892868042 s / img per device, on 1 devices)
2020-12-13 07:54:13,622 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.444055 (1.4440546035766602 s / img per device, on 1 devices)
2020-12-13 07:54:13,623 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:54:13,729 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:54:13,729 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0771, 0.0342, 0.0227, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([-1.,  2., -1.,  2.,  2.,  2.,  2.,  2.,  7.]), 'best match scores': tensor([0.0000, 1.0000, 0.0000, 1.0000, 0.5440, 0.9258, 0.9994, 0.7237, 0.9984]), 'num_pos': 9}
2020-12-13 07:54:13,735 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.666667
2020-12-13 07:54:45,435 maskrcnn_benchmark.trainer INFO: eta: 13:37:02  iter: 8480  loss: 4.3489 (5.9322)  loss_classifier: 0.1618 (0.1548)  loss_box_reg: 0.2007 (0.2201)  loss_objectness: 0.2784 (0.3696)  loss_rpn_box_reg: 3.6563 (5.1876)  time: 1.5707 (1.5553)  data: 0.1065 (0.1281)  lr: 0.000000  max mem: 986
2020-12-13 07:55:17,115 maskrcnn_benchmark.trainer INFO: eta: 13:36:33  iter: 8500  loss: 4.3172 (5.9284)  loss_classifier: 0.1402 (0.1548)  loss_box_reg: 0.2582 (0.2202)  loss_objectness: 0.2694 (0.3694)  loss_rpn_box_reg: 3.6485 (5.1840)  time: 1.5721 (1.5554)  data: 0.1073 (0.1280)  lr: 0.000000  max mem: 986
2020-12-13 07:55:48,131 maskrcnn_benchmark.trainer INFO: eta: 13:36:02  iter: 8520  loss: 4.3500 (5.9247)  loss_classifier: 0.1072 (0.1547)  loss_box_reg: 0.2275 (0.2203)  loss_objectness: 0.2573 (0.3692)  loss_rpn_box_reg: 3.6134 (5.1804)  time: 1.5483 (1.5553)  data: 0.0975 (0.1280)  lr: 0.000000  max mem: 986
2020-12-13 07:55:48,133 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 07:55:48,185 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 07:55:49,761 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.576536 (1.576535701751709 s / img per device, on 1 devices)
2020-12-13 07:55:49,762 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.466708 (1.4667081832885742 s / img per device, on 1 devices)
2020-12-13 07:55:49,762 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 07:55:49,865 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 07:55:49,865 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.), 'recalls': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([8.9790e-02, 8.8301e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([ 2., -1., -1.,  2.,  2.,  2.,  2.,  2.,  2.]), 'best match scores': tensor([0.7404, 0.0000, 0.0000, 0.9977, 0.9543, 1.0000, 1.0000, 0.1005, 0.9999]), 'num_pos': 9}
2020-12-13 07:55:49,869 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.777778
2020-12-13 07:56:21,473 maskrcnn_benchmark.trainer INFO: eta: 13:35:39  iter: 8540  loss: 4.4492 (5.9212)  loss_classifier: 0.1573 (0.1547)  loss_box_reg: 0.2806 (0.2205)  loss_objectness: 0.2740 (0.3690)  loss_rpn_box_reg: 3.7547 (5.1770)  time: 1.5597 (1.5556)  data: 0.0987 (0.1281)  lr: 0.000000  max mem: 986
2020-12-13 09:52:47,183 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 09:52:47,225 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 09:52:47,225 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 09:52:54,144 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 09:52:54,145 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 09:52:54,146 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_valid",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000008
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 40000
  IMS_PER_BATCH: 1
TEST:
  IMS_PER_BATCH: 1

2020-12-13 09:52:54,149 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_valid',)
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.1
    FG_IOU_THRESHOLD: 0.2
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 8e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  MAX_ITER: 40000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-13 09:52:55,831 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from visdrone_model_0360000.pth
2020-12-13 09:53:01,846 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                  loaded from backbone.body.layer1.0.bn1.bias                  of shape (256,)
2020-12-13 09:53:01,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_mean          loaded from backbone.body.layer1.0.bn1.running_mean          of shape (256,)
2020-12-13 09:53:01,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_var           loaded from backbone.body.layer1.0.bn1.running_var           of shape (256,)
2020-12-13 09:53:01,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                loaded from backbone.body.layer1.0.bn1.weight                of shape (256,)
2020-12-13 09:53:01,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                  loaded from backbone.body.layer1.0.bn2.bias                  of shape (256,)
2020-12-13 09:53:01,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_mean          loaded from backbone.body.layer1.0.bn2.running_mean          of shape (256,)
2020-12-13 09:53:01,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_var           loaded from backbone.body.layer1.0.bn2.running_var           of shape (256,)
2020-12-13 09:53:01,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                loaded from backbone.body.layer1.0.bn2.weight                of shape (256,)
2020-12-13 09:53:01,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                  loaded from backbone.body.layer1.0.bn3.bias                  of shape (256,)
2020-12-13 09:53:01,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_mean          loaded from backbone.body.layer1.0.bn3.running_mean          of shape (256,)
2020-12-13 09:53:01,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_var           loaded from backbone.body.layer1.0.bn3.running_var           of shape (256,)
2020-12-13 09:53:01,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                loaded from backbone.body.layer1.0.bn3.weight                of shape (256,)
2020-12-13 09:53:01,848 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight              loaded from backbone.body.layer1.0.conv1.weight              of shape (256, 64, 1, 1)
2020-12-13 09:53:01,848 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight              loaded from backbone.body.layer1.0.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 09:53:01,848 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight              loaded from backbone.body.layer1.0.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 09:53:01,848 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight       loaded from backbone.body.layer1.0.downsample.0.weight       of shape (256, 64, 1, 1)
2020-12-13 09:53:01,848 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias         loaded from backbone.body.layer1.0.downsample.1.bias         of shape (256,)
2020-12-13 09:53:01,848 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_mean loaded from backbone.body.layer1.0.downsample.1.running_mean of shape (256,)
2020-12-13 09:53:01,848 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_var  loaded from backbone.body.layer1.0.downsample.1.running_var  of shape (256,)
2020-12-13 09:53:01,848 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight       loaded from backbone.body.layer1.0.downsample.1.weight       of shape (256,)
2020-12-13 09:53:01,848 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                  loaded from backbone.body.layer1.1.bn1.bias                  of shape (256,)
2020-12-13 09:53:01,848 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_mean          loaded from backbone.body.layer1.1.bn1.running_mean          of shape (256,)
2020-12-13 09:53:01,848 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_var           loaded from backbone.body.layer1.1.bn1.running_var           of shape (256,)
2020-12-13 09:53:01,848 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                loaded from backbone.body.layer1.1.bn1.weight                of shape (256,)
2020-12-13 09:53:01,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                  loaded from backbone.body.layer1.1.bn2.bias                  of shape (256,)
2020-12-13 09:53:01,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_mean          loaded from backbone.body.layer1.1.bn2.running_mean          of shape (256,)
2020-12-13 09:53:01,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_var           loaded from backbone.body.layer1.1.bn2.running_var           of shape (256,)
2020-12-13 09:53:01,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                loaded from backbone.body.layer1.1.bn2.weight                of shape (256,)
2020-12-13 09:53:01,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                  loaded from backbone.body.layer1.1.bn3.bias                  of shape (256,)
2020-12-13 09:53:01,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_mean          loaded from backbone.body.layer1.1.bn3.running_mean          of shape (256,)
2020-12-13 09:53:01,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_var           loaded from backbone.body.layer1.1.bn3.running_var           of shape (256,)
2020-12-13 09:53:01,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                loaded from backbone.body.layer1.1.bn3.weight                of shape (256,)
2020-12-13 09:53:01,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight              loaded from backbone.body.layer1.1.conv1.weight              of shape (256, 256, 1, 1)
2020-12-13 09:53:01,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight              loaded from backbone.body.layer1.1.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 09:53:01,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight              loaded from backbone.body.layer1.1.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 09:53:01,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                  loaded from backbone.body.layer1.2.bn1.bias                  of shape (256,)
2020-12-13 09:53:01,849 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_mean          loaded from backbone.body.layer1.2.bn1.running_mean          of shape (256,)
2020-12-13 09:53:01,850 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_var           loaded from backbone.body.layer1.2.bn1.running_var           of shape (256,)
2020-12-13 09:53:01,850 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                loaded from backbone.body.layer1.2.bn1.weight                of shape (256,)
2020-12-13 09:53:01,850 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                  loaded from backbone.body.layer1.2.bn2.bias                  of shape (256,)
2020-12-13 09:53:01,850 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_mean          loaded from backbone.body.layer1.2.bn2.running_mean          of shape (256,)
2020-12-13 09:53:01,850 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_var           loaded from backbone.body.layer1.2.bn2.running_var           of shape (256,)
2020-12-13 09:53:01,850 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                loaded from backbone.body.layer1.2.bn2.weight                of shape (256,)
2020-12-13 09:53:01,850 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                  loaded from backbone.body.layer1.2.bn3.bias                  of shape (256,)
2020-12-13 09:53:01,850 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_mean          loaded from backbone.body.layer1.2.bn3.running_mean          of shape (256,)
2020-12-13 09:53:01,850 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_var           loaded from backbone.body.layer1.2.bn3.running_var           of shape (256,)
2020-12-13 09:53:01,850 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                loaded from backbone.body.layer1.2.bn3.weight                of shape (256,)
2020-12-13 09:53:01,850 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight              loaded from backbone.body.layer1.2.conv1.weight              of shape (256, 256, 1, 1)
2020-12-13 09:53:01,850 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight              loaded from backbone.body.layer1.2.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 09:53:01,851 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight              loaded from backbone.body.layer1.2.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 09:53:01,851 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                  loaded from backbone.body.layer2.0.bn1.bias                  of shape (512,)
2020-12-13 09:53:01,851 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_mean          loaded from backbone.body.layer2.0.bn1.running_mean          of shape (512,)
2020-12-13 09:53:01,851 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_var           loaded from backbone.body.layer2.0.bn1.running_var           of shape (512,)
2020-12-13 09:53:01,851 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                loaded from backbone.body.layer2.0.bn1.weight                of shape (512,)
2020-12-13 09:53:01,851 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                  loaded from backbone.body.layer2.0.bn2.bias                  of shape (512,)
2020-12-13 09:53:01,851 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_mean          loaded from backbone.body.layer2.0.bn2.running_mean          of shape (512,)
2020-12-13 09:53:01,851 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_var           loaded from backbone.body.layer2.0.bn2.running_var           of shape (512,)
2020-12-13 09:53:01,851 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                loaded from backbone.body.layer2.0.bn2.weight                of shape (512,)
2020-12-13 09:53:01,851 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                  loaded from backbone.body.layer2.0.bn3.bias                  of shape (512,)
2020-12-13 09:53:01,851 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_mean          loaded from backbone.body.layer2.0.bn3.running_mean          of shape (512,)
2020-12-13 09:53:01,851 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_var           loaded from backbone.body.layer2.0.bn3.running_var           of shape (512,)
2020-12-13 09:53:01,852 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                loaded from backbone.body.layer2.0.bn3.weight                of shape (512,)
2020-12-13 09:53:01,852 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight              loaded from backbone.body.layer2.0.conv1.weight              of shape (512, 256, 1, 1)
2020-12-13 09:53:01,852 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight              loaded from backbone.body.layer2.0.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 09:53:01,852 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight              loaded from backbone.body.layer2.0.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 09:53:01,852 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight       loaded from backbone.body.layer2.0.downsample.0.weight       of shape (512, 256, 1, 1)
2020-12-13 09:53:01,852 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias         loaded from backbone.body.layer2.0.downsample.1.bias         of shape (512,)
2020-12-13 09:53:01,852 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_mean loaded from backbone.body.layer2.0.downsample.1.running_mean of shape (512,)
2020-12-13 09:53:01,852 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_var  loaded from backbone.body.layer2.0.downsample.1.running_var  of shape (512,)
2020-12-13 09:53:01,852 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight       loaded from backbone.body.layer2.0.downsample.1.weight       of shape (512,)
2020-12-13 09:53:01,852 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                  loaded from backbone.body.layer2.1.bn1.bias                  of shape (512,)
2020-12-13 09:53:01,852 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_mean          loaded from backbone.body.layer2.1.bn1.running_mean          of shape (512,)
2020-12-13 09:53:01,852 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_var           loaded from backbone.body.layer2.1.bn1.running_var           of shape (512,)
2020-12-13 09:53:01,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                loaded from backbone.body.layer2.1.bn1.weight                of shape (512,)
2020-12-13 09:53:01,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                  loaded from backbone.body.layer2.1.bn2.bias                  of shape (512,)
2020-12-13 09:53:01,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_mean          loaded from backbone.body.layer2.1.bn2.running_mean          of shape (512,)
2020-12-13 09:53:01,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_var           loaded from backbone.body.layer2.1.bn2.running_var           of shape (512,)
2020-12-13 09:53:01,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                loaded from backbone.body.layer2.1.bn2.weight                of shape (512,)
2020-12-13 09:53:01,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                  loaded from backbone.body.layer2.1.bn3.bias                  of shape (512,)
2020-12-13 09:53:01,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_mean          loaded from backbone.body.layer2.1.bn3.running_mean          of shape (512,)
2020-12-13 09:53:01,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_var           loaded from backbone.body.layer2.1.bn3.running_var           of shape (512,)
2020-12-13 09:53:01,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                loaded from backbone.body.layer2.1.bn3.weight                of shape (512,)
2020-12-13 09:53:01,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight              loaded from backbone.body.layer2.1.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 09:53:01,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight              loaded from backbone.body.layer2.1.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 09:53:01,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight              loaded from backbone.body.layer2.1.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 09:53:01,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                  loaded from backbone.body.layer2.2.bn1.bias                  of shape (512,)
2020-12-13 09:53:01,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_mean          loaded from backbone.body.layer2.2.bn1.running_mean          of shape (512,)
2020-12-13 09:53:01,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_var           loaded from backbone.body.layer2.2.bn1.running_var           of shape (512,)
2020-12-13 09:53:01,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                loaded from backbone.body.layer2.2.bn1.weight                of shape (512,)
2020-12-13 09:53:01,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                  loaded from backbone.body.layer2.2.bn2.bias                  of shape (512,)
2020-12-13 09:53:01,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_mean          loaded from backbone.body.layer2.2.bn2.running_mean          of shape (512,)
2020-12-13 09:53:01,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_var           loaded from backbone.body.layer2.2.bn2.running_var           of shape (512,)
2020-12-13 09:53:01,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                loaded from backbone.body.layer2.2.bn2.weight                of shape (512,)
2020-12-13 09:53:01,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                  loaded from backbone.body.layer2.2.bn3.bias                  of shape (512,)
2020-12-13 09:53:01,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_mean          loaded from backbone.body.layer2.2.bn3.running_mean          of shape (512,)
2020-12-13 09:53:01,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_var           loaded from backbone.body.layer2.2.bn3.running_var           of shape (512,)
2020-12-13 09:53:01,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                loaded from backbone.body.layer2.2.bn3.weight                of shape (512,)
2020-12-13 09:53:01,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight              loaded from backbone.body.layer2.2.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 09:53:01,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight              loaded from backbone.body.layer2.2.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 09:53:01,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight              loaded from backbone.body.layer2.2.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 09:53:01,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                  loaded from backbone.body.layer2.3.bn1.bias                  of shape (512,)
2020-12-13 09:53:01,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_mean          loaded from backbone.body.layer2.3.bn1.running_mean          of shape (512,)
2020-12-13 09:53:01,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_var           loaded from backbone.body.layer2.3.bn1.running_var           of shape (512,)
2020-12-13 09:53:01,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                loaded from backbone.body.layer2.3.bn1.weight                of shape (512,)
2020-12-13 09:53:01,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                  loaded from backbone.body.layer2.3.bn2.bias                  of shape (512,)
2020-12-13 09:53:01,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_mean          loaded from backbone.body.layer2.3.bn2.running_mean          of shape (512,)
2020-12-13 09:53:01,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_var           loaded from backbone.body.layer2.3.bn2.running_var           of shape (512,)
2020-12-13 09:53:01,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                loaded from backbone.body.layer2.3.bn2.weight                of shape (512,)
2020-12-13 09:53:01,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                  loaded from backbone.body.layer2.3.bn3.bias                  of shape (512,)
2020-12-13 09:53:01,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_mean          loaded from backbone.body.layer2.3.bn3.running_mean          of shape (512,)
2020-12-13 09:53:01,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_var           loaded from backbone.body.layer2.3.bn3.running_var           of shape (512,)
2020-12-13 09:53:01,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                loaded from backbone.body.layer2.3.bn3.weight                of shape (512,)
2020-12-13 09:53:01,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight              loaded from backbone.body.layer2.3.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 09:53:01,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight              loaded from backbone.body.layer2.3.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 09:53:01,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight              loaded from backbone.body.layer2.3.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 09:53:01,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                  loaded from backbone.body.layer3.0.bn1.bias                  of shape (1024,)
2020-12-13 09:53:01,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_mean          loaded from backbone.body.layer3.0.bn1.running_mean          of shape (1024,)
2020-12-13 09:53:01,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_var           loaded from backbone.body.layer3.0.bn1.running_var           of shape (1024,)
2020-12-13 09:53:01,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                loaded from backbone.body.layer3.0.bn1.weight                of shape (1024,)
2020-12-13 09:53:01,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                  loaded from backbone.body.layer3.0.bn2.bias                  of shape (1024,)
2020-12-13 09:53:01,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_mean          loaded from backbone.body.layer3.0.bn2.running_mean          of shape (1024,)
2020-12-13 09:53:01,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_var           loaded from backbone.body.layer3.0.bn2.running_var           of shape (1024,)
2020-12-13 09:53:01,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                loaded from backbone.body.layer3.0.bn2.weight                of shape (1024,)
2020-12-13 09:53:01,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                  loaded from backbone.body.layer3.0.bn3.bias                  of shape (1024,)
2020-12-13 09:53:01,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_mean          loaded from backbone.body.layer3.0.bn3.running_mean          of shape (1024,)
2020-12-13 09:53:01,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_var           loaded from backbone.body.layer3.0.bn3.running_var           of shape (1024,)
2020-12-13 09:53:01,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                loaded from backbone.body.layer3.0.bn3.weight                of shape (1024,)
2020-12-13 09:53:01,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight              loaded from backbone.body.layer3.0.conv1.weight              of shape (1024, 512, 1, 1)
2020-12-13 09:53:01,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight              loaded from backbone.body.layer3.0.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight              loaded from backbone.body.layer3.0.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight       loaded from backbone.body.layer3.0.downsample.0.weight       of shape (1024, 512, 1, 1)
2020-12-13 09:53:01,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias         loaded from backbone.body.layer3.0.downsample.1.bias         of shape (1024,)
2020-12-13 09:53:01,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_mean loaded from backbone.body.layer3.0.downsample.1.running_mean of shape (1024,)
2020-12-13 09:53:01,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_var  loaded from backbone.body.layer3.0.downsample.1.running_var  of shape (1024,)
2020-12-13 09:53:01,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight       loaded from backbone.body.layer3.0.downsample.1.weight       of shape (1024,)
2020-12-13 09:53:01,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                  loaded from backbone.body.layer3.1.bn1.bias                  of shape (1024,)
2020-12-13 09:53:01,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_mean          loaded from backbone.body.layer3.1.bn1.running_mean          of shape (1024,)
2020-12-13 09:53:01,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_var           loaded from backbone.body.layer3.1.bn1.running_var           of shape (1024,)
2020-12-13 09:53:01,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                loaded from backbone.body.layer3.1.bn1.weight                of shape (1024,)
2020-12-13 09:53:01,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                  loaded from backbone.body.layer3.1.bn2.bias                  of shape (1024,)
2020-12-13 09:53:01,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_mean          loaded from backbone.body.layer3.1.bn2.running_mean          of shape (1024,)
2020-12-13 09:53:01,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_var           loaded from backbone.body.layer3.1.bn2.running_var           of shape (1024,)
2020-12-13 09:53:01,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                loaded from backbone.body.layer3.1.bn2.weight                of shape (1024,)
2020-12-13 09:53:01,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                  loaded from backbone.body.layer3.1.bn3.bias                  of shape (1024,)
2020-12-13 09:53:01,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_mean          loaded from backbone.body.layer3.1.bn3.running_mean          of shape (1024,)
2020-12-13 09:53:01,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_var           loaded from backbone.body.layer3.1.bn3.running_var           of shape (1024,)
2020-12-13 09:53:01,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                loaded from backbone.body.layer3.1.bn3.weight                of shape (1024,)
2020-12-13 09:53:01,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight              loaded from backbone.body.layer3.1.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight              loaded from backbone.body.layer3.1.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight              loaded from backbone.body.layer3.1.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.bias                 loaded from backbone.body.layer3.10.bn1.bias                 of shape (1024,)
2020-12-13 09:53:01,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.running_mean         loaded from backbone.body.layer3.10.bn1.running_mean         of shape (1024,)
2020-12-13 09:53:01,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.running_var          loaded from backbone.body.layer3.10.bn1.running_var          of shape (1024,)
2020-12-13 09:53:01,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.weight               loaded from backbone.body.layer3.10.bn1.weight               of shape (1024,)
2020-12-13 09:53:01,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.bias                 loaded from backbone.body.layer3.10.bn2.bias                 of shape (1024,)
2020-12-13 09:53:01,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.running_mean         loaded from backbone.body.layer3.10.bn2.running_mean         of shape (1024,)
2020-12-13 09:53:01,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.running_var          loaded from backbone.body.layer3.10.bn2.running_var          of shape (1024,)
2020-12-13 09:53:01,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.weight               loaded from backbone.body.layer3.10.bn2.weight               of shape (1024,)
2020-12-13 09:53:01,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.bias                 loaded from backbone.body.layer3.10.bn3.bias                 of shape (1024,)
2020-12-13 09:53:01,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.running_mean         loaded from backbone.body.layer3.10.bn3.running_mean         of shape (1024,)
2020-12-13 09:53:01,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.running_var          loaded from backbone.body.layer3.10.bn3.running_var          of shape (1024,)
2020-12-13 09:53:01,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.weight               loaded from backbone.body.layer3.10.bn3.weight               of shape (1024,)
2020-12-13 09:53:01,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv1.weight             loaded from backbone.body.layer3.10.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv2.weight             loaded from backbone.body.layer3.10.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv3.weight             loaded from backbone.body.layer3.10.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.bias                 loaded from backbone.body.layer3.11.bn1.bias                 of shape (1024,)
2020-12-13 09:53:01,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.running_mean         loaded from backbone.body.layer3.11.bn1.running_mean         of shape (1024,)
2020-12-13 09:53:01,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.running_var          loaded from backbone.body.layer3.11.bn1.running_var          of shape (1024,)
2020-12-13 09:53:01,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.weight               loaded from backbone.body.layer3.11.bn1.weight               of shape (1024,)
2020-12-13 09:53:01,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.bias                 loaded from backbone.body.layer3.11.bn2.bias                 of shape (1024,)
2020-12-13 09:53:01,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.running_mean         loaded from backbone.body.layer3.11.bn2.running_mean         of shape (1024,)
2020-12-13 09:53:01,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.running_var          loaded from backbone.body.layer3.11.bn2.running_var          of shape (1024,)
2020-12-13 09:53:01,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.weight               loaded from backbone.body.layer3.11.bn2.weight               of shape (1024,)
2020-12-13 09:53:01,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.bias                 loaded from backbone.body.layer3.11.bn3.bias                 of shape (1024,)
2020-12-13 09:53:01,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.running_mean         loaded from backbone.body.layer3.11.bn3.running_mean         of shape (1024,)
2020-12-13 09:53:01,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.running_var          loaded from backbone.body.layer3.11.bn3.running_var          of shape (1024,)
2020-12-13 09:53:01,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.weight               loaded from backbone.body.layer3.11.bn3.weight               of shape (1024,)
2020-12-13 09:53:01,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv1.weight             loaded from backbone.body.layer3.11.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv2.weight             loaded from backbone.body.layer3.11.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv3.weight             loaded from backbone.body.layer3.11.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.bias                 loaded from backbone.body.layer3.12.bn1.bias                 of shape (1024,)
2020-12-13 09:53:01,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.running_mean         loaded from backbone.body.layer3.12.bn1.running_mean         of shape (1024,)
2020-12-13 09:53:01,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.running_var          loaded from backbone.body.layer3.12.bn1.running_var          of shape (1024,)
2020-12-13 09:53:01,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.weight               loaded from backbone.body.layer3.12.bn1.weight               of shape (1024,)
2020-12-13 09:53:01,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.bias                 loaded from backbone.body.layer3.12.bn2.bias                 of shape (1024,)
2020-12-13 09:53:01,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.running_mean         loaded from backbone.body.layer3.12.bn2.running_mean         of shape (1024,)
2020-12-13 09:53:01,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.running_var          loaded from backbone.body.layer3.12.bn2.running_var          of shape (1024,)
2020-12-13 09:53:01,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.weight               loaded from backbone.body.layer3.12.bn2.weight               of shape (1024,)
2020-12-13 09:53:01,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.bias                 loaded from backbone.body.layer3.12.bn3.bias                 of shape (1024,)
2020-12-13 09:53:01,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.running_mean         loaded from backbone.body.layer3.12.bn3.running_mean         of shape (1024,)
2020-12-13 09:53:01,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.running_var          loaded from backbone.body.layer3.12.bn3.running_var          of shape (1024,)
2020-12-13 09:53:01,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.weight               loaded from backbone.body.layer3.12.bn3.weight               of shape (1024,)
2020-12-13 09:53:01,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv1.weight             loaded from backbone.body.layer3.12.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv2.weight             loaded from backbone.body.layer3.12.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv3.weight             loaded from backbone.body.layer3.12.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.bias                 loaded from backbone.body.layer3.13.bn1.bias                 of shape (1024,)
2020-12-13 09:53:01,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.running_mean         loaded from backbone.body.layer3.13.bn1.running_mean         of shape (1024,)
2020-12-13 09:53:01,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.running_var          loaded from backbone.body.layer3.13.bn1.running_var          of shape (1024,)
2020-12-13 09:53:01,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.weight               loaded from backbone.body.layer3.13.bn1.weight               of shape (1024,)
2020-12-13 09:53:01,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.bias                 loaded from backbone.body.layer3.13.bn2.bias                 of shape (1024,)
2020-12-13 09:53:01,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.running_mean         loaded from backbone.body.layer3.13.bn2.running_mean         of shape (1024,)
2020-12-13 09:53:01,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.running_var          loaded from backbone.body.layer3.13.bn2.running_var          of shape (1024,)
2020-12-13 09:53:01,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.weight               loaded from backbone.body.layer3.13.bn2.weight               of shape (1024,)
2020-12-13 09:53:01,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.bias                 loaded from backbone.body.layer3.13.bn3.bias                 of shape (1024,)
2020-12-13 09:53:01,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.running_mean         loaded from backbone.body.layer3.13.bn3.running_mean         of shape (1024,)
2020-12-13 09:53:01,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.running_var          loaded from backbone.body.layer3.13.bn3.running_var          of shape (1024,)
2020-12-13 09:53:01,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.weight               loaded from backbone.body.layer3.13.bn3.weight               of shape (1024,)
2020-12-13 09:53:01,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv1.weight             loaded from backbone.body.layer3.13.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv2.weight             loaded from backbone.body.layer3.13.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv3.weight             loaded from backbone.body.layer3.13.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.bias                 loaded from backbone.body.layer3.14.bn1.bias                 of shape (1024,)
2020-12-13 09:53:01,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.running_mean         loaded from backbone.body.layer3.14.bn1.running_mean         of shape (1024,)
2020-12-13 09:53:01,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.running_var          loaded from backbone.body.layer3.14.bn1.running_var          of shape (1024,)
2020-12-13 09:53:01,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.weight               loaded from backbone.body.layer3.14.bn1.weight               of shape (1024,)
2020-12-13 09:53:01,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.bias                 loaded from backbone.body.layer3.14.bn2.bias                 of shape (1024,)
2020-12-13 09:53:01,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.running_mean         loaded from backbone.body.layer3.14.bn2.running_mean         of shape (1024,)
2020-12-13 09:53:01,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.running_var          loaded from backbone.body.layer3.14.bn2.running_var          of shape (1024,)
2020-12-13 09:53:01,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.weight               loaded from backbone.body.layer3.14.bn2.weight               of shape (1024,)
2020-12-13 09:53:01,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.bias                 loaded from backbone.body.layer3.14.bn3.bias                 of shape (1024,)
2020-12-13 09:53:01,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.running_mean         loaded from backbone.body.layer3.14.bn3.running_mean         of shape (1024,)
2020-12-13 09:53:01,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.running_var          loaded from backbone.body.layer3.14.bn3.running_var          of shape (1024,)
2020-12-13 09:53:01,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.weight               loaded from backbone.body.layer3.14.bn3.weight               of shape (1024,)
2020-12-13 09:53:01,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv1.weight             loaded from backbone.body.layer3.14.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv2.weight             loaded from backbone.body.layer3.14.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv3.weight             loaded from backbone.body.layer3.14.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.bias                 loaded from backbone.body.layer3.15.bn1.bias                 of shape (1024,)
2020-12-13 09:53:01,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.running_mean         loaded from backbone.body.layer3.15.bn1.running_mean         of shape (1024,)
2020-12-13 09:53:01,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.running_var          loaded from backbone.body.layer3.15.bn1.running_var          of shape (1024,)
2020-12-13 09:53:01,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.weight               loaded from backbone.body.layer3.15.bn1.weight               of shape (1024,)
2020-12-13 09:53:01,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.bias                 loaded from backbone.body.layer3.15.bn2.bias                 of shape (1024,)
2020-12-13 09:53:01,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.running_mean         loaded from backbone.body.layer3.15.bn2.running_mean         of shape (1024,)
2020-12-13 09:53:01,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.running_var          loaded from backbone.body.layer3.15.bn2.running_var          of shape (1024,)
2020-12-13 09:53:01,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.weight               loaded from backbone.body.layer3.15.bn2.weight               of shape (1024,)
2020-12-13 09:53:01,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.bias                 loaded from backbone.body.layer3.15.bn3.bias                 of shape (1024,)
2020-12-13 09:53:01,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.running_mean         loaded from backbone.body.layer3.15.bn3.running_mean         of shape (1024,)
2020-12-13 09:53:01,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.running_var          loaded from backbone.body.layer3.15.bn3.running_var          of shape (1024,)
2020-12-13 09:53:01,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.weight               loaded from backbone.body.layer3.15.bn3.weight               of shape (1024,)
2020-12-13 09:53:01,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv1.weight             loaded from backbone.body.layer3.15.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv2.weight             loaded from backbone.body.layer3.15.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv3.weight             loaded from backbone.body.layer3.15.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.bias                 loaded from backbone.body.layer3.16.bn1.bias                 of shape (1024,)
2020-12-13 09:53:01,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.running_mean         loaded from backbone.body.layer3.16.bn1.running_mean         of shape (1024,)
2020-12-13 09:53:01,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.running_var          loaded from backbone.body.layer3.16.bn1.running_var          of shape (1024,)
2020-12-13 09:53:01,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.weight               loaded from backbone.body.layer3.16.bn1.weight               of shape (1024,)
2020-12-13 09:53:01,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.bias                 loaded from backbone.body.layer3.16.bn2.bias                 of shape (1024,)
2020-12-13 09:53:01,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.running_mean         loaded from backbone.body.layer3.16.bn2.running_mean         of shape (1024,)
2020-12-13 09:53:01,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.running_var          loaded from backbone.body.layer3.16.bn2.running_var          of shape (1024,)
2020-12-13 09:53:01,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.weight               loaded from backbone.body.layer3.16.bn2.weight               of shape (1024,)
2020-12-13 09:53:01,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.bias                 loaded from backbone.body.layer3.16.bn3.bias                 of shape (1024,)
2020-12-13 09:53:01,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.running_mean         loaded from backbone.body.layer3.16.bn3.running_mean         of shape (1024,)
2020-12-13 09:53:01,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.running_var          loaded from backbone.body.layer3.16.bn3.running_var          of shape (1024,)
2020-12-13 09:53:01,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.weight               loaded from backbone.body.layer3.16.bn3.weight               of shape (1024,)
2020-12-13 09:53:01,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv1.weight             loaded from backbone.body.layer3.16.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv2.weight             loaded from backbone.body.layer3.16.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv3.weight             loaded from backbone.body.layer3.16.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.bias                 loaded from backbone.body.layer3.17.bn1.bias                 of shape (1024,)
2020-12-13 09:53:01,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.running_mean         loaded from backbone.body.layer3.17.bn1.running_mean         of shape (1024,)
2020-12-13 09:53:01,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.running_var          loaded from backbone.body.layer3.17.bn1.running_var          of shape (1024,)
2020-12-13 09:53:01,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.weight               loaded from backbone.body.layer3.17.bn1.weight               of shape (1024,)
2020-12-13 09:53:01,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.bias                 loaded from backbone.body.layer3.17.bn2.bias                 of shape (1024,)
2020-12-13 09:53:01,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.running_mean         loaded from backbone.body.layer3.17.bn2.running_mean         of shape (1024,)
2020-12-13 09:53:01,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.running_var          loaded from backbone.body.layer3.17.bn2.running_var          of shape (1024,)
2020-12-13 09:53:01,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.weight               loaded from backbone.body.layer3.17.bn2.weight               of shape (1024,)
2020-12-13 09:53:01,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.bias                 loaded from backbone.body.layer3.17.bn3.bias                 of shape (1024,)
2020-12-13 09:53:01,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.running_mean         loaded from backbone.body.layer3.17.bn3.running_mean         of shape (1024,)
2020-12-13 09:53:01,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.running_var          loaded from backbone.body.layer3.17.bn3.running_var          of shape (1024,)
2020-12-13 09:53:01,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.weight               loaded from backbone.body.layer3.17.bn3.weight               of shape (1024,)
2020-12-13 09:53:01,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv1.weight             loaded from backbone.body.layer3.17.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv2.weight             loaded from backbone.body.layer3.17.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv3.weight             loaded from backbone.body.layer3.17.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.bias                 loaded from backbone.body.layer3.18.bn1.bias                 of shape (1024,)
2020-12-13 09:53:01,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.running_mean         loaded from backbone.body.layer3.18.bn1.running_mean         of shape (1024,)
2020-12-13 09:53:01,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.running_var          loaded from backbone.body.layer3.18.bn1.running_var          of shape (1024,)
2020-12-13 09:53:01,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.weight               loaded from backbone.body.layer3.18.bn1.weight               of shape (1024,)
2020-12-13 09:53:01,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.bias                 loaded from backbone.body.layer3.18.bn2.bias                 of shape (1024,)
2020-12-13 09:53:01,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.running_mean         loaded from backbone.body.layer3.18.bn2.running_mean         of shape (1024,)
2020-12-13 09:53:01,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.running_var          loaded from backbone.body.layer3.18.bn2.running_var          of shape (1024,)
2020-12-13 09:53:01,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.weight               loaded from backbone.body.layer3.18.bn2.weight               of shape (1024,)
2020-12-13 09:53:01,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.bias                 loaded from backbone.body.layer3.18.bn3.bias                 of shape (1024,)
2020-12-13 09:53:01,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.running_mean         loaded from backbone.body.layer3.18.bn3.running_mean         of shape (1024,)
2020-12-13 09:53:01,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.running_var          loaded from backbone.body.layer3.18.bn3.running_var          of shape (1024,)
2020-12-13 09:53:01,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.weight               loaded from backbone.body.layer3.18.bn3.weight               of shape (1024,)
2020-12-13 09:53:01,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv1.weight             loaded from backbone.body.layer3.18.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv2.weight             loaded from backbone.body.layer3.18.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv3.weight             loaded from backbone.body.layer3.18.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.bias                 loaded from backbone.body.layer3.19.bn1.bias                 of shape (1024,)
2020-12-13 09:53:01,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.running_mean         loaded from backbone.body.layer3.19.bn1.running_mean         of shape (1024,)
2020-12-13 09:53:01,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.running_var          loaded from backbone.body.layer3.19.bn1.running_var          of shape (1024,)
2020-12-13 09:53:01,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.weight               loaded from backbone.body.layer3.19.bn1.weight               of shape (1024,)
2020-12-13 09:53:01,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.bias                 loaded from backbone.body.layer3.19.bn2.bias                 of shape (1024,)
2020-12-13 09:53:01,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.running_mean         loaded from backbone.body.layer3.19.bn2.running_mean         of shape (1024,)
2020-12-13 09:53:01,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.running_var          loaded from backbone.body.layer3.19.bn2.running_var          of shape (1024,)
2020-12-13 09:53:01,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.weight               loaded from backbone.body.layer3.19.bn2.weight               of shape (1024,)
2020-12-13 09:53:01,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.bias                 loaded from backbone.body.layer3.19.bn3.bias                 of shape (1024,)
2020-12-13 09:53:01,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.running_mean         loaded from backbone.body.layer3.19.bn3.running_mean         of shape (1024,)
2020-12-13 09:53:01,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.running_var          loaded from backbone.body.layer3.19.bn3.running_var          of shape (1024,)
2020-12-13 09:53:01,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.weight               loaded from backbone.body.layer3.19.bn3.weight               of shape (1024,)
2020-12-13 09:53:01,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv1.weight             loaded from backbone.body.layer3.19.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv2.weight             loaded from backbone.body.layer3.19.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv3.weight             loaded from backbone.body.layer3.19.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                  loaded from backbone.body.layer3.2.bn1.bias                  of shape (1024,)
2020-12-13 09:53:01,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_mean          loaded from backbone.body.layer3.2.bn1.running_mean          of shape (1024,)
2020-12-13 09:53:01,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_var           loaded from backbone.body.layer3.2.bn1.running_var           of shape (1024,)
2020-12-13 09:53:01,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                loaded from backbone.body.layer3.2.bn1.weight                of shape (1024,)
2020-12-13 09:53:01,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                  loaded from backbone.body.layer3.2.bn2.bias                  of shape (1024,)
2020-12-13 09:53:01,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_mean          loaded from backbone.body.layer3.2.bn2.running_mean          of shape (1024,)
2020-12-13 09:53:01,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_var           loaded from backbone.body.layer3.2.bn2.running_var           of shape (1024,)
2020-12-13 09:53:01,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                loaded from backbone.body.layer3.2.bn2.weight                of shape (1024,)
2020-12-13 09:53:01,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                  loaded from backbone.body.layer3.2.bn3.bias                  of shape (1024,)
2020-12-13 09:53:01,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_mean          loaded from backbone.body.layer3.2.bn3.running_mean          of shape (1024,)
2020-12-13 09:53:01,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_var           loaded from backbone.body.layer3.2.bn3.running_var           of shape (1024,)
2020-12-13 09:53:01,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                loaded from backbone.body.layer3.2.bn3.weight                of shape (1024,)
2020-12-13 09:53:01,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight              loaded from backbone.body.layer3.2.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight              loaded from backbone.body.layer3.2.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight              loaded from backbone.body.layer3.2.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.bias                 loaded from backbone.body.layer3.20.bn1.bias                 of shape (1024,)
2020-12-13 09:53:01,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.running_mean         loaded from backbone.body.layer3.20.bn1.running_mean         of shape (1024,)
2020-12-13 09:53:01,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.running_var          loaded from backbone.body.layer3.20.bn1.running_var          of shape (1024,)
2020-12-13 09:53:01,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.weight               loaded from backbone.body.layer3.20.bn1.weight               of shape (1024,)
2020-12-13 09:53:01,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.bias                 loaded from backbone.body.layer3.20.bn2.bias                 of shape (1024,)
2020-12-13 09:53:01,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.running_mean         loaded from backbone.body.layer3.20.bn2.running_mean         of shape (1024,)
2020-12-13 09:53:01,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.running_var          loaded from backbone.body.layer3.20.bn2.running_var          of shape (1024,)
2020-12-13 09:53:01,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.weight               loaded from backbone.body.layer3.20.bn2.weight               of shape (1024,)
2020-12-13 09:53:01,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.bias                 loaded from backbone.body.layer3.20.bn3.bias                 of shape (1024,)
2020-12-13 09:53:01,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.running_mean         loaded from backbone.body.layer3.20.bn3.running_mean         of shape (1024,)
2020-12-13 09:53:01,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.running_var          loaded from backbone.body.layer3.20.bn3.running_var          of shape (1024,)
2020-12-13 09:53:01,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.weight               loaded from backbone.body.layer3.20.bn3.weight               of shape (1024,)
2020-12-13 09:53:01,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv1.weight             loaded from backbone.body.layer3.20.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv2.weight             loaded from backbone.body.layer3.20.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv3.weight             loaded from backbone.body.layer3.20.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.bias                 loaded from backbone.body.layer3.21.bn1.bias                 of shape (1024,)
2020-12-13 09:53:01,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.running_mean         loaded from backbone.body.layer3.21.bn1.running_mean         of shape (1024,)
2020-12-13 09:53:01,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.running_var          loaded from backbone.body.layer3.21.bn1.running_var          of shape (1024,)
2020-12-13 09:53:01,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.weight               loaded from backbone.body.layer3.21.bn1.weight               of shape (1024,)
2020-12-13 09:53:01,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.bias                 loaded from backbone.body.layer3.21.bn2.bias                 of shape (1024,)
2020-12-13 09:53:01,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.running_mean         loaded from backbone.body.layer3.21.bn2.running_mean         of shape (1024,)
2020-12-13 09:53:01,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.running_var          loaded from backbone.body.layer3.21.bn2.running_var          of shape (1024,)
2020-12-13 09:53:01,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.weight               loaded from backbone.body.layer3.21.bn2.weight               of shape (1024,)
2020-12-13 09:53:01,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.bias                 loaded from backbone.body.layer3.21.bn3.bias                 of shape (1024,)
2020-12-13 09:53:01,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.running_mean         loaded from backbone.body.layer3.21.bn3.running_mean         of shape (1024,)
2020-12-13 09:53:01,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.running_var          loaded from backbone.body.layer3.21.bn3.running_var          of shape (1024,)
2020-12-13 09:53:01,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.weight               loaded from backbone.body.layer3.21.bn3.weight               of shape (1024,)
2020-12-13 09:53:01,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv1.weight             loaded from backbone.body.layer3.21.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv2.weight             loaded from backbone.body.layer3.21.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv3.weight             loaded from backbone.body.layer3.21.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.bias                 loaded from backbone.body.layer3.22.bn1.bias                 of shape (1024,)
2020-12-13 09:53:01,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.running_mean         loaded from backbone.body.layer3.22.bn1.running_mean         of shape (1024,)
2020-12-13 09:53:01,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.running_var          loaded from backbone.body.layer3.22.bn1.running_var          of shape (1024,)
2020-12-13 09:53:01,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.weight               loaded from backbone.body.layer3.22.bn1.weight               of shape (1024,)
2020-12-13 09:53:01,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.bias                 loaded from backbone.body.layer3.22.bn2.bias                 of shape (1024,)
2020-12-13 09:53:01,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.running_mean         loaded from backbone.body.layer3.22.bn2.running_mean         of shape (1024,)
2020-12-13 09:53:01,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.running_var          loaded from backbone.body.layer3.22.bn2.running_var          of shape (1024,)
2020-12-13 09:53:01,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.weight               loaded from backbone.body.layer3.22.bn2.weight               of shape (1024,)
2020-12-13 09:53:01,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.bias                 loaded from backbone.body.layer3.22.bn3.bias                 of shape (1024,)
2020-12-13 09:53:01,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.running_mean         loaded from backbone.body.layer3.22.bn3.running_mean         of shape (1024,)
2020-12-13 09:53:01,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.running_var          loaded from backbone.body.layer3.22.bn3.running_var          of shape (1024,)
2020-12-13 09:53:01,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.weight               loaded from backbone.body.layer3.22.bn3.weight               of shape (1024,)
2020-12-13 09:53:01,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv1.weight             loaded from backbone.body.layer3.22.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv2.weight             loaded from backbone.body.layer3.22.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv3.weight             loaded from backbone.body.layer3.22.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                  loaded from backbone.body.layer3.3.bn1.bias                  of shape (1024,)
2020-12-13 09:53:01,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_mean          loaded from backbone.body.layer3.3.bn1.running_mean          of shape (1024,)
2020-12-13 09:53:01,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_var           loaded from backbone.body.layer3.3.bn1.running_var           of shape (1024,)
2020-12-13 09:53:01,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                loaded from backbone.body.layer3.3.bn1.weight                of shape (1024,)
2020-12-13 09:53:01,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                  loaded from backbone.body.layer3.3.bn2.bias                  of shape (1024,)
2020-12-13 09:53:01,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_mean          loaded from backbone.body.layer3.3.bn2.running_mean          of shape (1024,)
2020-12-13 09:53:01,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_var           loaded from backbone.body.layer3.3.bn2.running_var           of shape (1024,)
2020-12-13 09:53:01,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                loaded from backbone.body.layer3.3.bn2.weight                of shape (1024,)
2020-12-13 09:53:01,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                  loaded from backbone.body.layer3.3.bn3.bias                  of shape (1024,)
2020-12-13 09:53:01,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_mean          loaded from backbone.body.layer3.3.bn3.running_mean          of shape (1024,)
2020-12-13 09:53:01,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_var           loaded from backbone.body.layer3.3.bn3.running_var           of shape (1024,)
2020-12-13 09:53:01,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                loaded from backbone.body.layer3.3.bn3.weight                of shape (1024,)
2020-12-13 09:53:01,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight              loaded from backbone.body.layer3.3.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight              loaded from backbone.body.layer3.3.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight              loaded from backbone.body.layer3.3.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                  loaded from backbone.body.layer3.4.bn1.bias                  of shape (1024,)
2020-12-13 09:53:01,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_mean          loaded from backbone.body.layer3.4.bn1.running_mean          of shape (1024,)
2020-12-13 09:53:01,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_var           loaded from backbone.body.layer3.4.bn1.running_var           of shape (1024,)
2020-12-13 09:53:01,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                loaded from backbone.body.layer3.4.bn1.weight                of shape (1024,)
2020-12-13 09:53:01,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                  loaded from backbone.body.layer3.4.bn2.bias                  of shape (1024,)
2020-12-13 09:53:01,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_mean          loaded from backbone.body.layer3.4.bn2.running_mean          of shape (1024,)
2020-12-13 09:53:01,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_var           loaded from backbone.body.layer3.4.bn2.running_var           of shape (1024,)
2020-12-13 09:53:01,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                loaded from backbone.body.layer3.4.bn2.weight                of shape (1024,)
2020-12-13 09:53:01,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                  loaded from backbone.body.layer3.4.bn3.bias                  of shape (1024,)
2020-12-13 09:53:01,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_mean          loaded from backbone.body.layer3.4.bn3.running_mean          of shape (1024,)
2020-12-13 09:53:01,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_var           loaded from backbone.body.layer3.4.bn3.running_var           of shape (1024,)
2020-12-13 09:53:01,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                loaded from backbone.body.layer3.4.bn3.weight                of shape (1024,)
2020-12-13 09:53:01,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight              loaded from backbone.body.layer3.4.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight              loaded from backbone.body.layer3.4.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight              loaded from backbone.body.layer3.4.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                  loaded from backbone.body.layer3.5.bn1.bias                  of shape (1024,)
2020-12-13 09:53:01,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_mean          loaded from backbone.body.layer3.5.bn1.running_mean          of shape (1024,)
2020-12-13 09:53:01,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_var           loaded from backbone.body.layer3.5.bn1.running_var           of shape (1024,)
2020-12-13 09:53:01,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                loaded from backbone.body.layer3.5.bn1.weight                of shape (1024,)
2020-12-13 09:53:01,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                  loaded from backbone.body.layer3.5.bn2.bias                  of shape (1024,)
2020-12-13 09:53:01,877 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_mean          loaded from backbone.body.layer3.5.bn2.running_mean          of shape (1024,)
2020-12-13 09:53:01,877 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_var           loaded from backbone.body.layer3.5.bn2.running_var           of shape (1024,)
2020-12-13 09:53:01,877 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                loaded from backbone.body.layer3.5.bn2.weight                of shape (1024,)
2020-12-13 09:53:01,877 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                  loaded from backbone.body.layer3.5.bn3.bias                  of shape (1024,)
2020-12-13 09:53:01,877 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_mean          loaded from backbone.body.layer3.5.bn3.running_mean          of shape (1024,)
2020-12-13 09:53:01,877 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_var           loaded from backbone.body.layer3.5.bn3.running_var           of shape (1024,)
2020-12-13 09:53:01,877 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                loaded from backbone.body.layer3.5.bn3.weight                of shape (1024,)
2020-12-13 09:53:01,877 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight              loaded from backbone.body.layer3.5.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,877 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight              loaded from backbone.body.layer3.5.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,877 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight              loaded from backbone.body.layer3.5.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,877 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.bias                  loaded from backbone.body.layer3.6.bn1.bias                  of shape (1024,)
2020-12-13 09:53:01,877 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.running_mean          loaded from backbone.body.layer3.6.bn1.running_mean          of shape (1024,)
2020-12-13 09:53:01,877 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.running_var           loaded from backbone.body.layer3.6.bn1.running_var           of shape (1024,)
2020-12-13 09:53:01,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.weight                loaded from backbone.body.layer3.6.bn1.weight                of shape (1024,)
2020-12-13 09:53:01,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.bias                  loaded from backbone.body.layer3.6.bn2.bias                  of shape (1024,)
2020-12-13 09:53:01,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.running_mean          loaded from backbone.body.layer3.6.bn2.running_mean          of shape (1024,)
2020-12-13 09:53:01,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.running_var           loaded from backbone.body.layer3.6.bn2.running_var           of shape (1024,)
2020-12-13 09:53:01,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.weight                loaded from backbone.body.layer3.6.bn2.weight                of shape (1024,)
2020-12-13 09:53:01,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.bias                  loaded from backbone.body.layer3.6.bn3.bias                  of shape (1024,)
2020-12-13 09:53:01,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.running_mean          loaded from backbone.body.layer3.6.bn3.running_mean          of shape (1024,)
2020-12-13 09:53:01,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.running_var           loaded from backbone.body.layer3.6.bn3.running_var           of shape (1024,)
2020-12-13 09:53:01,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.weight                loaded from backbone.body.layer3.6.bn3.weight                of shape (1024,)
2020-12-13 09:53:01,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv1.weight              loaded from backbone.body.layer3.6.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv2.weight              loaded from backbone.body.layer3.6.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv3.weight              loaded from backbone.body.layer3.6.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.bias                  loaded from backbone.body.layer3.7.bn1.bias                  of shape (1024,)
2020-12-13 09:53:01,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.running_mean          loaded from backbone.body.layer3.7.bn1.running_mean          of shape (1024,)
2020-12-13 09:53:01,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.running_var           loaded from backbone.body.layer3.7.bn1.running_var           of shape (1024,)
2020-12-13 09:53:01,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.weight                loaded from backbone.body.layer3.7.bn1.weight                of shape (1024,)
2020-12-13 09:53:01,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.bias                  loaded from backbone.body.layer3.7.bn2.bias                  of shape (1024,)
2020-12-13 09:53:01,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.running_mean          loaded from backbone.body.layer3.7.bn2.running_mean          of shape (1024,)
2020-12-13 09:53:01,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.running_var           loaded from backbone.body.layer3.7.bn2.running_var           of shape (1024,)
2020-12-13 09:53:01,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.weight                loaded from backbone.body.layer3.7.bn2.weight                of shape (1024,)
2020-12-13 09:53:01,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.bias                  loaded from backbone.body.layer3.7.bn3.bias                  of shape (1024,)
2020-12-13 09:53:01,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.running_mean          loaded from backbone.body.layer3.7.bn3.running_mean          of shape (1024,)
2020-12-13 09:53:01,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.running_var           loaded from backbone.body.layer3.7.bn3.running_var           of shape (1024,)
2020-12-13 09:53:01,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.weight                loaded from backbone.body.layer3.7.bn3.weight                of shape (1024,)
2020-12-13 09:53:01,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv1.weight              loaded from backbone.body.layer3.7.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv2.weight              loaded from backbone.body.layer3.7.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv3.weight              loaded from backbone.body.layer3.7.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.bias                  loaded from backbone.body.layer3.8.bn1.bias                  of shape (1024,)
2020-12-13 09:53:01,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.running_mean          loaded from backbone.body.layer3.8.bn1.running_mean          of shape (1024,)
2020-12-13 09:53:01,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.running_var           loaded from backbone.body.layer3.8.bn1.running_var           of shape (1024,)
2020-12-13 09:53:01,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.weight                loaded from backbone.body.layer3.8.bn1.weight                of shape (1024,)
2020-12-13 09:53:01,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.bias                  loaded from backbone.body.layer3.8.bn2.bias                  of shape (1024,)
2020-12-13 09:53:01,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.running_mean          loaded from backbone.body.layer3.8.bn2.running_mean          of shape (1024,)
2020-12-13 09:53:01,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.running_var           loaded from backbone.body.layer3.8.bn2.running_var           of shape (1024,)
2020-12-13 09:53:01,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.weight                loaded from backbone.body.layer3.8.bn2.weight                of shape (1024,)
2020-12-13 09:53:01,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.bias                  loaded from backbone.body.layer3.8.bn3.bias                  of shape (1024,)
2020-12-13 09:53:01,880 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.running_mean          loaded from backbone.body.layer3.8.bn3.running_mean          of shape (1024,)
2020-12-13 09:53:01,881 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.running_var           loaded from backbone.body.layer3.8.bn3.running_var           of shape (1024,)
2020-12-13 09:53:01,881 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.weight                loaded from backbone.body.layer3.8.bn3.weight                of shape (1024,)
2020-12-13 09:53:01,881 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv1.weight              loaded from backbone.body.layer3.8.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,881 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv2.weight              loaded from backbone.body.layer3.8.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,881 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv3.weight              loaded from backbone.body.layer3.8.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,881 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.bias                  loaded from backbone.body.layer3.9.bn1.bias                  of shape (1024,)
2020-12-13 09:53:01,881 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.running_mean          loaded from backbone.body.layer3.9.bn1.running_mean          of shape (1024,)
2020-12-13 09:53:01,881 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.running_var           loaded from backbone.body.layer3.9.bn1.running_var           of shape (1024,)
2020-12-13 09:53:01,881 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.weight                loaded from backbone.body.layer3.9.bn1.weight                of shape (1024,)
2020-12-13 09:53:01,881 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.bias                  loaded from backbone.body.layer3.9.bn2.bias                  of shape (1024,)
2020-12-13 09:53:01,881 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.running_mean          loaded from backbone.body.layer3.9.bn2.running_mean          of shape (1024,)
2020-12-13 09:53:01,881 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.running_var           loaded from backbone.body.layer3.9.bn2.running_var           of shape (1024,)
2020-12-13 09:53:01,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.weight                loaded from backbone.body.layer3.9.bn2.weight                of shape (1024,)
2020-12-13 09:53:01,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.bias                  loaded from backbone.body.layer3.9.bn3.bias                  of shape (1024,)
2020-12-13 09:53:01,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.running_mean          loaded from backbone.body.layer3.9.bn3.running_mean          of shape (1024,)
2020-12-13 09:53:01,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.running_var           loaded from backbone.body.layer3.9.bn3.running_var           of shape (1024,)
2020-12-13 09:53:01,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.weight                loaded from backbone.body.layer3.9.bn3.weight                of shape (1024,)
2020-12-13 09:53:01,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv1.weight              loaded from backbone.body.layer3.9.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv2.weight              loaded from backbone.body.layer3.9.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:53:01,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv3.weight              loaded from backbone.body.layer3.9.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:53:01,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                  loaded from backbone.body.layer4.0.bn1.bias                  of shape (2048,)
2020-12-13 09:53:01,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_mean          loaded from backbone.body.layer4.0.bn1.running_mean          of shape (2048,)
2020-12-13 09:53:01,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_var           loaded from backbone.body.layer4.0.bn1.running_var           of shape (2048,)
2020-12-13 09:53:01,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                loaded from backbone.body.layer4.0.bn1.weight                of shape (2048,)
2020-12-13 09:53:01,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                  loaded from backbone.body.layer4.0.bn2.bias                  of shape (2048,)
2020-12-13 09:53:01,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_mean          loaded from backbone.body.layer4.0.bn2.running_mean          of shape (2048,)
2020-12-13 09:53:01,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_var           loaded from backbone.body.layer4.0.bn2.running_var           of shape (2048,)
2020-12-13 09:53:01,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                loaded from backbone.body.layer4.0.bn2.weight                of shape (2048,)
2020-12-13 09:53:01,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                  loaded from backbone.body.layer4.0.bn3.bias                  of shape (2048,)
2020-12-13 09:53:01,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_mean          loaded from backbone.body.layer4.0.bn3.running_mean          of shape (2048,)
2020-12-13 09:53:01,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_var           loaded from backbone.body.layer4.0.bn3.running_var           of shape (2048,)
2020-12-13 09:53:01,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                loaded from backbone.body.layer4.0.bn3.weight                of shape (2048,)
2020-12-13 09:53:01,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight              loaded from backbone.body.layer4.0.conv1.weight              of shape (2048, 1024, 1, 1)
2020-12-13 09:53:01,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv2.weight              loaded from backbone.body.layer4.0.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 09:53:01,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight              loaded from backbone.body.layer4.0.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 09:53:01,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight       loaded from backbone.body.layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)
2020-12-13 09:53:01,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias         loaded from backbone.body.layer4.0.downsample.1.bias         of shape (2048,)
2020-12-13 09:53:01,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_mean loaded from backbone.body.layer4.0.downsample.1.running_mean of shape (2048,)
2020-12-13 09:53:01,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_var  loaded from backbone.body.layer4.0.downsample.1.running_var  of shape (2048,)
2020-12-13 09:53:01,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight       loaded from backbone.body.layer4.0.downsample.1.weight       of shape (2048,)
2020-12-13 09:53:01,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                  loaded from backbone.body.layer4.1.bn1.bias                  of shape (2048,)
2020-12-13 09:53:01,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_mean          loaded from backbone.body.layer4.1.bn1.running_mean          of shape (2048,)
2020-12-13 09:53:01,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_var           loaded from backbone.body.layer4.1.bn1.running_var           of shape (2048,)
2020-12-13 09:53:01,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                loaded from backbone.body.layer4.1.bn1.weight                of shape (2048,)
2020-12-13 09:53:01,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                  loaded from backbone.body.layer4.1.bn2.bias                  of shape (2048,)
2020-12-13 09:53:01,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_mean          loaded from backbone.body.layer4.1.bn2.running_mean          of shape (2048,)
2020-12-13 09:53:01,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_var           loaded from backbone.body.layer4.1.bn2.running_var           of shape (2048,)
2020-12-13 09:53:01,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                loaded from backbone.body.layer4.1.bn2.weight                of shape (2048,)
2020-12-13 09:53:01,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                  loaded from backbone.body.layer4.1.bn3.bias                  of shape (2048,)
2020-12-13 09:53:01,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_mean          loaded from backbone.body.layer4.1.bn3.running_mean          of shape (2048,)
2020-12-13 09:53:01,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_var           loaded from backbone.body.layer4.1.bn3.running_var           of shape (2048,)
2020-12-13 09:53:01,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                loaded from backbone.body.layer4.1.bn3.weight                of shape (2048,)
2020-12-13 09:53:01,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight              loaded from backbone.body.layer4.1.conv1.weight              of shape (2048, 2048, 1, 1)
2020-12-13 09:53:01,884 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv2.weight              loaded from backbone.body.layer4.1.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 09:53:01,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight              loaded from backbone.body.layer4.1.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 09:53:01,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                  loaded from backbone.body.layer4.2.bn1.bias                  of shape (2048,)
2020-12-13 09:53:01,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_mean          loaded from backbone.body.layer4.2.bn1.running_mean          of shape (2048,)
2020-12-13 09:53:01,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_var           loaded from backbone.body.layer4.2.bn1.running_var           of shape (2048,)
2020-12-13 09:53:01,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                loaded from backbone.body.layer4.2.bn1.weight                of shape (2048,)
2020-12-13 09:53:01,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                  loaded from backbone.body.layer4.2.bn2.bias                  of shape (2048,)
2020-12-13 09:53:01,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_mean          loaded from backbone.body.layer4.2.bn2.running_mean          of shape (2048,)
2020-12-13 09:53:01,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_var           loaded from backbone.body.layer4.2.bn2.running_var           of shape (2048,)
2020-12-13 09:53:01,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                loaded from backbone.body.layer4.2.bn2.weight                of shape (2048,)
2020-12-13 09:53:01,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                  loaded from backbone.body.layer4.2.bn3.bias                  of shape (2048,)
2020-12-13 09:53:01,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_mean          loaded from backbone.body.layer4.2.bn3.running_mean          of shape (2048,)
2020-12-13 09:53:01,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_var           loaded from backbone.body.layer4.2.bn3.running_var           of shape (2048,)
2020-12-13 09:53:01,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                loaded from backbone.body.layer4.2.bn3.weight                of shape (2048,)
2020-12-13 09:53:01,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight              loaded from backbone.body.layer4.2.conv1.weight              of shape (2048, 2048, 1, 1)
2020-12-13 09:53:01,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv2.weight              loaded from backbone.body.layer4.2.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 09:53:01,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight              loaded from backbone.body.layer4.2.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 09:53:01,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                      loaded from backbone.body.stem.bn1.bias                      of shape (64,)
2020-12-13 09:53:01,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_mean              loaded from backbone.body.stem.bn1.running_mean              of shape (64,)
2020-12-13 09:53:01,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_var               loaded from backbone.body.stem.bn1.running_var               of shape (64,)
2020-12-13 09:53:01,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                    loaded from backbone.body.stem.bn1.weight                    of shape (64,)
2020-12-13 09:53:01,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                  loaded from backbone.body.stem.conv1.weight                  of shape (64, 3, 7, 7)
2020-12-13 09:53:01,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.bias                     loaded from backbone.fpn.fpn_inner1.bias                     of shape (256,)
2020-12-13 09:53:01,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.weight                   loaded from backbone.fpn.fpn_inner1.weight                   of shape (256, 256, 1, 1)
2020-12-13 09:53:01,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                     loaded from backbone.fpn.fpn_inner2.bias                     of shape (256,)
2020-12-13 09:53:01,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                   loaded from backbone.fpn.fpn_inner2.weight                   of shape (256, 512, 1, 1)
2020-12-13 09:53:01,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                     loaded from backbone.fpn.fpn_inner3.bias                     of shape (256,)
2020-12-13 09:53:01,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                   loaded from backbone.fpn.fpn_inner3.weight                   of shape (256, 1024, 1, 1)
2020-12-13 09:53:01,886 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                     loaded from backbone.fpn.fpn_inner4.bias                     of shape (256,)
2020-12-13 09:53:01,887 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                   loaded from backbone.fpn.fpn_inner4.weight                   of shape (256, 2048, 1, 1)
2020-12-13 09:53:01,887 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.bias                     loaded from backbone.fpn.fpn_layer1.bias                     of shape (256,)
2020-12-13 09:53:01,887 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.weight                   loaded from backbone.fpn.fpn_layer1.weight                   of shape (256, 256, 3, 3)
2020-12-13 09:53:01,887 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                     loaded from backbone.fpn.fpn_layer2.bias                     of shape (256,)
2020-12-13 09:53:01,887 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                   loaded from backbone.fpn.fpn_layer2.weight                   of shape (256, 256, 3, 3)
2020-12-13 09:53:01,887 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                     loaded from backbone.fpn.fpn_layer3.bias                     of shape (256,)
2020-12-13 09:53:01,887 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                   loaded from backbone.fpn.fpn_layer3.weight                   of shape (256, 256, 3, 3)
2020-12-13 09:53:01,887 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                     loaded from backbone.fpn.fpn_layer4.bias                     of shape (256,)
2020-12-13 09:53:01,887 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                   loaded from backbone.fpn.fpn_layer4.weight                   of shape (256, 256, 3, 3)
2020-12-13 09:53:01,887 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.bias         loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (1024,)
2020-12-13 09:53:01,887 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.weight       loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (1024, 12544)
2020-12-13 09:53:01,887 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.bias         loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (1024,)
2020-12-13 09:53:01,887 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.weight       loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (1024, 1024)
2020-12-13 09:53:01,887 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.bias           loaded from roi_heads.box.predictor.bbox_pred.bias           of shape (324,)
2020-12-13 09:53:01,888 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.weight         loaded from roi_heads.box.predictor.bbox_pred.weight         of shape (324, 1024)
2020-12-13 09:53:01,888 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.bias           loaded from roi_heads.box.predictor.cls_score.bias           of shape (81,)
2020-12-13 09:53:01,888 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.weight         loaded from roi_heads.box.predictor.cls_score.weight         of shape (81, 1024)
2020-12-13 09:53:01,888 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.0              loaded from rpn.anchor_generator.cell_anchors.0              of shape (3, 4)
2020-12-13 09:53:01,888 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.1              loaded from rpn.anchor_generator.cell_anchors.1              of shape (3, 4)
2020-12-13 09:53:01,888 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.2              loaded from rpn.anchor_generator.cell_anchors.2              of shape (3, 4)
2020-12-13 09:53:01,888 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.3              loaded from rpn.anchor_generator.cell_anchors.3              of shape (3, 4)
2020-12-13 09:53:01,888 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.4              loaded from rpn.anchor_generator.cell_anchors.4              of shape (3, 4)
2020-12-13 09:53:01,888 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                          loaded from rpn.head.bbox_pred.bias                          of shape (12,)
2020-12-13 09:53:01,888 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                        loaded from rpn.head.bbox_pred.weight                        of shape (12, 256, 1, 1)
2020-12-13 09:53:01,888 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                         loaded from rpn.head.cls_logits.bias                         of shape (3,)
2020-12-13 09:53:01,888 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                       loaded from rpn.head.cls_logits.weight                       of shape (3, 256, 1, 1)
2020-12-13 09:53:01,888 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.bias                               loaded from rpn.head.conv.bias                               of shape (256,)
2020-12-13 09:53:01,888 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.weight                             loaded from rpn.head.conv.weight                             of shape (256, 256, 3, 3)
2020-12-13 09:53:02,057 maskrcnn_benchmark INFO: reloading weigts from _best_acc_r5_v5.pth
2020-12-13 09:53:08,533 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-13 09:53:08,534 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-13 09:53:08,534 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-13 09:53:08,534 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-13 09:53:08,534 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-13 09:53:08,534 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-13 09:53:08,535 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-13 09:53:08,535 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-13 09:53:08,535 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-13 09:53:08,535 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-13 09:53:08,535 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-13 09:53:08,535 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-13 09:53:08,536 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-13 09:53:08,536 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-13 09:53:09,048 maskrcnn_benchmark.trainer INFO: Start training
2020-12-13 09:53:40,211 maskrcnn_benchmark.trainer INFO: eta: 17:18:01  iter: 20  loss: 9.5561 (9.7808)  loss_classifier: 0.1934 (0.3913)  loss_box_reg: 0.4575 (0.5933)  loss_objectness: 0.6721 (0.7425)  loss_rpn_box_reg: 8.0155 (8.0538)  time: 1.5242 (1.5578)  data: 0.0986 (0.1053)  lr: 0.000000  max mem: 974
2020-12-13 09:54:13,079 maskrcnn_benchmark.trainer INFO: eta: 17:46:00  iter: 40  loss: 9.5673 (9.7270)  loss_classifier: 0.2500 (0.3267)  loss_box_reg: 0.5309 (0.5577)  loss_objectness: 0.6929 (0.7303)  loss_rpn_box_reg: 8.2405 (8.1123)  time: 1.6450 (1.6006)  data: 0.1081 (0.1079)  lr: 0.000000  max mem: 974
2020-12-13 09:55:12,761 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 09:55:12,761 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 09:55:12,761 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 09:55:17,220 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 09:55:17,221 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 09:55:17,222 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_valid",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00000008
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 40000
  IMS_PER_BATCH: 1
TEST:
  IMS_PER_BATCH: 1

2020-12-13 09:55:17,224 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_valid',)
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.1
    FG_IOU_THRESHOLD: 0.2
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 8e-08
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  MAX_ITER: 40000
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-13 09:55:19,047 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from visdrone_model_0360000.pth
2020-12-13 09:55:22,033 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                  loaded from backbone.body.layer1.0.bn1.bias                  of shape (256,)
2020-12-13 09:55:22,034 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_mean          loaded from backbone.body.layer1.0.bn1.running_mean          of shape (256,)
2020-12-13 09:55:22,034 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_var           loaded from backbone.body.layer1.0.bn1.running_var           of shape (256,)
2020-12-13 09:55:22,034 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                loaded from backbone.body.layer1.0.bn1.weight                of shape (256,)
2020-12-13 09:55:22,034 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                  loaded from backbone.body.layer1.0.bn2.bias                  of shape (256,)
2020-12-13 09:55:22,034 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_mean          loaded from backbone.body.layer1.0.bn2.running_mean          of shape (256,)
2020-12-13 09:55:22,034 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_var           loaded from backbone.body.layer1.0.bn2.running_var           of shape (256,)
2020-12-13 09:55:22,034 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                loaded from backbone.body.layer1.0.bn2.weight                of shape (256,)
2020-12-13 09:55:22,034 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                  loaded from backbone.body.layer1.0.bn3.bias                  of shape (256,)
2020-12-13 09:55:22,034 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_mean          loaded from backbone.body.layer1.0.bn3.running_mean          of shape (256,)
2020-12-13 09:55:22,035 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_var           loaded from backbone.body.layer1.0.bn3.running_var           of shape (256,)
2020-12-13 09:55:22,035 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                loaded from backbone.body.layer1.0.bn3.weight                of shape (256,)
2020-12-13 09:55:22,035 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight              loaded from backbone.body.layer1.0.conv1.weight              of shape (256, 64, 1, 1)
2020-12-13 09:55:22,035 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight              loaded from backbone.body.layer1.0.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 09:55:22,035 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight              loaded from backbone.body.layer1.0.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 09:55:22,035 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight       loaded from backbone.body.layer1.0.downsample.0.weight       of shape (256, 64, 1, 1)
2020-12-13 09:55:22,035 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias         loaded from backbone.body.layer1.0.downsample.1.bias         of shape (256,)
2020-12-13 09:55:22,035 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_mean loaded from backbone.body.layer1.0.downsample.1.running_mean of shape (256,)
2020-12-13 09:55:22,035 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_var  loaded from backbone.body.layer1.0.downsample.1.running_var  of shape (256,)
2020-12-13 09:55:22,035 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight       loaded from backbone.body.layer1.0.downsample.1.weight       of shape (256,)
2020-12-13 09:55:22,035 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                  loaded from backbone.body.layer1.1.bn1.bias                  of shape (256,)
2020-12-13 09:55:22,035 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_mean          loaded from backbone.body.layer1.1.bn1.running_mean          of shape (256,)
2020-12-13 09:55:22,036 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_var           loaded from backbone.body.layer1.1.bn1.running_var           of shape (256,)
2020-12-13 09:55:22,036 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                loaded from backbone.body.layer1.1.bn1.weight                of shape (256,)
2020-12-13 09:55:22,036 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                  loaded from backbone.body.layer1.1.bn2.bias                  of shape (256,)
2020-12-13 09:55:22,036 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_mean          loaded from backbone.body.layer1.1.bn2.running_mean          of shape (256,)
2020-12-13 09:55:22,036 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_var           loaded from backbone.body.layer1.1.bn2.running_var           of shape (256,)
2020-12-13 09:55:22,036 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                loaded from backbone.body.layer1.1.bn2.weight                of shape (256,)
2020-12-13 09:55:22,036 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                  loaded from backbone.body.layer1.1.bn3.bias                  of shape (256,)
2020-12-13 09:55:22,036 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_mean          loaded from backbone.body.layer1.1.bn3.running_mean          of shape (256,)
2020-12-13 09:55:22,036 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_var           loaded from backbone.body.layer1.1.bn3.running_var           of shape (256,)
2020-12-13 09:55:22,036 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                loaded from backbone.body.layer1.1.bn3.weight                of shape (256,)
2020-12-13 09:55:22,036 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight              loaded from backbone.body.layer1.1.conv1.weight              of shape (256, 256, 1, 1)
2020-12-13 09:55:22,036 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight              loaded from backbone.body.layer1.1.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 09:55:22,037 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight              loaded from backbone.body.layer1.1.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 09:55:22,037 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                  loaded from backbone.body.layer1.2.bn1.bias                  of shape (256,)
2020-12-13 09:55:22,037 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_mean          loaded from backbone.body.layer1.2.bn1.running_mean          of shape (256,)
2020-12-13 09:55:22,037 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_var           loaded from backbone.body.layer1.2.bn1.running_var           of shape (256,)
2020-12-13 09:55:22,037 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                loaded from backbone.body.layer1.2.bn1.weight                of shape (256,)
2020-12-13 09:55:22,037 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                  loaded from backbone.body.layer1.2.bn2.bias                  of shape (256,)
2020-12-13 09:55:22,037 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_mean          loaded from backbone.body.layer1.2.bn2.running_mean          of shape (256,)
2020-12-13 09:55:22,037 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_var           loaded from backbone.body.layer1.2.bn2.running_var           of shape (256,)
2020-12-13 09:55:22,037 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                loaded from backbone.body.layer1.2.bn2.weight                of shape (256,)
2020-12-13 09:55:22,037 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                  loaded from backbone.body.layer1.2.bn3.bias                  of shape (256,)
2020-12-13 09:55:22,037 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_mean          loaded from backbone.body.layer1.2.bn3.running_mean          of shape (256,)
2020-12-13 09:55:22,037 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_var           loaded from backbone.body.layer1.2.bn3.running_var           of shape (256,)
2020-12-13 09:55:22,038 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                loaded from backbone.body.layer1.2.bn3.weight                of shape (256,)
2020-12-13 09:55:22,038 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight              loaded from backbone.body.layer1.2.conv1.weight              of shape (256, 256, 1, 1)
2020-12-13 09:55:22,038 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight              loaded from backbone.body.layer1.2.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 09:55:22,038 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight              loaded from backbone.body.layer1.2.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 09:55:22,038 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                  loaded from backbone.body.layer2.0.bn1.bias                  of shape (512,)
2020-12-13 09:55:22,038 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_mean          loaded from backbone.body.layer2.0.bn1.running_mean          of shape (512,)
2020-12-13 09:55:22,038 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_var           loaded from backbone.body.layer2.0.bn1.running_var           of shape (512,)
2020-12-13 09:55:22,038 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                loaded from backbone.body.layer2.0.bn1.weight                of shape (512,)
2020-12-13 09:55:22,038 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                  loaded from backbone.body.layer2.0.bn2.bias                  of shape (512,)
2020-12-13 09:55:22,038 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_mean          loaded from backbone.body.layer2.0.bn2.running_mean          of shape (512,)
2020-12-13 09:55:22,038 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_var           loaded from backbone.body.layer2.0.bn2.running_var           of shape (512,)
2020-12-13 09:55:22,038 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                loaded from backbone.body.layer2.0.bn2.weight                of shape (512,)
2020-12-13 09:55:22,038 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                  loaded from backbone.body.layer2.0.bn3.bias                  of shape (512,)
2020-12-13 09:55:22,039 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_mean          loaded from backbone.body.layer2.0.bn3.running_mean          of shape (512,)
2020-12-13 09:55:22,039 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_var           loaded from backbone.body.layer2.0.bn3.running_var           of shape (512,)
2020-12-13 09:55:22,039 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                loaded from backbone.body.layer2.0.bn3.weight                of shape (512,)
2020-12-13 09:55:22,039 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight              loaded from backbone.body.layer2.0.conv1.weight              of shape (512, 256, 1, 1)
2020-12-13 09:55:22,039 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight              loaded from backbone.body.layer2.0.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 09:55:22,039 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight              loaded from backbone.body.layer2.0.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 09:55:22,039 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight       loaded from backbone.body.layer2.0.downsample.0.weight       of shape (512, 256, 1, 1)
2020-12-13 09:55:22,039 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias         loaded from backbone.body.layer2.0.downsample.1.bias         of shape (512,)
2020-12-13 09:55:22,039 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_mean loaded from backbone.body.layer2.0.downsample.1.running_mean of shape (512,)
2020-12-13 09:55:22,039 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_var  loaded from backbone.body.layer2.0.downsample.1.running_var  of shape (512,)
2020-12-13 09:55:22,039 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight       loaded from backbone.body.layer2.0.downsample.1.weight       of shape (512,)
2020-12-13 09:55:22,039 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                  loaded from backbone.body.layer2.1.bn1.bias                  of shape (512,)
2020-12-13 09:55:22,039 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_mean          loaded from backbone.body.layer2.1.bn1.running_mean          of shape (512,)
2020-12-13 09:55:22,040 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_var           loaded from backbone.body.layer2.1.bn1.running_var           of shape (512,)
2020-12-13 09:55:22,040 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                loaded from backbone.body.layer2.1.bn1.weight                of shape (512,)
2020-12-13 09:55:22,040 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                  loaded from backbone.body.layer2.1.bn2.bias                  of shape (512,)
2020-12-13 09:55:22,040 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_mean          loaded from backbone.body.layer2.1.bn2.running_mean          of shape (512,)
2020-12-13 09:55:22,040 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_var           loaded from backbone.body.layer2.1.bn2.running_var           of shape (512,)
2020-12-13 09:55:22,040 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                loaded from backbone.body.layer2.1.bn2.weight                of shape (512,)
2020-12-13 09:55:22,040 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                  loaded from backbone.body.layer2.1.bn3.bias                  of shape (512,)
2020-12-13 09:55:22,040 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_mean          loaded from backbone.body.layer2.1.bn3.running_mean          of shape (512,)
2020-12-13 09:55:22,040 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_var           loaded from backbone.body.layer2.1.bn3.running_var           of shape (512,)
2020-12-13 09:55:22,040 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                loaded from backbone.body.layer2.1.bn3.weight                of shape (512,)
2020-12-13 09:55:22,040 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight              loaded from backbone.body.layer2.1.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 09:55:22,040 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight              loaded from backbone.body.layer2.1.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 09:55:22,041 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight              loaded from backbone.body.layer2.1.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 09:55:22,041 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                  loaded from backbone.body.layer2.2.bn1.bias                  of shape (512,)
2020-12-13 09:55:22,041 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_mean          loaded from backbone.body.layer2.2.bn1.running_mean          of shape (512,)
2020-12-13 09:55:22,041 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_var           loaded from backbone.body.layer2.2.bn1.running_var           of shape (512,)
2020-12-13 09:55:22,041 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                loaded from backbone.body.layer2.2.bn1.weight                of shape (512,)
2020-12-13 09:55:22,041 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                  loaded from backbone.body.layer2.2.bn2.bias                  of shape (512,)
2020-12-13 09:55:22,041 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_mean          loaded from backbone.body.layer2.2.bn2.running_mean          of shape (512,)
2020-12-13 09:55:22,041 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_var           loaded from backbone.body.layer2.2.bn2.running_var           of shape (512,)
2020-12-13 09:55:22,041 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                loaded from backbone.body.layer2.2.bn2.weight                of shape (512,)
2020-12-13 09:55:22,041 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                  loaded from backbone.body.layer2.2.bn3.bias                  of shape (512,)
2020-12-13 09:55:22,042 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_mean          loaded from backbone.body.layer2.2.bn3.running_mean          of shape (512,)
2020-12-13 09:55:22,042 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_var           loaded from backbone.body.layer2.2.bn3.running_var           of shape (512,)
2020-12-13 09:55:22,042 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                loaded from backbone.body.layer2.2.bn3.weight                of shape (512,)
2020-12-13 09:55:22,042 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight              loaded from backbone.body.layer2.2.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 09:55:22,042 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight              loaded from backbone.body.layer2.2.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 09:55:22,042 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight              loaded from backbone.body.layer2.2.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 09:55:22,042 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                  loaded from backbone.body.layer2.3.bn1.bias                  of shape (512,)
2020-12-13 09:55:22,042 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_mean          loaded from backbone.body.layer2.3.bn1.running_mean          of shape (512,)
2020-12-13 09:55:22,042 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_var           loaded from backbone.body.layer2.3.bn1.running_var           of shape (512,)
2020-12-13 09:55:22,042 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                loaded from backbone.body.layer2.3.bn1.weight                of shape (512,)
2020-12-13 09:55:22,042 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                  loaded from backbone.body.layer2.3.bn2.bias                  of shape (512,)
2020-12-13 09:55:22,043 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_mean          loaded from backbone.body.layer2.3.bn2.running_mean          of shape (512,)
2020-12-13 09:55:22,043 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_var           loaded from backbone.body.layer2.3.bn2.running_var           of shape (512,)
2020-12-13 09:55:22,043 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                loaded from backbone.body.layer2.3.bn2.weight                of shape (512,)
2020-12-13 09:55:22,043 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                  loaded from backbone.body.layer2.3.bn3.bias                  of shape (512,)
2020-12-13 09:55:22,043 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_mean          loaded from backbone.body.layer2.3.bn3.running_mean          of shape (512,)
2020-12-13 09:55:22,043 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_var           loaded from backbone.body.layer2.3.bn3.running_var           of shape (512,)
2020-12-13 09:55:22,043 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                loaded from backbone.body.layer2.3.bn3.weight                of shape (512,)
2020-12-13 09:55:22,043 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight              loaded from backbone.body.layer2.3.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 09:55:22,043 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight              loaded from backbone.body.layer2.3.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 09:55:22,043 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight              loaded from backbone.body.layer2.3.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 09:55:22,043 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                  loaded from backbone.body.layer3.0.bn1.bias                  of shape (1024,)
2020-12-13 09:55:22,044 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_mean          loaded from backbone.body.layer3.0.bn1.running_mean          of shape (1024,)
2020-12-13 09:55:22,044 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_var           loaded from backbone.body.layer3.0.bn1.running_var           of shape (1024,)
2020-12-13 09:55:22,044 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                loaded from backbone.body.layer3.0.bn1.weight                of shape (1024,)
2020-12-13 09:55:22,044 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                  loaded from backbone.body.layer3.0.bn2.bias                  of shape (1024,)
2020-12-13 09:55:22,044 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_mean          loaded from backbone.body.layer3.0.bn2.running_mean          of shape (1024,)
2020-12-13 09:55:22,044 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_var           loaded from backbone.body.layer3.0.bn2.running_var           of shape (1024,)
2020-12-13 09:55:22,044 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                loaded from backbone.body.layer3.0.bn2.weight                of shape (1024,)
2020-12-13 09:55:22,044 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                  loaded from backbone.body.layer3.0.bn3.bias                  of shape (1024,)
2020-12-13 09:55:22,044 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_mean          loaded from backbone.body.layer3.0.bn3.running_mean          of shape (1024,)
2020-12-13 09:55:22,044 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_var           loaded from backbone.body.layer3.0.bn3.running_var           of shape (1024,)
2020-12-13 09:55:22,044 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                loaded from backbone.body.layer3.0.bn3.weight                of shape (1024,)
2020-12-13 09:55:22,044 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight              loaded from backbone.body.layer3.0.conv1.weight              of shape (1024, 512, 1, 1)
2020-12-13 09:55:22,044 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight              loaded from backbone.body.layer3.0.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,045 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight              loaded from backbone.body.layer3.0.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,045 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight       loaded from backbone.body.layer3.0.downsample.0.weight       of shape (1024, 512, 1, 1)
2020-12-13 09:55:22,045 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias         loaded from backbone.body.layer3.0.downsample.1.bias         of shape (1024,)
2020-12-13 09:55:22,045 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_mean loaded from backbone.body.layer3.0.downsample.1.running_mean of shape (1024,)
2020-12-13 09:55:22,045 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_var  loaded from backbone.body.layer3.0.downsample.1.running_var  of shape (1024,)
2020-12-13 09:55:22,045 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight       loaded from backbone.body.layer3.0.downsample.1.weight       of shape (1024,)
2020-12-13 09:55:22,045 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                  loaded from backbone.body.layer3.1.bn1.bias                  of shape (1024,)
2020-12-13 09:55:22,045 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_mean          loaded from backbone.body.layer3.1.bn1.running_mean          of shape (1024,)
2020-12-13 09:55:22,045 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_var           loaded from backbone.body.layer3.1.bn1.running_var           of shape (1024,)
2020-12-13 09:55:22,045 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                loaded from backbone.body.layer3.1.bn1.weight                of shape (1024,)
2020-12-13 09:55:22,045 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                  loaded from backbone.body.layer3.1.bn2.bias                  of shape (1024,)
2020-12-13 09:55:22,045 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_mean          loaded from backbone.body.layer3.1.bn2.running_mean          of shape (1024,)
2020-12-13 09:55:22,045 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_var           loaded from backbone.body.layer3.1.bn2.running_var           of shape (1024,)
2020-12-13 09:55:22,046 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                loaded from backbone.body.layer3.1.bn2.weight                of shape (1024,)
2020-12-13 09:55:22,046 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                  loaded from backbone.body.layer3.1.bn3.bias                  of shape (1024,)
2020-12-13 09:55:22,046 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_mean          loaded from backbone.body.layer3.1.bn3.running_mean          of shape (1024,)
2020-12-13 09:55:22,046 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_var           loaded from backbone.body.layer3.1.bn3.running_var           of shape (1024,)
2020-12-13 09:55:22,046 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                loaded from backbone.body.layer3.1.bn3.weight                of shape (1024,)
2020-12-13 09:55:22,046 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight              loaded from backbone.body.layer3.1.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,046 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight              loaded from backbone.body.layer3.1.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,046 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight              loaded from backbone.body.layer3.1.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,046 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.bias                 loaded from backbone.body.layer3.10.bn1.bias                 of shape (1024,)
2020-12-13 09:55:22,046 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.running_mean         loaded from backbone.body.layer3.10.bn1.running_mean         of shape (1024,)
2020-12-13 09:55:22,046 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.running_var          loaded from backbone.body.layer3.10.bn1.running_var          of shape (1024,)
2020-12-13 09:55:22,046 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.weight               loaded from backbone.body.layer3.10.bn1.weight               of shape (1024,)
2020-12-13 09:55:22,046 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.bias                 loaded from backbone.body.layer3.10.bn2.bias                 of shape (1024,)
2020-12-13 09:55:22,047 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.running_mean         loaded from backbone.body.layer3.10.bn2.running_mean         of shape (1024,)
2020-12-13 09:55:22,047 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.running_var          loaded from backbone.body.layer3.10.bn2.running_var          of shape (1024,)
2020-12-13 09:55:22,047 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.weight               loaded from backbone.body.layer3.10.bn2.weight               of shape (1024,)
2020-12-13 09:55:22,047 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.bias                 loaded from backbone.body.layer3.10.bn3.bias                 of shape (1024,)
2020-12-13 09:55:22,047 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.running_mean         loaded from backbone.body.layer3.10.bn3.running_mean         of shape (1024,)
2020-12-13 09:55:22,047 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.running_var          loaded from backbone.body.layer3.10.bn3.running_var          of shape (1024,)
2020-12-13 09:55:22,047 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.weight               loaded from backbone.body.layer3.10.bn3.weight               of shape (1024,)
2020-12-13 09:55:22,047 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv1.weight             loaded from backbone.body.layer3.10.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,047 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv2.weight             loaded from backbone.body.layer3.10.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,047 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv3.weight             loaded from backbone.body.layer3.10.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,047 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.bias                 loaded from backbone.body.layer3.11.bn1.bias                 of shape (1024,)
2020-12-13 09:55:22,047 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.running_mean         loaded from backbone.body.layer3.11.bn1.running_mean         of shape (1024,)
2020-12-13 09:55:22,047 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.running_var          loaded from backbone.body.layer3.11.bn1.running_var          of shape (1024,)
2020-12-13 09:55:22,048 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.weight               loaded from backbone.body.layer3.11.bn1.weight               of shape (1024,)
2020-12-13 09:55:22,048 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.bias                 loaded from backbone.body.layer3.11.bn2.bias                 of shape (1024,)
2020-12-13 09:55:22,048 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.running_mean         loaded from backbone.body.layer3.11.bn2.running_mean         of shape (1024,)
2020-12-13 09:55:22,048 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.running_var          loaded from backbone.body.layer3.11.bn2.running_var          of shape (1024,)
2020-12-13 09:55:22,048 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.weight               loaded from backbone.body.layer3.11.bn2.weight               of shape (1024,)
2020-12-13 09:55:22,048 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.bias                 loaded from backbone.body.layer3.11.bn3.bias                 of shape (1024,)
2020-12-13 09:55:22,048 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.running_mean         loaded from backbone.body.layer3.11.bn3.running_mean         of shape (1024,)
2020-12-13 09:55:22,048 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.running_var          loaded from backbone.body.layer3.11.bn3.running_var          of shape (1024,)
2020-12-13 09:55:22,048 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.weight               loaded from backbone.body.layer3.11.bn3.weight               of shape (1024,)
2020-12-13 09:55:22,048 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv1.weight             loaded from backbone.body.layer3.11.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,048 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv2.weight             loaded from backbone.body.layer3.11.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,048 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv3.weight             loaded from backbone.body.layer3.11.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,048 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.bias                 loaded from backbone.body.layer3.12.bn1.bias                 of shape (1024,)
2020-12-13 09:55:22,048 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.running_mean         loaded from backbone.body.layer3.12.bn1.running_mean         of shape (1024,)
2020-12-13 09:55:22,049 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.running_var          loaded from backbone.body.layer3.12.bn1.running_var          of shape (1024,)
2020-12-13 09:55:22,049 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.weight               loaded from backbone.body.layer3.12.bn1.weight               of shape (1024,)
2020-12-13 09:55:22,049 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.bias                 loaded from backbone.body.layer3.12.bn2.bias                 of shape (1024,)
2020-12-13 09:55:22,049 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.running_mean         loaded from backbone.body.layer3.12.bn2.running_mean         of shape (1024,)
2020-12-13 09:55:22,049 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.running_var          loaded from backbone.body.layer3.12.bn2.running_var          of shape (1024,)
2020-12-13 09:55:22,049 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.weight               loaded from backbone.body.layer3.12.bn2.weight               of shape (1024,)
2020-12-13 09:55:22,049 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.bias                 loaded from backbone.body.layer3.12.bn3.bias                 of shape (1024,)
2020-12-13 09:55:22,049 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.running_mean         loaded from backbone.body.layer3.12.bn3.running_mean         of shape (1024,)
2020-12-13 09:55:22,049 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.running_var          loaded from backbone.body.layer3.12.bn3.running_var          of shape (1024,)
2020-12-13 09:55:22,049 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.weight               loaded from backbone.body.layer3.12.bn3.weight               of shape (1024,)
2020-12-13 09:55:22,049 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv1.weight             loaded from backbone.body.layer3.12.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,049 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv2.weight             loaded from backbone.body.layer3.12.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,049 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv3.weight             loaded from backbone.body.layer3.12.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,049 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.bias                 loaded from backbone.body.layer3.13.bn1.bias                 of shape (1024,)
2020-12-13 09:55:22,050 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.running_mean         loaded from backbone.body.layer3.13.bn1.running_mean         of shape (1024,)
2020-12-13 09:55:22,050 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.running_var          loaded from backbone.body.layer3.13.bn1.running_var          of shape (1024,)
2020-12-13 09:55:22,050 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.weight               loaded from backbone.body.layer3.13.bn1.weight               of shape (1024,)
2020-12-13 09:55:22,050 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.bias                 loaded from backbone.body.layer3.13.bn2.bias                 of shape (1024,)
2020-12-13 09:55:22,050 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.running_mean         loaded from backbone.body.layer3.13.bn2.running_mean         of shape (1024,)
2020-12-13 09:55:22,050 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.running_var          loaded from backbone.body.layer3.13.bn2.running_var          of shape (1024,)
2020-12-13 09:55:22,050 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.weight               loaded from backbone.body.layer3.13.bn2.weight               of shape (1024,)
2020-12-13 09:55:22,050 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.bias                 loaded from backbone.body.layer3.13.bn3.bias                 of shape (1024,)
2020-12-13 09:55:22,050 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.running_mean         loaded from backbone.body.layer3.13.bn3.running_mean         of shape (1024,)
2020-12-13 09:55:22,050 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.running_var          loaded from backbone.body.layer3.13.bn3.running_var          of shape (1024,)
2020-12-13 09:55:22,050 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.weight               loaded from backbone.body.layer3.13.bn3.weight               of shape (1024,)
2020-12-13 09:55:22,050 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv1.weight             loaded from backbone.body.layer3.13.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,051 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv2.weight             loaded from backbone.body.layer3.13.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,051 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv3.weight             loaded from backbone.body.layer3.13.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,051 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.bias                 loaded from backbone.body.layer3.14.bn1.bias                 of shape (1024,)
2020-12-13 09:55:22,051 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.running_mean         loaded from backbone.body.layer3.14.bn1.running_mean         of shape (1024,)
2020-12-13 09:55:22,051 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.running_var          loaded from backbone.body.layer3.14.bn1.running_var          of shape (1024,)
2020-12-13 09:55:22,051 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.weight               loaded from backbone.body.layer3.14.bn1.weight               of shape (1024,)
2020-12-13 09:55:22,051 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.bias                 loaded from backbone.body.layer3.14.bn2.bias                 of shape (1024,)
2020-12-13 09:55:22,051 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.running_mean         loaded from backbone.body.layer3.14.bn2.running_mean         of shape (1024,)
2020-12-13 09:55:22,051 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.running_var          loaded from backbone.body.layer3.14.bn2.running_var          of shape (1024,)
2020-12-13 09:55:22,051 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.weight               loaded from backbone.body.layer3.14.bn2.weight               of shape (1024,)
2020-12-13 09:55:22,051 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.bias                 loaded from backbone.body.layer3.14.bn3.bias                 of shape (1024,)
2020-12-13 09:55:22,051 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.running_mean         loaded from backbone.body.layer3.14.bn3.running_mean         of shape (1024,)
2020-12-13 09:55:22,051 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.running_var          loaded from backbone.body.layer3.14.bn3.running_var          of shape (1024,)
2020-12-13 09:55:22,052 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.weight               loaded from backbone.body.layer3.14.bn3.weight               of shape (1024,)
2020-12-13 09:55:22,052 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv1.weight             loaded from backbone.body.layer3.14.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,052 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv2.weight             loaded from backbone.body.layer3.14.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,052 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv3.weight             loaded from backbone.body.layer3.14.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,052 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.bias                 loaded from backbone.body.layer3.15.bn1.bias                 of shape (1024,)
2020-12-13 09:55:22,052 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.running_mean         loaded from backbone.body.layer3.15.bn1.running_mean         of shape (1024,)
2020-12-13 09:55:22,052 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.running_var          loaded from backbone.body.layer3.15.bn1.running_var          of shape (1024,)
2020-12-13 09:55:22,052 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.weight               loaded from backbone.body.layer3.15.bn1.weight               of shape (1024,)
2020-12-13 09:55:22,052 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.bias                 loaded from backbone.body.layer3.15.bn2.bias                 of shape (1024,)
2020-12-13 09:55:22,052 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.running_mean         loaded from backbone.body.layer3.15.bn2.running_mean         of shape (1024,)
2020-12-13 09:55:22,052 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.running_var          loaded from backbone.body.layer3.15.bn2.running_var          of shape (1024,)
2020-12-13 09:55:22,052 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.weight               loaded from backbone.body.layer3.15.bn2.weight               of shape (1024,)
2020-12-13 09:55:22,052 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.bias                 loaded from backbone.body.layer3.15.bn3.bias                 of shape (1024,)
2020-12-13 09:55:22,053 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.running_mean         loaded from backbone.body.layer3.15.bn3.running_mean         of shape (1024,)
2020-12-13 09:55:22,053 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.running_var          loaded from backbone.body.layer3.15.bn3.running_var          of shape (1024,)
2020-12-13 09:55:22,053 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.weight               loaded from backbone.body.layer3.15.bn3.weight               of shape (1024,)
2020-12-13 09:55:22,053 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv1.weight             loaded from backbone.body.layer3.15.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,053 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv2.weight             loaded from backbone.body.layer3.15.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,053 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv3.weight             loaded from backbone.body.layer3.15.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,053 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.bias                 loaded from backbone.body.layer3.16.bn1.bias                 of shape (1024,)
2020-12-13 09:55:22,053 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.running_mean         loaded from backbone.body.layer3.16.bn1.running_mean         of shape (1024,)
2020-12-13 09:55:22,053 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.running_var          loaded from backbone.body.layer3.16.bn1.running_var          of shape (1024,)
2020-12-13 09:55:22,053 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.weight               loaded from backbone.body.layer3.16.bn1.weight               of shape (1024,)
2020-12-13 09:55:22,053 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.bias                 loaded from backbone.body.layer3.16.bn2.bias                 of shape (1024,)
2020-12-13 09:55:22,053 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.running_mean         loaded from backbone.body.layer3.16.bn2.running_mean         of shape (1024,)
2020-12-13 09:55:22,053 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.running_var          loaded from backbone.body.layer3.16.bn2.running_var          of shape (1024,)
2020-12-13 09:55:22,054 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.weight               loaded from backbone.body.layer3.16.bn2.weight               of shape (1024,)
2020-12-13 09:55:22,054 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.bias                 loaded from backbone.body.layer3.16.bn3.bias                 of shape (1024,)
2020-12-13 09:55:22,054 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.running_mean         loaded from backbone.body.layer3.16.bn3.running_mean         of shape (1024,)
2020-12-13 09:55:22,054 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.running_var          loaded from backbone.body.layer3.16.bn3.running_var          of shape (1024,)
2020-12-13 09:55:22,054 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.weight               loaded from backbone.body.layer3.16.bn3.weight               of shape (1024,)
2020-12-13 09:55:22,054 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv1.weight             loaded from backbone.body.layer3.16.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,054 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv2.weight             loaded from backbone.body.layer3.16.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,054 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv3.weight             loaded from backbone.body.layer3.16.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,054 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.bias                 loaded from backbone.body.layer3.17.bn1.bias                 of shape (1024,)
2020-12-13 09:55:22,054 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.running_mean         loaded from backbone.body.layer3.17.bn1.running_mean         of shape (1024,)
2020-12-13 09:55:22,054 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.running_var          loaded from backbone.body.layer3.17.bn1.running_var          of shape (1024,)
2020-12-13 09:55:22,054 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.weight               loaded from backbone.body.layer3.17.bn1.weight               of shape (1024,)
2020-12-13 09:55:22,054 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.bias                 loaded from backbone.body.layer3.17.bn2.bias                 of shape (1024,)
2020-12-13 09:55:22,055 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.running_mean         loaded from backbone.body.layer3.17.bn2.running_mean         of shape (1024,)
2020-12-13 09:55:22,055 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.running_var          loaded from backbone.body.layer3.17.bn2.running_var          of shape (1024,)
2020-12-13 09:55:22,055 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.weight               loaded from backbone.body.layer3.17.bn2.weight               of shape (1024,)
2020-12-13 09:55:22,055 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.bias                 loaded from backbone.body.layer3.17.bn3.bias                 of shape (1024,)
2020-12-13 09:55:22,055 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.running_mean         loaded from backbone.body.layer3.17.bn3.running_mean         of shape (1024,)
2020-12-13 09:55:22,055 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.running_var          loaded from backbone.body.layer3.17.bn3.running_var          of shape (1024,)
2020-12-13 09:55:22,055 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.weight               loaded from backbone.body.layer3.17.bn3.weight               of shape (1024,)
2020-12-13 09:55:22,055 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv1.weight             loaded from backbone.body.layer3.17.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,055 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv2.weight             loaded from backbone.body.layer3.17.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,055 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv3.weight             loaded from backbone.body.layer3.17.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,055 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.bias                 loaded from backbone.body.layer3.18.bn1.bias                 of shape (1024,)
2020-12-13 09:55:22,055 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.running_mean         loaded from backbone.body.layer3.18.bn1.running_mean         of shape (1024,)
2020-12-13 09:55:22,055 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.running_var          loaded from backbone.body.layer3.18.bn1.running_var          of shape (1024,)
2020-12-13 09:55:22,056 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.weight               loaded from backbone.body.layer3.18.bn1.weight               of shape (1024,)
2020-12-13 09:55:22,056 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.bias                 loaded from backbone.body.layer3.18.bn2.bias                 of shape (1024,)
2020-12-13 09:55:22,056 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.running_mean         loaded from backbone.body.layer3.18.bn2.running_mean         of shape (1024,)
2020-12-13 09:55:22,056 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.running_var          loaded from backbone.body.layer3.18.bn2.running_var          of shape (1024,)
2020-12-13 09:55:22,056 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.weight               loaded from backbone.body.layer3.18.bn2.weight               of shape (1024,)
2020-12-13 09:55:22,056 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.bias                 loaded from backbone.body.layer3.18.bn3.bias                 of shape (1024,)
2020-12-13 09:55:22,056 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.running_mean         loaded from backbone.body.layer3.18.bn3.running_mean         of shape (1024,)
2020-12-13 09:55:22,056 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.running_var          loaded from backbone.body.layer3.18.bn3.running_var          of shape (1024,)
2020-12-13 09:55:22,056 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.weight               loaded from backbone.body.layer3.18.bn3.weight               of shape (1024,)
2020-12-13 09:55:22,056 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv1.weight             loaded from backbone.body.layer3.18.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,056 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv2.weight             loaded from backbone.body.layer3.18.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,056 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv3.weight             loaded from backbone.body.layer3.18.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,056 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.bias                 loaded from backbone.body.layer3.19.bn1.bias                 of shape (1024,)
2020-12-13 09:55:22,056 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.running_mean         loaded from backbone.body.layer3.19.bn1.running_mean         of shape (1024,)
2020-12-13 09:55:22,056 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.running_var          loaded from backbone.body.layer3.19.bn1.running_var          of shape (1024,)
2020-12-13 09:55:22,057 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.weight               loaded from backbone.body.layer3.19.bn1.weight               of shape (1024,)
2020-12-13 09:55:22,057 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.bias                 loaded from backbone.body.layer3.19.bn2.bias                 of shape (1024,)
2020-12-13 09:55:22,057 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.running_mean         loaded from backbone.body.layer3.19.bn2.running_mean         of shape (1024,)
2020-12-13 09:55:22,057 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.running_var          loaded from backbone.body.layer3.19.bn2.running_var          of shape (1024,)
2020-12-13 09:55:22,057 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.weight               loaded from backbone.body.layer3.19.bn2.weight               of shape (1024,)
2020-12-13 09:55:22,057 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.bias                 loaded from backbone.body.layer3.19.bn3.bias                 of shape (1024,)
2020-12-13 09:55:22,057 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.running_mean         loaded from backbone.body.layer3.19.bn3.running_mean         of shape (1024,)
2020-12-13 09:55:22,057 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.running_var          loaded from backbone.body.layer3.19.bn3.running_var          of shape (1024,)
2020-12-13 09:55:22,057 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.weight               loaded from backbone.body.layer3.19.bn3.weight               of shape (1024,)
2020-12-13 09:55:22,057 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv1.weight             loaded from backbone.body.layer3.19.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,057 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv2.weight             loaded from backbone.body.layer3.19.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,057 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv3.weight             loaded from backbone.body.layer3.19.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,057 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                  loaded from backbone.body.layer3.2.bn1.bias                  of shape (1024,)
2020-12-13 09:55:22,057 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_mean          loaded from backbone.body.layer3.2.bn1.running_mean          of shape (1024,)
2020-12-13 09:55:22,058 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_var           loaded from backbone.body.layer3.2.bn1.running_var           of shape (1024,)
2020-12-13 09:55:22,058 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                loaded from backbone.body.layer3.2.bn1.weight                of shape (1024,)
2020-12-13 09:55:22,058 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                  loaded from backbone.body.layer3.2.bn2.bias                  of shape (1024,)
2020-12-13 09:55:22,058 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_mean          loaded from backbone.body.layer3.2.bn2.running_mean          of shape (1024,)
2020-12-13 09:55:22,058 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_var           loaded from backbone.body.layer3.2.bn2.running_var           of shape (1024,)
2020-12-13 09:55:22,058 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                loaded from backbone.body.layer3.2.bn2.weight                of shape (1024,)
2020-12-13 09:55:22,058 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                  loaded from backbone.body.layer3.2.bn3.bias                  of shape (1024,)
2020-12-13 09:55:22,058 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_mean          loaded from backbone.body.layer3.2.bn3.running_mean          of shape (1024,)
2020-12-13 09:55:22,058 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_var           loaded from backbone.body.layer3.2.bn3.running_var           of shape (1024,)
2020-12-13 09:55:22,058 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                loaded from backbone.body.layer3.2.bn3.weight                of shape (1024,)
2020-12-13 09:55:22,058 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight              loaded from backbone.body.layer3.2.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,059 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight              loaded from backbone.body.layer3.2.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,059 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight              loaded from backbone.body.layer3.2.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,059 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.bias                 loaded from backbone.body.layer3.20.bn1.bias                 of shape (1024,)
2020-12-13 09:55:22,059 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.running_mean         loaded from backbone.body.layer3.20.bn1.running_mean         of shape (1024,)
2020-12-13 09:55:22,059 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.running_var          loaded from backbone.body.layer3.20.bn1.running_var          of shape (1024,)
2020-12-13 09:55:22,059 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.weight               loaded from backbone.body.layer3.20.bn1.weight               of shape (1024,)
2020-12-13 09:55:22,059 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.bias                 loaded from backbone.body.layer3.20.bn2.bias                 of shape (1024,)
2020-12-13 09:55:22,059 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.running_mean         loaded from backbone.body.layer3.20.bn2.running_mean         of shape (1024,)
2020-12-13 09:55:22,059 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.running_var          loaded from backbone.body.layer3.20.bn2.running_var          of shape (1024,)
2020-12-13 09:55:22,060 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.weight               loaded from backbone.body.layer3.20.bn2.weight               of shape (1024,)
2020-12-13 09:55:22,060 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.bias                 loaded from backbone.body.layer3.20.bn3.bias                 of shape (1024,)
2020-12-13 09:55:22,060 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.running_mean         loaded from backbone.body.layer3.20.bn3.running_mean         of shape (1024,)
2020-12-13 09:55:22,060 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.running_var          loaded from backbone.body.layer3.20.bn3.running_var          of shape (1024,)
2020-12-13 09:55:22,060 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.weight               loaded from backbone.body.layer3.20.bn3.weight               of shape (1024,)
2020-12-13 09:55:22,060 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv1.weight             loaded from backbone.body.layer3.20.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,060 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv2.weight             loaded from backbone.body.layer3.20.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,060 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv3.weight             loaded from backbone.body.layer3.20.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,060 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.bias                 loaded from backbone.body.layer3.21.bn1.bias                 of shape (1024,)
2020-12-13 09:55:22,061 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.running_mean         loaded from backbone.body.layer3.21.bn1.running_mean         of shape (1024,)
2020-12-13 09:55:22,061 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.running_var          loaded from backbone.body.layer3.21.bn1.running_var          of shape (1024,)
2020-12-13 09:55:22,061 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.weight               loaded from backbone.body.layer3.21.bn1.weight               of shape (1024,)
2020-12-13 09:55:22,061 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.bias                 loaded from backbone.body.layer3.21.bn2.bias                 of shape (1024,)
2020-12-13 09:55:22,061 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.running_mean         loaded from backbone.body.layer3.21.bn2.running_mean         of shape (1024,)
2020-12-13 09:55:22,061 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.running_var          loaded from backbone.body.layer3.21.bn2.running_var          of shape (1024,)
2020-12-13 09:55:22,061 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.weight               loaded from backbone.body.layer3.21.bn2.weight               of shape (1024,)
2020-12-13 09:55:22,061 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.bias                 loaded from backbone.body.layer3.21.bn3.bias                 of shape (1024,)
2020-12-13 09:55:22,061 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.running_mean         loaded from backbone.body.layer3.21.bn3.running_mean         of shape (1024,)
2020-12-13 09:55:22,062 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.running_var          loaded from backbone.body.layer3.21.bn3.running_var          of shape (1024,)
2020-12-13 09:55:22,062 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.weight               loaded from backbone.body.layer3.21.bn3.weight               of shape (1024,)
2020-12-13 09:55:22,062 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv1.weight             loaded from backbone.body.layer3.21.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,062 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv2.weight             loaded from backbone.body.layer3.21.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,062 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv3.weight             loaded from backbone.body.layer3.21.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,062 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.bias                 loaded from backbone.body.layer3.22.bn1.bias                 of shape (1024,)
2020-12-13 09:55:22,062 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.running_mean         loaded from backbone.body.layer3.22.bn1.running_mean         of shape (1024,)
2020-12-13 09:55:22,062 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.running_var          loaded from backbone.body.layer3.22.bn1.running_var          of shape (1024,)
2020-12-13 09:55:22,062 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.weight               loaded from backbone.body.layer3.22.bn1.weight               of shape (1024,)
2020-12-13 09:55:22,062 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.bias                 loaded from backbone.body.layer3.22.bn2.bias                 of shape (1024,)
2020-12-13 09:55:22,063 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.running_mean         loaded from backbone.body.layer3.22.bn2.running_mean         of shape (1024,)
2020-12-13 09:55:22,063 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.running_var          loaded from backbone.body.layer3.22.bn2.running_var          of shape (1024,)
2020-12-13 09:55:22,063 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.weight               loaded from backbone.body.layer3.22.bn2.weight               of shape (1024,)
2020-12-13 09:55:22,063 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.bias                 loaded from backbone.body.layer3.22.bn3.bias                 of shape (1024,)
2020-12-13 09:55:22,063 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.running_mean         loaded from backbone.body.layer3.22.bn3.running_mean         of shape (1024,)
2020-12-13 09:55:22,063 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.running_var          loaded from backbone.body.layer3.22.bn3.running_var          of shape (1024,)
2020-12-13 09:55:22,063 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.weight               loaded from backbone.body.layer3.22.bn3.weight               of shape (1024,)
2020-12-13 09:55:22,063 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv1.weight             loaded from backbone.body.layer3.22.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,063 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv2.weight             loaded from backbone.body.layer3.22.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,063 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv3.weight             loaded from backbone.body.layer3.22.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,064 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                  loaded from backbone.body.layer3.3.bn1.bias                  of shape (1024,)
2020-12-13 09:55:22,064 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_mean          loaded from backbone.body.layer3.3.bn1.running_mean          of shape (1024,)
2020-12-13 09:55:22,064 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_var           loaded from backbone.body.layer3.3.bn1.running_var           of shape (1024,)
2020-12-13 09:55:22,064 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                loaded from backbone.body.layer3.3.bn1.weight                of shape (1024,)
2020-12-13 09:55:22,064 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                  loaded from backbone.body.layer3.3.bn2.bias                  of shape (1024,)
2020-12-13 09:55:22,064 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_mean          loaded from backbone.body.layer3.3.bn2.running_mean          of shape (1024,)
2020-12-13 09:55:22,064 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_var           loaded from backbone.body.layer3.3.bn2.running_var           of shape (1024,)
2020-12-13 09:55:22,064 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                loaded from backbone.body.layer3.3.bn2.weight                of shape (1024,)
2020-12-13 09:55:22,064 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                  loaded from backbone.body.layer3.3.bn3.bias                  of shape (1024,)
2020-12-13 09:55:22,064 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_mean          loaded from backbone.body.layer3.3.bn3.running_mean          of shape (1024,)
2020-12-13 09:55:22,064 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_var           loaded from backbone.body.layer3.3.bn3.running_var           of shape (1024,)
2020-12-13 09:55:22,065 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                loaded from backbone.body.layer3.3.bn3.weight                of shape (1024,)
2020-12-13 09:55:22,065 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight              loaded from backbone.body.layer3.3.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,065 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight              loaded from backbone.body.layer3.3.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,065 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight              loaded from backbone.body.layer3.3.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,065 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                  loaded from backbone.body.layer3.4.bn1.bias                  of shape (1024,)
2020-12-13 09:55:22,065 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_mean          loaded from backbone.body.layer3.4.bn1.running_mean          of shape (1024,)
2020-12-13 09:55:22,065 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_var           loaded from backbone.body.layer3.4.bn1.running_var           of shape (1024,)
2020-12-13 09:55:22,065 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                loaded from backbone.body.layer3.4.bn1.weight                of shape (1024,)
2020-12-13 09:55:22,065 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                  loaded from backbone.body.layer3.4.bn2.bias                  of shape (1024,)
2020-12-13 09:55:22,065 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_mean          loaded from backbone.body.layer3.4.bn2.running_mean          of shape (1024,)
2020-12-13 09:55:22,066 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_var           loaded from backbone.body.layer3.4.bn2.running_var           of shape (1024,)
2020-12-13 09:55:22,066 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                loaded from backbone.body.layer3.4.bn2.weight                of shape (1024,)
2020-12-13 09:55:22,066 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                  loaded from backbone.body.layer3.4.bn3.bias                  of shape (1024,)
2020-12-13 09:55:22,066 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_mean          loaded from backbone.body.layer3.4.bn3.running_mean          of shape (1024,)
2020-12-13 09:55:22,066 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_var           loaded from backbone.body.layer3.4.bn3.running_var           of shape (1024,)
2020-12-13 09:55:22,066 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                loaded from backbone.body.layer3.4.bn3.weight                of shape (1024,)
2020-12-13 09:55:22,066 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight              loaded from backbone.body.layer3.4.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,066 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight              loaded from backbone.body.layer3.4.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,066 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight              loaded from backbone.body.layer3.4.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,066 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                  loaded from backbone.body.layer3.5.bn1.bias                  of shape (1024,)
2020-12-13 09:55:22,067 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_mean          loaded from backbone.body.layer3.5.bn1.running_mean          of shape (1024,)
2020-12-13 09:55:22,067 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_var           loaded from backbone.body.layer3.5.bn1.running_var           of shape (1024,)
2020-12-13 09:55:22,067 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                loaded from backbone.body.layer3.5.bn1.weight                of shape (1024,)
2020-12-13 09:55:22,067 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                  loaded from backbone.body.layer3.5.bn2.bias                  of shape (1024,)
2020-12-13 09:55:22,067 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_mean          loaded from backbone.body.layer3.5.bn2.running_mean          of shape (1024,)
2020-12-13 09:55:22,067 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_var           loaded from backbone.body.layer3.5.bn2.running_var           of shape (1024,)
2020-12-13 09:55:22,067 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                loaded from backbone.body.layer3.5.bn2.weight                of shape (1024,)
2020-12-13 09:55:22,067 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                  loaded from backbone.body.layer3.5.bn3.bias                  of shape (1024,)
2020-12-13 09:55:22,067 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_mean          loaded from backbone.body.layer3.5.bn3.running_mean          of shape (1024,)
2020-12-13 09:55:22,067 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_var           loaded from backbone.body.layer3.5.bn3.running_var           of shape (1024,)
2020-12-13 09:55:22,067 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                loaded from backbone.body.layer3.5.bn3.weight                of shape (1024,)
2020-12-13 09:55:22,067 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight              loaded from backbone.body.layer3.5.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,068 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight              loaded from backbone.body.layer3.5.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,068 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight              loaded from backbone.body.layer3.5.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,068 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.bias                  loaded from backbone.body.layer3.6.bn1.bias                  of shape (1024,)
2020-12-13 09:55:22,068 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.running_mean          loaded from backbone.body.layer3.6.bn1.running_mean          of shape (1024,)
2020-12-13 09:55:22,068 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.running_var           loaded from backbone.body.layer3.6.bn1.running_var           of shape (1024,)
2020-12-13 09:55:22,068 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.weight                loaded from backbone.body.layer3.6.bn1.weight                of shape (1024,)
2020-12-13 09:55:22,068 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.bias                  loaded from backbone.body.layer3.6.bn2.bias                  of shape (1024,)
2020-12-13 09:55:22,068 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.running_mean          loaded from backbone.body.layer3.6.bn2.running_mean          of shape (1024,)
2020-12-13 09:55:22,068 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.running_var           loaded from backbone.body.layer3.6.bn2.running_var           of shape (1024,)
2020-12-13 09:55:22,068 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.weight                loaded from backbone.body.layer3.6.bn2.weight                of shape (1024,)
2020-12-13 09:55:22,068 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.bias                  loaded from backbone.body.layer3.6.bn3.bias                  of shape (1024,)
2020-12-13 09:55:22,069 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.running_mean          loaded from backbone.body.layer3.6.bn3.running_mean          of shape (1024,)
2020-12-13 09:55:22,069 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.running_var           loaded from backbone.body.layer3.6.bn3.running_var           of shape (1024,)
2020-12-13 09:55:22,069 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.weight                loaded from backbone.body.layer3.6.bn3.weight                of shape (1024,)
2020-12-13 09:55:22,069 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv1.weight              loaded from backbone.body.layer3.6.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,069 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv2.weight              loaded from backbone.body.layer3.6.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,069 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv3.weight              loaded from backbone.body.layer3.6.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,069 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.bias                  loaded from backbone.body.layer3.7.bn1.bias                  of shape (1024,)
2020-12-13 09:55:22,069 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.running_mean          loaded from backbone.body.layer3.7.bn1.running_mean          of shape (1024,)
2020-12-13 09:55:22,069 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.running_var           loaded from backbone.body.layer3.7.bn1.running_var           of shape (1024,)
2020-12-13 09:55:22,069 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.weight                loaded from backbone.body.layer3.7.bn1.weight                of shape (1024,)
2020-12-13 09:55:22,069 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.bias                  loaded from backbone.body.layer3.7.bn2.bias                  of shape (1024,)
2020-12-13 09:55:22,070 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.running_mean          loaded from backbone.body.layer3.7.bn2.running_mean          of shape (1024,)
2020-12-13 09:55:22,070 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.running_var           loaded from backbone.body.layer3.7.bn2.running_var           of shape (1024,)
2020-12-13 09:55:22,070 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.weight                loaded from backbone.body.layer3.7.bn2.weight                of shape (1024,)
2020-12-13 09:55:22,070 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.bias                  loaded from backbone.body.layer3.7.bn3.bias                  of shape (1024,)
2020-12-13 09:55:22,070 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.running_mean          loaded from backbone.body.layer3.7.bn3.running_mean          of shape (1024,)
2020-12-13 09:55:22,070 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.running_var           loaded from backbone.body.layer3.7.bn3.running_var           of shape (1024,)
2020-12-13 09:55:22,070 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.weight                loaded from backbone.body.layer3.7.bn3.weight                of shape (1024,)
2020-12-13 09:55:22,070 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv1.weight              loaded from backbone.body.layer3.7.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,070 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv2.weight              loaded from backbone.body.layer3.7.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,070 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv3.weight              loaded from backbone.body.layer3.7.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,070 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.bias                  loaded from backbone.body.layer3.8.bn1.bias                  of shape (1024,)
2020-12-13 09:55:22,070 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.running_mean          loaded from backbone.body.layer3.8.bn1.running_mean          of shape (1024,)
2020-12-13 09:55:22,071 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.running_var           loaded from backbone.body.layer3.8.bn1.running_var           of shape (1024,)
2020-12-13 09:55:22,071 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.weight                loaded from backbone.body.layer3.8.bn1.weight                of shape (1024,)
2020-12-13 09:55:22,071 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.bias                  loaded from backbone.body.layer3.8.bn2.bias                  of shape (1024,)
2020-12-13 09:55:22,071 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.running_mean          loaded from backbone.body.layer3.8.bn2.running_mean          of shape (1024,)
2020-12-13 09:55:22,071 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.running_var           loaded from backbone.body.layer3.8.bn2.running_var           of shape (1024,)
2020-12-13 09:55:22,071 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.weight                loaded from backbone.body.layer3.8.bn2.weight                of shape (1024,)
2020-12-13 09:55:22,071 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.bias                  loaded from backbone.body.layer3.8.bn3.bias                  of shape (1024,)
2020-12-13 09:55:22,071 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.running_mean          loaded from backbone.body.layer3.8.bn3.running_mean          of shape (1024,)
2020-12-13 09:55:22,071 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.running_var           loaded from backbone.body.layer3.8.bn3.running_var           of shape (1024,)
2020-12-13 09:55:22,071 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.weight                loaded from backbone.body.layer3.8.bn3.weight                of shape (1024,)
2020-12-13 09:55:22,071 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv1.weight              loaded from backbone.body.layer3.8.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,071 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv2.weight              loaded from backbone.body.layer3.8.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,072 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv3.weight              loaded from backbone.body.layer3.8.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,072 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.bias                  loaded from backbone.body.layer3.9.bn1.bias                  of shape (1024,)
2020-12-13 09:55:22,072 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.running_mean          loaded from backbone.body.layer3.9.bn1.running_mean          of shape (1024,)
2020-12-13 09:55:22,072 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.running_var           loaded from backbone.body.layer3.9.bn1.running_var           of shape (1024,)
2020-12-13 09:55:22,072 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.weight                loaded from backbone.body.layer3.9.bn1.weight                of shape (1024,)
2020-12-13 09:55:22,072 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.bias                  loaded from backbone.body.layer3.9.bn2.bias                  of shape (1024,)
2020-12-13 09:55:22,072 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.running_mean          loaded from backbone.body.layer3.9.bn2.running_mean          of shape (1024,)
2020-12-13 09:55:22,072 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.running_var           loaded from backbone.body.layer3.9.bn2.running_var           of shape (1024,)
2020-12-13 09:55:22,072 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.weight                loaded from backbone.body.layer3.9.bn2.weight                of shape (1024,)
2020-12-13 09:55:22,072 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.bias                  loaded from backbone.body.layer3.9.bn3.bias                  of shape (1024,)
2020-12-13 09:55:22,072 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.running_mean          loaded from backbone.body.layer3.9.bn3.running_mean          of shape (1024,)
2020-12-13 09:55:22,072 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.running_var           loaded from backbone.body.layer3.9.bn3.running_var           of shape (1024,)
2020-12-13 09:55:22,073 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.weight                loaded from backbone.body.layer3.9.bn3.weight                of shape (1024,)
2020-12-13 09:55:22,073 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv1.weight              loaded from backbone.body.layer3.9.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,073 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv2.weight              loaded from backbone.body.layer3.9.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 09:55:22,073 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv3.weight              loaded from backbone.body.layer3.9.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 09:55:22,073 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                  loaded from backbone.body.layer4.0.bn1.bias                  of shape (2048,)
2020-12-13 09:55:22,073 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_mean          loaded from backbone.body.layer4.0.bn1.running_mean          of shape (2048,)
2020-12-13 09:55:22,073 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_var           loaded from backbone.body.layer4.0.bn1.running_var           of shape (2048,)
2020-12-13 09:55:22,073 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                loaded from backbone.body.layer4.0.bn1.weight                of shape (2048,)
2020-12-13 09:55:22,073 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                  loaded from backbone.body.layer4.0.bn2.bias                  of shape (2048,)
2020-12-13 09:55:22,073 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_mean          loaded from backbone.body.layer4.0.bn2.running_mean          of shape (2048,)
2020-12-13 09:55:22,073 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_var           loaded from backbone.body.layer4.0.bn2.running_var           of shape (2048,)
2020-12-13 09:55:22,073 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                loaded from backbone.body.layer4.0.bn2.weight                of shape (2048,)
2020-12-13 09:55:22,073 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                  loaded from backbone.body.layer4.0.bn3.bias                  of shape (2048,)
2020-12-13 09:55:22,074 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_mean          loaded from backbone.body.layer4.0.bn3.running_mean          of shape (2048,)
2020-12-13 09:55:22,074 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_var           loaded from backbone.body.layer4.0.bn3.running_var           of shape (2048,)
2020-12-13 09:55:22,074 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                loaded from backbone.body.layer4.0.bn3.weight                of shape (2048,)
2020-12-13 09:55:22,074 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight              loaded from backbone.body.layer4.0.conv1.weight              of shape (2048, 1024, 1, 1)
2020-12-13 09:55:22,074 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv2.weight              loaded from backbone.body.layer4.0.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 09:55:22,074 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight              loaded from backbone.body.layer4.0.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 09:55:22,074 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight       loaded from backbone.body.layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)
2020-12-13 09:55:22,074 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias         loaded from backbone.body.layer4.0.downsample.1.bias         of shape (2048,)
2020-12-13 09:55:22,074 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_mean loaded from backbone.body.layer4.0.downsample.1.running_mean of shape (2048,)
2020-12-13 09:55:22,074 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_var  loaded from backbone.body.layer4.0.downsample.1.running_var  of shape (2048,)
2020-12-13 09:55:22,074 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight       loaded from backbone.body.layer4.0.downsample.1.weight       of shape (2048,)
2020-12-13 09:55:22,074 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                  loaded from backbone.body.layer4.1.bn1.bias                  of shape (2048,)
2020-12-13 09:55:22,074 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_mean          loaded from backbone.body.layer4.1.bn1.running_mean          of shape (2048,)
2020-12-13 09:55:22,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_var           loaded from backbone.body.layer4.1.bn1.running_var           of shape (2048,)
2020-12-13 09:55:22,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                loaded from backbone.body.layer4.1.bn1.weight                of shape (2048,)
2020-12-13 09:55:22,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                  loaded from backbone.body.layer4.1.bn2.bias                  of shape (2048,)
2020-12-13 09:55:22,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_mean          loaded from backbone.body.layer4.1.bn2.running_mean          of shape (2048,)
2020-12-13 09:55:22,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_var           loaded from backbone.body.layer4.1.bn2.running_var           of shape (2048,)
2020-12-13 09:55:22,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                loaded from backbone.body.layer4.1.bn2.weight                of shape (2048,)
2020-12-13 09:55:22,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                  loaded from backbone.body.layer4.1.bn3.bias                  of shape (2048,)
2020-12-13 09:55:22,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_mean          loaded from backbone.body.layer4.1.bn3.running_mean          of shape (2048,)
2020-12-13 09:55:22,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_var           loaded from backbone.body.layer4.1.bn3.running_var           of shape (2048,)
2020-12-13 09:55:22,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                loaded from backbone.body.layer4.1.bn3.weight                of shape (2048,)
2020-12-13 09:55:22,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight              loaded from backbone.body.layer4.1.conv1.weight              of shape (2048, 2048, 1, 1)
2020-12-13 09:55:22,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv2.weight              loaded from backbone.body.layer4.1.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 09:55:22,075 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight              loaded from backbone.body.layer4.1.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 09:55:22,076 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                  loaded from backbone.body.layer4.2.bn1.bias                  of shape (2048,)
2020-12-13 09:55:22,076 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_mean          loaded from backbone.body.layer4.2.bn1.running_mean          of shape (2048,)
2020-12-13 09:55:22,076 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_var           loaded from backbone.body.layer4.2.bn1.running_var           of shape (2048,)
2020-12-13 09:55:22,076 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                loaded from backbone.body.layer4.2.bn1.weight                of shape (2048,)
2020-12-13 09:55:22,076 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                  loaded from backbone.body.layer4.2.bn2.bias                  of shape (2048,)
2020-12-13 09:55:22,076 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_mean          loaded from backbone.body.layer4.2.bn2.running_mean          of shape (2048,)
2020-12-13 09:55:22,076 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_var           loaded from backbone.body.layer4.2.bn2.running_var           of shape (2048,)
2020-12-13 09:55:22,076 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                loaded from backbone.body.layer4.2.bn2.weight                of shape (2048,)
2020-12-13 09:55:22,076 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                  loaded from backbone.body.layer4.2.bn3.bias                  of shape (2048,)
2020-12-13 09:55:22,076 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_mean          loaded from backbone.body.layer4.2.bn3.running_mean          of shape (2048,)
2020-12-13 09:55:22,076 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_var           loaded from backbone.body.layer4.2.bn3.running_var           of shape (2048,)
2020-12-13 09:55:22,077 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                loaded from backbone.body.layer4.2.bn3.weight                of shape (2048,)
2020-12-13 09:55:22,077 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight              loaded from backbone.body.layer4.2.conv1.weight              of shape (2048, 2048, 1, 1)
2020-12-13 09:55:22,077 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv2.weight              loaded from backbone.body.layer4.2.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 09:55:22,077 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight              loaded from backbone.body.layer4.2.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 09:55:22,077 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                      loaded from backbone.body.stem.bn1.bias                      of shape (64,)
2020-12-13 09:55:22,077 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_mean              loaded from backbone.body.stem.bn1.running_mean              of shape (64,)
2020-12-13 09:55:22,077 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_var               loaded from backbone.body.stem.bn1.running_var               of shape (64,)
2020-12-13 09:55:22,077 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                    loaded from backbone.body.stem.bn1.weight                    of shape (64,)
2020-12-13 09:55:22,077 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                  loaded from backbone.body.stem.conv1.weight                  of shape (64, 3, 7, 7)
2020-12-13 09:55:22,078 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.bias                     loaded from backbone.fpn.fpn_inner1.bias                     of shape (256,)
2020-12-13 09:55:22,078 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.weight                   loaded from backbone.fpn.fpn_inner1.weight                   of shape (256, 256, 1, 1)
2020-12-13 09:55:22,078 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                     loaded from backbone.fpn.fpn_inner2.bias                     of shape (256,)
2020-12-13 09:55:22,078 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                   loaded from backbone.fpn.fpn_inner2.weight                   of shape (256, 512, 1, 1)
2020-12-13 09:55:22,078 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                     loaded from backbone.fpn.fpn_inner3.bias                     of shape (256,)
2020-12-13 09:55:22,078 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                   loaded from backbone.fpn.fpn_inner3.weight                   of shape (256, 1024, 1, 1)
2020-12-13 09:55:22,078 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                     loaded from backbone.fpn.fpn_inner4.bias                     of shape (256,)
2020-12-13 09:55:22,078 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                   loaded from backbone.fpn.fpn_inner4.weight                   of shape (256, 2048, 1, 1)
2020-12-13 09:55:22,078 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.bias                     loaded from backbone.fpn.fpn_layer1.bias                     of shape (256,)
2020-12-13 09:55:22,078 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.weight                   loaded from backbone.fpn.fpn_layer1.weight                   of shape (256, 256, 3, 3)
2020-12-13 09:55:22,079 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                     loaded from backbone.fpn.fpn_layer2.bias                     of shape (256,)
2020-12-13 09:55:22,079 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                   loaded from backbone.fpn.fpn_layer2.weight                   of shape (256, 256, 3, 3)
2020-12-13 09:55:22,079 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                     loaded from backbone.fpn.fpn_layer3.bias                     of shape (256,)
2020-12-13 09:55:22,079 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                   loaded from backbone.fpn.fpn_layer3.weight                   of shape (256, 256, 3, 3)
2020-12-13 09:55:22,079 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                     loaded from backbone.fpn.fpn_layer4.bias                     of shape (256,)
2020-12-13 09:55:22,079 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                   loaded from backbone.fpn.fpn_layer4.weight                   of shape (256, 256, 3, 3)
2020-12-13 09:55:22,079 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.bias         loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (1024,)
2020-12-13 09:55:22,079 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.weight       loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (1024, 12544)
2020-12-13 09:55:22,079 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.bias         loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (1024,)
2020-12-13 09:55:22,079 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.weight       loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (1024, 1024)
2020-12-13 09:55:22,079 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.bias           loaded from roi_heads.box.predictor.bbox_pred.bias           of shape (324,)
2020-12-13 09:55:22,080 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.weight         loaded from roi_heads.box.predictor.bbox_pred.weight         of shape (324, 1024)
2020-12-13 09:55:22,080 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.bias           loaded from roi_heads.box.predictor.cls_score.bias           of shape (81,)
2020-12-13 09:55:22,080 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.weight         loaded from roi_heads.box.predictor.cls_score.weight         of shape (81, 1024)
2020-12-13 09:55:22,080 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.0              loaded from rpn.anchor_generator.cell_anchors.0              of shape (3, 4)
2020-12-13 09:55:22,080 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.1              loaded from rpn.anchor_generator.cell_anchors.1              of shape (3, 4)
2020-12-13 09:55:22,080 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.2              loaded from rpn.anchor_generator.cell_anchors.2              of shape (3, 4)
2020-12-13 09:55:22,080 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.3              loaded from rpn.anchor_generator.cell_anchors.3              of shape (3, 4)
2020-12-13 09:55:22,080 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.4              loaded from rpn.anchor_generator.cell_anchors.4              of shape (3, 4)
2020-12-13 09:55:22,080 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                          loaded from rpn.head.bbox_pred.bias                          of shape (12,)
2020-12-13 09:55:22,080 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                        loaded from rpn.head.bbox_pred.weight                        of shape (12, 256, 1, 1)
2020-12-13 09:55:22,080 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                         loaded from rpn.head.cls_logits.bias                         of shape (3,)
2020-12-13 09:55:22,080 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                       loaded from rpn.head.cls_logits.weight                       of shape (3, 256, 1, 1)
2020-12-13 09:55:22,081 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.bias                               loaded from rpn.head.conv.bias                               of shape (256,)
2020-12-13 09:55:22,081 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.weight                             loaded from rpn.head.conv.weight                             of shape (256, 256, 3, 3)
2020-12-13 09:55:22,262 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-13 09:55:22,262 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-13 09:55:22,262 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-13 09:55:22,262 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-13 09:55:22,263 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-13 09:55:22,263 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-13 09:55:22,263 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-13 09:55:22,263 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-13 09:55:22,264 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-13 09:55:22,264 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-13 09:55:22,264 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-13 09:55:22,264 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-13 09:55:22,265 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-13 09:55:22,265 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-13 09:55:24,573 maskrcnn_benchmark.trainer INFO: Start training
2020-12-13 09:55:57,754 maskrcnn_benchmark.trainer INFO: eta: 18:25:24  iter: 20  loss: 6.4780 (6.4865)  loss_classifier: 2.1166 (2.1165)  loss_box_reg: 0.8278 (0.7860)  loss_objectness: 2.6058 (2.6326)  loss_rpn_box_reg: 0.9541 (0.9514)  time: 1.6456 (1.6589)  data: 0.1092 (0.1102)  lr: 0.000000  max mem: 970
2020-12-13 09:56:30,702 maskrcnn_benchmark.trainer INFO: eta: 18:21:01  iter: 40  loss: 6.5188 (6.4600)  loss_classifier: 2.1139 (2.1152)  loss_box_reg: 0.8269 (0.7857)  loss_objectness: 2.6624 (2.6220)  loss_rpn_box_reg: 0.9225 (0.9372)  time: 1.6469 (1.6532)  data: 0.1063 (0.1090)  lr: 0.000000  max mem: 970
2020-12-13 09:57:03,706 maskrcnn_benchmark.trainer INFO: eta: 18:19:48  iter: 60  loss: 6.4547 (6.4648)  loss_classifier: 2.1085 (2.1134)  loss_box_reg: 0.8260 (0.7852)  loss_objectness: 2.6318 (2.6304)  loss_rpn_box_reg: 0.9291 (0.9358)  time: 1.6477 (1.6522)  data: 0.1059 (0.1085)  lr: 0.000000  max mem: 970
2020-12-13 09:57:03,708 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 09:57:03,763 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 09:57:05,427 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.664019 (1.6640193462371826 s / img per device, on 1 devices)
2020-12-13 09:57:05,427 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.525541 (1.5255405902862549 s / img per device, on 1 devices)
2020-12-13 09:57:05,427 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 09:57:05,576 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 09:57:05,577 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.1444), 'recalls': tensor([0.5556, 0.5556, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.6460, 0.6026, 0.6009, 0.5703, 0.5506, 0.4876, 0.4530, 0.4513, 0.3912]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([8., 3., 4., 4., 4., 4., 4., 4., 6.]), 'best match scores': tensor([0.2370, 0.2462, 0.2489, 0.2304, 0.2652, 0.2844, 0.2593, 0.3280, 0.2326]), 'num_pos': 9}
2020-12-13 09:57:05,611 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-13 09:57:05,614 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v6.pth
2020-12-13 09:57:06,391 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v6
2020-12-13 09:57:39,378 maskrcnn_benchmark.trainer INFO: eta: 18:41:06  iter: 80  loss: 6.2600 (6.4302)  loss_classifier: 2.0997 (2.1111)  loss_box_reg: 0.7324 (0.7836)  loss_objectness: 2.4770 (2.6020)  loss_rpn_box_reg: 0.9279 (0.9334)  time: 1.6469 (1.6850)  data: 0.1070 (0.1423)  lr: 0.000000  max mem: 982
2020-12-13 09:58:12,351 maskrcnn_benchmark.trainer INFO: eta: 18:35:42  iter: 100  loss: 6.3035 (6.4141)  loss_classifier: 2.1013 (2.1097)  loss_box_reg: 0.7314 (0.7815)  loss_objectness: 2.5106 (2.5882)  loss_rpn_box_reg: 0.9232 (0.9347)  time: 1.6468 (1.6778)  data: 0.1084 (0.1356)  lr: 0.000000  max mem: 982
2020-12-13 09:58:45,518 maskrcnn_benchmark.trainer INFO: eta: 18:32:59  iter: 120  loss: 6.3160 (6.4046)  loss_classifier: 2.0986 (2.1080)  loss_box_reg: 0.7305 (0.7799)  loss_objectness: 2.5368 (2.5842)  loss_rpn_box_reg: 0.9265 (0.9326)  time: 1.6514 (1.6745)  data: 0.1100 (0.1314)  lr: 0.000000  max mem: 982
2020-12-13 09:58:45,519 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 09:58:45,571 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_valid dataset(1 images).
2020-12-13 09:58:47,239 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.667533 (1.6675326824188232 s / img per device, on 1 devices)
2020-12-13 09:58:47,239 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.538534 (1.538534164428711 s / img per device, on 1 devices)
2020-12-13 09:58:47,239 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 09:58:47,350 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 09:58:47,351 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.1444), 'recalls': tensor([0.5556, 0.5556, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.6461, 0.6030, 0.6009, 0.5708, 0.5510, 0.4875, 0.4533, 0.4518, 0.3914]), 'gt_labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2]), 'best match labels': tensor([8., 3., 4., 4., 4., 4., 4., 4., 6.]), 'best match scores': tensor([0.2361, 0.2455, 0.2478, 0.2296, 0.2638, 0.2831, 0.2582, 0.3268, 0.2315]), 'num_pos': 9}
2020-12-13 09:58:47,356 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.000000
2020-12-13 10:23:29,380 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 10:23:29,380 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 10:23:29,380 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 10:23:31,677 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 10:23:31,677 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 10:23:31,678 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train, giro4_train, giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 2

2020-12-13 10:23:31,679 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train, giro4_train, giro8_train',)
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 1e-06
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 2
2020-12-13 10:23:33,397 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from visdrone_model_0360000.pth
2020-12-13 10:23:34,136 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                  loaded from backbone.body.layer1.0.bn1.bias                  of shape (256,)
2020-12-13 10:23:34,137 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_mean          loaded from backbone.body.layer1.0.bn1.running_mean          of shape (256,)
2020-12-13 10:23:34,137 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_var           loaded from backbone.body.layer1.0.bn1.running_var           of shape (256,)
2020-12-13 10:23:34,137 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                loaded from backbone.body.layer1.0.bn1.weight                of shape (256,)
2020-12-13 10:23:34,137 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                  loaded from backbone.body.layer1.0.bn2.bias                  of shape (256,)
2020-12-13 10:23:34,137 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_mean          loaded from backbone.body.layer1.0.bn2.running_mean          of shape (256,)
2020-12-13 10:23:34,137 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_var           loaded from backbone.body.layer1.0.bn2.running_var           of shape (256,)
2020-12-13 10:23:34,137 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                loaded from backbone.body.layer1.0.bn2.weight                of shape (256,)
2020-12-13 10:23:34,137 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                  loaded from backbone.body.layer1.0.bn3.bias                  of shape (256,)
2020-12-13 10:23:34,137 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_mean          loaded from backbone.body.layer1.0.bn3.running_mean          of shape (256,)
2020-12-13 10:23:34,137 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_var           loaded from backbone.body.layer1.0.bn3.running_var           of shape (256,)
2020-12-13 10:23:34,138 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                loaded from backbone.body.layer1.0.bn3.weight                of shape (256,)
2020-12-13 10:23:34,138 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight              loaded from backbone.body.layer1.0.conv1.weight              of shape (256, 64, 1, 1)
2020-12-13 10:23:34,138 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight              loaded from backbone.body.layer1.0.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 10:23:34,138 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight              loaded from backbone.body.layer1.0.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 10:23:34,138 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight       loaded from backbone.body.layer1.0.downsample.0.weight       of shape (256, 64, 1, 1)
2020-12-13 10:23:34,138 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias         loaded from backbone.body.layer1.0.downsample.1.bias         of shape (256,)
2020-12-13 10:23:34,138 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_mean loaded from backbone.body.layer1.0.downsample.1.running_mean of shape (256,)
2020-12-13 10:23:34,138 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_var  loaded from backbone.body.layer1.0.downsample.1.running_var  of shape (256,)
2020-12-13 10:23:34,138 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight       loaded from backbone.body.layer1.0.downsample.1.weight       of shape (256,)
2020-12-13 10:23:34,138 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                  loaded from backbone.body.layer1.1.bn1.bias                  of shape (256,)
2020-12-13 10:23:34,138 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_mean          loaded from backbone.body.layer1.1.bn1.running_mean          of shape (256,)
2020-12-13 10:23:34,138 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_var           loaded from backbone.body.layer1.1.bn1.running_var           of shape (256,)
2020-12-13 10:23:34,138 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                loaded from backbone.body.layer1.1.bn1.weight                of shape (256,)
2020-12-13 10:23:34,139 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                  loaded from backbone.body.layer1.1.bn2.bias                  of shape (256,)
2020-12-13 10:23:34,139 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_mean          loaded from backbone.body.layer1.1.bn2.running_mean          of shape (256,)
2020-12-13 10:23:34,139 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_var           loaded from backbone.body.layer1.1.bn2.running_var           of shape (256,)
2020-12-13 10:23:34,139 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                loaded from backbone.body.layer1.1.bn2.weight                of shape (256,)
2020-12-13 10:23:34,139 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                  loaded from backbone.body.layer1.1.bn3.bias                  of shape (256,)
2020-12-13 10:23:34,139 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_mean          loaded from backbone.body.layer1.1.bn3.running_mean          of shape (256,)
2020-12-13 10:23:34,139 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_var           loaded from backbone.body.layer1.1.bn3.running_var           of shape (256,)
2020-12-13 10:23:34,139 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                loaded from backbone.body.layer1.1.bn3.weight                of shape (256,)
2020-12-13 10:23:34,139 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight              loaded from backbone.body.layer1.1.conv1.weight              of shape (256, 256, 1, 1)
2020-12-13 10:23:34,139 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight              loaded from backbone.body.layer1.1.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 10:23:34,139 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight              loaded from backbone.body.layer1.1.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 10:23:34,139 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                  loaded from backbone.body.layer1.2.bn1.bias                  of shape (256,)
2020-12-13 10:23:34,140 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_mean          loaded from backbone.body.layer1.2.bn1.running_mean          of shape (256,)
2020-12-13 10:23:34,140 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_var           loaded from backbone.body.layer1.2.bn1.running_var           of shape (256,)
2020-12-13 10:23:34,140 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                loaded from backbone.body.layer1.2.bn1.weight                of shape (256,)
2020-12-13 10:23:34,140 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                  loaded from backbone.body.layer1.2.bn2.bias                  of shape (256,)
2020-12-13 10:23:34,140 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_mean          loaded from backbone.body.layer1.2.bn2.running_mean          of shape (256,)
2020-12-13 10:23:34,140 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_var           loaded from backbone.body.layer1.2.bn2.running_var           of shape (256,)
2020-12-13 10:23:34,140 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                loaded from backbone.body.layer1.2.bn2.weight                of shape (256,)
2020-12-13 10:23:34,140 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                  loaded from backbone.body.layer1.2.bn3.bias                  of shape (256,)
2020-12-13 10:23:34,140 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_mean          loaded from backbone.body.layer1.2.bn3.running_mean          of shape (256,)
2020-12-13 10:23:34,140 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_var           loaded from backbone.body.layer1.2.bn3.running_var           of shape (256,)
2020-12-13 10:23:34,140 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                loaded from backbone.body.layer1.2.bn3.weight                of shape (256,)
2020-12-13 10:23:34,140 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight              loaded from backbone.body.layer1.2.conv1.weight              of shape (256, 256, 1, 1)
2020-12-13 10:23:34,140 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight              loaded from backbone.body.layer1.2.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 10:23:34,141 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight              loaded from backbone.body.layer1.2.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 10:23:34,141 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                  loaded from backbone.body.layer2.0.bn1.bias                  of shape (512,)
2020-12-13 10:23:34,141 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_mean          loaded from backbone.body.layer2.0.bn1.running_mean          of shape (512,)
2020-12-13 10:23:34,141 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_var           loaded from backbone.body.layer2.0.bn1.running_var           of shape (512,)
2020-12-13 10:23:34,141 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                loaded from backbone.body.layer2.0.bn1.weight                of shape (512,)
2020-12-13 10:23:34,141 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                  loaded from backbone.body.layer2.0.bn2.bias                  of shape (512,)
2020-12-13 10:23:34,141 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_mean          loaded from backbone.body.layer2.0.bn2.running_mean          of shape (512,)
2020-12-13 10:23:34,141 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_var           loaded from backbone.body.layer2.0.bn2.running_var           of shape (512,)
2020-12-13 10:23:34,141 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                loaded from backbone.body.layer2.0.bn2.weight                of shape (512,)
2020-12-13 10:23:34,141 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                  loaded from backbone.body.layer2.0.bn3.bias                  of shape (512,)
2020-12-13 10:23:34,141 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_mean          loaded from backbone.body.layer2.0.bn3.running_mean          of shape (512,)
2020-12-13 10:23:34,141 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_var           loaded from backbone.body.layer2.0.bn3.running_var           of shape (512,)
2020-12-13 10:23:34,141 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                loaded from backbone.body.layer2.0.bn3.weight                of shape (512,)
2020-12-13 10:23:34,141 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight              loaded from backbone.body.layer2.0.conv1.weight              of shape (512, 256, 1, 1)
2020-12-13 10:23:34,142 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight              loaded from backbone.body.layer2.0.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:23:34,142 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight              loaded from backbone.body.layer2.0.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:23:34,142 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight       loaded from backbone.body.layer2.0.downsample.0.weight       of shape (512, 256, 1, 1)
2020-12-13 10:23:34,142 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias         loaded from backbone.body.layer2.0.downsample.1.bias         of shape (512,)
2020-12-13 10:23:34,142 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_mean loaded from backbone.body.layer2.0.downsample.1.running_mean of shape (512,)
2020-12-13 10:23:34,142 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_var  loaded from backbone.body.layer2.0.downsample.1.running_var  of shape (512,)
2020-12-13 10:23:34,142 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight       loaded from backbone.body.layer2.0.downsample.1.weight       of shape (512,)
2020-12-13 10:23:34,142 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                  loaded from backbone.body.layer2.1.bn1.bias                  of shape (512,)
2020-12-13 10:23:34,142 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_mean          loaded from backbone.body.layer2.1.bn1.running_mean          of shape (512,)
2020-12-13 10:23:34,142 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_var           loaded from backbone.body.layer2.1.bn1.running_var           of shape (512,)
2020-12-13 10:23:34,142 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                loaded from backbone.body.layer2.1.bn1.weight                of shape (512,)
2020-12-13 10:23:34,142 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                  loaded from backbone.body.layer2.1.bn2.bias                  of shape (512,)
2020-12-13 10:23:34,142 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_mean          loaded from backbone.body.layer2.1.bn2.running_mean          of shape (512,)
2020-12-13 10:23:34,143 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_var           loaded from backbone.body.layer2.1.bn2.running_var           of shape (512,)
2020-12-13 10:23:34,143 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                loaded from backbone.body.layer2.1.bn2.weight                of shape (512,)
2020-12-13 10:23:34,143 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                  loaded from backbone.body.layer2.1.bn3.bias                  of shape (512,)
2020-12-13 10:23:34,143 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_mean          loaded from backbone.body.layer2.1.bn3.running_mean          of shape (512,)
2020-12-13 10:23:34,143 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_var           loaded from backbone.body.layer2.1.bn3.running_var           of shape (512,)
2020-12-13 10:23:34,143 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                loaded from backbone.body.layer2.1.bn3.weight                of shape (512,)
2020-12-13 10:23:34,143 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight              loaded from backbone.body.layer2.1.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 10:23:34,143 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight              loaded from backbone.body.layer2.1.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:23:34,143 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight              loaded from backbone.body.layer2.1.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:23:34,143 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                  loaded from backbone.body.layer2.2.bn1.bias                  of shape (512,)
2020-12-13 10:23:34,143 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_mean          loaded from backbone.body.layer2.2.bn1.running_mean          of shape (512,)
2020-12-13 10:23:34,144 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_var           loaded from backbone.body.layer2.2.bn1.running_var           of shape (512,)
2020-12-13 10:23:34,144 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                loaded from backbone.body.layer2.2.bn1.weight                of shape (512,)
2020-12-13 10:23:34,144 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                  loaded from backbone.body.layer2.2.bn2.bias                  of shape (512,)
2020-12-13 10:23:34,144 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_mean          loaded from backbone.body.layer2.2.bn2.running_mean          of shape (512,)
2020-12-13 10:23:34,144 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_var           loaded from backbone.body.layer2.2.bn2.running_var           of shape (512,)
2020-12-13 10:23:34,144 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                loaded from backbone.body.layer2.2.bn2.weight                of shape (512,)
2020-12-13 10:23:34,144 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                  loaded from backbone.body.layer2.2.bn3.bias                  of shape (512,)
2020-12-13 10:23:34,144 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_mean          loaded from backbone.body.layer2.2.bn3.running_mean          of shape (512,)
2020-12-13 10:23:34,144 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_var           loaded from backbone.body.layer2.2.bn3.running_var           of shape (512,)
2020-12-13 10:23:34,144 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                loaded from backbone.body.layer2.2.bn3.weight                of shape (512,)
2020-12-13 10:23:34,144 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight              loaded from backbone.body.layer2.2.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 10:23:34,145 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight              loaded from backbone.body.layer2.2.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:23:34,145 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight              loaded from backbone.body.layer2.2.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:23:34,145 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                  loaded from backbone.body.layer2.3.bn1.bias                  of shape (512,)
2020-12-13 10:23:34,145 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_mean          loaded from backbone.body.layer2.3.bn1.running_mean          of shape (512,)
2020-12-13 10:23:34,145 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_var           loaded from backbone.body.layer2.3.bn1.running_var           of shape (512,)
2020-12-13 10:23:34,145 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                loaded from backbone.body.layer2.3.bn1.weight                of shape (512,)
2020-12-13 10:23:34,145 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                  loaded from backbone.body.layer2.3.bn2.bias                  of shape (512,)
2020-12-13 10:23:34,145 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_mean          loaded from backbone.body.layer2.3.bn2.running_mean          of shape (512,)
2020-12-13 10:23:34,145 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_var           loaded from backbone.body.layer2.3.bn2.running_var           of shape (512,)
2020-12-13 10:23:34,145 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                loaded from backbone.body.layer2.3.bn2.weight                of shape (512,)
2020-12-13 10:23:34,145 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                  loaded from backbone.body.layer2.3.bn3.bias                  of shape (512,)
2020-12-13 10:23:34,145 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_mean          loaded from backbone.body.layer2.3.bn3.running_mean          of shape (512,)
2020-12-13 10:23:34,146 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_var           loaded from backbone.body.layer2.3.bn3.running_var           of shape (512,)
2020-12-13 10:23:34,146 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                loaded from backbone.body.layer2.3.bn3.weight                of shape (512,)
2020-12-13 10:23:34,146 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight              loaded from backbone.body.layer2.3.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 10:23:34,146 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight              loaded from backbone.body.layer2.3.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:23:34,146 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight              loaded from backbone.body.layer2.3.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:23:34,146 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                  loaded from backbone.body.layer3.0.bn1.bias                  of shape (1024,)
2020-12-13 10:23:34,146 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_mean          loaded from backbone.body.layer3.0.bn1.running_mean          of shape (1024,)
2020-12-13 10:23:34,146 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_var           loaded from backbone.body.layer3.0.bn1.running_var           of shape (1024,)
2020-12-13 10:23:34,146 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                loaded from backbone.body.layer3.0.bn1.weight                of shape (1024,)
2020-12-13 10:23:34,146 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                  loaded from backbone.body.layer3.0.bn2.bias                  of shape (1024,)
2020-12-13 10:23:34,146 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_mean          loaded from backbone.body.layer3.0.bn2.running_mean          of shape (1024,)
2020-12-13 10:23:34,146 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_var           loaded from backbone.body.layer3.0.bn2.running_var           of shape (1024,)
2020-12-13 10:23:34,147 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                loaded from backbone.body.layer3.0.bn2.weight                of shape (1024,)
2020-12-13 10:23:34,147 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                  loaded from backbone.body.layer3.0.bn3.bias                  of shape (1024,)
2020-12-13 10:23:34,147 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_mean          loaded from backbone.body.layer3.0.bn3.running_mean          of shape (1024,)
2020-12-13 10:23:34,147 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_var           loaded from backbone.body.layer3.0.bn3.running_var           of shape (1024,)
2020-12-13 10:23:34,147 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                loaded from backbone.body.layer3.0.bn3.weight                of shape (1024,)
2020-12-13 10:23:34,147 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight              loaded from backbone.body.layer3.0.conv1.weight              of shape (1024, 512, 1, 1)
2020-12-13 10:23:34,147 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight              loaded from backbone.body.layer3.0.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,147 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight              loaded from backbone.body.layer3.0.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,147 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight       loaded from backbone.body.layer3.0.downsample.0.weight       of shape (1024, 512, 1, 1)
2020-12-13 10:23:34,147 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias         loaded from backbone.body.layer3.0.downsample.1.bias         of shape (1024,)
2020-12-13 10:23:34,147 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_mean loaded from backbone.body.layer3.0.downsample.1.running_mean of shape (1024,)
2020-12-13 10:23:34,148 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_var  loaded from backbone.body.layer3.0.downsample.1.running_var  of shape (1024,)
2020-12-13 10:23:34,148 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight       loaded from backbone.body.layer3.0.downsample.1.weight       of shape (1024,)
2020-12-13 10:23:34,148 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                  loaded from backbone.body.layer3.1.bn1.bias                  of shape (1024,)
2020-12-13 10:23:34,148 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_mean          loaded from backbone.body.layer3.1.bn1.running_mean          of shape (1024,)
2020-12-13 10:23:34,148 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_var           loaded from backbone.body.layer3.1.bn1.running_var           of shape (1024,)
2020-12-13 10:23:34,148 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                loaded from backbone.body.layer3.1.bn1.weight                of shape (1024,)
2020-12-13 10:23:34,148 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                  loaded from backbone.body.layer3.1.bn2.bias                  of shape (1024,)
2020-12-13 10:23:34,148 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_mean          loaded from backbone.body.layer3.1.bn2.running_mean          of shape (1024,)
2020-12-13 10:23:34,148 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_var           loaded from backbone.body.layer3.1.bn2.running_var           of shape (1024,)
2020-12-13 10:23:34,148 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                loaded from backbone.body.layer3.1.bn2.weight                of shape (1024,)
2020-12-13 10:23:34,148 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                  loaded from backbone.body.layer3.1.bn3.bias                  of shape (1024,)
2020-12-13 10:23:34,149 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_mean          loaded from backbone.body.layer3.1.bn3.running_mean          of shape (1024,)
2020-12-13 10:23:34,149 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_var           loaded from backbone.body.layer3.1.bn3.running_var           of shape (1024,)
2020-12-13 10:23:34,149 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                loaded from backbone.body.layer3.1.bn3.weight                of shape (1024,)
2020-12-13 10:23:34,149 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight              loaded from backbone.body.layer3.1.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,149 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight              loaded from backbone.body.layer3.1.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,149 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight              loaded from backbone.body.layer3.1.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,149 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.bias                 loaded from backbone.body.layer3.10.bn1.bias                 of shape (1024,)
2020-12-13 10:23:34,149 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.running_mean         loaded from backbone.body.layer3.10.bn1.running_mean         of shape (1024,)
2020-12-13 10:23:34,149 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.running_var          loaded from backbone.body.layer3.10.bn1.running_var          of shape (1024,)
2020-12-13 10:23:34,149 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.weight               loaded from backbone.body.layer3.10.bn1.weight               of shape (1024,)
2020-12-13 10:23:34,149 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.bias                 loaded from backbone.body.layer3.10.bn2.bias                 of shape (1024,)
2020-12-13 10:23:34,150 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.running_mean         loaded from backbone.body.layer3.10.bn2.running_mean         of shape (1024,)
2020-12-13 10:23:34,150 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.running_var          loaded from backbone.body.layer3.10.bn2.running_var          of shape (1024,)
2020-12-13 10:23:34,150 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.weight               loaded from backbone.body.layer3.10.bn2.weight               of shape (1024,)
2020-12-13 10:23:34,150 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.bias                 loaded from backbone.body.layer3.10.bn3.bias                 of shape (1024,)
2020-12-13 10:23:34,150 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.running_mean         loaded from backbone.body.layer3.10.bn3.running_mean         of shape (1024,)
2020-12-13 10:23:34,150 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.running_var          loaded from backbone.body.layer3.10.bn3.running_var          of shape (1024,)
2020-12-13 10:23:34,150 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.weight               loaded from backbone.body.layer3.10.bn3.weight               of shape (1024,)
2020-12-13 10:23:34,150 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv1.weight             loaded from backbone.body.layer3.10.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,150 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv2.weight             loaded from backbone.body.layer3.10.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,151 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv3.weight             loaded from backbone.body.layer3.10.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,151 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.bias                 loaded from backbone.body.layer3.11.bn1.bias                 of shape (1024,)
2020-12-13 10:23:34,151 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.running_mean         loaded from backbone.body.layer3.11.bn1.running_mean         of shape (1024,)
2020-12-13 10:23:34,151 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.running_var          loaded from backbone.body.layer3.11.bn1.running_var          of shape (1024,)
2020-12-13 10:23:34,151 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.weight               loaded from backbone.body.layer3.11.bn1.weight               of shape (1024,)
2020-12-13 10:23:34,151 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.bias                 loaded from backbone.body.layer3.11.bn2.bias                 of shape (1024,)
2020-12-13 10:23:34,151 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.running_mean         loaded from backbone.body.layer3.11.bn2.running_mean         of shape (1024,)
2020-12-13 10:23:34,151 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.running_var          loaded from backbone.body.layer3.11.bn2.running_var          of shape (1024,)
2020-12-13 10:23:34,151 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.weight               loaded from backbone.body.layer3.11.bn2.weight               of shape (1024,)
2020-12-13 10:23:34,151 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.bias                 loaded from backbone.body.layer3.11.bn3.bias                 of shape (1024,)
2020-12-13 10:23:34,152 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.running_mean         loaded from backbone.body.layer3.11.bn3.running_mean         of shape (1024,)
2020-12-13 10:23:34,152 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.running_var          loaded from backbone.body.layer3.11.bn3.running_var          of shape (1024,)
2020-12-13 10:23:34,152 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.weight               loaded from backbone.body.layer3.11.bn3.weight               of shape (1024,)
2020-12-13 10:23:34,152 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv1.weight             loaded from backbone.body.layer3.11.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,152 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv2.weight             loaded from backbone.body.layer3.11.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,152 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv3.weight             loaded from backbone.body.layer3.11.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,152 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.bias                 loaded from backbone.body.layer3.12.bn1.bias                 of shape (1024,)
2020-12-13 10:23:34,152 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.running_mean         loaded from backbone.body.layer3.12.bn1.running_mean         of shape (1024,)
2020-12-13 10:23:34,152 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.running_var          loaded from backbone.body.layer3.12.bn1.running_var          of shape (1024,)
2020-12-13 10:23:34,152 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.weight               loaded from backbone.body.layer3.12.bn1.weight               of shape (1024,)
2020-12-13 10:23:34,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.bias                 loaded from backbone.body.layer3.12.bn2.bias                 of shape (1024,)
2020-12-13 10:23:34,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.running_mean         loaded from backbone.body.layer3.12.bn2.running_mean         of shape (1024,)
2020-12-13 10:23:34,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.running_var          loaded from backbone.body.layer3.12.bn2.running_var          of shape (1024,)
2020-12-13 10:23:34,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.weight               loaded from backbone.body.layer3.12.bn2.weight               of shape (1024,)
2020-12-13 10:23:34,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.bias                 loaded from backbone.body.layer3.12.bn3.bias                 of shape (1024,)
2020-12-13 10:23:34,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.running_mean         loaded from backbone.body.layer3.12.bn3.running_mean         of shape (1024,)
2020-12-13 10:23:34,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.running_var          loaded from backbone.body.layer3.12.bn3.running_var          of shape (1024,)
2020-12-13 10:23:34,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.weight               loaded from backbone.body.layer3.12.bn3.weight               of shape (1024,)
2020-12-13 10:23:34,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv1.weight             loaded from backbone.body.layer3.12.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv2.weight             loaded from backbone.body.layer3.12.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv3.weight             loaded from backbone.body.layer3.12.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.bias                 loaded from backbone.body.layer3.13.bn1.bias                 of shape (1024,)
2020-12-13 10:23:34,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.running_mean         loaded from backbone.body.layer3.13.bn1.running_mean         of shape (1024,)
2020-12-13 10:23:34,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.running_var          loaded from backbone.body.layer3.13.bn1.running_var          of shape (1024,)
2020-12-13 10:23:34,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.weight               loaded from backbone.body.layer3.13.bn1.weight               of shape (1024,)
2020-12-13 10:23:34,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.bias                 loaded from backbone.body.layer3.13.bn2.bias                 of shape (1024,)
2020-12-13 10:23:34,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.running_mean         loaded from backbone.body.layer3.13.bn2.running_mean         of shape (1024,)
2020-12-13 10:23:34,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.running_var          loaded from backbone.body.layer3.13.bn2.running_var          of shape (1024,)
2020-12-13 10:23:34,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.weight               loaded from backbone.body.layer3.13.bn2.weight               of shape (1024,)
2020-12-13 10:23:34,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.bias                 loaded from backbone.body.layer3.13.bn3.bias                 of shape (1024,)
2020-12-13 10:23:34,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.running_mean         loaded from backbone.body.layer3.13.bn3.running_mean         of shape (1024,)
2020-12-13 10:23:34,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.running_var          loaded from backbone.body.layer3.13.bn3.running_var          of shape (1024,)
2020-12-13 10:23:34,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.weight               loaded from backbone.body.layer3.13.bn3.weight               of shape (1024,)
2020-12-13 10:23:34,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv1.weight             loaded from backbone.body.layer3.13.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv2.weight             loaded from backbone.body.layer3.13.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv3.weight             loaded from backbone.body.layer3.13.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.bias                 loaded from backbone.body.layer3.14.bn1.bias                 of shape (1024,)
2020-12-13 10:23:34,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.running_mean         loaded from backbone.body.layer3.14.bn1.running_mean         of shape (1024,)
2020-12-13 10:23:34,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.running_var          loaded from backbone.body.layer3.14.bn1.running_var          of shape (1024,)
2020-12-13 10:23:34,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.weight               loaded from backbone.body.layer3.14.bn1.weight               of shape (1024,)
2020-12-13 10:23:34,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.bias                 loaded from backbone.body.layer3.14.bn2.bias                 of shape (1024,)
2020-12-13 10:23:34,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.running_mean         loaded from backbone.body.layer3.14.bn2.running_mean         of shape (1024,)
2020-12-13 10:23:34,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.running_var          loaded from backbone.body.layer3.14.bn2.running_var          of shape (1024,)
2020-12-13 10:23:34,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.weight               loaded from backbone.body.layer3.14.bn2.weight               of shape (1024,)
2020-12-13 10:23:34,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.bias                 loaded from backbone.body.layer3.14.bn3.bias                 of shape (1024,)
2020-12-13 10:23:34,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.running_mean         loaded from backbone.body.layer3.14.bn3.running_mean         of shape (1024,)
2020-12-13 10:23:34,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.running_var          loaded from backbone.body.layer3.14.bn3.running_var          of shape (1024,)
2020-12-13 10:23:34,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.weight               loaded from backbone.body.layer3.14.bn3.weight               of shape (1024,)
2020-12-13 10:23:34,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv1.weight             loaded from backbone.body.layer3.14.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv2.weight             loaded from backbone.body.layer3.14.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv3.weight             loaded from backbone.body.layer3.14.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.bias                 loaded from backbone.body.layer3.15.bn1.bias                 of shape (1024,)
2020-12-13 10:23:34,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.running_mean         loaded from backbone.body.layer3.15.bn1.running_mean         of shape (1024,)
2020-12-13 10:23:34,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.running_var          loaded from backbone.body.layer3.15.bn1.running_var          of shape (1024,)
2020-12-13 10:23:34,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.weight               loaded from backbone.body.layer3.15.bn1.weight               of shape (1024,)
2020-12-13 10:23:34,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.bias                 loaded from backbone.body.layer3.15.bn2.bias                 of shape (1024,)
2020-12-13 10:23:34,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.running_mean         loaded from backbone.body.layer3.15.bn2.running_mean         of shape (1024,)
2020-12-13 10:23:34,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.running_var          loaded from backbone.body.layer3.15.bn2.running_var          of shape (1024,)
2020-12-13 10:23:34,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.weight               loaded from backbone.body.layer3.15.bn2.weight               of shape (1024,)
2020-12-13 10:23:34,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.bias                 loaded from backbone.body.layer3.15.bn3.bias                 of shape (1024,)
2020-12-13 10:23:34,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.running_mean         loaded from backbone.body.layer3.15.bn3.running_mean         of shape (1024,)
2020-12-13 10:23:34,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.running_var          loaded from backbone.body.layer3.15.bn3.running_var          of shape (1024,)
2020-12-13 10:23:34,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.weight               loaded from backbone.body.layer3.15.bn3.weight               of shape (1024,)
2020-12-13 10:23:34,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv1.weight             loaded from backbone.body.layer3.15.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv2.weight             loaded from backbone.body.layer3.15.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv3.weight             loaded from backbone.body.layer3.15.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.bias                 loaded from backbone.body.layer3.16.bn1.bias                 of shape (1024,)
2020-12-13 10:23:34,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.running_mean         loaded from backbone.body.layer3.16.bn1.running_mean         of shape (1024,)
2020-12-13 10:23:34,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.running_var          loaded from backbone.body.layer3.16.bn1.running_var          of shape (1024,)
2020-12-13 10:23:34,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.weight               loaded from backbone.body.layer3.16.bn1.weight               of shape (1024,)
2020-12-13 10:23:34,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.bias                 loaded from backbone.body.layer3.16.bn2.bias                 of shape (1024,)
2020-12-13 10:23:34,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.running_mean         loaded from backbone.body.layer3.16.bn2.running_mean         of shape (1024,)
2020-12-13 10:23:34,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.running_var          loaded from backbone.body.layer3.16.bn2.running_var          of shape (1024,)
2020-12-13 10:23:34,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.weight               loaded from backbone.body.layer3.16.bn2.weight               of shape (1024,)
2020-12-13 10:23:34,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.bias                 loaded from backbone.body.layer3.16.bn3.bias                 of shape (1024,)
2020-12-13 10:23:34,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.running_mean         loaded from backbone.body.layer3.16.bn3.running_mean         of shape (1024,)
2020-12-13 10:23:34,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.running_var          loaded from backbone.body.layer3.16.bn3.running_var          of shape (1024,)
2020-12-13 10:23:34,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.weight               loaded from backbone.body.layer3.16.bn3.weight               of shape (1024,)
2020-12-13 10:23:34,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv1.weight             loaded from backbone.body.layer3.16.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv2.weight             loaded from backbone.body.layer3.16.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv3.weight             loaded from backbone.body.layer3.16.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.bias                 loaded from backbone.body.layer3.17.bn1.bias                 of shape (1024,)
2020-12-13 10:23:34,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.running_mean         loaded from backbone.body.layer3.17.bn1.running_mean         of shape (1024,)
2020-12-13 10:23:34,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.running_var          loaded from backbone.body.layer3.17.bn1.running_var          of shape (1024,)
2020-12-13 10:23:34,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.weight               loaded from backbone.body.layer3.17.bn1.weight               of shape (1024,)
2020-12-13 10:23:34,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.bias                 loaded from backbone.body.layer3.17.bn2.bias                 of shape (1024,)
2020-12-13 10:23:34,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.running_mean         loaded from backbone.body.layer3.17.bn2.running_mean         of shape (1024,)
2020-12-13 10:23:34,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.running_var          loaded from backbone.body.layer3.17.bn2.running_var          of shape (1024,)
2020-12-13 10:23:34,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.weight               loaded from backbone.body.layer3.17.bn2.weight               of shape (1024,)
2020-12-13 10:23:34,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.bias                 loaded from backbone.body.layer3.17.bn3.bias                 of shape (1024,)
2020-12-13 10:23:34,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.running_mean         loaded from backbone.body.layer3.17.bn3.running_mean         of shape (1024,)
2020-12-13 10:23:34,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.running_var          loaded from backbone.body.layer3.17.bn3.running_var          of shape (1024,)
2020-12-13 10:23:34,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.weight               loaded from backbone.body.layer3.17.bn3.weight               of shape (1024,)
2020-12-13 10:23:34,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv1.weight             loaded from backbone.body.layer3.17.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv2.weight             loaded from backbone.body.layer3.17.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv3.weight             loaded from backbone.body.layer3.17.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.bias                 loaded from backbone.body.layer3.18.bn1.bias                 of shape (1024,)
2020-12-13 10:23:34,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.running_mean         loaded from backbone.body.layer3.18.bn1.running_mean         of shape (1024,)
2020-12-13 10:23:34,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.running_var          loaded from backbone.body.layer3.18.bn1.running_var          of shape (1024,)
2020-12-13 10:23:34,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.weight               loaded from backbone.body.layer3.18.bn1.weight               of shape (1024,)
2020-12-13 10:23:34,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.bias                 loaded from backbone.body.layer3.18.bn2.bias                 of shape (1024,)
2020-12-13 10:23:34,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.running_mean         loaded from backbone.body.layer3.18.bn2.running_mean         of shape (1024,)
2020-12-13 10:23:34,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.running_var          loaded from backbone.body.layer3.18.bn2.running_var          of shape (1024,)
2020-12-13 10:23:34,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.weight               loaded from backbone.body.layer3.18.bn2.weight               of shape (1024,)
2020-12-13 10:23:34,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.bias                 loaded from backbone.body.layer3.18.bn3.bias                 of shape (1024,)
2020-12-13 10:23:34,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.running_mean         loaded from backbone.body.layer3.18.bn3.running_mean         of shape (1024,)
2020-12-13 10:23:34,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.running_var          loaded from backbone.body.layer3.18.bn3.running_var          of shape (1024,)
2020-12-13 10:23:34,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.weight               loaded from backbone.body.layer3.18.bn3.weight               of shape (1024,)
2020-12-13 10:23:34,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv1.weight             loaded from backbone.body.layer3.18.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv2.weight             loaded from backbone.body.layer3.18.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv3.weight             loaded from backbone.body.layer3.18.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.bias                 loaded from backbone.body.layer3.19.bn1.bias                 of shape (1024,)
2020-12-13 10:23:34,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.running_mean         loaded from backbone.body.layer3.19.bn1.running_mean         of shape (1024,)
2020-12-13 10:23:34,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.running_var          loaded from backbone.body.layer3.19.bn1.running_var          of shape (1024,)
2020-12-13 10:23:34,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.weight               loaded from backbone.body.layer3.19.bn1.weight               of shape (1024,)
2020-12-13 10:23:34,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.bias                 loaded from backbone.body.layer3.19.bn2.bias                 of shape (1024,)
2020-12-13 10:23:34,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.running_mean         loaded from backbone.body.layer3.19.bn2.running_mean         of shape (1024,)
2020-12-13 10:23:34,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.running_var          loaded from backbone.body.layer3.19.bn2.running_var          of shape (1024,)
2020-12-13 10:23:34,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.weight               loaded from backbone.body.layer3.19.bn2.weight               of shape (1024,)
2020-12-13 10:23:34,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.bias                 loaded from backbone.body.layer3.19.bn3.bias                 of shape (1024,)
2020-12-13 10:23:34,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.running_mean         loaded from backbone.body.layer3.19.bn3.running_mean         of shape (1024,)
2020-12-13 10:23:34,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.running_var          loaded from backbone.body.layer3.19.bn3.running_var          of shape (1024,)
2020-12-13 10:23:34,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.weight               loaded from backbone.body.layer3.19.bn3.weight               of shape (1024,)
2020-12-13 10:23:34,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv1.weight             loaded from backbone.body.layer3.19.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv2.weight             loaded from backbone.body.layer3.19.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv3.weight             loaded from backbone.body.layer3.19.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                  loaded from backbone.body.layer3.2.bn1.bias                  of shape (1024,)
2020-12-13 10:23:34,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_mean          loaded from backbone.body.layer3.2.bn1.running_mean          of shape (1024,)
2020-12-13 10:23:34,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_var           loaded from backbone.body.layer3.2.bn1.running_var           of shape (1024,)
2020-12-13 10:23:34,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                loaded from backbone.body.layer3.2.bn1.weight                of shape (1024,)
2020-12-13 10:23:34,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                  loaded from backbone.body.layer3.2.bn2.bias                  of shape (1024,)
2020-12-13 10:23:34,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_mean          loaded from backbone.body.layer3.2.bn2.running_mean          of shape (1024,)
2020-12-13 10:23:34,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_var           loaded from backbone.body.layer3.2.bn2.running_var           of shape (1024,)
2020-12-13 10:23:34,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                loaded from backbone.body.layer3.2.bn2.weight                of shape (1024,)
2020-12-13 10:23:34,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                  loaded from backbone.body.layer3.2.bn3.bias                  of shape (1024,)
2020-12-13 10:23:34,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_mean          loaded from backbone.body.layer3.2.bn3.running_mean          of shape (1024,)
2020-12-13 10:23:34,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_var           loaded from backbone.body.layer3.2.bn3.running_var           of shape (1024,)
2020-12-13 10:23:34,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                loaded from backbone.body.layer3.2.bn3.weight                of shape (1024,)
2020-12-13 10:23:34,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight              loaded from backbone.body.layer3.2.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight              loaded from backbone.body.layer3.2.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight              loaded from backbone.body.layer3.2.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.bias                 loaded from backbone.body.layer3.20.bn1.bias                 of shape (1024,)
2020-12-13 10:23:34,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.running_mean         loaded from backbone.body.layer3.20.bn1.running_mean         of shape (1024,)
2020-12-13 10:23:34,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.running_var          loaded from backbone.body.layer3.20.bn1.running_var          of shape (1024,)
2020-12-13 10:23:34,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.weight               loaded from backbone.body.layer3.20.bn1.weight               of shape (1024,)
2020-12-13 10:23:34,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.bias                 loaded from backbone.body.layer3.20.bn2.bias                 of shape (1024,)
2020-12-13 10:23:34,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.running_mean         loaded from backbone.body.layer3.20.bn2.running_mean         of shape (1024,)
2020-12-13 10:23:34,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.running_var          loaded from backbone.body.layer3.20.bn2.running_var          of shape (1024,)
2020-12-13 10:23:34,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.weight               loaded from backbone.body.layer3.20.bn2.weight               of shape (1024,)
2020-12-13 10:23:34,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.bias                 loaded from backbone.body.layer3.20.bn3.bias                 of shape (1024,)
2020-12-13 10:23:34,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.running_mean         loaded from backbone.body.layer3.20.bn3.running_mean         of shape (1024,)
2020-12-13 10:23:34,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.running_var          loaded from backbone.body.layer3.20.bn3.running_var          of shape (1024,)
2020-12-13 10:23:34,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.weight               loaded from backbone.body.layer3.20.bn3.weight               of shape (1024,)
2020-12-13 10:23:34,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv1.weight             loaded from backbone.body.layer3.20.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv2.weight             loaded from backbone.body.layer3.20.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv3.weight             loaded from backbone.body.layer3.20.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.bias                 loaded from backbone.body.layer3.21.bn1.bias                 of shape (1024,)
2020-12-13 10:23:34,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.running_mean         loaded from backbone.body.layer3.21.bn1.running_mean         of shape (1024,)
2020-12-13 10:23:34,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.running_var          loaded from backbone.body.layer3.21.bn1.running_var          of shape (1024,)
2020-12-13 10:23:34,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.weight               loaded from backbone.body.layer3.21.bn1.weight               of shape (1024,)
2020-12-13 10:23:34,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.bias                 loaded from backbone.body.layer3.21.bn2.bias                 of shape (1024,)
2020-12-13 10:23:34,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.running_mean         loaded from backbone.body.layer3.21.bn2.running_mean         of shape (1024,)
2020-12-13 10:23:34,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.running_var          loaded from backbone.body.layer3.21.bn2.running_var          of shape (1024,)
2020-12-13 10:23:34,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.weight               loaded from backbone.body.layer3.21.bn2.weight               of shape (1024,)
2020-12-13 10:23:34,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.bias                 loaded from backbone.body.layer3.21.bn3.bias                 of shape (1024,)
2020-12-13 10:23:34,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.running_mean         loaded from backbone.body.layer3.21.bn3.running_mean         of shape (1024,)
2020-12-13 10:23:34,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.running_var          loaded from backbone.body.layer3.21.bn3.running_var          of shape (1024,)
2020-12-13 10:23:34,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.weight               loaded from backbone.body.layer3.21.bn3.weight               of shape (1024,)
2020-12-13 10:23:34,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv1.weight             loaded from backbone.body.layer3.21.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv2.weight             loaded from backbone.body.layer3.21.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv3.weight             loaded from backbone.body.layer3.21.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.bias                 loaded from backbone.body.layer3.22.bn1.bias                 of shape (1024,)
2020-12-13 10:23:34,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.running_mean         loaded from backbone.body.layer3.22.bn1.running_mean         of shape (1024,)
2020-12-13 10:23:34,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.running_var          loaded from backbone.body.layer3.22.bn1.running_var          of shape (1024,)
2020-12-13 10:23:34,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.weight               loaded from backbone.body.layer3.22.bn1.weight               of shape (1024,)
2020-12-13 10:23:34,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.bias                 loaded from backbone.body.layer3.22.bn2.bias                 of shape (1024,)
2020-12-13 10:23:34,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.running_mean         loaded from backbone.body.layer3.22.bn2.running_mean         of shape (1024,)
2020-12-13 10:23:34,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.running_var          loaded from backbone.body.layer3.22.bn2.running_var          of shape (1024,)
2020-12-13 10:23:34,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.weight               loaded from backbone.body.layer3.22.bn2.weight               of shape (1024,)
2020-12-13 10:23:34,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.bias                 loaded from backbone.body.layer3.22.bn3.bias                 of shape (1024,)
2020-12-13 10:23:34,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.running_mean         loaded from backbone.body.layer3.22.bn3.running_mean         of shape (1024,)
2020-12-13 10:23:34,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.running_var          loaded from backbone.body.layer3.22.bn3.running_var          of shape (1024,)
2020-12-13 10:23:34,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.weight               loaded from backbone.body.layer3.22.bn3.weight               of shape (1024,)
2020-12-13 10:23:34,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv1.weight             loaded from backbone.body.layer3.22.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv2.weight             loaded from backbone.body.layer3.22.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv3.weight             loaded from backbone.body.layer3.22.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                  loaded from backbone.body.layer3.3.bn1.bias                  of shape (1024,)
2020-12-13 10:23:34,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_mean          loaded from backbone.body.layer3.3.bn1.running_mean          of shape (1024,)
2020-12-13 10:23:34,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_var           loaded from backbone.body.layer3.3.bn1.running_var           of shape (1024,)
2020-12-13 10:23:34,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                loaded from backbone.body.layer3.3.bn1.weight                of shape (1024,)
2020-12-13 10:23:34,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                  loaded from backbone.body.layer3.3.bn2.bias                  of shape (1024,)
2020-12-13 10:23:34,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_mean          loaded from backbone.body.layer3.3.bn2.running_mean          of shape (1024,)
2020-12-13 10:23:34,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_var           loaded from backbone.body.layer3.3.bn2.running_var           of shape (1024,)
2020-12-13 10:23:34,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                loaded from backbone.body.layer3.3.bn2.weight                of shape (1024,)
2020-12-13 10:23:34,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                  loaded from backbone.body.layer3.3.bn3.bias                  of shape (1024,)
2020-12-13 10:23:34,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_mean          loaded from backbone.body.layer3.3.bn3.running_mean          of shape (1024,)
2020-12-13 10:23:34,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_var           loaded from backbone.body.layer3.3.bn3.running_var           of shape (1024,)
2020-12-13 10:23:34,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                loaded from backbone.body.layer3.3.bn3.weight                of shape (1024,)
2020-12-13 10:23:34,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight              loaded from backbone.body.layer3.3.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight              loaded from backbone.body.layer3.3.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight              loaded from backbone.body.layer3.3.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                  loaded from backbone.body.layer3.4.bn1.bias                  of shape (1024,)
2020-12-13 10:23:34,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_mean          loaded from backbone.body.layer3.4.bn1.running_mean          of shape (1024,)
2020-12-13 10:23:34,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_var           loaded from backbone.body.layer3.4.bn1.running_var           of shape (1024,)
2020-12-13 10:23:34,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                loaded from backbone.body.layer3.4.bn1.weight                of shape (1024,)
2020-12-13 10:23:34,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                  loaded from backbone.body.layer3.4.bn2.bias                  of shape (1024,)
2020-12-13 10:23:34,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_mean          loaded from backbone.body.layer3.4.bn2.running_mean          of shape (1024,)
2020-12-13 10:23:34,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_var           loaded from backbone.body.layer3.4.bn2.running_var           of shape (1024,)
2020-12-13 10:23:34,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                loaded from backbone.body.layer3.4.bn2.weight                of shape (1024,)
2020-12-13 10:23:34,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                  loaded from backbone.body.layer3.4.bn3.bias                  of shape (1024,)
2020-12-13 10:23:34,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_mean          loaded from backbone.body.layer3.4.bn3.running_mean          of shape (1024,)
2020-12-13 10:23:34,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_var           loaded from backbone.body.layer3.4.bn3.running_var           of shape (1024,)
2020-12-13 10:23:34,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                loaded from backbone.body.layer3.4.bn3.weight                of shape (1024,)
2020-12-13 10:23:34,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight              loaded from backbone.body.layer3.4.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight              loaded from backbone.body.layer3.4.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight              loaded from backbone.body.layer3.4.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                  loaded from backbone.body.layer3.5.bn1.bias                  of shape (1024,)
2020-12-13 10:23:34,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_mean          loaded from backbone.body.layer3.5.bn1.running_mean          of shape (1024,)
2020-12-13 10:23:34,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_var           loaded from backbone.body.layer3.5.bn1.running_var           of shape (1024,)
2020-12-13 10:23:34,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                loaded from backbone.body.layer3.5.bn1.weight                of shape (1024,)
2020-12-13 10:23:34,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                  loaded from backbone.body.layer3.5.bn2.bias                  of shape (1024,)
2020-12-13 10:23:34,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_mean          loaded from backbone.body.layer3.5.bn2.running_mean          of shape (1024,)
2020-12-13 10:23:34,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_var           loaded from backbone.body.layer3.5.bn2.running_var           of shape (1024,)
2020-12-13 10:23:34,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                loaded from backbone.body.layer3.5.bn2.weight                of shape (1024,)
2020-12-13 10:23:34,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                  loaded from backbone.body.layer3.5.bn3.bias                  of shape (1024,)
2020-12-13 10:23:34,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_mean          loaded from backbone.body.layer3.5.bn3.running_mean          of shape (1024,)
2020-12-13 10:23:34,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_var           loaded from backbone.body.layer3.5.bn3.running_var           of shape (1024,)
2020-12-13 10:23:34,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                loaded from backbone.body.layer3.5.bn3.weight                of shape (1024,)
2020-12-13 10:23:34,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight              loaded from backbone.body.layer3.5.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight              loaded from backbone.body.layer3.5.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight              loaded from backbone.body.layer3.5.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.bias                  loaded from backbone.body.layer3.6.bn1.bias                  of shape (1024,)
2020-12-13 10:23:34,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.running_mean          loaded from backbone.body.layer3.6.bn1.running_mean          of shape (1024,)
2020-12-13 10:23:34,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.running_var           loaded from backbone.body.layer3.6.bn1.running_var           of shape (1024,)
2020-12-13 10:23:34,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.weight                loaded from backbone.body.layer3.6.bn1.weight                of shape (1024,)
2020-12-13 10:23:34,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.bias                  loaded from backbone.body.layer3.6.bn2.bias                  of shape (1024,)
2020-12-13 10:23:34,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.running_mean          loaded from backbone.body.layer3.6.bn2.running_mean          of shape (1024,)
2020-12-13 10:23:34,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.running_var           loaded from backbone.body.layer3.6.bn2.running_var           of shape (1024,)
2020-12-13 10:23:34,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.weight                loaded from backbone.body.layer3.6.bn2.weight                of shape (1024,)
2020-12-13 10:23:34,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.bias                  loaded from backbone.body.layer3.6.bn3.bias                  of shape (1024,)
2020-12-13 10:23:34,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.running_mean          loaded from backbone.body.layer3.6.bn3.running_mean          of shape (1024,)
2020-12-13 10:23:34,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.running_var           loaded from backbone.body.layer3.6.bn3.running_var           of shape (1024,)
2020-12-13 10:23:34,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.weight                loaded from backbone.body.layer3.6.bn3.weight                of shape (1024,)
2020-12-13 10:23:34,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv1.weight              loaded from backbone.body.layer3.6.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv2.weight              loaded from backbone.body.layer3.6.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv3.weight              loaded from backbone.body.layer3.6.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.bias                  loaded from backbone.body.layer3.7.bn1.bias                  of shape (1024,)
2020-12-13 10:23:34,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.running_mean          loaded from backbone.body.layer3.7.bn1.running_mean          of shape (1024,)
2020-12-13 10:23:34,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.running_var           loaded from backbone.body.layer3.7.bn1.running_var           of shape (1024,)
2020-12-13 10:23:34,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.weight                loaded from backbone.body.layer3.7.bn1.weight                of shape (1024,)
2020-12-13 10:23:34,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.bias                  loaded from backbone.body.layer3.7.bn2.bias                  of shape (1024,)
2020-12-13 10:23:34,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.running_mean          loaded from backbone.body.layer3.7.bn2.running_mean          of shape (1024,)
2020-12-13 10:23:34,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.running_var           loaded from backbone.body.layer3.7.bn2.running_var           of shape (1024,)
2020-12-13 10:23:34,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.weight                loaded from backbone.body.layer3.7.bn2.weight                of shape (1024,)
2020-12-13 10:23:34,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.bias                  loaded from backbone.body.layer3.7.bn3.bias                  of shape (1024,)
2020-12-13 10:23:34,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.running_mean          loaded from backbone.body.layer3.7.bn3.running_mean          of shape (1024,)
2020-12-13 10:23:34,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.running_var           loaded from backbone.body.layer3.7.bn3.running_var           of shape (1024,)
2020-12-13 10:23:34,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.weight                loaded from backbone.body.layer3.7.bn3.weight                of shape (1024,)
2020-12-13 10:23:34,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv1.weight              loaded from backbone.body.layer3.7.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv2.weight              loaded from backbone.body.layer3.7.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv3.weight              loaded from backbone.body.layer3.7.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.bias                  loaded from backbone.body.layer3.8.bn1.bias                  of shape (1024,)
2020-12-13 10:23:34,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.running_mean          loaded from backbone.body.layer3.8.bn1.running_mean          of shape (1024,)
2020-12-13 10:23:34,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.running_var           loaded from backbone.body.layer3.8.bn1.running_var           of shape (1024,)
2020-12-13 10:23:34,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.weight                loaded from backbone.body.layer3.8.bn1.weight                of shape (1024,)
2020-12-13 10:23:34,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.bias                  loaded from backbone.body.layer3.8.bn2.bias                  of shape (1024,)
2020-12-13 10:23:34,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.running_mean          loaded from backbone.body.layer3.8.bn2.running_mean          of shape (1024,)
2020-12-13 10:23:34,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.running_var           loaded from backbone.body.layer3.8.bn2.running_var           of shape (1024,)
2020-12-13 10:23:34,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.weight                loaded from backbone.body.layer3.8.bn2.weight                of shape (1024,)
2020-12-13 10:23:34,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.bias                  loaded from backbone.body.layer3.8.bn3.bias                  of shape (1024,)
2020-12-13 10:23:34,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.running_mean          loaded from backbone.body.layer3.8.bn3.running_mean          of shape (1024,)
2020-12-13 10:23:34,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.running_var           loaded from backbone.body.layer3.8.bn3.running_var           of shape (1024,)
2020-12-13 10:23:34,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.weight                loaded from backbone.body.layer3.8.bn3.weight                of shape (1024,)
2020-12-13 10:23:34,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv1.weight              loaded from backbone.body.layer3.8.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv2.weight              loaded from backbone.body.layer3.8.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv3.weight              loaded from backbone.body.layer3.8.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.bias                  loaded from backbone.body.layer3.9.bn1.bias                  of shape (1024,)
2020-12-13 10:23:34,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.running_mean          loaded from backbone.body.layer3.9.bn1.running_mean          of shape (1024,)
2020-12-13 10:23:34,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.running_var           loaded from backbone.body.layer3.9.bn1.running_var           of shape (1024,)
2020-12-13 10:23:34,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.weight                loaded from backbone.body.layer3.9.bn1.weight                of shape (1024,)
2020-12-13 10:23:34,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.bias                  loaded from backbone.body.layer3.9.bn2.bias                  of shape (1024,)
2020-12-13 10:23:34,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.running_mean          loaded from backbone.body.layer3.9.bn2.running_mean          of shape (1024,)
2020-12-13 10:23:34,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.running_var           loaded from backbone.body.layer3.9.bn2.running_var           of shape (1024,)
2020-12-13 10:23:34,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.weight                loaded from backbone.body.layer3.9.bn2.weight                of shape (1024,)
2020-12-13 10:23:34,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.bias                  loaded from backbone.body.layer3.9.bn3.bias                  of shape (1024,)
2020-12-13 10:23:34,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.running_mean          loaded from backbone.body.layer3.9.bn3.running_mean          of shape (1024,)
2020-12-13 10:23:34,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.running_var           loaded from backbone.body.layer3.9.bn3.running_var           of shape (1024,)
2020-12-13 10:23:34,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.weight                loaded from backbone.body.layer3.9.bn3.weight                of shape (1024,)
2020-12-13 10:23:34,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv1.weight              loaded from backbone.body.layer3.9.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv2.weight              loaded from backbone.body.layer3.9.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:23:34,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv3.weight              loaded from backbone.body.layer3.9.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:23:34,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                  loaded from backbone.body.layer4.0.bn1.bias                  of shape (2048,)
2020-12-13 10:23:34,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_mean          loaded from backbone.body.layer4.0.bn1.running_mean          of shape (2048,)
2020-12-13 10:23:34,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_var           loaded from backbone.body.layer4.0.bn1.running_var           of shape (2048,)
2020-12-13 10:23:34,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                loaded from backbone.body.layer4.0.bn1.weight                of shape (2048,)
2020-12-13 10:23:34,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                  loaded from backbone.body.layer4.0.bn2.bias                  of shape (2048,)
2020-12-13 10:23:34,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_mean          loaded from backbone.body.layer4.0.bn2.running_mean          of shape (2048,)
2020-12-13 10:23:34,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_var           loaded from backbone.body.layer4.0.bn2.running_var           of shape (2048,)
2020-12-13 10:23:34,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                loaded from backbone.body.layer4.0.bn2.weight                of shape (2048,)
2020-12-13 10:23:34,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                  loaded from backbone.body.layer4.0.bn3.bias                  of shape (2048,)
2020-12-13 10:23:34,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_mean          loaded from backbone.body.layer4.0.bn3.running_mean          of shape (2048,)
2020-12-13 10:23:34,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_var           loaded from backbone.body.layer4.0.bn3.running_var           of shape (2048,)
2020-12-13 10:23:34,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                loaded from backbone.body.layer4.0.bn3.weight                of shape (2048,)
2020-12-13 10:23:34,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight              loaded from backbone.body.layer4.0.conv1.weight              of shape (2048, 1024, 1, 1)
2020-12-13 10:23:34,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv2.weight              loaded from backbone.body.layer4.0.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 10:23:34,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight              loaded from backbone.body.layer4.0.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:23:34,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight       loaded from backbone.body.layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)
2020-12-13 10:23:34,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias         loaded from backbone.body.layer4.0.downsample.1.bias         of shape (2048,)
2020-12-13 10:23:34,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_mean loaded from backbone.body.layer4.0.downsample.1.running_mean of shape (2048,)
2020-12-13 10:23:34,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_var  loaded from backbone.body.layer4.0.downsample.1.running_var  of shape (2048,)
2020-12-13 10:23:34,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight       loaded from backbone.body.layer4.0.downsample.1.weight       of shape (2048,)
2020-12-13 10:23:34,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                  loaded from backbone.body.layer4.1.bn1.bias                  of shape (2048,)
2020-12-13 10:23:34,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_mean          loaded from backbone.body.layer4.1.bn1.running_mean          of shape (2048,)
2020-12-13 10:23:34,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_var           loaded from backbone.body.layer4.1.bn1.running_var           of shape (2048,)
2020-12-13 10:23:34,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                loaded from backbone.body.layer4.1.bn1.weight                of shape (2048,)
2020-12-13 10:23:34,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                  loaded from backbone.body.layer4.1.bn2.bias                  of shape (2048,)
2020-12-13 10:23:34,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_mean          loaded from backbone.body.layer4.1.bn2.running_mean          of shape (2048,)
2020-12-13 10:23:34,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_var           loaded from backbone.body.layer4.1.bn2.running_var           of shape (2048,)
2020-12-13 10:23:34,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                loaded from backbone.body.layer4.1.bn2.weight                of shape (2048,)
2020-12-13 10:23:34,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                  loaded from backbone.body.layer4.1.bn3.bias                  of shape (2048,)
2020-12-13 10:23:34,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_mean          loaded from backbone.body.layer4.1.bn3.running_mean          of shape (2048,)
2020-12-13 10:23:34,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_var           loaded from backbone.body.layer4.1.bn3.running_var           of shape (2048,)
2020-12-13 10:23:34,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                loaded from backbone.body.layer4.1.bn3.weight                of shape (2048,)
2020-12-13 10:23:34,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight              loaded from backbone.body.layer4.1.conv1.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:23:34,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv2.weight              loaded from backbone.body.layer4.1.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 10:23:34,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight              loaded from backbone.body.layer4.1.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:23:34,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                  loaded from backbone.body.layer4.2.bn1.bias                  of shape (2048,)
2020-12-13 10:23:34,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_mean          loaded from backbone.body.layer4.2.bn1.running_mean          of shape (2048,)
2020-12-13 10:23:34,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_var           loaded from backbone.body.layer4.2.bn1.running_var           of shape (2048,)
2020-12-13 10:23:34,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                loaded from backbone.body.layer4.2.bn1.weight                of shape (2048,)
2020-12-13 10:23:34,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                  loaded from backbone.body.layer4.2.bn2.bias                  of shape (2048,)
2020-12-13 10:23:34,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_mean          loaded from backbone.body.layer4.2.bn2.running_mean          of shape (2048,)
2020-12-13 10:23:34,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_var           loaded from backbone.body.layer4.2.bn2.running_var           of shape (2048,)
2020-12-13 10:23:34,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                loaded from backbone.body.layer4.2.bn2.weight                of shape (2048,)
2020-12-13 10:23:34,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                  loaded from backbone.body.layer4.2.bn3.bias                  of shape (2048,)
2020-12-13 10:23:34,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_mean          loaded from backbone.body.layer4.2.bn3.running_mean          of shape (2048,)
2020-12-13 10:23:34,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_var           loaded from backbone.body.layer4.2.bn3.running_var           of shape (2048,)
2020-12-13 10:23:34,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                loaded from backbone.body.layer4.2.bn3.weight                of shape (2048,)
2020-12-13 10:23:34,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight              loaded from backbone.body.layer4.2.conv1.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:23:34,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv2.weight              loaded from backbone.body.layer4.2.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 10:23:34,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight              loaded from backbone.body.layer4.2.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:23:34,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                      loaded from backbone.body.stem.bn1.bias                      of shape (64,)
2020-12-13 10:23:34,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_mean              loaded from backbone.body.stem.bn1.running_mean              of shape (64,)
2020-12-13 10:23:34,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_var               loaded from backbone.body.stem.bn1.running_var               of shape (64,)
2020-12-13 10:23:34,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                    loaded from backbone.body.stem.bn1.weight                    of shape (64,)
2020-12-13 10:23:34,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                  loaded from backbone.body.stem.conv1.weight                  of shape (64, 3, 7, 7)
2020-12-13 10:23:34,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.bias                     loaded from backbone.fpn.fpn_inner1.bias                     of shape (256,)
2020-12-13 10:23:34,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.weight                   loaded from backbone.fpn.fpn_inner1.weight                   of shape (256, 256, 1, 1)
2020-12-13 10:23:34,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                     loaded from backbone.fpn.fpn_inner2.bias                     of shape (256,)
2020-12-13 10:23:34,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                   loaded from backbone.fpn.fpn_inner2.weight                   of shape (256, 512, 1, 1)
2020-12-13 10:23:34,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                     loaded from backbone.fpn.fpn_inner3.bias                     of shape (256,)
2020-12-13 10:23:34,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                   loaded from backbone.fpn.fpn_inner3.weight                   of shape (256, 1024, 1, 1)
2020-12-13 10:23:34,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                     loaded from backbone.fpn.fpn_inner4.bias                     of shape (256,)
2020-12-13 10:23:34,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                   loaded from backbone.fpn.fpn_inner4.weight                   of shape (256, 2048, 1, 1)
2020-12-13 10:23:34,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.bias                     loaded from backbone.fpn.fpn_layer1.bias                     of shape (256,)
2020-12-13 10:23:34,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.weight                   loaded from backbone.fpn.fpn_layer1.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:23:34,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                     loaded from backbone.fpn.fpn_layer2.bias                     of shape (256,)
2020-12-13 10:23:34,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                   loaded from backbone.fpn.fpn_layer2.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:23:34,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                     loaded from backbone.fpn.fpn_layer3.bias                     of shape (256,)
2020-12-13 10:23:34,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                   loaded from backbone.fpn.fpn_layer3.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:23:34,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                     loaded from backbone.fpn.fpn_layer4.bias                     of shape (256,)
2020-12-13 10:23:34,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                   loaded from backbone.fpn.fpn_layer4.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:23:34,183 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.bias         loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (1024,)
2020-12-13 10:23:34,183 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.weight       loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (1024, 12544)
2020-12-13 10:23:34,183 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.bias         loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (1024,)
2020-12-13 10:23:34,183 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.weight       loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (1024, 1024)
2020-12-13 10:23:34,183 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.bias           loaded from roi_heads.box.predictor.bbox_pred.bias           of shape (324,)
2020-12-13 10:23:34,183 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.weight         loaded from roi_heads.box.predictor.bbox_pred.weight         of shape (324, 1024)
2020-12-13 10:23:34,183 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.bias           loaded from roi_heads.box.predictor.cls_score.bias           of shape (81,)
2020-12-13 10:23:34,184 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.weight         loaded from roi_heads.box.predictor.cls_score.weight         of shape (81, 1024)
2020-12-13 10:23:34,184 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.0              loaded from rpn.anchor_generator.cell_anchors.0              of shape (3, 4)
2020-12-13 10:23:34,184 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.1              loaded from rpn.anchor_generator.cell_anchors.1              of shape (3, 4)
2020-12-13 10:23:34,184 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.2              loaded from rpn.anchor_generator.cell_anchors.2              of shape (3, 4)
2020-12-13 10:23:34,184 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.3              loaded from rpn.anchor_generator.cell_anchors.3              of shape (3, 4)
2020-12-13 10:23:34,184 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.4              loaded from rpn.anchor_generator.cell_anchors.4              of shape (3, 4)
2020-12-13 10:23:34,184 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                          loaded from rpn.head.bbox_pred.bias                          of shape (12,)
2020-12-13 10:23:34,184 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                        loaded from rpn.head.bbox_pred.weight                        of shape (12, 256, 1, 1)
2020-12-13 10:23:34,184 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                         loaded from rpn.head.cls_logits.bias                         of shape (3,)
2020-12-13 10:23:34,184 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                       loaded from rpn.head.cls_logits.weight                       of shape (3, 256, 1, 1)
2020-12-13 10:23:34,184 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.bias                               loaded from rpn.head.conv.bias                               of shape (256,)
2020-12-13 10:23:34,184 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.weight                             loaded from rpn.head.conv.weight                             of shape (256, 256, 3, 3)
2020-12-13 10:23:34,363 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-13 10:23:34,363 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-13 10:23:34,363 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-13 10:23:34,364 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-13 10:23:36,380 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-13 10:24:38,191 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 10:24:38,191 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 10:24:38,191 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 10:24:40,479 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 10:24:40,480 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 10:24:40,480 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train", "giro4_train", "giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 2

2020-12-13 10:24:40,481 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 1e-06
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 2
2020-12-13 10:24:42,206 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from visdrone_model_0360000.pth
2020-12-13 10:24:42,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                  loaded from backbone.body.layer1.0.bn1.bias                  of shape (256,)
2020-12-13 10:24:42,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_mean          loaded from backbone.body.layer1.0.bn1.running_mean          of shape (256,)
2020-12-13 10:24:42,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_var           loaded from backbone.body.layer1.0.bn1.running_var           of shape (256,)
2020-12-13 10:24:42,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                loaded from backbone.body.layer1.0.bn1.weight                of shape (256,)
2020-12-13 10:24:42,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                  loaded from backbone.body.layer1.0.bn2.bias                  of shape (256,)
2020-12-13 10:24:42,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_mean          loaded from backbone.body.layer1.0.bn2.running_mean          of shape (256,)
2020-12-13 10:24:42,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_var           loaded from backbone.body.layer1.0.bn2.running_var           of shape (256,)
2020-12-13 10:24:42,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                loaded from backbone.body.layer1.0.bn2.weight                of shape (256,)
2020-12-13 10:24:42,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                  loaded from backbone.body.layer1.0.bn3.bias                  of shape (256,)
2020-12-13 10:24:42,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_mean          loaded from backbone.body.layer1.0.bn3.running_mean          of shape (256,)
2020-12-13 10:24:42,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_var           loaded from backbone.body.layer1.0.bn3.running_var           of shape (256,)
2020-12-13 10:24:42,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                loaded from backbone.body.layer1.0.bn3.weight                of shape (256,)
2020-12-13 10:24:42,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight              loaded from backbone.body.layer1.0.conv1.weight              of shape (256, 64, 1, 1)
2020-12-13 10:24:42,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight              loaded from backbone.body.layer1.0.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 10:24:42,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight              loaded from backbone.body.layer1.0.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 10:24:42,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight       loaded from backbone.body.layer1.0.downsample.0.weight       of shape (256, 64, 1, 1)
2020-12-13 10:24:42,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias         loaded from backbone.body.layer1.0.downsample.1.bias         of shape (256,)
2020-12-13 10:24:42,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_mean loaded from backbone.body.layer1.0.downsample.1.running_mean of shape (256,)
2020-12-13 10:24:42,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_var  loaded from backbone.body.layer1.0.downsample.1.running_var  of shape (256,)
2020-12-13 10:24:42,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight       loaded from backbone.body.layer1.0.downsample.1.weight       of shape (256,)
2020-12-13 10:24:42,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                  loaded from backbone.body.layer1.1.bn1.bias                  of shape (256,)
2020-12-13 10:24:42,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_mean          loaded from backbone.body.layer1.1.bn1.running_mean          of shape (256,)
2020-12-13 10:24:42,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_var           loaded from backbone.body.layer1.1.bn1.running_var           of shape (256,)
2020-12-13 10:24:42,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                loaded from backbone.body.layer1.1.bn1.weight                of shape (256,)
2020-12-13 10:24:42,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                  loaded from backbone.body.layer1.1.bn2.bias                  of shape (256,)
2020-12-13 10:24:42,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_mean          loaded from backbone.body.layer1.1.bn2.running_mean          of shape (256,)
2020-12-13 10:24:42,855 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_var           loaded from backbone.body.layer1.1.bn2.running_var           of shape (256,)
2020-12-13 10:24:42,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                loaded from backbone.body.layer1.1.bn2.weight                of shape (256,)
2020-12-13 10:24:42,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                  loaded from backbone.body.layer1.1.bn3.bias                  of shape (256,)
2020-12-13 10:24:42,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_mean          loaded from backbone.body.layer1.1.bn3.running_mean          of shape (256,)
2020-12-13 10:24:42,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_var           loaded from backbone.body.layer1.1.bn3.running_var           of shape (256,)
2020-12-13 10:24:42,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                loaded from backbone.body.layer1.1.bn3.weight                of shape (256,)
2020-12-13 10:24:42,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight              loaded from backbone.body.layer1.1.conv1.weight              of shape (256, 256, 1, 1)
2020-12-13 10:24:42,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight              loaded from backbone.body.layer1.1.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 10:24:42,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight              loaded from backbone.body.layer1.1.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 10:24:42,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                  loaded from backbone.body.layer1.2.bn1.bias                  of shape (256,)
2020-12-13 10:24:42,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_mean          loaded from backbone.body.layer1.2.bn1.running_mean          of shape (256,)
2020-12-13 10:24:42,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_var           loaded from backbone.body.layer1.2.bn1.running_var           of shape (256,)
2020-12-13 10:24:42,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                loaded from backbone.body.layer1.2.bn1.weight                of shape (256,)
2020-12-13 10:24:42,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                  loaded from backbone.body.layer1.2.bn2.bias                  of shape (256,)
2020-12-13 10:24:42,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_mean          loaded from backbone.body.layer1.2.bn2.running_mean          of shape (256,)
2020-12-13 10:24:42,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_var           loaded from backbone.body.layer1.2.bn2.running_var           of shape (256,)
2020-12-13 10:24:42,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                loaded from backbone.body.layer1.2.bn2.weight                of shape (256,)
2020-12-13 10:24:42,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                  loaded from backbone.body.layer1.2.bn3.bias                  of shape (256,)
2020-12-13 10:24:42,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_mean          loaded from backbone.body.layer1.2.bn3.running_mean          of shape (256,)
2020-12-13 10:24:42,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_var           loaded from backbone.body.layer1.2.bn3.running_var           of shape (256,)
2020-12-13 10:24:42,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                loaded from backbone.body.layer1.2.bn3.weight                of shape (256,)
2020-12-13 10:24:42,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight              loaded from backbone.body.layer1.2.conv1.weight              of shape (256, 256, 1, 1)
2020-12-13 10:24:42,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight              loaded from backbone.body.layer1.2.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 10:24:42,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight              loaded from backbone.body.layer1.2.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 10:24:42,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                  loaded from backbone.body.layer2.0.bn1.bias                  of shape (512,)
2020-12-13 10:24:42,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_mean          loaded from backbone.body.layer2.0.bn1.running_mean          of shape (512,)
2020-12-13 10:24:42,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_var           loaded from backbone.body.layer2.0.bn1.running_var           of shape (512,)
2020-12-13 10:24:42,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                loaded from backbone.body.layer2.0.bn1.weight                of shape (512,)
2020-12-13 10:24:42,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                  loaded from backbone.body.layer2.0.bn2.bias                  of shape (512,)
2020-12-13 10:24:42,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_mean          loaded from backbone.body.layer2.0.bn2.running_mean          of shape (512,)
2020-12-13 10:24:42,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_var           loaded from backbone.body.layer2.0.bn2.running_var           of shape (512,)
2020-12-13 10:24:42,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                loaded from backbone.body.layer2.0.bn2.weight                of shape (512,)
2020-12-13 10:24:42,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                  loaded from backbone.body.layer2.0.bn3.bias                  of shape (512,)
2020-12-13 10:24:42,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_mean          loaded from backbone.body.layer2.0.bn3.running_mean          of shape (512,)
2020-12-13 10:24:42,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_var           loaded from backbone.body.layer2.0.bn3.running_var           of shape (512,)
2020-12-13 10:24:42,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                loaded from backbone.body.layer2.0.bn3.weight                of shape (512,)
2020-12-13 10:24:42,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight              loaded from backbone.body.layer2.0.conv1.weight              of shape (512, 256, 1, 1)
2020-12-13 10:24:42,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight              loaded from backbone.body.layer2.0.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:24:42,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight              loaded from backbone.body.layer2.0.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:24:42,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight       loaded from backbone.body.layer2.0.downsample.0.weight       of shape (512, 256, 1, 1)
2020-12-13 10:24:42,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias         loaded from backbone.body.layer2.0.downsample.1.bias         of shape (512,)
2020-12-13 10:24:42,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_mean loaded from backbone.body.layer2.0.downsample.1.running_mean of shape (512,)
2020-12-13 10:24:42,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_var  loaded from backbone.body.layer2.0.downsample.1.running_var  of shape (512,)
2020-12-13 10:24:42,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight       loaded from backbone.body.layer2.0.downsample.1.weight       of shape (512,)
2020-12-13 10:24:42,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                  loaded from backbone.body.layer2.1.bn1.bias                  of shape (512,)
2020-12-13 10:24:42,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_mean          loaded from backbone.body.layer2.1.bn1.running_mean          of shape (512,)
2020-12-13 10:24:42,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_var           loaded from backbone.body.layer2.1.bn1.running_var           of shape (512,)
2020-12-13 10:24:42,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                loaded from backbone.body.layer2.1.bn1.weight                of shape (512,)
2020-12-13 10:24:42,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                  loaded from backbone.body.layer2.1.bn2.bias                  of shape (512,)
2020-12-13 10:24:42,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_mean          loaded from backbone.body.layer2.1.bn2.running_mean          of shape (512,)
2020-12-13 10:24:42,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_var           loaded from backbone.body.layer2.1.bn2.running_var           of shape (512,)
2020-12-13 10:24:42,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                loaded from backbone.body.layer2.1.bn2.weight                of shape (512,)
2020-12-13 10:24:42,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                  loaded from backbone.body.layer2.1.bn3.bias                  of shape (512,)
2020-12-13 10:24:42,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_mean          loaded from backbone.body.layer2.1.bn3.running_mean          of shape (512,)
2020-12-13 10:24:42,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_var           loaded from backbone.body.layer2.1.bn3.running_var           of shape (512,)
2020-12-13 10:24:42,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                loaded from backbone.body.layer2.1.bn3.weight                of shape (512,)
2020-12-13 10:24:42,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight              loaded from backbone.body.layer2.1.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 10:24:42,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight              loaded from backbone.body.layer2.1.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:24:42,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight              loaded from backbone.body.layer2.1.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:24:42,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                  loaded from backbone.body.layer2.2.bn1.bias                  of shape (512,)
2020-12-13 10:24:42,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_mean          loaded from backbone.body.layer2.2.bn1.running_mean          of shape (512,)
2020-12-13 10:24:42,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_var           loaded from backbone.body.layer2.2.bn1.running_var           of shape (512,)
2020-12-13 10:24:42,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                loaded from backbone.body.layer2.2.bn1.weight                of shape (512,)
2020-12-13 10:24:42,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                  loaded from backbone.body.layer2.2.bn2.bias                  of shape (512,)
2020-12-13 10:24:42,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_mean          loaded from backbone.body.layer2.2.bn2.running_mean          of shape (512,)
2020-12-13 10:24:42,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_var           loaded from backbone.body.layer2.2.bn2.running_var           of shape (512,)
2020-12-13 10:24:42,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                loaded from backbone.body.layer2.2.bn2.weight                of shape (512,)
2020-12-13 10:24:42,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                  loaded from backbone.body.layer2.2.bn3.bias                  of shape (512,)
2020-12-13 10:24:42,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_mean          loaded from backbone.body.layer2.2.bn3.running_mean          of shape (512,)
2020-12-13 10:24:42,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_var           loaded from backbone.body.layer2.2.bn3.running_var           of shape (512,)
2020-12-13 10:24:42,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                loaded from backbone.body.layer2.2.bn3.weight                of shape (512,)
2020-12-13 10:24:42,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight              loaded from backbone.body.layer2.2.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 10:24:42,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight              loaded from backbone.body.layer2.2.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:24:42,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight              loaded from backbone.body.layer2.2.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:24:42,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                  loaded from backbone.body.layer2.3.bn1.bias                  of shape (512,)
2020-12-13 10:24:42,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_mean          loaded from backbone.body.layer2.3.bn1.running_mean          of shape (512,)
2020-12-13 10:24:42,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_var           loaded from backbone.body.layer2.3.bn1.running_var           of shape (512,)
2020-12-13 10:24:42,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                loaded from backbone.body.layer2.3.bn1.weight                of shape (512,)
2020-12-13 10:24:42,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                  loaded from backbone.body.layer2.3.bn2.bias                  of shape (512,)
2020-12-13 10:24:42,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_mean          loaded from backbone.body.layer2.3.bn2.running_mean          of shape (512,)
2020-12-13 10:24:42,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_var           loaded from backbone.body.layer2.3.bn2.running_var           of shape (512,)
2020-12-13 10:24:42,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                loaded from backbone.body.layer2.3.bn2.weight                of shape (512,)
2020-12-13 10:24:42,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                  loaded from backbone.body.layer2.3.bn3.bias                  of shape (512,)
2020-12-13 10:24:42,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_mean          loaded from backbone.body.layer2.3.bn3.running_mean          of shape (512,)
2020-12-13 10:24:42,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_var           loaded from backbone.body.layer2.3.bn3.running_var           of shape (512,)
2020-12-13 10:24:42,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                loaded from backbone.body.layer2.3.bn3.weight                of shape (512,)
2020-12-13 10:24:42,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight              loaded from backbone.body.layer2.3.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 10:24:42,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight              loaded from backbone.body.layer2.3.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:24:42,863 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight              loaded from backbone.body.layer2.3.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:24:42,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                  loaded from backbone.body.layer3.0.bn1.bias                  of shape (1024,)
2020-12-13 10:24:42,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_mean          loaded from backbone.body.layer3.0.bn1.running_mean          of shape (1024,)
2020-12-13 10:24:42,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_var           loaded from backbone.body.layer3.0.bn1.running_var           of shape (1024,)
2020-12-13 10:24:42,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                loaded from backbone.body.layer3.0.bn1.weight                of shape (1024,)
2020-12-13 10:24:42,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                  loaded from backbone.body.layer3.0.bn2.bias                  of shape (1024,)
2020-12-13 10:24:42,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_mean          loaded from backbone.body.layer3.0.bn2.running_mean          of shape (1024,)
2020-12-13 10:24:42,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_var           loaded from backbone.body.layer3.0.bn2.running_var           of shape (1024,)
2020-12-13 10:24:42,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                loaded from backbone.body.layer3.0.bn2.weight                of shape (1024,)
2020-12-13 10:24:42,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                  loaded from backbone.body.layer3.0.bn3.bias                  of shape (1024,)
2020-12-13 10:24:42,864 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_mean          loaded from backbone.body.layer3.0.bn3.running_mean          of shape (1024,)
2020-12-13 10:24:42,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_var           loaded from backbone.body.layer3.0.bn3.running_var           of shape (1024,)
2020-12-13 10:24:42,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                loaded from backbone.body.layer3.0.bn3.weight                of shape (1024,)
2020-12-13 10:24:42,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight              loaded from backbone.body.layer3.0.conv1.weight              of shape (1024, 512, 1, 1)
2020-12-13 10:24:42,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight              loaded from backbone.body.layer3.0.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight              loaded from backbone.body.layer3.0.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight       loaded from backbone.body.layer3.0.downsample.0.weight       of shape (1024, 512, 1, 1)
2020-12-13 10:24:42,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias         loaded from backbone.body.layer3.0.downsample.1.bias         of shape (1024,)
2020-12-13 10:24:42,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_mean loaded from backbone.body.layer3.0.downsample.1.running_mean of shape (1024,)
2020-12-13 10:24:42,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_var  loaded from backbone.body.layer3.0.downsample.1.running_var  of shape (1024,)
2020-12-13 10:24:42,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight       loaded from backbone.body.layer3.0.downsample.1.weight       of shape (1024,)
2020-12-13 10:24:42,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                  loaded from backbone.body.layer3.1.bn1.bias                  of shape (1024,)
2020-12-13 10:24:42,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_mean          loaded from backbone.body.layer3.1.bn1.running_mean          of shape (1024,)
2020-12-13 10:24:42,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_var           loaded from backbone.body.layer3.1.bn1.running_var           of shape (1024,)
2020-12-13 10:24:42,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                loaded from backbone.body.layer3.1.bn1.weight                of shape (1024,)
2020-12-13 10:24:42,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                  loaded from backbone.body.layer3.1.bn2.bias                  of shape (1024,)
2020-12-13 10:24:42,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_mean          loaded from backbone.body.layer3.1.bn2.running_mean          of shape (1024,)
2020-12-13 10:24:42,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_var           loaded from backbone.body.layer3.1.bn2.running_var           of shape (1024,)
2020-12-13 10:24:42,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                loaded from backbone.body.layer3.1.bn2.weight                of shape (1024,)
2020-12-13 10:24:42,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                  loaded from backbone.body.layer3.1.bn3.bias                  of shape (1024,)
2020-12-13 10:24:42,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_mean          loaded from backbone.body.layer3.1.bn3.running_mean          of shape (1024,)
2020-12-13 10:24:42,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_var           loaded from backbone.body.layer3.1.bn3.running_var           of shape (1024,)
2020-12-13 10:24:42,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                loaded from backbone.body.layer3.1.bn3.weight                of shape (1024,)
2020-12-13 10:24:42,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight              loaded from backbone.body.layer3.1.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight              loaded from backbone.body.layer3.1.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight              loaded from backbone.body.layer3.1.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.bias                 loaded from backbone.body.layer3.10.bn1.bias                 of shape (1024,)
2020-12-13 10:24:42,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.running_mean         loaded from backbone.body.layer3.10.bn1.running_mean         of shape (1024,)
2020-12-13 10:24:42,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.running_var          loaded from backbone.body.layer3.10.bn1.running_var          of shape (1024,)
2020-12-13 10:24:42,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.weight               loaded from backbone.body.layer3.10.bn1.weight               of shape (1024,)
2020-12-13 10:24:42,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.bias                 loaded from backbone.body.layer3.10.bn2.bias                 of shape (1024,)
2020-12-13 10:24:42,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.running_mean         loaded from backbone.body.layer3.10.bn2.running_mean         of shape (1024,)
2020-12-13 10:24:42,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.running_var          loaded from backbone.body.layer3.10.bn2.running_var          of shape (1024,)
2020-12-13 10:24:42,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.weight               loaded from backbone.body.layer3.10.bn2.weight               of shape (1024,)
2020-12-13 10:24:42,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.bias                 loaded from backbone.body.layer3.10.bn3.bias                 of shape (1024,)
2020-12-13 10:24:42,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.running_mean         loaded from backbone.body.layer3.10.bn3.running_mean         of shape (1024,)
2020-12-13 10:24:42,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.running_var          loaded from backbone.body.layer3.10.bn3.running_var          of shape (1024,)
2020-12-13 10:24:42,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.weight               loaded from backbone.body.layer3.10.bn3.weight               of shape (1024,)
2020-12-13 10:24:42,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv1.weight             loaded from backbone.body.layer3.10.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv2.weight             loaded from backbone.body.layer3.10.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,868 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv3.weight             loaded from backbone.body.layer3.10.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.bias                 loaded from backbone.body.layer3.11.bn1.bias                 of shape (1024,)
2020-12-13 10:24:42,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.running_mean         loaded from backbone.body.layer3.11.bn1.running_mean         of shape (1024,)
2020-12-13 10:24:42,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.running_var          loaded from backbone.body.layer3.11.bn1.running_var          of shape (1024,)
2020-12-13 10:24:42,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.weight               loaded from backbone.body.layer3.11.bn1.weight               of shape (1024,)
2020-12-13 10:24:42,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.bias                 loaded from backbone.body.layer3.11.bn2.bias                 of shape (1024,)
2020-12-13 10:24:42,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.running_mean         loaded from backbone.body.layer3.11.bn2.running_mean         of shape (1024,)
2020-12-13 10:24:42,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.running_var          loaded from backbone.body.layer3.11.bn2.running_var          of shape (1024,)
2020-12-13 10:24:42,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.weight               loaded from backbone.body.layer3.11.bn2.weight               of shape (1024,)
2020-12-13 10:24:42,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.bias                 loaded from backbone.body.layer3.11.bn3.bias                 of shape (1024,)
2020-12-13 10:24:42,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.running_mean         loaded from backbone.body.layer3.11.bn3.running_mean         of shape (1024,)
2020-12-13 10:24:42,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.running_var          loaded from backbone.body.layer3.11.bn3.running_var          of shape (1024,)
2020-12-13 10:24:42,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.weight               loaded from backbone.body.layer3.11.bn3.weight               of shape (1024,)
2020-12-13 10:24:42,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv1.weight             loaded from backbone.body.layer3.11.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv2.weight             loaded from backbone.body.layer3.11.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv3.weight             loaded from backbone.body.layer3.11.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.bias                 loaded from backbone.body.layer3.12.bn1.bias                 of shape (1024,)
2020-12-13 10:24:42,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.running_mean         loaded from backbone.body.layer3.12.bn1.running_mean         of shape (1024,)
2020-12-13 10:24:42,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.running_var          loaded from backbone.body.layer3.12.bn1.running_var          of shape (1024,)
2020-12-13 10:24:42,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.weight               loaded from backbone.body.layer3.12.bn1.weight               of shape (1024,)
2020-12-13 10:24:42,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.bias                 loaded from backbone.body.layer3.12.bn2.bias                 of shape (1024,)
2020-12-13 10:24:42,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.running_mean         loaded from backbone.body.layer3.12.bn2.running_mean         of shape (1024,)
2020-12-13 10:24:42,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.running_var          loaded from backbone.body.layer3.12.bn2.running_var          of shape (1024,)
2020-12-13 10:24:42,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.weight               loaded from backbone.body.layer3.12.bn2.weight               of shape (1024,)
2020-12-13 10:24:42,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.bias                 loaded from backbone.body.layer3.12.bn3.bias                 of shape (1024,)
2020-12-13 10:24:42,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.running_mean         loaded from backbone.body.layer3.12.bn3.running_mean         of shape (1024,)
2020-12-13 10:24:42,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.running_var          loaded from backbone.body.layer3.12.bn3.running_var          of shape (1024,)
2020-12-13 10:24:42,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.weight               loaded from backbone.body.layer3.12.bn3.weight               of shape (1024,)
2020-12-13 10:24:42,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv1.weight             loaded from backbone.body.layer3.12.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv2.weight             loaded from backbone.body.layer3.12.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv3.weight             loaded from backbone.body.layer3.12.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.bias                 loaded from backbone.body.layer3.13.bn1.bias                 of shape (1024,)
2020-12-13 10:24:42,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.running_mean         loaded from backbone.body.layer3.13.bn1.running_mean         of shape (1024,)
2020-12-13 10:24:42,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.running_var          loaded from backbone.body.layer3.13.bn1.running_var          of shape (1024,)
2020-12-13 10:24:42,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.weight               loaded from backbone.body.layer3.13.bn1.weight               of shape (1024,)
2020-12-13 10:24:42,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.bias                 loaded from backbone.body.layer3.13.bn2.bias                 of shape (1024,)
2020-12-13 10:24:42,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.running_mean         loaded from backbone.body.layer3.13.bn2.running_mean         of shape (1024,)
2020-12-13 10:24:42,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.running_var          loaded from backbone.body.layer3.13.bn2.running_var          of shape (1024,)
2020-12-13 10:24:42,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.weight               loaded from backbone.body.layer3.13.bn2.weight               of shape (1024,)
2020-12-13 10:24:42,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.bias                 loaded from backbone.body.layer3.13.bn3.bias                 of shape (1024,)
2020-12-13 10:24:42,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.running_mean         loaded from backbone.body.layer3.13.bn3.running_mean         of shape (1024,)
2020-12-13 10:24:42,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.running_var          loaded from backbone.body.layer3.13.bn3.running_var          of shape (1024,)
2020-12-13 10:24:42,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.weight               loaded from backbone.body.layer3.13.bn3.weight               of shape (1024,)
2020-12-13 10:24:42,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv1.weight             loaded from backbone.body.layer3.13.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv2.weight             loaded from backbone.body.layer3.13.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv3.weight             loaded from backbone.body.layer3.13.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.bias                 loaded from backbone.body.layer3.14.bn1.bias                 of shape (1024,)
2020-12-13 10:24:42,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.running_mean         loaded from backbone.body.layer3.14.bn1.running_mean         of shape (1024,)
2020-12-13 10:24:42,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.running_var          loaded from backbone.body.layer3.14.bn1.running_var          of shape (1024,)
2020-12-13 10:24:42,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.weight               loaded from backbone.body.layer3.14.bn1.weight               of shape (1024,)
2020-12-13 10:24:42,872 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.bias                 loaded from backbone.body.layer3.14.bn2.bias                 of shape (1024,)
2020-12-13 10:24:42,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.running_mean         loaded from backbone.body.layer3.14.bn2.running_mean         of shape (1024,)
2020-12-13 10:24:42,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.running_var          loaded from backbone.body.layer3.14.bn2.running_var          of shape (1024,)
2020-12-13 10:24:42,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.weight               loaded from backbone.body.layer3.14.bn2.weight               of shape (1024,)
2020-12-13 10:24:42,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.bias                 loaded from backbone.body.layer3.14.bn3.bias                 of shape (1024,)
2020-12-13 10:24:42,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.running_mean         loaded from backbone.body.layer3.14.bn3.running_mean         of shape (1024,)
2020-12-13 10:24:42,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.running_var          loaded from backbone.body.layer3.14.bn3.running_var          of shape (1024,)
2020-12-13 10:24:42,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.weight               loaded from backbone.body.layer3.14.bn3.weight               of shape (1024,)
2020-12-13 10:24:42,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv1.weight             loaded from backbone.body.layer3.14.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv2.weight             loaded from backbone.body.layer3.14.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv3.weight             loaded from backbone.body.layer3.14.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.bias                 loaded from backbone.body.layer3.15.bn1.bias                 of shape (1024,)
2020-12-13 10:24:42,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.running_mean         loaded from backbone.body.layer3.15.bn1.running_mean         of shape (1024,)
2020-12-13 10:24:42,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.running_var          loaded from backbone.body.layer3.15.bn1.running_var          of shape (1024,)
2020-12-13 10:24:42,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.weight               loaded from backbone.body.layer3.15.bn1.weight               of shape (1024,)
2020-12-13 10:24:42,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.bias                 loaded from backbone.body.layer3.15.bn2.bias                 of shape (1024,)
2020-12-13 10:24:42,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.running_mean         loaded from backbone.body.layer3.15.bn2.running_mean         of shape (1024,)
2020-12-13 10:24:42,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.running_var          loaded from backbone.body.layer3.15.bn2.running_var          of shape (1024,)
2020-12-13 10:24:42,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.weight               loaded from backbone.body.layer3.15.bn2.weight               of shape (1024,)
2020-12-13 10:24:42,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.bias                 loaded from backbone.body.layer3.15.bn3.bias                 of shape (1024,)
2020-12-13 10:24:42,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.running_mean         loaded from backbone.body.layer3.15.bn3.running_mean         of shape (1024,)
2020-12-13 10:24:42,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.running_var          loaded from backbone.body.layer3.15.bn3.running_var          of shape (1024,)
2020-12-13 10:24:42,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.weight               loaded from backbone.body.layer3.15.bn3.weight               of shape (1024,)
2020-12-13 10:24:42,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv1.weight             loaded from backbone.body.layer3.15.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv2.weight             loaded from backbone.body.layer3.15.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv3.weight             loaded from backbone.body.layer3.15.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.bias                 loaded from backbone.body.layer3.16.bn1.bias                 of shape (1024,)
2020-12-13 10:24:42,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.running_mean         loaded from backbone.body.layer3.16.bn1.running_mean         of shape (1024,)
2020-12-13 10:24:42,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.running_var          loaded from backbone.body.layer3.16.bn1.running_var          of shape (1024,)
2020-12-13 10:24:42,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.weight               loaded from backbone.body.layer3.16.bn1.weight               of shape (1024,)
2020-12-13 10:24:42,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.bias                 loaded from backbone.body.layer3.16.bn2.bias                 of shape (1024,)
2020-12-13 10:24:42,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.running_mean         loaded from backbone.body.layer3.16.bn2.running_mean         of shape (1024,)
2020-12-13 10:24:42,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.running_var          loaded from backbone.body.layer3.16.bn2.running_var          of shape (1024,)
2020-12-13 10:24:42,875 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.weight               loaded from backbone.body.layer3.16.bn2.weight               of shape (1024,)
2020-12-13 10:24:42,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.bias                 loaded from backbone.body.layer3.16.bn3.bias                 of shape (1024,)
2020-12-13 10:24:42,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.running_mean         loaded from backbone.body.layer3.16.bn3.running_mean         of shape (1024,)
2020-12-13 10:24:42,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.running_var          loaded from backbone.body.layer3.16.bn3.running_var          of shape (1024,)
2020-12-13 10:24:42,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.weight               loaded from backbone.body.layer3.16.bn3.weight               of shape (1024,)
2020-12-13 10:24:42,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv1.weight             loaded from backbone.body.layer3.16.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv2.weight             loaded from backbone.body.layer3.16.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv3.weight             loaded from backbone.body.layer3.16.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.bias                 loaded from backbone.body.layer3.17.bn1.bias                 of shape (1024,)
2020-12-13 10:24:42,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.running_mean         loaded from backbone.body.layer3.17.bn1.running_mean         of shape (1024,)
2020-12-13 10:24:42,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.running_var          loaded from backbone.body.layer3.17.bn1.running_var          of shape (1024,)
2020-12-13 10:24:42,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.weight               loaded from backbone.body.layer3.17.bn1.weight               of shape (1024,)
2020-12-13 10:24:42,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.bias                 loaded from backbone.body.layer3.17.bn2.bias                 of shape (1024,)
2020-12-13 10:24:42,906 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.running_mean         loaded from backbone.body.layer3.17.bn2.running_mean         of shape (1024,)
2020-12-13 10:24:42,906 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.running_var          loaded from backbone.body.layer3.17.bn2.running_var          of shape (1024,)
2020-12-13 10:24:42,906 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.weight               loaded from backbone.body.layer3.17.bn2.weight               of shape (1024,)
2020-12-13 10:24:42,906 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.bias                 loaded from backbone.body.layer3.17.bn3.bias                 of shape (1024,)
2020-12-13 10:24:42,906 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.running_mean         loaded from backbone.body.layer3.17.bn3.running_mean         of shape (1024,)
2020-12-13 10:24:42,906 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.running_var          loaded from backbone.body.layer3.17.bn3.running_var          of shape (1024,)
2020-12-13 10:24:42,906 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.weight               loaded from backbone.body.layer3.17.bn3.weight               of shape (1024,)
2020-12-13 10:24:42,906 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv1.weight             loaded from backbone.body.layer3.17.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,906 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv2.weight             loaded from backbone.body.layer3.17.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,906 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv3.weight             loaded from backbone.body.layer3.17.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,907 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.bias                 loaded from backbone.body.layer3.18.bn1.bias                 of shape (1024,)
2020-12-13 10:24:42,907 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.running_mean         loaded from backbone.body.layer3.18.bn1.running_mean         of shape (1024,)
2020-12-13 10:24:42,907 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.running_var          loaded from backbone.body.layer3.18.bn1.running_var          of shape (1024,)
2020-12-13 10:24:42,907 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.weight               loaded from backbone.body.layer3.18.bn1.weight               of shape (1024,)
2020-12-13 10:24:42,907 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.bias                 loaded from backbone.body.layer3.18.bn2.bias                 of shape (1024,)
2020-12-13 10:24:42,907 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.running_mean         loaded from backbone.body.layer3.18.bn2.running_mean         of shape (1024,)
2020-12-13 10:24:42,907 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.running_var          loaded from backbone.body.layer3.18.bn2.running_var          of shape (1024,)
2020-12-13 10:24:42,907 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.weight               loaded from backbone.body.layer3.18.bn2.weight               of shape (1024,)
2020-12-13 10:24:42,907 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.bias                 loaded from backbone.body.layer3.18.bn3.bias                 of shape (1024,)
2020-12-13 10:24:42,907 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.running_mean         loaded from backbone.body.layer3.18.bn3.running_mean         of shape (1024,)
2020-12-13 10:24:42,907 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.running_var          loaded from backbone.body.layer3.18.bn3.running_var          of shape (1024,)
2020-12-13 10:24:42,907 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.weight               loaded from backbone.body.layer3.18.bn3.weight               of shape (1024,)
2020-12-13 10:24:42,908 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv1.weight             loaded from backbone.body.layer3.18.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,908 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv2.weight             loaded from backbone.body.layer3.18.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,908 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv3.weight             loaded from backbone.body.layer3.18.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,908 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.bias                 loaded from backbone.body.layer3.19.bn1.bias                 of shape (1024,)
2020-12-13 10:24:42,908 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.running_mean         loaded from backbone.body.layer3.19.bn1.running_mean         of shape (1024,)
2020-12-13 10:24:42,908 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.running_var          loaded from backbone.body.layer3.19.bn1.running_var          of shape (1024,)
2020-12-13 10:24:42,908 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.weight               loaded from backbone.body.layer3.19.bn1.weight               of shape (1024,)
2020-12-13 10:24:42,908 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.bias                 loaded from backbone.body.layer3.19.bn2.bias                 of shape (1024,)
2020-12-13 10:24:42,908 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.running_mean         loaded from backbone.body.layer3.19.bn2.running_mean         of shape (1024,)
2020-12-13 10:24:42,908 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.running_var          loaded from backbone.body.layer3.19.bn2.running_var          of shape (1024,)
2020-12-13 10:24:42,908 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.weight               loaded from backbone.body.layer3.19.bn2.weight               of shape (1024,)
2020-12-13 10:24:42,909 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.bias                 loaded from backbone.body.layer3.19.bn3.bias                 of shape (1024,)
2020-12-13 10:24:42,909 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.running_mean         loaded from backbone.body.layer3.19.bn3.running_mean         of shape (1024,)
2020-12-13 10:24:42,909 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.running_var          loaded from backbone.body.layer3.19.bn3.running_var          of shape (1024,)
2020-12-13 10:24:42,909 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.weight               loaded from backbone.body.layer3.19.bn3.weight               of shape (1024,)
2020-12-13 10:24:42,909 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv1.weight             loaded from backbone.body.layer3.19.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,909 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv2.weight             loaded from backbone.body.layer3.19.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,909 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv3.weight             loaded from backbone.body.layer3.19.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,909 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                  loaded from backbone.body.layer3.2.bn1.bias                  of shape (1024,)
2020-12-13 10:24:42,909 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_mean          loaded from backbone.body.layer3.2.bn1.running_mean          of shape (1024,)
2020-12-13 10:24:42,909 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_var           loaded from backbone.body.layer3.2.bn1.running_var           of shape (1024,)
2020-12-13 10:24:42,909 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                loaded from backbone.body.layer3.2.bn1.weight                of shape (1024,)
2020-12-13 10:24:42,910 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                  loaded from backbone.body.layer3.2.bn2.bias                  of shape (1024,)
2020-12-13 10:24:42,910 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_mean          loaded from backbone.body.layer3.2.bn2.running_mean          of shape (1024,)
2020-12-13 10:24:42,910 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_var           loaded from backbone.body.layer3.2.bn2.running_var           of shape (1024,)
2020-12-13 10:24:42,910 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                loaded from backbone.body.layer3.2.bn2.weight                of shape (1024,)
2020-12-13 10:24:42,910 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                  loaded from backbone.body.layer3.2.bn3.bias                  of shape (1024,)
2020-12-13 10:24:42,910 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_mean          loaded from backbone.body.layer3.2.bn3.running_mean          of shape (1024,)
2020-12-13 10:24:42,910 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_var           loaded from backbone.body.layer3.2.bn3.running_var           of shape (1024,)
2020-12-13 10:24:42,910 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                loaded from backbone.body.layer3.2.bn3.weight                of shape (1024,)
2020-12-13 10:24:42,910 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight              loaded from backbone.body.layer3.2.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,910 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight              loaded from backbone.body.layer3.2.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,910 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight              loaded from backbone.body.layer3.2.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,910 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.bias                 loaded from backbone.body.layer3.20.bn1.bias                 of shape (1024,)
2020-12-13 10:24:42,911 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.running_mean         loaded from backbone.body.layer3.20.bn1.running_mean         of shape (1024,)
2020-12-13 10:24:42,911 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.running_var          loaded from backbone.body.layer3.20.bn1.running_var          of shape (1024,)
2020-12-13 10:24:42,911 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.weight               loaded from backbone.body.layer3.20.bn1.weight               of shape (1024,)
2020-12-13 10:24:42,911 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.bias                 loaded from backbone.body.layer3.20.bn2.bias                 of shape (1024,)
2020-12-13 10:24:42,911 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.running_mean         loaded from backbone.body.layer3.20.bn2.running_mean         of shape (1024,)
2020-12-13 10:24:42,911 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.running_var          loaded from backbone.body.layer3.20.bn2.running_var          of shape (1024,)
2020-12-13 10:24:42,911 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.weight               loaded from backbone.body.layer3.20.bn2.weight               of shape (1024,)
2020-12-13 10:24:42,911 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.bias                 loaded from backbone.body.layer3.20.bn3.bias                 of shape (1024,)
2020-12-13 10:24:42,911 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.running_mean         loaded from backbone.body.layer3.20.bn3.running_mean         of shape (1024,)
2020-12-13 10:24:42,911 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.running_var          loaded from backbone.body.layer3.20.bn3.running_var          of shape (1024,)
2020-12-13 10:24:42,911 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.weight               loaded from backbone.body.layer3.20.bn3.weight               of shape (1024,)
2020-12-13 10:24:42,911 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv1.weight             loaded from backbone.body.layer3.20.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,912 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv2.weight             loaded from backbone.body.layer3.20.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,912 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv3.weight             loaded from backbone.body.layer3.20.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,912 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.bias                 loaded from backbone.body.layer3.21.bn1.bias                 of shape (1024,)
2020-12-13 10:24:42,912 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.running_mean         loaded from backbone.body.layer3.21.bn1.running_mean         of shape (1024,)
2020-12-13 10:24:42,912 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.running_var          loaded from backbone.body.layer3.21.bn1.running_var          of shape (1024,)
2020-12-13 10:24:42,912 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.weight               loaded from backbone.body.layer3.21.bn1.weight               of shape (1024,)
2020-12-13 10:24:42,912 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.bias                 loaded from backbone.body.layer3.21.bn2.bias                 of shape (1024,)
2020-12-13 10:24:42,912 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.running_mean         loaded from backbone.body.layer3.21.bn2.running_mean         of shape (1024,)
2020-12-13 10:24:42,912 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.running_var          loaded from backbone.body.layer3.21.bn2.running_var          of shape (1024,)
2020-12-13 10:24:42,912 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.weight               loaded from backbone.body.layer3.21.bn2.weight               of shape (1024,)
2020-12-13 10:24:42,912 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.bias                 loaded from backbone.body.layer3.21.bn3.bias                 of shape (1024,)
2020-12-13 10:24:42,912 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.running_mean         loaded from backbone.body.layer3.21.bn3.running_mean         of shape (1024,)
2020-12-13 10:24:42,913 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.running_var          loaded from backbone.body.layer3.21.bn3.running_var          of shape (1024,)
2020-12-13 10:24:42,913 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.weight               loaded from backbone.body.layer3.21.bn3.weight               of shape (1024,)
2020-12-13 10:24:42,913 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv1.weight             loaded from backbone.body.layer3.21.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,913 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv2.weight             loaded from backbone.body.layer3.21.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,913 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv3.weight             loaded from backbone.body.layer3.21.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,913 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.bias                 loaded from backbone.body.layer3.22.bn1.bias                 of shape (1024,)
2020-12-13 10:24:42,913 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.running_mean         loaded from backbone.body.layer3.22.bn1.running_mean         of shape (1024,)
2020-12-13 10:24:42,913 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.running_var          loaded from backbone.body.layer3.22.bn1.running_var          of shape (1024,)
2020-12-13 10:24:42,913 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.weight               loaded from backbone.body.layer3.22.bn1.weight               of shape (1024,)
2020-12-13 10:24:42,913 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.bias                 loaded from backbone.body.layer3.22.bn2.bias                 of shape (1024,)
2020-12-13 10:24:42,913 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.running_mean         loaded from backbone.body.layer3.22.bn2.running_mean         of shape (1024,)
2020-12-13 10:24:42,914 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.running_var          loaded from backbone.body.layer3.22.bn2.running_var          of shape (1024,)
2020-12-13 10:24:42,914 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.weight               loaded from backbone.body.layer3.22.bn2.weight               of shape (1024,)
2020-12-13 10:24:42,914 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.bias                 loaded from backbone.body.layer3.22.bn3.bias                 of shape (1024,)
2020-12-13 10:24:42,914 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.running_mean         loaded from backbone.body.layer3.22.bn3.running_mean         of shape (1024,)
2020-12-13 10:24:42,914 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.running_var          loaded from backbone.body.layer3.22.bn3.running_var          of shape (1024,)
2020-12-13 10:24:42,914 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.weight               loaded from backbone.body.layer3.22.bn3.weight               of shape (1024,)
2020-12-13 10:24:42,914 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv1.weight             loaded from backbone.body.layer3.22.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,914 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv2.weight             loaded from backbone.body.layer3.22.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,914 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv3.weight             loaded from backbone.body.layer3.22.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,914 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                  loaded from backbone.body.layer3.3.bn1.bias                  of shape (1024,)
2020-12-13 10:24:42,914 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_mean          loaded from backbone.body.layer3.3.bn1.running_mean          of shape (1024,)
2020-12-13 10:24:42,914 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_var           loaded from backbone.body.layer3.3.bn1.running_var           of shape (1024,)
2020-12-13 10:24:42,915 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                loaded from backbone.body.layer3.3.bn1.weight                of shape (1024,)
2020-12-13 10:24:42,915 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                  loaded from backbone.body.layer3.3.bn2.bias                  of shape (1024,)
2020-12-13 10:24:42,915 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_mean          loaded from backbone.body.layer3.3.bn2.running_mean          of shape (1024,)
2020-12-13 10:24:42,915 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_var           loaded from backbone.body.layer3.3.bn2.running_var           of shape (1024,)
2020-12-13 10:24:42,915 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                loaded from backbone.body.layer3.3.bn2.weight                of shape (1024,)
2020-12-13 10:24:42,915 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                  loaded from backbone.body.layer3.3.bn3.bias                  of shape (1024,)
2020-12-13 10:24:42,915 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_mean          loaded from backbone.body.layer3.3.bn3.running_mean          of shape (1024,)
2020-12-13 10:24:42,915 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_var           loaded from backbone.body.layer3.3.bn3.running_var           of shape (1024,)
2020-12-13 10:24:42,915 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                loaded from backbone.body.layer3.3.bn3.weight                of shape (1024,)
2020-12-13 10:24:42,915 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight              loaded from backbone.body.layer3.3.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,915 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight              loaded from backbone.body.layer3.3.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,915 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight              loaded from backbone.body.layer3.3.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,916 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                  loaded from backbone.body.layer3.4.bn1.bias                  of shape (1024,)
2020-12-13 10:24:42,916 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_mean          loaded from backbone.body.layer3.4.bn1.running_mean          of shape (1024,)
2020-12-13 10:24:42,916 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_var           loaded from backbone.body.layer3.4.bn1.running_var           of shape (1024,)
2020-12-13 10:24:42,916 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                loaded from backbone.body.layer3.4.bn1.weight                of shape (1024,)
2020-12-13 10:24:42,916 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                  loaded from backbone.body.layer3.4.bn2.bias                  of shape (1024,)
2020-12-13 10:24:42,916 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_mean          loaded from backbone.body.layer3.4.bn2.running_mean          of shape (1024,)
2020-12-13 10:24:42,916 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_var           loaded from backbone.body.layer3.4.bn2.running_var           of shape (1024,)
2020-12-13 10:24:42,916 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                loaded from backbone.body.layer3.4.bn2.weight                of shape (1024,)
2020-12-13 10:24:42,916 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                  loaded from backbone.body.layer3.4.bn3.bias                  of shape (1024,)
2020-12-13 10:24:42,916 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_mean          loaded from backbone.body.layer3.4.bn3.running_mean          of shape (1024,)
2020-12-13 10:24:42,916 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_var           loaded from backbone.body.layer3.4.bn3.running_var           of shape (1024,)
2020-12-13 10:24:42,917 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                loaded from backbone.body.layer3.4.bn3.weight                of shape (1024,)
2020-12-13 10:24:42,917 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight              loaded from backbone.body.layer3.4.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,917 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight              loaded from backbone.body.layer3.4.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,917 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight              loaded from backbone.body.layer3.4.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,917 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                  loaded from backbone.body.layer3.5.bn1.bias                  of shape (1024,)
2020-12-13 10:24:42,917 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_mean          loaded from backbone.body.layer3.5.bn1.running_mean          of shape (1024,)
2020-12-13 10:24:42,917 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_var           loaded from backbone.body.layer3.5.bn1.running_var           of shape (1024,)
2020-12-13 10:24:42,917 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                loaded from backbone.body.layer3.5.bn1.weight                of shape (1024,)
2020-12-13 10:24:42,917 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                  loaded from backbone.body.layer3.5.bn2.bias                  of shape (1024,)
2020-12-13 10:24:42,917 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_mean          loaded from backbone.body.layer3.5.bn2.running_mean          of shape (1024,)
2020-12-13 10:24:42,917 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_var           loaded from backbone.body.layer3.5.bn2.running_var           of shape (1024,)
2020-12-13 10:24:42,917 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                loaded from backbone.body.layer3.5.bn2.weight                of shape (1024,)
2020-12-13 10:24:42,918 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                  loaded from backbone.body.layer3.5.bn3.bias                  of shape (1024,)
2020-12-13 10:24:42,918 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_mean          loaded from backbone.body.layer3.5.bn3.running_mean          of shape (1024,)
2020-12-13 10:24:42,918 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_var           loaded from backbone.body.layer3.5.bn3.running_var           of shape (1024,)
2020-12-13 10:24:42,918 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                loaded from backbone.body.layer3.5.bn3.weight                of shape (1024,)
2020-12-13 10:24:42,918 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight              loaded from backbone.body.layer3.5.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,918 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight              loaded from backbone.body.layer3.5.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,918 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight              loaded from backbone.body.layer3.5.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,918 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.bias                  loaded from backbone.body.layer3.6.bn1.bias                  of shape (1024,)
2020-12-13 10:24:42,918 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.running_mean          loaded from backbone.body.layer3.6.bn1.running_mean          of shape (1024,)
2020-12-13 10:24:42,918 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.running_var           loaded from backbone.body.layer3.6.bn1.running_var           of shape (1024,)
2020-12-13 10:24:42,918 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.weight                loaded from backbone.body.layer3.6.bn1.weight                of shape (1024,)
2020-12-13 10:24:42,918 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.bias                  loaded from backbone.body.layer3.6.bn2.bias                  of shape (1024,)
2020-12-13 10:24:42,919 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.running_mean          loaded from backbone.body.layer3.6.bn2.running_mean          of shape (1024,)
2020-12-13 10:24:42,919 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.running_var           loaded from backbone.body.layer3.6.bn2.running_var           of shape (1024,)
2020-12-13 10:24:42,919 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.weight                loaded from backbone.body.layer3.6.bn2.weight                of shape (1024,)
2020-12-13 10:24:42,919 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.bias                  loaded from backbone.body.layer3.6.bn3.bias                  of shape (1024,)
2020-12-13 10:24:42,919 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.running_mean          loaded from backbone.body.layer3.6.bn3.running_mean          of shape (1024,)
2020-12-13 10:24:42,919 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.running_var           loaded from backbone.body.layer3.6.bn3.running_var           of shape (1024,)
2020-12-13 10:24:42,919 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.weight                loaded from backbone.body.layer3.6.bn3.weight                of shape (1024,)
2020-12-13 10:24:42,919 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv1.weight              loaded from backbone.body.layer3.6.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,919 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv2.weight              loaded from backbone.body.layer3.6.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,919 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv3.weight              loaded from backbone.body.layer3.6.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,919 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.bias                  loaded from backbone.body.layer3.7.bn1.bias                  of shape (1024,)
2020-12-13 10:24:42,919 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.running_mean          loaded from backbone.body.layer3.7.bn1.running_mean          of shape (1024,)
2020-12-13 10:24:42,920 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.running_var           loaded from backbone.body.layer3.7.bn1.running_var           of shape (1024,)
2020-12-13 10:24:42,920 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.weight                loaded from backbone.body.layer3.7.bn1.weight                of shape (1024,)
2020-12-13 10:24:42,920 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.bias                  loaded from backbone.body.layer3.7.bn2.bias                  of shape (1024,)
2020-12-13 10:24:42,920 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.running_mean          loaded from backbone.body.layer3.7.bn2.running_mean          of shape (1024,)
2020-12-13 10:24:42,920 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.running_var           loaded from backbone.body.layer3.7.bn2.running_var           of shape (1024,)
2020-12-13 10:24:42,920 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.weight                loaded from backbone.body.layer3.7.bn2.weight                of shape (1024,)
2020-12-13 10:24:42,920 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.bias                  loaded from backbone.body.layer3.7.bn3.bias                  of shape (1024,)
2020-12-13 10:24:42,920 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.running_mean          loaded from backbone.body.layer3.7.bn3.running_mean          of shape (1024,)
2020-12-13 10:24:42,920 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.running_var           loaded from backbone.body.layer3.7.bn3.running_var           of shape (1024,)
2020-12-13 10:24:42,920 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.weight                loaded from backbone.body.layer3.7.bn3.weight                of shape (1024,)
2020-12-13 10:24:42,920 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv1.weight              loaded from backbone.body.layer3.7.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,920 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv2.weight              loaded from backbone.body.layer3.7.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,920 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv3.weight              loaded from backbone.body.layer3.7.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,921 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.bias                  loaded from backbone.body.layer3.8.bn1.bias                  of shape (1024,)
2020-12-13 10:24:42,921 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.running_mean          loaded from backbone.body.layer3.8.bn1.running_mean          of shape (1024,)
2020-12-13 10:24:42,921 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.running_var           loaded from backbone.body.layer3.8.bn1.running_var           of shape (1024,)
2020-12-13 10:24:42,921 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.weight                loaded from backbone.body.layer3.8.bn1.weight                of shape (1024,)
2020-12-13 10:24:42,921 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.bias                  loaded from backbone.body.layer3.8.bn2.bias                  of shape (1024,)
2020-12-13 10:24:42,921 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.running_mean          loaded from backbone.body.layer3.8.bn2.running_mean          of shape (1024,)
2020-12-13 10:24:42,921 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.running_var           loaded from backbone.body.layer3.8.bn2.running_var           of shape (1024,)
2020-12-13 10:24:42,921 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.weight                loaded from backbone.body.layer3.8.bn2.weight                of shape (1024,)
2020-12-13 10:24:42,921 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.bias                  loaded from backbone.body.layer3.8.bn3.bias                  of shape (1024,)
2020-12-13 10:24:42,921 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.running_mean          loaded from backbone.body.layer3.8.bn3.running_mean          of shape (1024,)
2020-12-13 10:24:42,921 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.running_var           loaded from backbone.body.layer3.8.bn3.running_var           of shape (1024,)
2020-12-13 10:24:42,922 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.weight                loaded from backbone.body.layer3.8.bn3.weight                of shape (1024,)
2020-12-13 10:24:42,922 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv1.weight              loaded from backbone.body.layer3.8.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,922 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv2.weight              loaded from backbone.body.layer3.8.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,922 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv3.weight              loaded from backbone.body.layer3.8.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,922 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.bias                  loaded from backbone.body.layer3.9.bn1.bias                  of shape (1024,)
2020-12-13 10:24:42,922 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.running_mean          loaded from backbone.body.layer3.9.bn1.running_mean          of shape (1024,)
2020-12-13 10:24:42,922 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.running_var           loaded from backbone.body.layer3.9.bn1.running_var           of shape (1024,)
2020-12-13 10:24:42,922 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.weight                loaded from backbone.body.layer3.9.bn1.weight                of shape (1024,)
2020-12-13 10:24:42,922 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.bias                  loaded from backbone.body.layer3.9.bn2.bias                  of shape (1024,)
2020-12-13 10:24:42,922 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.running_mean          loaded from backbone.body.layer3.9.bn2.running_mean          of shape (1024,)
2020-12-13 10:24:42,922 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.running_var           loaded from backbone.body.layer3.9.bn2.running_var           of shape (1024,)
2020-12-13 10:24:42,922 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.weight                loaded from backbone.body.layer3.9.bn2.weight                of shape (1024,)
2020-12-13 10:24:42,923 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.bias                  loaded from backbone.body.layer3.9.bn3.bias                  of shape (1024,)
2020-12-13 10:24:42,923 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.running_mean          loaded from backbone.body.layer3.9.bn3.running_mean          of shape (1024,)
2020-12-13 10:24:42,923 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.running_var           loaded from backbone.body.layer3.9.bn3.running_var           of shape (1024,)
2020-12-13 10:24:42,923 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.weight                loaded from backbone.body.layer3.9.bn3.weight                of shape (1024,)
2020-12-13 10:24:42,923 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv1.weight              loaded from backbone.body.layer3.9.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,923 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv2.weight              loaded from backbone.body.layer3.9.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:24:42,923 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv3.weight              loaded from backbone.body.layer3.9.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:24:42,923 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                  loaded from backbone.body.layer4.0.bn1.bias                  of shape (2048,)
2020-12-13 10:24:42,923 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_mean          loaded from backbone.body.layer4.0.bn1.running_mean          of shape (2048,)
2020-12-13 10:24:42,923 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_var           loaded from backbone.body.layer4.0.bn1.running_var           of shape (2048,)
2020-12-13 10:24:42,923 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                loaded from backbone.body.layer4.0.bn1.weight                of shape (2048,)
2020-12-13 10:24:42,924 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                  loaded from backbone.body.layer4.0.bn2.bias                  of shape (2048,)
2020-12-13 10:24:42,924 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_mean          loaded from backbone.body.layer4.0.bn2.running_mean          of shape (2048,)
2020-12-13 10:24:42,924 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_var           loaded from backbone.body.layer4.0.bn2.running_var           of shape (2048,)
2020-12-13 10:24:42,924 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                loaded from backbone.body.layer4.0.bn2.weight                of shape (2048,)
2020-12-13 10:24:42,924 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                  loaded from backbone.body.layer4.0.bn3.bias                  of shape (2048,)
2020-12-13 10:24:42,924 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_mean          loaded from backbone.body.layer4.0.bn3.running_mean          of shape (2048,)
2020-12-13 10:24:42,924 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_var           loaded from backbone.body.layer4.0.bn3.running_var           of shape (2048,)
2020-12-13 10:24:42,924 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                loaded from backbone.body.layer4.0.bn3.weight                of shape (2048,)
2020-12-13 10:24:42,924 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight              loaded from backbone.body.layer4.0.conv1.weight              of shape (2048, 1024, 1, 1)
2020-12-13 10:24:42,924 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv2.weight              loaded from backbone.body.layer4.0.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 10:24:42,924 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight              loaded from backbone.body.layer4.0.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:24:42,924 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight       loaded from backbone.body.layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)
2020-12-13 10:24:42,925 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias         loaded from backbone.body.layer4.0.downsample.1.bias         of shape (2048,)
2020-12-13 10:24:42,925 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_mean loaded from backbone.body.layer4.0.downsample.1.running_mean of shape (2048,)
2020-12-13 10:24:42,925 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_var  loaded from backbone.body.layer4.0.downsample.1.running_var  of shape (2048,)
2020-12-13 10:24:42,925 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight       loaded from backbone.body.layer4.0.downsample.1.weight       of shape (2048,)
2020-12-13 10:24:42,925 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                  loaded from backbone.body.layer4.1.bn1.bias                  of shape (2048,)
2020-12-13 10:24:42,925 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_mean          loaded from backbone.body.layer4.1.bn1.running_mean          of shape (2048,)
2020-12-13 10:24:42,925 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_var           loaded from backbone.body.layer4.1.bn1.running_var           of shape (2048,)
2020-12-13 10:24:42,925 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                loaded from backbone.body.layer4.1.bn1.weight                of shape (2048,)
2020-12-13 10:24:42,925 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                  loaded from backbone.body.layer4.1.bn2.bias                  of shape (2048,)
2020-12-13 10:24:42,925 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_mean          loaded from backbone.body.layer4.1.bn2.running_mean          of shape (2048,)
2020-12-13 10:24:42,925 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_var           loaded from backbone.body.layer4.1.bn2.running_var           of shape (2048,)
2020-12-13 10:24:42,925 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                loaded from backbone.body.layer4.1.bn2.weight                of shape (2048,)
2020-12-13 10:24:42,926 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                  loaded from backbone.body.layer4.1.bn3.bias                  of shape (2048,)
2020-12-13 10:24:42,926 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_mean          loaded from backbone.body.layer4.1.bn3.running_mean          of shape (2048,)
2020-12-13 10:24:42,926 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_var           loaded from backbone.body.layer4.1.bn3.running_var           of shape (2048,)
2020-12-13 10:24:42,926 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                loaded from backbone.body.layer4.1.bn3.weight                of shape (2048,)
2020-12-13 10:24:42,926 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight              loaded from backbone.body.layer4.1.conv1.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:24:42,926 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv2.weight              loaded from backbone.body.layer4.1.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 10:24:42,926 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight              loaded from backbone.body.layer4.1.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:24:42,926 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                  loaded from backbone.body.layer4.2.bn1.bias                  of shape (2048,)
2020-12-13 10:24:42,926 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_mean          loaded from backbone.body.layer4.2.bn1.running_mean          of shape (2048,)
2020-12-13 10:24:42,926 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_var           loaded from backbone.body.layer4.2.bn1.running_var           of shape (2048,)
2020-12-13 10:24:42,926 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                loaded from backbone.body.layer4.2.bn1.weight                of shape (2048,)
2020-12-13 10:24:42,927 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                  loaded from backbone.body.layer4.2.bn2.bias                  of shape (2048,)
2020-12-13 10:24:42,927 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_mean          loaded from backbone.body.layer4.2.bn2.running_mean          of shape (2048,)
2020-12-13 10:24:42,927 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_var           loaded from backbone.body.layer4.2.bn2.running_var           of shape (2048,)
2020-12-13 10:24:42,927 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                loaded from backbone.body.layer4.2.bn2.weight                of shape (2048,)
2020-12-13 10:24:42,927 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                  loaded from backbone.body.layer4.2.bn3.bias                  of shape (2048,)
2020-12-13 10:24:42,927 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_mean          loaded from backbone.body.layer4.2.bn3.running_mean          of shape (2048,)
2020-12-13 10:24:42,927 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_var           loaded from backbone.body.layer4.2.bn3.running_var           of shape (2048,)
2020-12-13 10:24:42,927 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                loaded from backbone.body.layer4.2.bn3.weight                of shape (2048,)
2020-12-13 10:24:42,927 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight              loaded from backbone.body.layer4.2.conv1.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:24:42,927 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv2.weight              loaded from backbone.body.layer4.2.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 10:24:42,927 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight              loaded from backbone.body.layer4.2.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:24:42,927 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                      loaded from backbone.body.stem.bn1.bias                      of shape (64,)
2020-12-13 10:24:42,928 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_mean              loaded from backbone.body.stem.bn1.running_mean              of shape (64,)
2020-12-13 10:24:42,928 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_var               loaded from backbone.body.stem.bn1.running_var               of shape (64,)
2020-12-13 10:24:42,928 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                    loaded from backbone.body.stem.bn1.weight                    of shape (64,)
2020-12-13 10:24:42,928 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                  loaded from backbone.body.stem.conv1.weight                  of shape (64, 3, 7, 7)
2020-12-13 10:24:42,928 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.bias                     loaded from backbone.fpn.fpn_inner1.bias                     of shape (256,)
2020-12-13 10:24:42,928 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.weight                   loaded from backbone.fpn.fpn_inner1.weight                   of shape (256, 256, 1, 1)
2020-12-13 10:24:42,928 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                     loaded from backbone.fpn.fpn_inner2.bias                     of shape (256,)
2020-12-13 10:24:42,928 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                   loaded from backbone.fpn.fpn_inner2.weight                   of shape (256, 512, 1, 1)
2020-12-13 10:24:42,928 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                     loaded from backbone.fpn.fpn_inner3.bias                     of shape (256,)
2020-12-13 10:24:42,928 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                   loaded from backbone.fpn.fpn_inner3.weight                   of shape (256, 1024, 1, 1)
2020-12-13 10:24:42,928 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                     loaded from backbone.fpn.fpn_inner4.bias                     of shape (256,)
2020-12-13 10:24:42,928 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                   loaded from backbone.fpn.fpn_inner4.weight                   of shape (256, 2048, 1, 1)
2020-12-13 10:24:42,929 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.bias                     loaded from backbone.fpn.fpn_layer1.bias                     of shape (256,)
2020-12-13 10:24:42,929 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.weight                   loaded from backbone.fpn.fpn_layer1.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:24:42,929 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                     loaded from backbone.fpn.fpn_layer2.bias                     of shape (256,)
2020-12-13 10:24:42,929 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                   loaded from backbone.fpn.fpn_layer2.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:24:42,929 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                     loaded from backbone.fpn.fpn_layer3.bias                     of shape (256,)
2020-12-13 10:24:42,929 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                   loaded from backbone.fpn.fpn_layer3.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:24:42,929 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                     loaded from backbone.fpn.fpn_layer4.bias                     of shape (256,)
2020-12-13 10:24:42,929 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                   loaded from backbone.fpn.fpn_layer4.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:24:42,929 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.bias         loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (1024,)
2020-12-13 10:24:42,929 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.weight       loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (1024, 12544)
2020-12-13 10:24:42,929 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.bias         loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (1024,)
2020-12-13 10:24:42,929 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.weight       loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (1024, 1024)
2020-12-13 10:24:42,930 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.bias           loaded from roi_heads.box.predictor.bbox_pred.bias           of shape (324,)
2020-12-13 10:24:42,930 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.weight         loaded from roi_heads.box.predictor.bbox_pred.weight         of shape (324, 1024)
2020-12-13 10:24:42,930 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.bias           loaded from roi_heads.box.predictor.cls_score.bias           of shape (81,)
2020-12-13 10:24:42,930 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.weight         loaded from roi_heads.box.predictor.cls_score.weight         of shape (81, 1024)
2020-12-13 10:24:42,930 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.0              loaded from rpn.anchor_generator.cell_anchors.0              of shape (3, 4)
2020-12-13 10:24:42,930 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.1              loaded from rpn.anchor_generator.cell_anchors.1              of shape (3, 4)
2020-12-13 10:24:42,930 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.2              loaded from rpn.anchor_generator.cell_anchors.2              of shape (3, 4)
2020-12-13 10:24:42,930 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.3              loaded from rpn.anchor_generator.cell_anchors.3              of shape (3, 4)
2020-12-13 10:24:42,930 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.4              loaded from rpn.anchor_generator.cell_anchors.4              of shape (3, 4)
2020-12-13 10:24:42,930 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                          loaded from rpn.head.bbox_pred.bias                          of shape (12,)
2020-12-13 10:24:42,930 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                        loaded from rpn.head.bbox_pred.weight                        of shape (12, 256, 1, 1)
2020-12-13 10:24:42,930 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                         loaded from rpn.head.cls_logits.bias                         of shape (3,)
2020-12-13 10:24:42,931 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                       loaded from rpn.head.cls_logits.weight                       of shape (3, 256, 1, 1)
2020-12-13 10:24:42,931 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.bias                               loaded from rpn.head.conv.bias                               of shape (256,)
2020-12-13 10:24:42,931 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.weight                             loaded from rpn.head.conv.weight                             of shape (256, 256, 3, 3)
2020-12-13 10:24:43,107 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-13 10:24:43,107 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-13 10:24:43,108 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-13 10:24:43,108 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-13 10:24:45,078 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-13 10:25:20,613 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 10:25:20,613 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 10:25:20,613 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 10:25:22,895 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 10:25:22,896 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 10:25:22,896 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train", "giro4_train", "giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.000001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 2

2020-12-13 10:25:22,897 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 1e-06
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 2
2020-12-13 10:25:24,627 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from visdrone_model_0360000.pth
2020-12-13 10:25:25,151 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                  loaded from backbone.body.layer1.0.bn1.bias                  of shape (256,)
2020-12-13 10:25:25,152 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_mean          loaded from backbone.body.layer1.0.bn1.running_mean          of shape (256,)
2020-12-13 10:25:25,152 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_var           loaded from backbone.body.layer1.0.bn1.running_var           of shape (256,)
2020-12-13 10:25:25,152 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                loaded from backbone.body.layer1.0.bn1.weight                of shape (256,)
2020-12-13 10:25:25,152 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                  loaded from backbone.body.layer1.0.bn2.bias                  of shape (256,)
2020-12-13 10:25:25,152 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_mean          loaded from backbone.body.layer1.0.bn2.running_mean          of shape (256,)
2020-12-13 10:25:25,152 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_var           loaded from backbone.body.layer1.0.bn2.running_var           of shape (256,)
2020-12-13 10:25:25,152 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                loaded from backbone.body.layer1.0.bn2.weight                of shape (256,)
2020-12-13 10:25:25,152 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                  loaded from backbone.body.layer1.0.bn3.bias                  of shape (256,)
2020-12-13 10:25:25,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_mean          loaded from backbone.body.layer1.0.bn3.running_mean          of shape (256,)
2020-12-13 10:25:25,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_var           loaded from backbone.body.layer1.0.bn3.running_var           of shape (256,)
2020-12-13 10:25:25,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                loaded from backbone.body.layer1.0.bn3.weight                of shape (256,)
2020-12-13 10:25:25,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight              loaded from backbone.body.layer1.0.conv1.weight              of shape (256, 64, 1, 1)
2020-12-13 10:25:25,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight              loaded from backbone.body.layer1.0.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 10:25:25,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight              loaded from backbone.body.layer1.0.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 10:25:25,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight       loaded from backbone.body.layer1.0.downsample.0.weight       of shape (256, 64, 1, 1)
2020-12-13 10:25:25,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias         loaded from backbone.body.layer1.0.downsample.1.bias         of shape (256,)
2020-12-13 10:25:25,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_mean loaded from backbone.body.layer1.0.downsample.1.running_mean of shape (256,)
2020-12-13 10:25:25,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_var  loaded from backbone.body.layer1.0.downsample.1.running_var  of shape (256,)
2020-12-13 10:25:25,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight       loaded from backbone.body.layer1.0.downsample.1.weight       of shape (256,)
2020-12-13 10:25:25,153 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                  loaded from backbone.body.layer1.1.bn1.bias                  of shape (256,)
2020-12-13 10:25:25,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_mean          loaded from backbone.body.layer1.1.bn1.running_mean          of shape (256,)
2020-12-13 10:25:25,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_var           loaded from backbone.body.layer1.1.bn1.running_var           of shape (256,)
2020-12-13 10:25:25,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                loaded from backbone.body.layer1.1.bn1.weight                of shape (256,)
2020-12-13 10:25:25,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                  loaded from backbone.body.layer1.1.bn2.bias                  of shape (256,)
2020-12-13 10:25:25,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_mean          loaded from backbone.body.layer1.1.bn2.running_mean          of shape (256,)
2020-12-13 10:25:25,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_var           loaded from backbone.body.layer1.1.bn2.running_var           of shape (256,)
2020-12-13 10:25:25,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                loaded from backbone.body.layer1.1.bn2.weight                of shape (256,)
2020-12-13 10:25:25,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                  loaded from backbone.body.layer1.1.bn3.bias                  of shape (256,)
2020-12-13 10:25:25,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_mean          loaded from backbone.body.layer1.1.bn3.running_mean          of shape (256,)
2020-12-13 10:25:25,154 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_var           loaded from backbone.body.layer1.1.bn3.running_var           of shape (256,)
2020-12-13 10:25:25,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                loaded from backbone.body.layer1.1.bn3.weight                of shape (256,)
2020-12-13 10:25:25,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight              loaded from backbone.body.layer1.1.conv1.weight              of shape (256, 256, 1, 1)
2020-12-13 10:25:25,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight              loaded from backbone.body.layer1.1.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 10:25:25,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight              loaded from backbone.body.layer1.1.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 10:25:25,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                  loaded from backbone.body.layer1.2.bn1.bias                  of shape (256,)
2020-12-13 10:25:25,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_mean          loaded from backbone.body.layer1.2.bn1.running_mean          of shape (256,)
2020-12-13 10:25:25,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_var           loaded from backbone.body.layer1.2.bn1.running_var           of shape (256,)
2020-12-13 10:25:25,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                loaded from backbone.body.layer1.2.bn1.weight                of shape (256,)
2020-12-13 10:25:25,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                  loaded from backbone.body.layer1.2.bn2.bias                  of shape (256,)
2020-12-13 10:25:25,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_mean          loaded from backbone.body.layer1.2.bn2.running_mean          of shape (256,)
2020-12-13 10:25:25,155 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_var           loaded from backbone.body.layer1.2.bn2.running_var           of shape (256,)
2020-12-13 10:25:25,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                loaded from backbone.body.layer1.2.bn2.weight                of shape (256,)
2020-12-13 10:25:25,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                  loaded from backbone.body.layer1.2.bn3.bias                  of shape (256,)
2020-12-13 10:25:25,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_mean          loaded from backbone.body.layer1.2.bn3.running_mean          of shape (256,)
2020-12-13 10:25:25,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_var           loaded from backbone.body.layer1.2.bn3.running_var           of shape (256,)
2020-12-13 10:25:25,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                loaded from backbone.body.layer1.2.bn3.weight                of shape (256,)
2020-12-13 10:25:25,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight              loaded from backbone.body.layer1.2.conv1.weight              of shape (256, 256, 1, 1)
2020-12-13 10:25:25,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight              loaded from backbone.body.layer1.2.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 10:25:25,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight              loaded from backbone.body.layer1.2.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 10:25:25,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                  loaded from backbone.body.layer2.0.bn1.bias                  of shape (512,)
2020-12-13 10:25:25,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_mean          loaded from backbone.body.layer2.0.bn1.running_mean          of shape (512,)
2020-12-13 10:25:25,156 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_var           loaded from backbone.body.layer2.0.bn1.running_var           of shape (512,)
2020-12-13 10:25:25,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                loaded from backbone.body.layer2.0.bn1.weight                of shape (512,)
2020-12-13 10:25:25,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                  loaded from backbone.body.layer2.0.bn2.bias                  of shape (512,)
2020-12-13 10:25:25,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_mean          loaded from backbone.body.layer2.0.bn2.running_mean          of shape (512,)
2020-12-13 10:25:25,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_var           loaded from backbone.body.layer2.0.bn2.running_var           of shape (512,)
2020-12-13 10:25:25,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                loaded from backbone.body.layer2.0.bn2.weight                of shape (512,)
2020-12-13 10:25:25,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                  loaded from backbone.body.layer2.0.bn3.bias                  of shape (512,)
2020-12-13 10:25:25,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_mean          loaded from backbone.body.layer2.0.bn3.running_mean          of shape (512,)
2020-12-13 10:25:25,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_var           loaded from backbone.body.layer2.0.bn3.running_var           of shape (512,)
2020-12-13 10:25:25,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                loaded from backbone.body.layer2.0.bn3.weight                of shape (512,)
2020-12-13 10:25:25,157 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight              loaded from backbone.body.layer2.0.conv1.weight              of shape (512, 256, 1, 1)
2020-12-13 10:25:25,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight              loaded from backbone.body.layer2.0.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:25:25,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight              loaded from backbone.body.layer2.0.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:25:25,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight       loaded from backbone.body.layer2.0.downsample.0.weight       of shape (512, 256, 1, 1)
2020-12-13 10:25:25,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias         loaded from backbone.body.layer2.0.downsample.1.bias         of shape (512,)
2020-12-13 10:25:25,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_mean loaded from backbone.body.layer2.0.downsample.1.running_mean of shape (512,)
2020-12-13 10:25:25,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_var  loaded from backbone.body.layer2.0.downsample.1.running_var  of shape (512,)
2020-12-13 10:25:25,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight       loaded from backbone.body.layer2.0.downsample.1.weight       of shape (512,)
2020-12-13 10:25:25,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                  loaded from backbone.body.layer2.1.bn1.bias                  of shape (512,)
2020-12-13 10:25:25,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_mean          loaded from backbone.body.layer2.1.bn1.running_mean          of shape (512,)
2020-12-13 10:25:25,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_var           loaded from backbone.body.layer2.1.bn1.running_var           of shape (512,)
2020-12-13 10:25:25,158 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                loaded from backbone.body.layer2.1.bn1.weight                of shape (512,)
2020-12-13 10:25:25,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                  loaded from backbone.body.layer2.1.bn2.bias                  of shape (512,)
2020-12-13 10:25:25,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_mean          loaded from backbone.body.layer2.1.bn2.running_mean          of shape (512,)
2020-12-13 10:25:25,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_var           loaded from backbone.body.layer2.1.bn2.running_var           of shape (512,)
2020-12-13 10:25:25,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                loaded from backbone.body.layer2.1.bn2.weight                of shape (512,)
2020-12-13 10:25:25,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                  loaded from backbone.body.layer2.1.bn3.bias                  of shape (512,)
2020-12-13 10:25:25,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_mean          loaded from backbone.body.layer2.1.bn3.running_mean          of shape (512,)
2020-12-13 10:25:25,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_var           loaded from backbone.body.layer2.1.bn3.running_var           of shape (512,)
2020-12-13 10:25:25,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                loaded from backbone.body.layer2.1.bn3.weight                of shape (512,)
2020-12-13 10:25:25,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight              loaded from backbone.body.layer2.1.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 10:25:25,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight              loaded from backbone.body.layer2.1.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:25:25,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight              loaded from backbone.body.layer2.1.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:25:25,159 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                  loaded from backbone.body.layer2.2.bn1.bias                  of shape (512,)
2020-12-13 10:25:25,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_mean          loaded from backbone.body.layer2.2.bn1.running_mean          of shape (512,)
2020-12-13 10:25:25,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_var           loaded from backbone.body.layer2.2.bn1.running_var           of shape (512,)
2020-12-13 10:25:25,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                loaded from backbone.body.layer2.2.bn1.weight                of shape (512,)
2020-12-13 10:25:25,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                  loaded from backbone.body.layer2.2.bn2.bias                  of shape (512,)
2020-12-13 10:25:25,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_mean          loaded from backbone.body.layer2.2.bn2.running_mean          of shape (512,)
2020-12-13 10:25:25,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_var           loaded from backbone.body.layer2.2.bn2.running_var           of shape (512,)
2020-12-13 10:25:25,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                loaded from backbone.body.layer2.2.bn2.weight                of shape (512,)
2020-12-13 10:25:25,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                  loaded from backbone.body.layer2.2.bn3.bias                  of shape (512,)
2020-12-13 10:25:25,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_mean          loaded from backbone.body.layer2.2.bn3.running_mean          of shape (512,)
2020-12-13 10:25:25,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_var           loaded from backbone.body.layer2.2.bn3.running_var           of shape (512,)
2020-12-13 10:25:25,160 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                loaded from backbone.body.layer2.2.bn3.weight                of shape (512,)
2020-12-13 10:25:25,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight              loaded from backbone.body.layer2.2.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 10:25:25,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight              loaded from backbone.body.layer2.2.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:25:25,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight              loaded from backbone.body.layer2.2.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:25:25,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                  loaded from backbone.body.layer2.3.bn1.bias                  of shape (512,)
2020-12-13 10:25:25,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_mean          loaded from backbone.body.layer2.3.bn1.running_mean          of shape (512,)
2020-12-13 10:25:25,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_var           loaded from backbone.body.layer2.3.bn1.running_var           of shape (512,)
2020-12-13 10:25:25,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                loaded from backbone.body.layer2.3.bn1.weight                of shape (512,)
2020-12-13 10:25:25,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                  loaded from backbone.body.layer2.3.bn2.bias                  of shape (512,)
2020-12-13 10:25:25,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_mean          loaded from backbone.body.layer2.3.bn2.running_mean          of shape (512,)
2020-12-13 10:25:25,161 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_var           loaded from backbone.body.layer2.3.bn2.running_var           of shape (512,)
2020-12-13 10:25:25,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                loaded from backbone.body.layer2.3.bn2.weight                of shape (512,)
2020-12-13 10:25:25,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                  loaded from backbone.body.layer2.3.bn3.bias                  of shape (512,)
2020-12-13 10:25:25,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_mean          loaded from backbone.body.layer2.3.bn3.running_mean          of shape (512,)
2020-12-13 10:25:25,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_var           loaded from backbone.body.layer2.3.bn3.running_var           of shape (512,)
2020-12-13 10:25:25,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                loaded from backbone.body.layer2.3.bn3.weight                of shape (512,)
2020-12-13 10:25:25,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight              loaded from backbone.body.layer2.3.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 10:25:25,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight              loaded from backbone.body.layer2.3.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:25:25,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight              loaded from backbone.body.layer2.3.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:25:25,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                  loaded from backbone.body.layer3.0.bn1.bias                  of shape (1024,)
2020-12-13 10:25:25,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_mean          loaded from backbone.body.layer3.0.bn1.running_mean          of shape (1024,)
2020-12-13 10:25:25,162 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_var           loaded from backbone.body.layer3.0.bn1.running_var           of shape (1024,)
2020-12-13 10:25:25,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                loaded from backbone.body.layer3.0.bn1.weight                of shape (1024,)
2020-12-13 10:25:25,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                  loaded from backbone.body.layer3.0.bn2.bias                  of shape (1024,)
2020-12-13 10:25:25,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_mean          loaded from backbone.body.layer3.0.bn2.running_mean          of shape (1024,)
2020-12-13 10:25:25,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_var           loaded from backbone.body.layer3.0.bn2.running_var           of shape (1024,)
2020-12-13 10:25:25,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                loaded from backbone.body.layer3.0.bn2.weight                of shape (1024,)
2020-12-13 10:25:25,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                  loaded from backbone.body.layer3.0.bn3.bias                  of shape (1024,)
2020-12-13 10:25:25,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_mean          loaded from backbone.body.layer3.0.bn3.running_mean          of shape (1024,)
2020-12-13 10:25:25,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_var           loaded from backbone.body.layer3.0.bn3.running_var           of shape (1024,)
2020-12-13 10:25:25,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                loaded from backbone.body.layer3.0.bn3.weight                of shape (1024,)
2020-12-13 10:25:25,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight              loaded from backbone.body.layer3.0.conv1.weight              of shape (1024, 512, 1, 1)
2020-12-13 10:25:25,163 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight              loaded from backbone.body.layer3.0.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight              loaded from backbone.body.layer3.0.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight       loaded from backbone.body.layer3.0.downsample.0.weight       of shape (1024, 512, 1, 1)
2020-12-13 10:25:25,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias         loaded from backbone.body.layer3.0.downsample.1.bias         of shape (1024,)
2020-12-13 10:25:25,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_mean loaded from backbone.body.layer3.0.downsample.1.running_mean of shape (1024,)
2020-12-13 10:25:25,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_var  loaded from backbone.body.layer3.0.downsample.1.running_var  of shape (1024,)
2020-12-13 10:25:25,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight       loaded from backbone.body.layer3.0.downsample.1.weight       of shape (1024,)
2020-12-13 10:25:25,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                  loaded from backbone.body.layer3.1.bn1.bias                  of shape (1024,)
2020-12-13 10:25:25,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_mean          loaded from backbone.body.layer3.1.bn1.running_mean          of shape (1024,)
2020-12-13 10:25:25,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_var           loaded from backbone.body.layer3.1.bn1.running_var           of shape (1024,)
2020-12-13 10:25:25,164 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                loaded from backbone.body.layer3.1.bn1.weight                of shape (1024,)
2020-12-13 10:25:25,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                  loaded from backbone.body.layer3.1.bn2.bias                  of shape (1024,)
2020-12-13 10:25:25,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_mean          loaded from backbone.body.layer3.1.bn2.running_mean          of shape (1024,)
2020-12-13 10:25:25,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_var           loaded from backbone.body.layer3.1.bn2.running_var           of shape (1024,)
2020-12-13 10:25:25,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                loaded from backbone.body.layer3.1.bn2.weight                of shape (1024,)
2020-12-13 10:25:25,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                  loaded from backbone.body.layer3.1.bn3.bias                  of shape (1024,)
2020-12-13 10:25:25,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_mean          loaded from backbone.body.layer3.1.bn3.running_mean          of shape (1024,)
2020-12-13 10:25:25,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_var           loaded from backbone.body.layer3.1.bn3.running_var           of shape (1024,)
2020-12-13 10:25:25,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                loaded from backbone.body.layer3.1.bn3.weight                of shape (1024,)
2020-12-13 10:25:25,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight              loaded from backbone.body.layer3.1.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,165 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight              loaded from backbone.body.layer3.1.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight              loaded from backbone.body.layer3.1.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.bias                 loaded from backbone.body.layer3.10.bn1.bias                 of shape (1024,)
2020-12-13 10:25:25,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.running_mean         loaded from backbone.body.layer3.10.bn1.running_mean         of shape (1024,)
2020-12-13 10:25:25,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.running_var          loaded from backbone.body.layer3.10.bn1.running_var          of shape (1024,)
2020-12-13 10:25:25,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.weight               loaded from backbone.body.layer3.10.bn1.weight               of shape (1024,)
2020-12-13 10:25:25,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.bias                 loaded from backbone.body.layer3.10.bn2.bias                 of shape (1024,)
2020-12-13 10:25:25,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.running_mean         loaded from backbone.body.layer3.10.bn2.running_mean         of shape (1024,)
2020-12-13 10:25:25,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.running_var          loaded from backbone.body.layer3.10.bn2.running_var          of shape (1024,)
2020-12-13 10:25:25,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.weight               loaded from backbone.body.layer3.10.bn2.weight               of shape (1024,)
2020-12-13 10:25:25,166 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.bias                 loaded from backbone.body.layer3.10.bn3.bias                 of shape (1024,)
2020-12-13 10:25:25,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.running_mean         loaded from backbone.body.layer3.10.bn3.running_mean         of shape (1024,)
2020-12-13 10:25:25,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.running_var          loaded from backbone.body.layer3.10.bn3.running_var          of shape (1024,)
2020-12-13 10:25:25,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.weight               loaded from backbone.body.layer3.10.bn3.weight               of shape (1024,)
2020-12-13 10:25:25,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv1.weight             loaded from backbone.body.layer3.10.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv2.weight             loaded from backbone.body.layer3.10.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv3.weight             loaded from backbone.body.layer3.10.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.bias                 loaded from backbone.body.layer3.11.bn1.bias                 of shape (1024,)
2020-12-13 10:25:25,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.running_mean         loaded from backbone.body.layer3.11.bn1.running_mean         of shape (1024,)
2020-12-13 10:25:25,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.running_var          loaded from backbone.body.layer3.11.bn1.running_var          of shape (1024,)
2020-12-13 10:25:25,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.weight               loaded from backbone.body.layer3.11.bn1.weight               of shape (1024,)
2020-12-13 10:25:25,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.bias                 loaded from backbone.body.layer3.11.bn2.bias                 of shape (1024,)
2020-12-13 10:25:25,167 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.running_mean         loaded from backbone.body.layer3.11.bn2.running_mean         of shape (1024,)
2020-12-13 10:25:25,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.running_var          loaded from backbone.body.layer3.11.bn2.running_var          of shape (1024,)
2020-12-13 10:25:25,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.weight               loaded from backbone.body.layer3.11.bn2.weight               of shape (1024,)
2020-12-13 10:25:25,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.bias                 loaded from backbone.body.layer3.11.bn3.bias                 of shape (1024,)
2020-12-13 10:25:25,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.running_mean         loaded from backbone.body.layer3.11.bn3.running_mean         of shape (1024,)
2020-12-13 10:25:25,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.running_var          loaded from backbone.body.layer3.11.bn3.running_var          of shape (1024,)
2020-12-13 10:25:25,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.weight               loaded from backbone.body.layer3.11.bn3.weight               of shape (1024,)
2020-12-13 10:25:25,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv1.weight             loaded from backbone.body.layer3.11.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv2.weight             loaded from backbone.body.layer3.11.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv3.weight             loaded from backbone.body.layer3.11.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.bias                 loaded from backbone.body.layer3.12.bn1.bias                 of shape (1024,)
2020-12-13 10:25:25,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.running_mean         loaded from backbone.body.layer3.12.bn1.running_mean         of shape (1024,)
2020-12-13 10:25:25,168 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.running_var          loaded from backbone.body.layer3.12.bn1.running_var          of shape (1024,)
2020-12-13 10:25:25,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.weight               loaded from backbone.body.layer3.12.bn1.weight               of shape (1024,)
2020-12-13 10:25:25,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.bias                 loaded from backbone.body.layer3.12.bn2.bias                 of shape (1024,)
2020-12-13 10:25:25,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.running_mean         loaded from backbone.body.layer3.12.bn2.running_mean         of shape (1024,)
2020-12-13 10:25:25,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.running_var          loaded from backbone.body.layer3.12.bn2.running_var          of shape (1024,)
2020-12-13 10:25:25,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.weight               loaded from backbone.body.layer3.12.bn2.weight               of shape (1024,)
2020-12-13 10:25:25,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.bias                 loaded from backbone.body.layer3.12.bn3.bias                 of shape (1024,)
2020-12-13 10:25:25,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.running_mean         loaded from backbone.body.layer3.12.bn3.running_mean         of shape (1024,)
2020-12-13 10:25:25,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.running_var          loaded from backbone.body.layer3.12.bn3.running_var          of shape (1024,)
2020-12-13 10:25:25,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.weight               loaded from backbone.body.layer3.12.bn3.weight               of shape (1024,)
2020-12-13 10:25:25,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv1.weight             loaded from backbone.body.layer3.12.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,169 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv2.weight             loaded from backbone.body.layer3.12.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv3.weight             loaded from backbone.body.layer3.12.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.bias                 loaded from backbone.body.layer3.13.bn1.bias                 of shape (1024,)
2020-12-13 10:25:25,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.running_mean         loaded from backbone.body.layer3.13.bn1.running_mean         of shape (1024,)
2020-12-13 10:25:25,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.running_var          loaded from backbone.body.layer3.13.bn1.running_var          of shape (1024,)
2020-12-13 10:25:25,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.weight               loaded from backbone.body.layer3.13.bn1.weight               of shape (1024,)
2020-12-13 10:25:25,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.bias                 loaded from backbone.body.layer3.13.bn2.bias                 of shape (1024,)
2020-12-13 10:25:25,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.running_mean         loaded from backbone.body.layer3.13.bn2.running_mean         of shape (1024,)
2020-12-13 10:25:25,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.running_var          loaded from backbone.body.layer3.13.bn2.running_var          of shape (1024,)
2020-12-13 10:25:25,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.weight               loaded from backbone.body.layer3.13.bn2.weight               of shape (1024,)
2020-12-13 10:25:25,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.bias                 loaded from backbone.body.layer3.13.bn3.bias                 of shape (1024,)
2020-12-13 10:25:25,170 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.running_mean         loaded from backbone.body.layer3.13.bn3.running_mean         of shape (1024,)
2020-12-13 10:25:25,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.running_var          loaded from backbone.body.layer3.13.bn3.running_var          of shape (1024,)
2020-12-13 10:25:25,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.weight               loaded from backbone.body.layer3.13.bn3.weight               of shape (1024,)
2020-12-13 10:25:25,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv1.weight             loaded from backbone.body.layer3.13.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv2.weight             loaded from backbone.body.layer3.13.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv3.weight             loaded from backbone.body.layer3.13.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.bias                 loaded from backbone.body.layer3.14.bn1.bias                 of shape (1024,)
2020-12-13 10:25:25,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.running_mean         loaded from backbone.body.layer3.14.bn1.running_mean         of shape (1024,)
2020-12-13 10:25:25,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.running_var          loaded from backbone.body.layer3.14.bn1.running_var          of shape (1024,)
2020-12-13 10:25:25,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.weight               loaded from backbone.body.layer3.14.bn1.weight               of shape (1024,)
2020-12-13 10:25:25,171 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.bias                 loaded from backbone.body.layer3.14.bn2.bias                 of shape (1024,)
2020-12-13 10:25:25,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.running_mean         loaded from backbone.body.layer3.14.bn2.running_mean         of shape (1024,)
2020-12-13 10:25:25,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.running_var          loaded from backbone.body.layer3.14.bn2.running_var          of shape (1024,)
2020-12-13 10:25:25,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.weight               loaded from backbone.body.layer3.14.bn2.weight               of shape (1024,)
2020-12-13 10:25:25,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.bias                 loaded from backbone.body.layer3.14.bn3.bias                 of shape (1024,)
2020-12-13 10:25:25,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.running_mean         loaded from backbone.body.layer3.14.bn3.running_mean         of shape (1024,)
2020-12-13 10:25:25,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.running_var          loaded from backbone.body.layer3.14.bn3.running_var          of shape (1024,)
2020-12-13 10:25:25,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.weight               loaded from backbone.body.layer3.14.bn3.weight               of shape (1024,)
2020-12-13 10:25:25,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv1.weight             loaded from backbone.body.layer3.14.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv2.weight             loaded from backbone.body.layer3.14.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv3.weight             loaded from backbone.body.layer3.14.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.bias                 loaded from backbone.body.layer3.15.bn1.bias                 of shape (1024,)
2020-12-13 10:25:25,172 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.running_mean         loaded from backbone.body.layer3.15.bn1.running_mean         of shape (1024,)
2020-12-13 10:25:25,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.running_var          loaded from backbone.body.layer3.15.bn1.running_var          of shape (1024,)
2020-12-13 10:25:25,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.weight               loaded from backbone.body.layer3.15.bn1.weight               of shape (1024,)
2020-12-13 10:25:25,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.bias                 loaded from backbone.body.layer3.15.bn2.bias                 of shape (1024,)
2020-12-13 10:25:25,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.running_mean         loaded from backbone.body.layer3.15.bn2.running_mean         of shape (1024,)
2020-12-13 10:25:25,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.running_var          loaded from backbone.body.layer3.15.bn2.running_var          of shape (1024,)
2020-12-13 10:25:25,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.weight               loaded from backbone.body.layer3.15.bn2.weight               of shape (1024,)
2020-12-13 10:25:25,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.bias                 loaded from backbone.body.layer3.15.bn3.bias                 of shape (1024,)
2020-12-13 10:25:25,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.running_mean         loaded from backbone.body.layer3.15.bn3.running_mean         of shape (1024,)
2020-12-13 10:25:25,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.running_var          loaded from backbone.body.layer3.15.bn3.running_var          of shape (1024,)
2020-12-13 10:25:25,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.weight               loaded from backbone.body.layer3.15.bn3.weight               of shape (1024,)
2020-12-13 10:25:25,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv1.weight             loaded from backbone.body.layer3.15.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv2.weight             loaded from backbone.body.layer3.15.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,173 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv3.weight             loaded from backbone.body.layer3.15.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.bias                 loaded from backbone.body.layer3.16.bn1.bias                 of shape (1024,)
2020-12-13 10:25:25,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.running_mean         loaded from backbone.body.layer3.16.bn1.running_mean         of shape (1024,)
2020-12-13 10:25:25,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.running_var          loaded from backbone.body.layer3.16.bn1.running_var          of shape (1024,)
2020-12-13 10:25:25,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.weight               loaded from backbone.body.layer3.16.bn1.weight               of shape (1024,)
2020-12-13 10:25:25,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.bias                 loaded from backbone.body.layer3.16.bn2.bias                 of shape (1024,)
2020-12-13 10:25:25,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.running_mean         loaded from backbone.body.layer3.16.bn2.running_mean         of shape (1024,)
2020-12-13 10:25:25,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.running_var          loaded from backbone.body.layer3.16.bn2.running_var          of shape (1024,)
2020-12-13 10:25:25,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.weight               loaded from backbone.body.layer3.16.bn2.weight               of shape (1024,)
2020-12-13 10:25:25,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.bias                 loaded from backbone.body.layer3.16.bn3.bias                 of shape (1024,)
2020-12-13 10:25:25,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.running_mean         loaded from backbone.body.layer3.16.bn3.running_mean         of shape (1024,)
2020-12-13 10:25:25,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.running_var          loaded from backbone.body.layer3.16.bn3.running_var          of shape (1024,)
2020-12-13 10:25:25,174 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.weight               loaded from backbone.body.layer3.16.bn3.weight               of shape (1024,)
2020-12-13 10:25:25,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv1.weight             loaded from backbone.body.layer3.16.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv2.weight             loaded from backbone.body.layer3.16.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv3.weight             loaded from backbone.body.layer3.16.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.bias                 loaded from backbone.body.layer3.17.bn1.bias                 of shape (1024,)
2020-12-13 10:25:25,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.running_mean         loaded from backbone.body.layer3.17.bn1.running_mean         of shape (1024,)
2020-12-13 10:25:25,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.running_var          loaded from backbone.body.layer3.17.bn1.running_var          of shape (1024,)
2020-12-13 10:25:25,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.weight               loaded from backbone.body.layer3.17.bn1.weight               of shape (1024,)
2020-12-13 10:25:25,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.bias                 loaded from backbone.body.layer3.17.bn2.bias                 of shape (1024,)
2020-12-13 10:25:25,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.running_mean         loaded from backbone.body.layer3.17.bn2.running_mean         of shape (1024,)
2020-12-13 10:25:25,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.running_var          loaded from backbone.body.layer3.17.bn2.running_var          of shape (1024,)
2020-12-13 10:25:25,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.weight               loaded from backbone.body.layer3.17.bn2.weight               of shape (1024,)
2020-12-13 10:25:25,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.bias                 loaded from backbone.body.layer3.17.bn3.bias                 of shape (1024,)
2020-12-13 10:25:25,175 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.running_mean         loaded from backbone.body.layer3.17.bn3.running_mean         of shape (1024,)
2020-12-13 10:25:25,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.running_var          loaded from backbone.body.layer3.17.bn3.running_var          of shape (1024,)
2020-12-13 10:25:25,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.weight               loaded from backbone.body.layer3.17.bn3.weight               of shape (1024,)
2020-12-13 10:25:25,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv1.weight             loaded from backbone.body.layer3.17.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv2.weight             loaded from backbone.body.layer3.17.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv3.weight             loaded from backbone.body.layer3.17.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.bias                 loaded from backbone.body.layer3.18.bn1.bias                 of shape (1024,)
2020-12-13 10:25:25,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.running_mean         loaded from backbone.body.layer3.18.bn1.running_mean         of shape (1024,)
2020-12-13 10:25:25,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.running_var          loaded from backbone.body.layer3.18.bn1.running_var          of shape (1024,)
2020-12-13 10:25:25,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.weight               loaded from backbone.body.layer3.18.bn1.weight               of shape (1024,)
2020-12-13 10:25:25,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.bias                 loaded from backbone.body.layer3.18.bn2.bias                 of shape (1024,)
2020-12-13 10:25:25,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.running_mean         loaded from backbone.body.layer3.18.bn2.running_mean         of shape (1024,)
2020-12-13 10:25:25,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.running_var          loaded from backbone.body.layer3.18.bn2.running_var          of shape (1024,)
2020-12-13 10:25:25,176 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.weight               loaded from backbone.body.layer3.18.bn2.weight               of shape (1024,)
2020-12-13 10:25:25,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.bias                 loaded from backbone.body.layer3.18.bn3.bias                 of shape (1024,)
2020-12-13 10:25:25,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.running_mean         loaded from backbone.body.layer3.18.bn3.running_mean         of shape (1024,)
2020-12-13 10:25:25,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.running_var          loaded from backbone.body.layer3.18.bn3.running_var          of shape (1024,)
2020-12-13 10:25:25,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.weight               loaded from backbone.body.layer3.18.bn3.weight               of shape (1024,)
2020-12-13 10:25:25,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv1.weight             loaded from backbone.body.layer3.18.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv2.weight             loaded from backbone.body.layer3.18.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv3.weight             loaded from backbone.body.layer3.18.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.bias                 loaded from backbone.body.layer3.19.bn1.bias                 of shape (1024,)
2020-12-13 10:25:25,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.running_mean         loaded from backbone.body.layer3.19.bn1.running_mean         of shape (1024,)
2020-12-13 10:25:25,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.running_var          loaded from backbone.body.layer3.19.bn1.running_var          of shape (1024,)
2020-12-13 10:25:25,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.weight               loaded from backbone.body.layer3.19.bn1.weight               of shape (1024,)
2020-12-13 10:25:25,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.bias                 loaded from backbone.body.layer3.19.bn2.bias                 of shape (1024,)
2020-12-13 10:25:25,177 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.running_mean         loaded from backbone.body.layer3.19.bn2.running_mean         of shape (1024,)
2020-12-13 10:25:25,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.running_var          loaded from backbone.body.layer3.19.bn2.running_var          of shape (1024,)
2020-12-13 10:25:25,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.weight               loaded from backbone.body.layer3.19.bn2.weight               of shape (1024,)
2020-12-13 10:25:25,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.bias                 loaded from backbone.body.layer3.19.bn3.bias                 of shape (1024,)
2020-12-13 10:25:25,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.running_mean         loaded from backbone.body.layer3.19.bn3.running_mean         of shape (1024,)
2020-12-13 10:25:25,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.running_var          loaded from backbone.body.layer3.19.bn3.running_var          of shape (1024,)
2020-12-13 10:25:25,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.weight               loaded from backbone.body.layer3.19.bn3.weight               of shape (1024,)
2020-12-13 10:25:25,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv1.weight             loaded from backbone.body.layer3.19.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv2.weight             loaded from backbone.body.layer3.19.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv3.weight             loaded from backbone.body.layer3.19.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                  loaded from backbone.body.layer3.2.bn1.bias                  of shape (1024,)
2020-12-13 10:25:25,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_mean          loaded from backbone.body.layer3.2.bn1.running_mean          of shape (1024,)
2020-12-13 10:25:25,178 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_var           loaded from backbone.body.layer3.2.bn1.running_var           of shape (1024,)
2020-12-13 10:25:25,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                loaded from backbone.body.layer3.2.bn1.weight                of shape (1024,)
2020-12-13 10:25:25,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                  loaded from backbone.body.layer3.2.bn2.bias                  of shape (1024,)
2020-12-13 10:25:25,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_mean          loaded from backbone.body.layer3.2.bn2.running_mean          of shape (1024,)
2020-12-13 10:25:25,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_var           loaded from backbone.body.layer3.2.bn2.running_var           of shape (1024,)
2020-12-13 10:25:25,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                loaded from backbone.body.layer3.2.bn2.weight                of shape (1024,)
2020-12-13 10:25:25,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                  loaded from backbone.body.layer3.2.bn3.bias                  of shape (1024,)
2020-12-13 10:25:25,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_mean          loaded from backbone.body.layer3.2.bn3.running_mean          of shape (1024,)
2020-12-13 10:25:25,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_var           loaded from backbone.body.layer3.2.bn3.running_var           of shape (1024,)
2020-12-13 10:25:25,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                loaded from backbone.body.layer3.2.bn3.weight                of shape (1024,)
2020-12-13 10:25:25,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight              loaded from backbone.body.layer3.2.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight              loaded from backbone.body.layer3.2.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,179 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight              loaded from backbone.body.layer3.2.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.bias                 loaded from backbone.body.layer3.20.bn1.bias                 of shape (1024,)
2020-12-13 10:25:25,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.running_mean         loaded from backbone.body.layer3.20.bn1.running_mean         of shape (1024,)
2020-12-13 10:25:25,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.running_var          loaded from backbone.body.layer3.20.bn1.running_var          of shape (1024,)
2020-12-13 10:25:25,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.weight               loaded from backbone.body.layer3.20.bn1.weight               of shape (1024,)
2020-12-13 10:25:25,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.bias                 loaded from backbone.body.layer3.20.bn2.bias                 of shape (1024,)
2020-12-13 10:25:25,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.running_mean         loaded from backbone.body.layer3.20.bn2.running_mean         of shape (1024,)
2020-12-13 10:25:25,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.running_var          loaded from backbone.body.layer3.20.bn2.running_var          of shape (1024,)
2020-12-13 10:25:25,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.weight               loaded from backbone.body.layer3.20.bn2.weight               of shape (1024,)
2020-12-13 10:25:25,180 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.bias                 loaded from backbone.body.layer3.20.bn3.bias                 of shape (1024,)
2020-12-13 10:25:25,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.running_mean         loaded from backbone.body.layer3.20.bn3.running_mean         of shape (1024,)
2020-12-13 10:25:25,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.running_var          loaded from backbone.body.layer3.20.bn3.running_var          of shape (1024,)
2020-12-13 10:25:25,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.weight               loaded from backbone.body.layer3.20.bn3.weight               of shape (1024,)
2020-12-13 10:25:25,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv1.weight             loaded from backbone.body.layer3.20.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv2.weight             loaded from backbone.body.layer3.20.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv3.weight             loaded from backbone.body.layer3.20.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.bias                 loaded from backbone.body.layer3.21.bn1.bias                 of shape (1024,)
2020-12-13 10:25:25,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.running_mean         loaded from backbone.body.layer3.21.bn1.running_mean         of shape (1024,)
2020-12-13 10:25:25,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.running_var          loaded from backbone.body.layer3.21.bn1.running_var          of shape (1024,)
2020-12-13 10:25:25,181 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.weight               loaded from backbone.body.layer3.21.bn1.weight               of shape (1024,)
2020-12-13 10:25:25,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.bias                 loaded from backbone.body.layer3.21.bn2.bias                 of shape (1024,)
2020-12-13 10:25:25,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.running_mean         loaded from backbone.body.layer3.21.bn2.running_mean         of shape (1024,)
2020-12-13 10:25:25,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.running_var          loaded from backbone.body.layer3.21.bn2.running_var          of shape (1024,)
2020-12-13 10:25:25,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.weight               loaded from backbone.body.layer3.21.bn2.weight               of shape (1024,)
2020-12-13 10:25:25,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.bias                 loaded from backbone.body.layer3.21.bn3.bias                 of shape (1024,)
2020-12-13 10:25:25,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.running_mean         loaded from backbone.body.layer3.21.bn3.running_mean         of shape (1024,)
2020-12-13 10:25:25,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.running_var          loaded from backbone.body.layer3.21.bn3.running_var          of shape (1024,)
2020-12-13 10:25:25,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.weight               loaded from backbone.body.layer3.21.bn3.weight               of shape (1024,)
2020-12-13 10:25:25,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv1.weight             loaded from backbone.body.layer3.21.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv2.weight             loaded from backbone.body.layer3.21.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,182 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv3.weight             loaded from backbone.body.layer3.21.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.bias                 loaded from backbone.body.layer3.22.bn1.bias                 of shape (1024,)
2020-12-13 10:25:25,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.running_mean         loaded from backbone.body.layer3.22.bn1.running_mean         of shape (1024,)
2020-12-13 10:25:25,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.running_var          loaded from backbone.body.layer3.22.bn1.running_var          of shape (1024,)
2020-12-13 10:25:25,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.weight               loaded from backbone.body.layer3.22.bn1.weight               of shape (1024,)
2020-12-13 10:25:25,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.bias                 loaded from backbone.body.layer3.22.bn2.bias                 of shape (1024,)
2020-12-13 10:25:25,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.running_mean         loaded from backbone.body.layer3.22.bn2.running_mean         of shape (1024,)
2020-12-13 10:25:25,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.running_var          loaded from backbone.body.layer3.22.bn2.running_var          of shape (1024,)
2020-12-13 10:25:25,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.weight               loaded from backbone.body.layer3.22.bn2.weight               of shape (1024,)
2020-12-13 10:25:25,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.bias                 loaded from backbone.body.layer3.22.bn3.bias                 of shape (1024,)
2020-12-13 10:25:25,183 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.running_mean         loaded from backbone.body.layer3.22.bn3.running_mean         of shape (1024,)
2020-12-13 10:25:25,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.running_var          loaded from backbone.body.layer3.22.bn3.running_var          of shape (1024,)
2020-12-13 10:25:25,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.weight               loaded from backbone.body.layer3.22.bn3.weight               of shape (1024,)
2020-12-13 10:25:25,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv1.weight             loaded from backbone.body.layer3.22.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv2.weight             loaded from backbone.body.layer3.22.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv3.weight             loaded from backbone.body.layer3.22.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                  loaded from backbone.body.layer3.3.bn1.bias                  of shape (1024,)
2020-12-13 10:25:25,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_mean          loaded from backbone.body.layer3.3.bn1.running_mean          of shape (1024,)
2020-12-13 10:25:25,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_var           loaded from backbone.body.layer3.3.bn1.running_var           of shape (1024,)
2020-12-13 10:25:25,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                loaded from backbone.body.layer3.3.bn1.weight                of shape (1024,)
2020-12-13 10:25:25,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                  loaded from backbone.body.layer3.3.bn2.bias                  of shape (1024,)
2020-12-13 10:25:25,184 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_mean          loaded from backbone.body.layer3.3.bn2.running_mean          of shape (1024,)
2020-12-13 10:25:25,185 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_var           loaded from backbone.body.layer3.3.bn2.running_var           of shape (1024,)
2020-12-13 10:25:25,185 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                loaded from backbone.body.layer3.3.bn2.weight                of shape (1024,)
2020-12-13 10:25:25,185 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                  loaded from backbone.body.layer3.3.bn3.bias                  of shape (1024,)
2020-12-13 10:25:25,185 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_mean          loaded from backbone.body.layer3.3.bn3.running_mean          of shape (1024,)
2020-12-13 10:25:25,185 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_var           loaded from backbone.body.layer3.3.bn3.running_var           of shape (1024,)
2020-12-13 10:25:25,185 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                loaded from backbone.body.layer3.3.bn3.weight                of shape (1024,)
2020-12-13 10:25:25,185 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight              loaded from backbone.body.layer3.3.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,185 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight              loaded from backbone.body.layer3.3.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,185 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight              loaded from backbone.body.layer3.3.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,185 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                  loaded from backbone.body.layer3.4.bn1.bias                  of shape (1024,)
2020-12-13 10:25:25,186 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_mean          loaded from backbone.body.layer3.4.bn1.running_mean          of shape (1024,)
2020-12-13 10:25:25,186 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_var           loaded from backbone.body.layer3.4.bn1.running_var           of shape (1024,)
2020-12-13 10:25:25,186 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                loaded from backbone.body.layer3.4.bn1.weight                of shape (1024,)
2020-12-13 10:25:25,186 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                  loaded from backbone.body.layer3.4.bn2.bias                  of shape (1024,)
2020-12-13 10:25:25,186 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_mean          loaded from backbone.body.layer3.4.bn2.running_mean          of shape (1024,)
2020-12-13 10:25:25,186 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_var           loaded from backbone.body.layer3.4.bn2.running_var           of shape (1024,)
2020-12-13 10:25:25,186 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                loaded from backbone.body.layer3.4.bn2.weight                of shape (1024,)
2020-12-13 10:25:25,186 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                  loaded from backbone.body.layer3.4.bn3.bias                  of shape (1024,)
2020-12-13 10:25:25,186 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_mean          loaded from backbone.body.layer3.4.bn3.running_mean          of shape (1024,)
2020-12-13 10:25:25,186 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_var           loaded from backbone.body.layer3.4.bn3.running_var           of shape (1024,)
2020-12-13 10:25:25,186 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                loaded from backbone.body.layer3.4.bn3.weight                of shape (1024,)
2020-12-13 10:25:25,187 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight              loaded from backbone.body.layer3.4.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,187 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight              loaded from backbone.body.layer3.4.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,187 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight              loaded from backbone.body.layer3.4.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,187 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                  loaded from backbone.body.layer3.5.bn1.bias                  of shape (1024,)
2020-12-13 10:25:25,187 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_mean          loaded from backbone.body.layer3.5.bn1.running_mean          of shape (1024,)
2020-12-13 10:25:25,187 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_var           loaded from backbone.body.layer3.5.bn1.running_var           of shape (1024,)
2020-12-13 10:25:25,187 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                loaded from backbone.body.layer3.5.bn1.weight                of shape (1024,)
2020-12-13 10:25:25,187 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                  loaded from backbone.body.layer3.5.bn2.bias                  of shape (1024,)
2020-12-13 10:25:25,187 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_mean          loaded from backbone.body.layer3.5.bn2.running_mean          of shape (1024,)
2020-12-13 10:25:25,188 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_var           loaded from backbone.body.layer3.5.bn2.running_var           of shape (1024,)
2020-12-13 10:25:25,188 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                loaded from backbone.body.layer3.5.bn2.weight                of shape (1024,)
2020-12-13 10:25:25,188 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                  loaded from backbone.body.layer3.5.bn3.bias                  of shape (1024,)
2020-12-13 10:25:25,188 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_mean          loaded from backbone.body.layer3.5.bn3.running_mean          of shape (1024,)
2020-12-13 10:25:25,188 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_var           loaded from backbone.body.layer3.5.bn3.running_var           of shape (1024,)
2020-12-13 10:25:25,188 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                loaded from backbone.body.layer3.5.bn3.weight                of shape (1024,)
2020-12-13 10:25:25,188 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight              loaded from backbone.body.layer3.5.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,188 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight              loaded from backbone.body.layer3.5.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,188 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight              loaded from backbone.body.layer3.5.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,188 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.bias                  loaded from backbone.body.layer3.6.bn1.bias                  of shape (1024,)
2020-12-13 10:25:25,189 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.running_mean          loaded from backbone.body.layer3.6.bn1.running_mean          of shape (1024,)
2020-12-13 10:25:25,189 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.running_var           loaded from backbone.body.layer3.6.bn1.running_var           of shape (1024,)
2020-12-13 10:25:25,189 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.weight                loaded from backbone.body.layer3.6.bn1.weight                of shape (1024,)
2020-12-13 10:25:25,189 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.bias                  loaded from backbone.body.layer3.6.bn2.bias                  of shape (1024,)
2020-12-13 10:25:25,189 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.running_mean          loaded from backbone.body.layer3.6.bn2.running_mean          of shape (1024,)
2020-12-13 10:25:25,189 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.running_var           loaded from backbone.body.layer3.6.bn2.running_var           of shape (1024,)
2020-12-13 10:25:25,189 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.weight                loaded from backbone.body.layer3.6.bn2.weight                of shape (1024,)
2020-12-13 10:25:25,189 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.bias                  loaded from backbone.body.layer3.6.bn3.bias                  of shape (1024,)
2020-12-13 10:25:25,189 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.running_mean          loaded from backbone.body.layer3.6.bn3.running_mean          of shape (1024,)
2020-12-13 10:25:25,190 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.running_var           loaded from backbone.body.layer3.6.bn3.running_var           of shape (1024,)
2020-12-13 10:25:25,190 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.weight                loaded from backbone.body.layer3.6.bn3.weight                of shape (1024,)
2020-12-13 10:25:25,190 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv1.weight              loaded from backbone.body.layer3.6.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,190 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv2.weight              loaded from backbone.body.layer3.6.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,190 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv3.weight              loaded from backbone.body.layer3.6.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,190 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.bias                  loaded from backbone.body.layer3.7.bn1.bias                  of shape (1024,)
2020-12-13 10:25:25,190 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.running_mean          loaded from backbone.body.layer3.7.bn1.running_mean          of shape (1024,)
2020-12-13 10:25:25,190 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.running_var           loaded from backbone.body.layer3.7.bn1.running_var           of shape (1024,)
2020-12-13 10:25:25,190 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.weight                loaded from backbone.body.layer3.7.bn1.weight                of shape (1024,)
2020-12-13 10:25:25,190 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.bias                  loaded from backbone.body.layer3.7.bn2.bias                  of shape (1024,)
2020-12-13 10:25:25,191 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.running_mean          loaded from backbone.body.layer3.7.bn2.running_mean          of shape (1024,)
2020-12-13 10:25:25,191 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.running_var           loaded from backbone.body.layer3.7.bn2.running_var           of shape (1024,)
2020-12-13 10:25:25,191 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.weight                loaded from backbone.body.layer3.7.bn2.weight                of shape (1024,)
2020-12-13 10:25:25,191 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.bias                  loaded from backbone.body.layer3.7.bn3.bias                  of shape (1024,)
2020-12-13 10:25:25,191 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.running_mean          loaded from backbone.body.layer3.7.bn3.running_mean          of shape (1024,)
2020-12-13 10:25:25,191 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.running_var           loaded from backbone.body.layer3.7.bn3.running_var           of shape (1024,)
2020-12-13 10:25:25,191 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.weight                loaded from backbone.body.layer3.7.bn3.weight                of shape (1024,)
2020-12-13 10:25:25,191 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv1.weight              loaded from backbone.body.layer3.7.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,191 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv2.weight              loaded from backbone.body.layer3.7.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,191 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv3.weight              loaded from backbone.body.layer3.7.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,192 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.bias                  loaded from backbone.body.layer3.8.bn1.bias                  of shape (1024,)
2020-12-13 10:25:25,192 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.running_mean          loaded from backbone.body.layer3.8.bn1.running_mean          of shape (1024,)
2020-12-13 10:25:25,192 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.running_var           loaded from backbone.body.layer3.8.bn1.running_var           of shape (1024,)
2020-12-13 10:25:25,192 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.weight                loaded from backbone.body.layer3.8.bn1.weight                of shape (1024,)
2020-12-13 10:25:25,192 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.bias                  loaded from backbone.body.layer3.8.bn2.bias                  of shape (1024,)
2020-12-13 10:25:25,192 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.running_mean          loaded from backbone.body.layer3.8.bn2.running_mean          of shape (1024,)
2020-12-13 10:25:25,192 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.running_var           loaded from backbone.body.layer3.8.bn2.running_var           of shape (1024,)
2020-12-13 10:25:25,192 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.weight                loaded from backbone.body.layer3.8.bn2.weight                of shape (1024,)
2020-12-13 10:25:25,192 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.bias                  loaded from backbone.body.layer3.8.bn3.bias                  of shape (1024,)
2020-12-13 10:25:25,192 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.running_mean          loaded from backbone.body.layer3.8.bn3.running_mean          of shape (1024,)
2020-12-13 10:25:25,193 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.running_var           loaded from backbone.body.layer3.8.bn3.running_var           of shape (1024,)
2020-12-13 10:25:25,193 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.weight                loaded from backbone.body.layer3.8.bn3.weight                of shape (1024,)
2020-12-13 10:25:25,193 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv1.weight              loaded from backbone.body.layer3.8.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,193 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv2.weight              loaded from backbone.body.layer3.8.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,193 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv3.weight              loaded from backbone.body.layer3.8.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,193 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.bias                  loaded from backbone.body.layer3.9.bn1.bias                  of shape (1024,)
2020-12-13 10:25:25,193 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.running_mean          loaded from backbone.body.layer3.9.bn1.running_mean          of shape (1024,)
2020-12-13 10:25:25,193 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.running_var           loaded from backbone.body.layer3.9.bn1.running_var           of shape (1024,)
2020-12-13 10:25:25,193 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.weight                loaded from backbone.body.layer3.9.bn1.weight                of shape (1024,)
2020-12-13 10:25:25,193 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.bias                  loaded from backbone.body.layer3.9.bn2.bias                  of shape (1024,)
2020-12-13 10:25:25,193 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.running_mean          loaded from backbone.body.layer3.9.bn2.running_mean          of shape (1024,)
2020-12-13 10:25:25,194 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.running_var           loaded from backbone.body.layer3.9.bn2.running_var           of shape (1024,)
2020-12-13 10:25:25,194 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.weight                loaded from backbone.body.layer3.9.bn2.weight                of shape (1024,)
2020-12-13 10:25:25,194 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.bias                  loaded from backbone.body.layer3.9.bn3.bias                  of shape (1024,)
2020-12-13 10:25:25,194 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.running_mean          loaded from backbone.body.layer3.9.bn3.running_mean          of shape (1024,)
2020-12-13 10:25:25,194 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.running_var           loaded from backbone.body.layer3.9.bn3.running_var           of shape (1024,)
2020-12-13 10:25:25,194 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.weight                loaded from backbone.body.layer3.9.bn3.weight                of shape (1024,)
2020-12-13 10:25:25,194 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv1.weight              loaded from backbone.body.layer3.9.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,194 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv2.weight              loaded from backbone.body.layer3.9.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:25:25,194 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv3.weight              loaded from backbone.body.layer3.9.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:25:25,194 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                  loaded from backbone.body.layer4.0.bn1.bias                  of shape (2048,)
2020-12-13 10:25:25,194 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_mean          loaded from backbone.body.layer4.0.bn1.running_mean          of shape (2048,)
2020-12-13 10:25:25,195 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_var           loaded from backbone.body.layer4.0.bn1.running_var           of shape (2048,)
2020-12-13 10:25:25,195 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                loaded from backbone.body.layer4.0.bn1.weight                of shape (2048,)
2020-12-13 10:25:25,195 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                  loaded from backbone.body.layer4.0.bn2.bias                  of shape (2048,)
2020-12-13 10:25:25,195 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_mean          loaded from backbone.body.layer4.0.bn2.running_mean          of shape (2048,)
2020-12-13 10:25:25,195 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_var           loaded from backbone.body.layer4.0.bn2.running_var           of shape (2048,)
2020-12-13 10:25:25,195 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                loaded from backbone.body.layer4.0.bn2.weight                of shape (2048,)
2020-12-13 10:25:25,195 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                  loaded from backbone.body.layer4.0.bn3.bias                  of shape (2048,)
2020-12-13 10:25:25,195 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_mean          loaded from backbone.body.layer4.0.bn3.running_mean          of shape (2048,)
2020-12-13 10:25:25,195 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_var           loaded from backbone.body.layer4.0.bn3.running_var           of shape (2048,)
2020-12-13 10:25:25,195 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                loaded from backbone.body.layer4.0.bn3.weight                of shape (2048,)
2020-12-13 10:25:25,196 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight              loaded from backbone.body.layer4.0.conv1.weight              of shape (2048, 1024, 1, 1)
2020-12-13 10:25:25,196 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv2.weight              loaded from backbone.body.layer4.0.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 10:25:25,196 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight              loaded from backbone.body.layer4.0.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:25:25,196 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight       loaded from backbone.body.layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)
2020-12-13 10:25:25,196 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias         loaded from backbone.body.layer4.0.downsample.1.bias         of shape (2048,)
2020-12-13 10:25:25,196 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_mean loaded from backbone.body.layer4.0.downsample.1.running_mean of shape (2048,)
2020-12-13 10:25:25,196 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_var  loaded from backbone.body.layer4.0.downsample.1.running_var  of shape (2048,)
2020-12-13 10:25:25,196 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight       loaded from backbone.body.layer4.0.downsample.1.weight       of shape (2048,)
2020-12-13 10:25:25,196 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                  loaded from backbone.body.layer4.1.bn1.bias                  of shape (2048,)
2020-12-13 10:25:25,196 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_mean          loaded from backbone.body.layer4.1.bn1.running_mean          of shape (2048,)
2020-12-13 10:25:25,196 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_var           loaded from backbone.body.layer4.1.bn1.running_var           of shape (2048,)
2020-12-13 10:25:25,196 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                loaded from backbone.body.layer4.1.bn1.weight                of shape (2048,)
2020-12-13 10:25:25,197 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                  loaded from backbone.body.layer4.1.bn2.bias                  of shape (2048,)
2020-12-13 10:25:25,197 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_mean          loaded from backbone.body.layer4.1.bn2.running_mean          of shape (2048,)
2020-12-13 10:25:25,197 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_var           loaded from backbone.body.layer4.1.bn2.running_var           of shape (2048,)
2020-12-13 10:25:25,197 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                loaded from backbone.body.layer4.1.bn2.weight                of shape (2048,)
2020-12-13 10:25:25,197 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                  loaded from backbone.body.layer4.1.bn3.bias                  of shape (2048,)
2020-12-13 10:25:25,197 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_mean          loaded from backbone.body.layer4.1.bn3.running_mean          of shape (2048,)
2020-12-13 10:25:25,197 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_var           loaded from backbone.body.layer4.1.bn3.running_var           of shape (2048,)
2020-12-13 10:25:25,197 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                loaded from backbone.body.layer4.1.bn3.weight                of shape (2048,)
2020-12-13 10:25:25,197 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight              loaded from backbone.body.layer4.1.conv1.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:25:25,197 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv2.weight              loaded from backbone.body.layer4.1.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 10:25:25,198 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight              loaded from backbone.body.layer4.1.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:25:25,198 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                  loaded from backbone.body.layer4.2.bn1.bias                  of shape (2048,)
2020-12-13 10:25:25,198 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_mean          loaded from backbone.body.layer4.2.bn1.running_mean          of shape (2048,)
2020-12-13 10:25:25,198 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_var           loaded from backbone.body.layer4.2.bn1.running_var           of shape (2048,)
2020-12-13 10:25:25,198 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                loaded from backbone.body.layer4.2.bn1.weight                of shape (2048,)
2020-12-13 10:25:25,198 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                  loaded from backbone.body.layer4.2.bn2.bias                  of shape (2048,)
2020-12-13 10:25:25,198 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_mean          loaded from backbone.body.layer4.2.bn2.running_mean          of shape (2048,)
2020-12-13 10:25:25,198 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_var           loaded from backbone.body.layer4.2.bn2.running_var           of shape (2048,)
2020-12-13 10:25:25,198 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                loaded from backbone.body.layer4.2.bn2.weight                of shape (2048,)
2020-12-13 10:25:25,198 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                  loaded from backbone.body.layer4.2.bn3.bias                  of shape (2048,)
2020-12-13 10:25:25,199 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_mean          loaded from backbone.body.layer4.2.bn3.running_mean          of shape (2048,)
2020-12-13 10:25:25,199 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_var           loaded from backbone.body.layer4.2.bn3.running_var           of shape (2048,)
2020-12-13 10:25:25,199 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                loaded from backbone.body.layer4.2.bn3.weight                of shape (2048,)
2020-12-13 10:25:25,199 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight              loaded from backbone.body.layer4.2.conv1.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:25:25,199 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv2.weight              loaded from backbone.body.layer4.2.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 10:25:25,199 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight              loaded from backbone.body.layer4.2.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:25:25,199 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                      loaded from backbone.body.stem.bn1.bias                      of shape (64,)
2020-12-13 10:25:25,199 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_mean              loaded from backbone.body.stem.bn1.running_mean              of shape (64,)
2020-12-13 10:25:25,199 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_var               loaded from backbone.body.stem.bn1.running_var               of shape (64,)
2020-12-13 10:25:25,199 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                    loaded from backbone.body.stem.bn1.weight                    of shape (64,)
2020-12-13 10:25:25,199 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                  loaded from backbone.body.stem.conv1.weight                  of shape (64, 3, 7, 7)
2020-12-13 10:25:25,200 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.bias                     loaded from backbone.fpn.fpn_inner1.bias                     of shape (256,)
2020-12-13 10:25:25,200 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.weight                   loaded from backbone.fpn.fpn_inner1.weight                   of shape (256, 256, 1, 1)
2020-12-13 10:25:25,200 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                     loaded from backbone.fpn.fpn_inner2.bias                     of shape (256,)
2020-12-13 10:25:25,200 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                   loaded from backbone.fpn.fpn_inner2.weight                   of shape (256, 512, 1, 1)
2020-12-13 10:25:25,200 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                     loaded from backbone.fpn.fpn_inner3.bias                     of shape (256,)
2020-12-13 10:25:25,200 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                   loaded from backbone.fpn.fpn_inner3.weight                   of shape (256, 1024, 1, 1)
2020-12-13 10:25:25,200 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                     loaded from backbone.fpn.fpn_inner4.bias                     of shape (256,)
2020-12-13 10:25:25,200 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                   loaded from backbone.fpn.fpn_inner4.weight                   of shape (256, 2048, 1, 1)
2020-12-13 10:25:25,200 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.bias                     loaded from backbone.fpn.fpn_layer1.bias                     of shape (256,)
2020-12-13 10:25:25,200 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.weight                   loaded from backbone.fpn.fpn_layer1.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:25:25,200 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                     loaded from backbone.fpn.fpn_layer2.bias                     of shape (256,)
2020-12-13 10:25:25,201 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                   loaded from backbone.fpn.fpn_layer2.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:25:25,201 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                     loaded from backbone.fpn.fpn_layer3.bias                     of shape (256,)
2020-12-13 10:25:25,201 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                   loaded from backbone.fpn.fpn_layer3.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:25:25,201 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                     loaded from backbone.fpn.fpn_layer4.bias                     of shape (256,)
2020-12-13 10:25:25,201 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                   loaded from backbone.fpn.fpn_layer4.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:25:25,201 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.bias         loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (1024,)
2020-12-13 10:25:25,201 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.weight       loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (1024, 12544)
2020-12-13 10:25:25,201 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.bias         loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (1024,)
2020-12-13 10:25:25,201 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.weight       loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (1024, 1024)
2020-12-13 10:25:25,201 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.bias           loaded from roi_heads.box.predictor.bbox_pred.bias           of shape (324,)
2020-12-13 10:25:25,201 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.weight         loaded from roi_heads.box.predictor.bbox_pred.weight         of shape (324, 1024)
2020-12-13 10:25:25,201 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.bias           loaded from roi_heads.box.predictor.cls_score.bias           of shape (81,)
2020-12-13 10:25:25,202 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.weight         loaded from roi_heads.box.predictor.cls_score.weight         of shape (81, 1024)
2020-12-13 10:25:25,202 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.0              loaded from rpn.anchor_generator.cell_anchors.0              of shape (3, 4)
2020-12-13 10:25:25,202 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.1              loaded from rpn.anchor_generator.cell_anchors.1              of shape (3, 4)
2020-12-13 10:25:25,202 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.2              loaded from rpn.anchor_generator.cell_anchors.2              of shape (3, 4)
2020-12-13 10:25:25,202 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.3              loaded from rpn.anchor_generator.cell_anchors.3              of shape (3, 4)
2020-12-13 10:25:25,202 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.4              loaded from rpn.anchor_generator.cell_anchors.4              of shape (3, 4)
2020-12-13 10:25:25,202 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                          loaded from rpn.head.bbox_pred.bias                          of shape (12,)
2020-12-13 10:25:25,202 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                        loaded from rpn.head.bbox_pred.weight                        of shape (12, 256, 1, 1)
2020-12-13 10:25:25,202 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                         loaded from rpn.head.cls_logits.bias                         of shape (3,)
2020-12-13 10:25:25,202 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                       loaded from rpn.head.cls_logits.weight                       of shape (3, 256, 1, 1)
2020-12-13 10:25:25,202 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.bias                               loaded from rpn.head.conv.bias                               of shape (256,)
2020-12-13 10:25:25,203 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.weight                             loaded from rpn.head.conv.weight                             of shape (256, 256, 3, 3)
2020-12-13 10:25:25,379 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-13 10:25:25,379 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-13 10:25:25,379 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-13 10:25:25,380 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-13 10:25:27,327 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-13 10:25:45,206 maskrcnn_benchmark.trainer INFO: Start training
2020-12-13 10:27:04,540 maskrcnn_benchmark.trainer INFO: eta: 1:44:27  iter: 20  loss: 3.0760 (2.9802)  loss_classifier: 2.0059 (2.0137)  loss_box_reg: 0.1758 (0.2423)  loss_objectness: 0.6045 (0.6066)  loss_rpn_box_reg: 0.1133 (0.1175)  time: 3.8690 (3.9666)  data: 0.2386 (0.2443)  lr: 0.000000  max mem: 1312
2020-12-13 10:28:21,741 maskrcnn_benchmark.trainer INFO: eta: 1:41:44  iter: 40  loss: 3.0552 (3.0236)  loss_classifier: 1.9556 (1.9936)  loss_box_reg: 0.0546 (0.2047)  loss_objectness: 0.8317 (0.6967)  loss_rpn_box_reg: 0.1371 (0.1286)  time: 3.8553 (3.9133)  data: 0.2318 (0.2397)  lr: 0.000000  max mem: 1312
2020-12-13 10:30:06,812 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 10:30:06,812 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 10:30:06,812 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 10:30:09,079 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 10:30:09,079 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 10:30:09,079 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train", "giro4_train", "giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.001
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-13 10:30:09,080 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 0.001
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-13 10:30:10,804 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from visdrone_model_0360000.pth
2020-12-13 10:30:11,322 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                  loaded from backbone.body.layer1.0.bn1.bias                  of shape (256,)
2020-12-13 10:30:11,322 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_mean          loaded from backbone.body.layer1.0.bn1.running_mean          of shape (256,)
2020-12-13 10:30:11,322 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_var           loaded from backbone.body.layer1.0.bn1.running_var           of shape (256,)
2020-12-13 10:30:11,322 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                loaded from backbone.body.layer1.0.bn1.weight                of shape (256,)
2020-12-13 10:30:11,322 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                  loaded from backbone.body.layer1.0.bn2.bias                  of shape (256,)
2020-12-13 10:30:11,322 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_mean          loaded from backbone.body.layer1.0.bn2.running_mean          of shape (256,)
2020-12-13 10:30:11,322 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_var           loaded from backbone.body.layer1.0.bn2.running_var           of shape (256,)
2020-12-13 10:30:11,322 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                loaded from backbone.body.layer1.0.bn2.weight                of shape (256,)
2020-12-13 10:30:11,322 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                  loaded from backbone.body.layer1.0.bn3.bias                  of shape (256,)
2020-12-13 10:30:11,323 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_mean          loaded from backbone.body.layer1.0.bn3.running_mean          of shape (256,)
2020-12-13 10:30:11,323 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_var           loaded from backbone.body.layer1.0.bn3.running_var           of shape (256,)
2020-12-13 10:30:11,323 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                loaded from backbone.body.layer1.0.bn3.weight                of shape (256,)
2020-12-13 10:30:11,323 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight              loaded from backbone.body.layer1.0.conv1.weight              of shape (256, 64, 1, 1)
2020-12-13 10:30:11,323 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight              loaded from backbone.body.layer1.0.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 10:30:11,323 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight              loaded from backbone.body.layer1.0.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 10:30:11,323 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight       loaded from backbone.body.layer1.0.downsample.0.weight       of shape (256, 64, 1, 1)
2020-12-13 10:30:11,323 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias         loaded from backbone.body.layer1.0.downsample.1.bias         of shape (256,)
2020-12-13 10:30:11,323 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_mean loaded from backbone.body.layer1.0.downsample.1.running_mean of shape (256,)
2020-12-13 10:30:11,324 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_var  loaded from backbone.body.layer1.0.downsample.1.running_var  of shape (256,)
2020-12-13 10:30:11,324 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight       loaded from backbone.body.layer1.0.downsample.1.weight       of shape (256,)
2020-12-13 10:30:11,324 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                  loaded from backbone.body.layer1.1.bn1.bias                  of shape (256,)
2020-12-13 10:30:11,324 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_mean          loaded from backbone.body.layer1.1.bn1.running_mean          of shape (256,)
2020-12-13 10:30:11,324 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_var           loaded from backbone.body.layer1.1.bn1.running_var           of shape (256,)
2020-12-13 10:30:11,324 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                loaded from backbone.body.layer1.1.bn1.weight                of shape (256,)
2020-12-13 10:30:11,324 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                  loaded from backbone.body.layer1.1.bn2.bias                  of shape (256,)
2020-12-13 10:30:11,324 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_mean          loaded from backbone.body.layer1.1.bn2.running_mean          of shape (256,)
2020-12-13 10:30:11,324 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_var           loaded from backbone.body.layer1.1.bn2.running_var           of shape (256,)
2020-12-13 10:30:11,324 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                loaded from backbone.body.layer1.1.bn2.weight                of shape (256,)
2020-12-13 10:30:11,324 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                  loaded from backbone.body.layer1.1.bn3.bias                  of shape (256,)
2020-12-13 10:30:11,324 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_mean          loaded from backbone.body.layer1.1.bn3.running_mean          of shape (256,)
2020-12-13 10:30:11,325 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_var           loaded from backbone.body.layer1.1.bn3.running_var           of shape (256,)
2020-12-13 10:30:11,325 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                loaded from backbone.body.layer1.1.bn3.weight                of shape (256,)
2020-12-13 10:30:11,325 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight              loaded from backbone.body.layer1.1.conv1.weight              of shape (256, 256, 1, 1)
2020-12-13 10:30:11,325 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight              loaded from backbone.body.layer1.1.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 10:30:11,325 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight              loaded from backbone.body.layer1.1.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 10:30:11,325 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                  loaded from backbone.body.layer1.2.bn1.bias                  of shape (256,)
2020-12-13 10:30:11,325 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_mean          loaded from backbone.body.layer1.2.bn1.running_mean          of shape (256,)
2020-12-13 10:30:11,325 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_var           loaded from backbone.body.layer1.2.bn1.running_var           of shape (256,)
2020-12-13 10:30:11,325 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                loaded from backbone.body.layer1.2.bn1.weight                of shape (256,)
2020-12-13 10:30:11,325 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                  loaded from backbone.body.layer1.2.bn2.bias                  of shape (256,)
2020-12-13 10:30:11,325 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_mean          loaded from backbone.body.layer1.2.bn2.running_mean          of shape (256,)
2020-12-13 10:30:11,325 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_var           loaded from backbone.body.layer1.2.bn2.running_var           of shape (256,)
2020-12-13 10:30:11,326 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                loaded from backbone.body.layer1.2.bn2.weight                of shape (256,)
2020-12-13 10:30:11,326 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                  loaded from backbone.body.layer1.2.bn3.bias                  of shape (256,)
2020-12-13 10:30:11,326 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_mean          loaded from backbone.body.layer1.2.bn3.running_mean          of shape (256,)
2020-12-13 10:30:11,326 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_var           loaded from backbone.body.layer1.2.bn3.running_var           of shape (256,)
2020-12-13 10:30:11,326 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                loaded from backbone.body.layer1.2.bn3.weight                of shape (256,)
2020-12-13 10:30:11,326 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight              loaded from backbone.body.layer1.2.conv1.weight              of shape (256, 256, 1, 1)
2020-12-13 10:30:11,326 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight              loaded from backbone.body.layer1.2.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 10:30:11,326 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight              loaded from backbone.body.layer1.2.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 10:30:11,326 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                  loaded from backbone.body.layer2.0.bn1.bias                  of shape (512,)
2020-12-13 10:30:11,326 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_mean          loaded from backbone.body.layer2.0.bn1.running_mean          of shape (512,)
2020-12-13 10:30:11,326 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_var           loaded from backbone.body.layer2.0.bn1.running_var           of shape (512,)
2020-12-13 10:30:11,327 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                loaded from backbone.body.layer2.0.bn1.weight                of shape (512,)
2020-12-13 10:30:11,327 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                  loaded from backbone.body.layer2.0.bn2.bias                  of shape (512,)
2020-12-13 10:30:11,327 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_mean          loaded from backbone.body.layer2.0.bn2.running_mean          of shape (512,)
2020-12-13 10:30:11,327 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_var           loaded from backbone.body.layer2.0.bn2.running_var           of shape (512,)
2020-12-13 10:30:11,327 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                loaded from backbone.body.layer2.0.bn2.weight                of shape (512,)
2020-12-13 10:30:11,327 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                  loaded from backbone.body.layer2.0.bn3.bias                  of shape (512,)
2020-12-13 10:30:11,327 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_mean          loaded from backbone.body.layer2.0.bn3.running_mean          of shape (512,)
2020-12-13 10:30:11,327 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_var           loaded from backbone.body.layer2.0.bn3.running_var           of shape (512,)
2020-12-13 10:30:11,327 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                loaded from backbone.body.layer2.0.bn3.weight                of shape (512,)
2020-12-13 10:30:11,327 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight              loaded from backbone.body.layer2.0.conv1.weight              of shape (512, 256, 1, 1)
2020-12-13 10:30:11,327 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight              loaded from backbone.body.layer2.0.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:30:11,328 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight              loaded from backbone.body.layer2.0.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:30:11,328 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight       loaded from backbone.body.layer2.0.downsample.0.weight       of shape (512, 256, 1, 1)
2020-12-13 10:30:11,328 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias         loaded from backbone.body.layer2.0.downsample.1.bias         of shape (512,)
2020-12-13 10:30:11,328 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_mean loaded from backbone.body.layer2.0.downsample.1.running_mean of shape (512,)
2020-12-13 10:30:11,328 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_var  loaded from backbone.body.layer2.0.downsample.1.running_var  of shape (512,)
2020-12-13 10:30:11,328 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight       loaded from backbone.body.layer2.0.downsample.1.weight       of shape (512,)
2020-12-13 10:30:11,328 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                  loaded from backbone.body.layer2.1.bn1.bias                  of shape (512,)
2020-12-13 10:30:11,328 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_mean          loaded from backbone.body.layer2.1.bn1.running_mean          of shape (512,)
2020-12-13 10:30:11,328 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_var           loaded from backbone.body.layer2.1.bn1.running_var           of shape (512,)
2020-12-13 10:30:11,328 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                loaded from backbone.body.layer2.1.bn1.weight                of shape (512,)
2020-12-13 10:30:11,328 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                  loaded from backbone.body.layer2.1.bn2.bias                  of shape (512,)
2020-12-13 10:30:11,329 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_mean          loaded from backbone.body.layer2.1.bn2.running_mean          of shape (512,)
2020-12-13 10:30:11,329 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_var           loaded from backbone.body.layer2.1.bn2.running_var           of shape (512,)
2020-12-13 10:30:11,329 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                loaded from backbone.body.layer2.1.bn2.weight                of shape (512,)
2020-12-13 10:30:11,329 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                  loaded from backbone.body.layer2.1.bn3.bias                  of shape (512,)
2020-12-13 10:30:11,329 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_mean          loaded from backbone.body.layer2.1.bn3.running_mean          of shape (512,)
2020-12-13 10:30:11,329 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_var           loaded from backbone.body.layer2.1.bn3.running_var           of shape (512,)
2020-12-13 10:30:11,329 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                loaded from backbone.body.layer2.1.bn3.weight                of shape (512,)
2020-12-13 10:30:11,329 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight              loaded from backbone.body.layer2.1.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 10:30:11,329 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight              loaded from backbone.body.layer2.1.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:30:11,329 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight              loaded from backbone.body.layer2.1.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:30:11,329 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                  loaded from backbone.body.layer2.2.bn1.bias                  of shape (512,)
2020-12-13 10:30:11,330 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_mean          loaded from backbone.body.layer2.2.bn1.running_mean          of shape (512,)
2020-12-13 10:30:11,330 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_var           loaded from backbone.body.layer2.2.bn1.running_var           of shape (512,)
2020-12-13 10:30:11,330 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                loaded from backbone.body.layer2.2.bn1.weight                of shape (512,)
2020-12-13 10:30:11,330 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                  loaded from backbone.body.layer2.2.bn2.bias                  of shape (512,)
2020-12-13 10:30:11,330 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_mean          loaded from backbone.body.layer2.2.bn2.running_mean          of shape (512,)
2020-12-13 10:30:11,330 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_var           loaded from backbone.body.layer2.2.bn2.running_var           of shape (512,)
2020-12-13 10:30:11,330 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                loaded from backbone.body.layer2.2.bn2.weight                of shape (512,)
2020-12-13 10:30:11,330 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                  loaded from backbone.body.layer2.2.bn3.bias                  of shape (512,)
2020-12-13 10:30:11,330 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_mean          loaded from backbone.body.layer2.2.bn3.running_mean          of shape (512,)
2020-12-13 10:30:11,330 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_var           loaded from backbone.body.layer2.2.bn3.running_var           of shape (512,)
2020-12-13 10:30:11,330 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                loaded from backbone.body.layer2.2.bn3.weight                of shape (512,)
2020-12-13 10:30:11,331 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight              loaded from backbone.body.layer2.2.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 10:30:11,331 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight              loaded from backbone.body.layer2.2.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:30:11,331 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight              loaded from backbone.body.layer2.2.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:30:11,331 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                  loaded from backbone.body.layer2.3.bn1.bias                  of shape (512,)
2020-12-13 10:30:11,331 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_mean          loaded from backbone.body.layer2.3.bn1.running_mean          of shape (512,)
2020-12-13 10:30:11,331 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_var           loaded from backbone.body.layer2.3.bn1.running_var           of shape (512,)
2020-12-13 10:30:11,331 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                loaded from backbone.body.layer2.3.bn1.weight                of shape (512,)
2020-12-13 10:30:11,331 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                  loaded from backbone.body.layer2.3.bn2.bias                  of shape (512,)
2020-12-13 10:30:11,331 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_mean          loaded from backbone.body.layer2.3.bn2.running_mean          of shape (512,)
2020-12-13 10:30:11,331 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_var           loaded from backbone.body.layer2.3.bn2.running_var           of shape (512,)
2020-12-13 10:30:11,332 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                loaded from backbone.body.layer2.3.bn2.weight                of shape (512,)
2020-12-13 10:30:11,332 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                  loaded from backbone.body.layer2.3.bn3.bias                  of shape (512,)
2020-12-13 10:30:11,332 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_mean          loaded from backbone.body.layer2.3.bn3.running_mean          of shape (512,)
2020-12-13 10:30:11,332 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_var           loaded from backbone.body.layer2.3.bn3.running_var           of shape (512,)
2020-12-13 10:30:11,332 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                loaded from backbone.body.layer2.3.bn3.weight                of shape (512,)
2020-12-13 10:30:11,332 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight              loaded from backbone.body.layer2.3.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 10:30:11,332 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight              loaded from backbone.body.layer2.3.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:30:11,332 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight              loaded from backbone.body.layer2.3.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:30:11,332 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                  loaded from backbone.body.layer3.0.bn1.bias                  of shape (1024,)
2020-12-13 10:30:11,332 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_mean          loaded from backbone.body.layer3.0.bn1.running_mean          of shape (1024,)
2020-12-13 10:30:11,332 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_var           loaded from backbone.body.layer3.0.bn1.running_var           of shape (1024,)
2020-12-13 10:30:11,333 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                loaded from backbone.body.layer3.0.bn1.weight                of shape (1024,)
2020-12-13 10:30:11,333 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                  loaded from backbone.body.layer3.0.bn2.bias                  of shape (1024,)
2020-12-13 10:30:11,333 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_mean          loaded from backbone.body.layer3.0.bn2.running_mean          of shape (1024,)
2020-12-13 10:30:11,333 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_var           loaded from backbone.body.layer3.0.bn2.running_var           of shape (1024,)
2020-12-13 10:30:11,333 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                loaded from backbone.body.layer3.0.bn2.weight                of shape (1024,)
2020-12-13 10:30:11,333 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                  loaded from backbone.body.layer3.0.bn3.bias                  of shape (1024,)
2020-12-13 10:30:11,333 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_mean          loaded from backbone.body.layer3.0.bn3.running_mean          of shape (1024,)
2020-12-13 10:30:11,333 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_var           loaded from backbone.body.layer3.0.bn3.running_var           of shape (1024,)
2020-12-13 10:30:11,333 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                loaded from backbone.body.layer3.0.bn3.weight                of shape (1024,)
2020-12-13 10:30:11,333 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight              loaded from backbone.body.layer3.0.conv1.weight              of shape (1024, 512, 1, 1)
2020-12-13 10:30:11,333 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight              loaded from backbone.body.layer3.0.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,334 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight              loaded from backbone.body.layer3.0.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,334 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight       loaded from backbone.body.layer3.0.downsample.0.weight       of shape (1024, 512, 1, 1)
2020-12-13 10:30:11,334 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias         loaded from backbone.body.layer3.0.downsample.1.bias         of shape (1024,)
2020-12-13 10:30:11,334 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_mean loaded from backbone.body.layer3.0.downsample.1.running_mean of shape (1024,)
2020-12-13 10:30:11,334 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_var  loaded from backbone.body.layer3.0.downsample.1.running_var  of shape (1024,)
2020-12-13 10:30:11,334 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight       loaded from backbone.body.layer3.0.downsample.1.weight       of shape (1024,)
2020-12-13 10:30:11,334 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                  loaded from backbone.body.layer3.1.bn1.bias                  of shape (1024,)
2020-12-13 10:30:11,334 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_mean          loaded from backbone.body.layer3.1.bn1.running_mean          of shape (1024,)
2020-12-13 10:30:11,334 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_var           loaded from backbone.body.layer3.1.bn1.running_var           of shape (1024,)
2020-12-13 10:30:11,334 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                loaded from backbone.body.layer3.1.bn1.weight                of shape (1024,)
2020-12-13 10:30:11,334 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                  loaded from backbone.body.layer3.1.bn2.bias                  of shape (1024,)
2020-12-13 10:30:11,334 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_mean          loaded from backbone.body.layer3.1.bn2.running_mean          of shape (1024,)
2020-12-13 10:30:11,335 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_var           loaded from backbone.body.layer3.1.bn2.running_var           of shape (1024,)
2020-12-13 10:30:11,335 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                loaded from backbone.body.layer3.1.bn2.weight                of shape (1024,)
2020-12-13 10:30:11,335 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                  loaded from backbone.body.layer3.1.bn3.bias                  of shape (1024,)
2020-12-13 10:30:11,335 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_mean          loaded from backbone.body.layer3.1.bn3.running_mean          of shape (1024,)
2020-12-13 10:30:11,335 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_var           loaded from backbone.body.layer3.1.bn3.running_var           of shape (1024,)
2020-12-13 10:30:11,335 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                loaded from backbone.body.layer3.1.bn3.weight                of shape (1024,)
2020-12-13 10:30:11,335 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight              loaded from backbone.body.layer3.1.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,335 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight              loaded from backbone.body.layer3.1.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,335 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight              loaded from backbone.body.layer3.1.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,335 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.bias                 loaded from backbone.body.layer3.10.bn1.bias                 of shape (1024,)
2020-12-13 10:30:11,336 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.running_mean         loaded from backbone.body.layer3.10.bn1.running_mean         of shape (1024,)
2020-12-13 10:30:11,336 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.running_var          loaded from backbone.body.layer3.10.bn1.running_var          of shape (1024,)
2020-12-13 10:30:11,336 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.weight               loaded from backbone.body.layer3.10.bn1.weight               of shape (1024,)
2020-12-13 10:30:11,336 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.bias                 loaded from backbone.body.layer3.10.bn2.bias                 of shape (1024,)
2020-12-13 10:30:11,336 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.running_mean         loaded from backbone.body.layer3.10.bn2.running_mean         of shape (1024,)
2020-12-13 10:30:11,336 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.running_var          loaded from backbone.body.layer3.10.bn2.running_var          of shape (1024,)
2020-12-13 10:30:11,336 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.weight               loaded from backbone.body.layer3.10.bn2.weight               of shape (1024,)
2020-12-13 10:30:11,336 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.bias                 loaded from backbone.body.layer3.10.bn3.bias                 of shape (1024,)
2020-12-13 10:30:11,336 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.running_mean         loaded from backbone.body.layer3.10.bn3.running_mean         of shape (1024,)
2020-12-13 10:30:11,336 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.running_var          loaded from backbone.body.layer3.10.bn3.running_var          of shape (1024,)
2020-12-13 10:30:11,337 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.weight               loaded from backbone.body.layer3.10.bn3.weight               of shape (1024,)
2020-12-13 10:30:11,337 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv1.weight             loaded from backbone.body.layer3.10.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,337 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv2.weight             loaded from backbone.body.layer3.10.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,337 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv3.weight             loaded from backbone.body.layer3.10.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,337 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.bias                 loaded from backbone.body.layer3.11.bn1.bias                 of shape (1024,)
2020-12-13 10:30:11,337 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.running_mean         loaded from backbone.body.layer3.11.bn1.running_mean         of shape (1024,)
2020-12-13 10:30:11,337 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.running_var          loaded from backbone.body.layer3.11.bn1.running_var          of shape (1024,)
2020-12-13 10:30:11,337 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.weight               loaded from backbone.body.layer3.11.bn1.weight               of shape (1024,)
2020-12-13 10:30:11,337 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.bias                 loaded from backbone.body.layer3.11.bn2.bias                 of shape (1024,)
2020-12-13 10:30:11,337 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.running_mean         loaded from backbone.body.layer3.11.bn2.running_mean         of shape (1024,)
2020-12-13 10:30:11,337 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.running_var          loaded from backbone.body.layer3.11.bn2.running_var          of shape (1024,)
2020-12-13 10:30:11,338 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.weight               loaded from backbone.body.layer3.11.bn2.weight               of shape (1024,)
2020-12-13 10:30:11,338 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.bias                 loaded from backbone.body.layer3.11.bn3.bias                 of shape (1024,)
2020-12-13 10:30:11,338 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.running_mean         loaded from backbone.body.layer3.11.bn3.running_mean         of shape (1024,)
2020-12-13 10:30:11,338 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.running_var          loaded from backbone.body.layer3.11.bn3.running_var          of shape (1024,)
2020-12-13 10:30:11,338 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.weight               loaded from backbone.body.layer3.11.bn3.weight               of shape (1024,)
2020-12-13 10:30:11,338 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv1.weight             loaded from backbone.body.layer3.11.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,338 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv2.weight             loaded from backbone.body.layer3.11.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,338 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv3.weight             loaded from backbone.body.layer3.11.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,338 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.bias                 loaded from backbone.body.layer3.12.bn1.bias                 of shape (1024,)
2020-12-13 10:30:11,338 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.running_mean         loaded from backbone.body.layer3.12.bn1.running_mean         of shape (1024,)
2020-12-13 10:30:11,338 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.running_var          loaded from backbone.body.layer3.12.bn1.running_var          of shape (1024,)
2020-12-13 10:30:11,339 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.weight               loaded from backbone.body.layer3.12.bn1.weight               of shape (1024,)
2020-12-13 10:30:11,339 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.bias                 loaded from backbone.body.layer3.12.bn2.bias                 of shape (1024,)
2020-12-13 10:30:11,339 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.running_mean         loaded from backbone.body.layer3.12.bn2.running_mean         of shape (1024,)
2020-12-13 10:30:11,339 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.running_var          loaded from backbone.body.layer3.12.bn2.running_var          of shape (1024,)
2020-12-13 10:30:11,339 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.weight               loaded from backbone.body.layer3.12.bn2.weight               of shape (1024,)
2020-12-13 10:30:11,339 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.bias                 loaded from backbone.body.layer3.12.bn3.bias                 of shape (1024,)
2020-12-13 10:30:11,339 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.running_mean         loaded from backbone.body.layer3.12.bn3.running_mean         of shape (1024,)
2020-12-13 10:30:11,339 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.running_var          loaded from backbone.body.layer3.12.bn3.running_var          of shape (1024,)
2020-12-13 10:30:11,339 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.weight               loaded from backbone.body.layer3.12.bn3.weight               of shape (1024,)
2020-12-13 10:30:11,339 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv1.weight             loaded from backbone.body.layer3.12.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,339 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv2.weight             loaded from backbone.body.layer3.12.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,340 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv3.weight             loaded from backbone.body.layer3.12.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,340 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.bias                 loaded from backbone.body.layer3.13.bn1.bias                 of shape (1024,)
2020-12-13 10:30:11,340 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.running_mean         loaded from backbone.body.layer3.13.bn1.running_mean         of shape (1024,)
2020-12-13 10:30:11,340 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.running_var          loaded from backbone.body.layer3.13.bn1.running_var          of shape (1024,)
2020-12-13 10:30:11,340 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.weight               loaded from backbone.body.layer3.13.bn1.weight               of shape (1024,)
2020-12-13 10:30:11,340 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.bias                 loaded from backbone.body.layer3.13.bn2.bias                 of shape (1024,)
2020-12-13 10:30:11,340 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.running_mean         loaded from backbone.body.layer3.13.bn2.running_mean         of shape (1024,)
2020-12-13 10:30:11,340 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.running_var          loaded from backbone.body.layer3.13.bn2.running_var          of shape (1024,)
2020-12-13 10:30:11,340 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.weight               loaded from backbone.body.layer3.13.bn2.weight               of shape (1024,)
2020-12-13 10:30:11,340 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.bias                 loaded from backbone.body.layer3.13.bn3.bias                 of shape (1024,)
2020-12-13 10:30:11,340 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.running_mean         loaded from backbone.body.layer3.13.bn3.running_mean         of shape (1024,)
2020-12-13 10:30:11,341 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.running_var          loaded from backbone.body.layer3.13.bn3.running_var          of shape (1024,)
2020-12-13 10:30:11,341 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.weight               loaded from backbone.body.layer3.13.bn3.weight               of shape (1024,)
2020-12-13 10:30:11,341 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv1.weight             loaded from backbone.body.layer3.13.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,341 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv2.weight             loaded from backbone.body.layer3.13.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,341 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv3.weight             loaded from backbone.body.layer3.13.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,341 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.bias                 loaded from backbone.body.layer3.14.bn1.bias                 of shape (1024,)
2020-12-13 10:30:11,341 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.running_mean         loaded from backbone.body.layer3.14.bn1.running_mean         of shape (1024,)
2020-12-13 10:30:11,341 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.running_var          loaded from backbone.body.layer3.14.bn1.running_var          of shape (1024,)
2020-12-13 10:30:11,341 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.weight               loaded from backbone.body.layer3.14.bn1.weight               of shape (1024,)
2020-12-13 10:30:11,341 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.bias                 loaded from backbone.body.layer3.14.bn2.bias                 of shape (1024,)
2020-12-13 10:30:11,342 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.running_mean         loaded from backbone.body.layer3.14.bn2.running_mean         of shape (1024,)
2020-12-13 10:30:11,342 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.running_var          loaded from backbone.body.layer3.14.bn2.running_var          of shape (1024,)
2020-12-13 10:30:11,342 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.weight               loaded from backbone.body.layer3.14.bn2.weight               of shape (1024,)
2020-12-13 10:30:11,342 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.bias                 loaded from backbone.body.layer3.14.bn3.bias                 of shape (1024,)
2020-12-13 10:30:11,342 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.running_mean         loaded from backbone.body.layer3.14.bn3.running_mean         of shape (1024,)
2020-12-13 10:30:11,342 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.running_var          loaded from backbone.body.layer3.14.bn3.running_var          of shape (1024,)
2020-12-13 10:30:11,342 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.weight               loaded from backbone.body.layer3.14.bn3.weight               of shape (1024,)
2020-12-13 10:30:11,342 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv1.weight             loaded from backbone.body.layer3.14.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,342 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv2.weight             loaded from backbone.body.layer3.14.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,342 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv3.weight             loaded from backbone.body.layer3.14.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,343 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.bias                 loaded from backbone.body.layer3.15.bn1.bias                 of shape (1024,)
2020-12-13 10:30:11,343 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.running_mean         loaded from backbone.body.layer3.15.bn1.running_mean         of shape (1024,)
2020-12-13 10:30:11,343 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.running_var          loaded from backbone.body.layer3.15.bn1.running_var          of shape (1024,)
2020-12-13 10:30:11,343 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.weight               loaded from backbone.body.layer3.15.bn1.weight               of shape (1024,)
2020-12-13 10:30:11,343 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.bias                 loaded from backbone.body.layer3.15.bn2.bias                 of shape (1024,)
2020-12-13 10:30:11,343 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.running_mean         loaded from backbone.body.layer3.15.bn2.running_mean         of shape (1024,)
2020-12-13 10:30:11,343 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.running_var          loaded from backbone.body.layer3.15.bn2.running_var          of shape (1024,)
2020-12-13 10:30:11,343 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.weight               loaded from backbone.body.layer3.15.bn2.weight               of shape (1024,)
2020-12-13 10:30:11,343 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.bias                 loaded from backbone.body.layer3.15.bn3.bias                 of shape (1024,)
2020-12-13 10:30:11,343 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.running_mean         loaded from backbone.body.layer3.15.bn3.running_mean         of shape (1024,)
2020-12-13 10:30:11,344 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.running_var          loaded from backbone.body.layer3.15.bn3.running_var          of shape (1024,)
2020-12-13 10:30:11,344 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.weight               loaded from backbone.body.layer3.15.bn3.weight               of shape (1024,)
2020-12-13 10:30:11,344 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv1.weight             loaded from backbone.body.layer3.15.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,344 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv2.weight             loaded from backbone.body.layer3.15.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,344 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv3.weight             loaded from backbone.body.layer3.15.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,344 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.bias                 loaded from backbone.body.layer3.16.bn1.bias                 of shape (1024,)
2020-12-13 10:30:11,344 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.running_mean         loaded from backbone.body.layer3.16.bn1.running_mean         of shape (1024,)
2020-12-13 10:30:11,344 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.running_var          loaded from backbone.body.layer3.16.bn1.running_var          of shape (1024,)
2020-12-13 10:30:11,344 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.weight               loaded from backbone.body.layer3.16.bn1.weight               of shape (1024,)
2020-12-13 10:30:11,344 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.bias                 loaded from backbone.body.layer3.16.bn2.bias                 of shape (1024,)
2020-12-13 10:30:11,345 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.running_mean         loaded from backbone.body.layer3.16.bn2.running_mean         of shape (1024,)
2020-12-13 10:30:11,345 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.running_var          loaded from backbone.body.layer3.16.bn2.running_var          of shape (1024,)
2020-12-13 10:30:11,345 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.weight               loaded from backbone.body.layer3.16.bn2.weight               of shape (1024,)
2020-12-13 10:30:11,345 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.bias                 loaded from backbone.body.layer3.16.bn3.bias                 of shape (1024,)
2020-12-13 10:30:11,345 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.running_mean         loaded from backbone.body.layer3.16.bn3.running_mean         of shape (1024,)
2020-12-13 10:30:11,345 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.running_var          loaded from backbone.body.layer3.16.bn3.running_var          of shape (1024,)
2020-12-13 10:30:11,345 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.weight               loaded from backbone.body.layer3.16.bn3.weight               of shape (1024,)
2020-12-13 10:30:11,345 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv1.weight             loaded from backbone.body.layer3.16.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,345 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv2.weight             loaded from backbone.body.layer3.16.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,345 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv3.weight             loaded from backbone.body.layer3.16.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,346 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.bias                 loaded from backbone.body.layer3.17.bn1.bias                 of shape (1024,)
2020-12-13 10:30:11,346 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.running_mean         loaded from backbone.body.layer3.17.bn1.running_mean         of shape (1024,)
2020-12-13 10:30:11,346 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.running_var          loaded from backbone.body.layer3.17.bn1.running_var          of shape (1024,)
2020-12-13 10:30:11,346 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.weight               loaded from backbone.body.layer3.17.bn1.weight               of shape (1024,)
2020-12-13 10:30:11,346 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.bias                 loaded from backbone.body.layer3.17.bn2.bias                 of shape (1024,)
2020-12-13 10:30:11,346 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.running_mean         loaded from backbone.body.layer3.17.bn2.running_mean         of shape (1024,)
2020-12-13 10:30:11,346 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.running_var          loaded from backbone.body.layer3.17.bn2.running_var          of shape (1024,)
2020-12-13 10:30:11,346 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.weight               loaded from backbone.body.layer3.17.bn2.weight               of shape (1024,)
2020-12-13 10:30:11,346 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.bias                 loaded from backbone.body.layer3.17.bn3.bias                 of shape (1024,)
2020-12-13 10:30:11,346 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.running_mean         loaded from backbone.body.layer3.17.bn3.running_mean         of shape (1024,)
2020-12-13 10:30:11,347 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.running_var          loaded from backbone.body.layer3.17.bn3.running_var          of shape (1024,)
2020-12-13 10:30:11,347 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.weight               loaded from backbone.body.layer3.17.bn3.weight               of shape (1024,)
2020-12-13 10:30:11,347 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv1.weight             loaded from backbone.body.layer3.17.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,347 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv2.weight             loaded from backbone.body.layer3.17.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,347 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv3.weight             loaded from backbone.body.layer3.17.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,347 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.bias                 loaded from backbone.body.layer3.18.bn1.bias                 of shape (1024,)
2020-12-13 10:30:11,347 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.running_mean         loaded from backbone.body.layer3.18.bn1.running_mean         of shape (1024,)
2020-12-13 10:30:11,347 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.running_var          loaded from backbone.body.layer3.18.bn1.running_var          of shape (1024,)
2020-12-13 10:30:11,347 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.weight               loaded from backbone.body.layer3.18.bn1.weight               of shape (1024,)
2020-12-13 10:30:11,347 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.bias                 loaded from backbone.body.layer3.18.bn2.bias                 of shape (1024,)
2020-12-13 10:30:11,347 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.running_mean         loaded from backbone.body.layer3.18.bn2.running_mean         of shape (1024,)
2020-12-13 10:30:11,347 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.running_var          loaded from backbone.body.layer3.18.bn2.running_var          of shape (1024,)
2020-12-13 10:30:11,348 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.weight               loaded from backbone.body.layer3.18.bn2.weight               of shape (1024,)
2020-12-13 10:30:11,348 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.bias                 loaded from backbone.body.layer3.18.bn3.bias                 of shape (1024,)
2020-12-13 10:30:11,348 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.running_mean         loaded from backbone.body.layer3.18.bn3.running_mean         of shape (1024,)
2020-12-13 10:30:11,348 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.running_var          loaded from backbone.body.layer3.18.bn3.running_var          of shape (1024,)
2020-12-13 10:30:11,348 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.weight               loaded from backbone.body.layer3.18.bn3.weight               of shape (1024,)
2020-12-13 10:30:11,348 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv1.weight             loaded from backbone.body.layer3.18.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,348 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv2.weight             loaded from backbone.body.layer3.18.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,348 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv3.weight             loaded from backbone.body.layer3.18.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,348 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.bias                 loaded from backbone.body.layer3.19.bn1.bias                 of shape (1024,)
2020-12-13 10:30:11,348 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.running_mean         loaded from backbone.body.layer3.19.bn1.running_mean         of shape (1024,)
2020-12-13 10:30:11,349 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.running_var          loaded from backbone.body.layer3.19.bn1.running_var          of shape (1024,)
2020-12-13 10:30:11,349 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.weight               loaded from backbone.body.layer3.19.bn1.weight               of shape (1024,)
2020-12-13 10:30:11,349 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.bias                 loaded from backbone.body.layer3.19.bn2.bias                 of shape (1024,)
2020-12-13 10:30:11,349 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.running_mean         loaded from backbone.body.layer3.19.bn2.running_mean         of shape (1024,)
2020-12-13 10:30:11,349 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.running_var          loaded from backbone.body.layer3.19.bn2.running_var          of shape (1024,)
2020-12-13 10:30:11,349 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.weight               loaded from backbone.body.layer3.19.bn2.weight               of shape (1024,)
2020-12-13 10:30:11,349 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.bias                 loaded from backbone.body.layer3.19.bn3.bias                 of shape (1024,)
2020-12-13 10:30:11,349 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.running_mean         loaded from backbone.body.layer3.19.bn3.running_mean         of shape (1024,)
2020-12-13 10:30:11,349 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.running_var          loaded from backbone.body.layer3.19.bn3.running_var          of shape (1024,)
2020-12-13 10:30:11,350 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.weight               loaded from backbone.body.layer3.19.bn3.weight               of shape (1024,)
2020-12-13 10:30:11,350 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv1.weight             loaded from backbone.body.layer3.19.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,350 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv2.weight             loaded from backbone.body.layer3.19.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,350 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv3.weight             loaded from backbone.body.layer3.19.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,350 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                  loaded from backbone.body.layer3.2.bn1.bias                  of shape (1024,)
2020-12-13 10:30:11,350 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_mean          loaded from backbone.body.layer3.2.bn1.running_mean          of shape (1024,)
2020-12-13 10:30:11,350 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_var           loaded from backbone.body.layer3.2.bn1.running_var           of shape (1024,)
2020-12-13 10:30:11,350 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                loaded from backbone.body.layer3.2.bn1.weight                of shape (1024,)
2020-12-13 10:30:11,350 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                  loaded from backbone.body.layer3.2.bn2.bias                  of shape (1024,)
2020-12-13 10:30:11,350 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_mean          loaded from backbone.body.layer3.2.bn2.running_mean          of shape (1024,)
2020-12-13 10:30:11,351 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_var           loaded from backbone.body.layer3.2.bn2.running_var           of shape (1024,)
2020-12-13 10:30:11,351 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                loaded from backbone.body.layer3.2.bn2.weight                of shape (1024,)
2020-12-13 10:30:11,351 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                  loaded from backbone.body.layer3.2.bn3.bias                  of shape (1024,)
2020-12-13 10:30:11,351 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_mean          loaded from backbone.body.layer3.2.bn3.running_mean          of shape (1024,)
2020-12-13 10:30:11,351 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_var           loaded from backbone.body.layer3.2.bn3.running_var           of shape (1024,)
2020-12-13 10:30:11,351 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                loaded from backbone.body.layer3.2.bn3.weight                of shape (1024,)
2020-12-13 10:30:11,351 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight              loaded from backbone.body.layer3.2.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,351 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight              loaded from backbone.body.layer3.2.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,351 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight              loaded from backbone.body.layer3.2.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,351 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.bias                 loaded from backbone.body.layer3.20.bn1.bias                 of shape (1024,)
2020-12-13 10:30:11,351 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.running_mean         loaded from backbone.body.layer3.20.bn1.running_mean         of shape (1024,)
2020-12-13 10:30:11,351 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.running_var          loaded from backbone.body.layer3.20.bn1.running_var          of shape (1024,)
2020-12-13 10:30:11,352 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.weight               loaded from backbone.body.layer3.20.bn1.weight               of shape (1024,)
2020-12-13 10:30:11,352 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.bias                 loaded from backbone.body.layer3.20.bn2.bias                 of shape (1024,)
2020-12-13 10:30:11,352 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.running_mean         loaded from backbone.body.layer3.20.bn2.running_mean         of shape (1024,)
2020-12-13 10:30:11,352 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.running_var          loaded from backbone.body.layer3.20.bn2.running_var          of shape (1024,)
2020-12-13 10:30:11,352 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.weight               loaded from backbone.body.layer3.20.bn2.weight               of shape (1024,)
2020-12-13 10:30:11,352 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.bias                 loaded from backbone.body.layer3.20.bn3.bias                 of shape (1024,)
2020-12-13 10:30:11,352 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.running_mean         loaded from backbone.body.layer3.20.bn3.running_mean         of shape (1024,)
2020-12-13 10:30:11,352 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.running_var          loaded from backbone.body.layer3.20.bn3.running_var          of shape (1024,)
2020-12-13 10:30:11,352 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.weight               loaded from backbone.body.layer3.20.bn3.weight               of shape (1024,)
2020-12-13 10:30:11,352 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv1.weight             loaded from backbone.body.layer3.20.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,352 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv2.weight             loaded from backbone.body.layer3.20.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,353 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv3.weight             loaded from backbone.body.layer3.20.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,353 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.bias                 loaded from backbone.body.layer3.21.bn1.bias                 of shape (1024,)
2020-12-13 10:30:11,353 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.running_mean         loaded from backbone.body.layer3.21.bn1.running_mean         of shape (1024,)
2020-12-13 10:30:11,353 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.running_var          loaded from backbone.body.layer3.21.bn1.running_var          of shape (1024,)
2020-12-13 10:30:11,353 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.weight               loaded from backbone.body.layer3.21.bn1.weight               of shape (1024,)
2020-12-13 10:30:11,353 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.bias                 loaded from backbone.body.layer3.21.bn2.bias                 of shape (1024,)
2020-12-13 10:30:11,353 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.running_mean         loaded from backbone.body.layer3.21.bn2.running_mean         of shape (1024,)
2020-12-13 10:30:11,353 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.running_var          loaded from backbone.body.layer3.21.bn2.running_var          of shape (1024,)
2020-12-13 10:30:11,353 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.weight               loaded from backbone.body.layer3.21.bn2.weight               of shape (1024,)
2020-12-13 10:30:11,353 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.bias                 loaded from backbone.body.layer3.21.bn3.bias                 of shape (1024,)
2020-12-13 10:30:11,354 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.running_mean         loaded from backbone.body.layer3.21.bn3.running_mean         of shape (1024,)
2020-12-13 10:30:11,354 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.running_var          loaded from backbone.body.layer3.21.bn3.running_var          of shape (1024,)
2020-12-13 10:30:11,354 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.weight               loaded from backbone.body.layer3.21.bn3.weight               of shape (1024,)
2020-12-13 10:30:11,354 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv1.weight             loaded from backbone.body.layer3.21.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,354 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv2.weight             loaded from backbone.body.layer3.21.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,354 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv3.weight             loaded from backbone.body.layer3.21.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,354 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.bias                 loaded from backbone.body.layer3.22.bn1.bias                 of shape (1024,)
2020-12-13 10:30:11,354 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.running_mean         loaded from backbone.body.layer3.22.bn1.running_mean         of shape (1024,)
2020-12-13 10:30:11,354 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.running_var          loaded from backbone.body.layer3.22.bn1.running_var          of shape (1024,)
2020-12-13 10:30:11,354 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.weight               loaded from backbone.body.layer3.22.bn1.weight               of shape (1024,)
2020-12-13 10:30:11,355 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.bias                 loaded from backbone.body.layer3.22.bn2.bias                 of shape (1024,)
2020-12-13 10:30:11,355 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.running_mean         loaded from backbone.body.layer3.22.bn2.running_mean         of shape (1024,)
2020-12-13 10:30:11,355 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.running_var          loaded from backbone.body.layer3.22.bn2.running_var          of shape (1024,)
2020-12-13 10:30:11,355 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.weight               loaded from backbone.body.layer3.22.bn2.weight               of shape (1024,)
2020-12-13 10:30:11,355 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.bias                 loaded from backbone.body.layer3.22.bn3.bias                 of shape (1024,)
2020-12-13 10:30:11,355 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.running_mean         loaded from backbone.body.layer3.22.bn3.running_mean         of shape (1024,)
2020-12-13 10:30:11,355 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.running_var          loaded from backbone.body.layer3.22.bn3.running_var          of shape (1024,)
2020-12-13 10:30:11,355 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.weight               loaded from backbone.body.layer3.22.bn3.weight               of shape (1024,)
2020-12-13 10:30:11,355 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv1.weight             loaded from backbone.body.layer3.22.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,355 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv2.weight             loaded from backbone.body.layer3.22.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,355 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv3.weight             loaded from backbone.body.layer3.22.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,355 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                  loaded from backbone.body.layer3.3.bn1.bias                  of shape (1024,)
2020-12-13 10:30:11,356 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_mean          loaded from backbone.body.layer3.3.bn1.running_mean          of shape (1024,)
2020-12-13 10:30:11,356 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_var           loaded from backbone.body.layer3.3.bn1.running_var           of shape (1024,)
2020-12-13 10:30:11,356 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                loaded from backbone.body.layer3.3.bn1.weight                of shape (1024,)
2020-12-13 10:30:11,356 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                  loaded from backbone.body.layer3.3.bn2.bias                  of shape (1024,)
2020-12-13 10:30:11,356 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_mean          loaded from backbone.body.layer3.3.bn2.running_mean          of shape (1024,)
2020-12-13 10:30:11,356 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_var           loaded from backbone.body.layer3.3.bn2.running_var           of shape (1024,)
2020-12-13 10:30:11,356 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                loaded from backbone.body.layer3.3.bn2.weight                of shape (1024,)
2020-12-13 10:30:11,356 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                  loaded from backbone.body.layer3.3.bn3.bias                  of shape (1024,)
2020-12-13 10:30:11,356 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_mean          loaded from backbone.body.layer3.3.bn3.running_mean          of shape (1024,)
2020-12-13 10:30:11,356 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_var           loaded from backbone.body.layer3.3.bn3.running_var           of shape (1024,)
2020-12-13 10:30:11,356 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                loaded from backbone.body.layer3.3.bn3.weight                of shape (1024,)
2020-12-13 10:30:11,357 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight              loaded from backbone.body.layer3.3.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,357 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight              loaded from backbone.body.layer3.3.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,357 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight              loaded from backbone.body.layer3.3.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,357 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                  loaded from backbone.body.layer3.4.bn1.bias                  of shape (1024,)
2020-12-13 10:30:11,357 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_mean          loaded from backbone.body.layer3.4.bn1.running_mean          of shape (1024,)
2020-12-13 10:30:11,357 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_var           loaded from backbone.body.layer3.4.bn1.running_var           of shape (1024,)
2020-12-13 10:30:11,357 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                loaded from backbone.body.layer3.4.bn1.weight                of shape (1024,)
2020-12-13 10:30:11,357 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                  loaded from backbone.body.layer3.4.bn2.bias                  of shape (1024,)
2020-12-13 10:30:11,357 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_mean          loaded from backbone.body.layer3.4.bn2.running_mean          of shape (1024,)
2020-12-13 10:30:11,357 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_var           loaded from backbone.body.layer3.4.bn2.running_var           of shape (1024,)
2020-12-13 10:30:11,357 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                loaded from backbone.body.layer3.4.bn2.weight                of shape (1024,)
2020-12-13 10:30:11,357 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                  loaded from backbone.body.layer3.4.bn3.bias                  of shape (1024,)
2020-12-13 10:30:11,358 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_mean          loaded from backbone.body.layer3.4.bn3.running_mean          of shape (1024,)
2020-12-13 10:30:11,358 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_var           loaded from backbone.body.layer3.4.bn3.running_var           of shape (1024,)
2020-12-13 10:30:11,358 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                loaded from backbone.body.layer3.4.bn3.weight                of shape (1024,)
2020-12-13 10:30:11,358 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight              loaded from backbone.body.layer3.4.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,358 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight              loaded from backbone.body.layer3.4.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,358 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight              loaded from backbone.body.layer3.4.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,358 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                  loaded from backbone.body.layer3.5.bn1.bias                  of shape (1024,)
2020-12-13 10:30:11,358 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_mean          loaded from backbone.body.layer3.5.bn1.running_mean          of shape (1024,)
2020-12-13 10:30:11,358 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_var           loaded from backbone.body.layer3.5.bn1.running_var           of shape (1024,)
2020-12-13 10:30:11,358 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                loaded from backbone.body.layer3.5.bn1.weight                of shape (1024,)
2020-12-13 10:30:11,359 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                  loaded from backbone.body.layer3.5.bn2.bias                  of shape (1024,)
2020-12-13 10:30:11,359 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_mean          loaded from backbone.body.layer3.5.bn2.running_mean          of shape (1024,)
2020-12-13 10:30:11,359 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_var           loaded from backbone.body.layer3.5.bn2.running_var           of shape (1024,)
2020-12-13 10:30:11,359 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                loaded from backbone.body.layer3.5.bn2.weight                of shape (1024,)
2020-12-13 10:30:11,359 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                  loaded from backbone.body.layer3.5.bn3.bias                  of shape (1024,)
2020-12-13 10:30:11,359 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_mean          loaded from backbone.body.layer3.5.bn3.running_mean          of shape (1024,)
2020-12-13 10:30:11,359 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_var           loaded from backbone.body.layer3.5.bn3.running_var           of shape (1024,)
2020-12-13 10:30:11,359 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                loaded from backbone.body.layer3.5.bn3.weight                of shape (1024,)
2020-12-13 10:30:11,359 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight              loaded from backbone.body.layer3.5.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,359 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight              loaded from backbone.body.layer3.5.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,359 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight              loaded from backbone.body.layer3.5.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,360 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.bias                  loaded from backbone.body.layer3.6.bn1.bias                  of shape (1024,)
2020-12-13 10:30:11,360 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.running_mean          loaded from backbone.body.layer3.6.bn1.running_mean          of shape (1024,)
2020-12-13 10:30:11,360 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.running_var           loaded from backbone.body.layer3.6.bn1.running_var           of shape (1024,)
2020-12-13 10:30:11,360 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.weight                loaded from backbone.body.layer3.6.bn1.weight                of shape (1024,)
2020-12-13 10:30:11,360 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.bias                  loaded from backbone.body.layer3.6.bn2.bias                  of shape (1024,)
2020-12-13 10:30:11,360 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.running_mean          loaded from backbone.body.layer3.6.bn2.running_mean          of shape (1024,)
2020-12-13 10:30:11,360 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.running_var           loaded from backbone.body.layer3.6.bn2.running_var           of shape (1024,)
2020-12-13 10:30:11,360 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.weight                loaded from backbone.body.layer3.6.bn2.weight                of shape (1024,)
2020-12-13 10:30:11,360 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.bias                  loaded from backbone.body.layer3.6.bn3.bias                  of shape (1024,)
2020-12-13 10:30:11,360 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.running_mean          loaded from backbone.body.layer3.6.bn3.running_mean          of shape (1024,)
2020-12-13 10:30:11,361 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.running_var           loaded from backbone.body.layer3.6.bn3.running_var           of shape (1024,)
2020-12-13 10:30:11,361 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.weight                loaded from backbone.body.layer3.6.bn3.weight                of shape (1024,)
2020-12-13 10:30:11,361 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv1.weight              loaded from backbone.body.layer3.6.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,361 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv2.weight              loaded from backbone.body.layer3.6.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,361 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv3.weight              loaded from backbone.body.layer3.6.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,361 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.bias                  loaded from backbone.body.layer3.7.bn1.bias                  of shape (1024,)
2020-12-13 10:30:11,361 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.running_mean          loaded from backbone.body.layer3.7.bn1.running_mean          of shape (1024,)
2020-12-13 10:30:11,361 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.running_var           loaded from backbone.body.layer3.7.bn1.running_var           of shape (1024,)
2020-12-13 10:30:11,361 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.weight                loaded from backbone.body.layer3.7.bn1.weight                of shape (1024,)
2020-12-13 10:30:11,361 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.bias                  loaded from backbone.body.layer3.7.bn2.bias                  of shape (1024,)
2020-12-13 10:30:11,362 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.running_mean          loaded from backbone.body.layer3.7.bn2.running_mean          of shape (1024,)
2020-12-13 10:30:11,362 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.running_var           loaded from backbone.body.layer3.7.bn2.running_var           of shape (1024,)
2020-12-13 10:30:11,362 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.weight                loaded from backbone.body.layer3.7.bn2.weight                of shape (1024,)
2020-12-13 10:30:11,362 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.bias                  loaded from backbone.body.layer3.7.bn3.bias                  of shape (1024,)
2020-12-13 10:30:11,362 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.running_mean          loaded from backbone.body.layer3.7.bn3.running_mean          of shape (1024,)
2020-12-13 10:30:11,362 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.running_var           loaded from backbone.body.layer3.7.bn3.running_var           of shape (1024,)
2020-12-13 10:30:11,362 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.weight                loaded from backbone.body.layer3.7.bn3.weight                of shape (1024,)
2020-12-13 10:30:11,362 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv1.weight              loaded from backbone.body.layer3.7.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,362 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv2.weight              loaded from backbone.body.layer3.7.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,362 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv3.weight              loaded from backbone.body.layer3.7.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,363 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.bias                  loaded from backbone.body.layer3.8.bn1.bias                  of shape (1024,)
2020-12-13 10:30:11,363 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.running_mean          loaded from backbone.body.layer3.8.bn1.running_mean          of shape (1024,)
2020-12-13 10:30:11,363 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.running_var           loaded from backbone.body.layer3.8.bn1.running_var           of shape (1024,)
2020-12-13 10:30:11,363 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.weight                loaded from backbone.body.layer3.8.bn1.weight                of shape (1024,)
2020-12-13 10:30:11,363 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.bias                  loaded from backbone.body.layer3.8.bn2.bias                  of shape (1024,)
2020-12-13 10:30:11,363 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.running_mean          loaded from backbone.body.layer3.8.bn2.running_mean          of shape (1024,)
2020-12-13 10:30:11,363 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.running_var           loaded from backbone.body.layer3.8.bn2.running_var           of shape (1024,)
2020-12-13 10:30:11,363 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.weight                loaded from backbone.body.layer3.8.bn2.weight                of shape (1024,)
2020-12-13 10:30:11,363 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.bias                  loaded from backbone.body.layer3.8.bn3.bias                  of shape (1024,)
2020-12-13 10:30:11,364 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.running_mean          loaded from backbone.body.layer3.8.bn3.running_mean          of shape (1024,)
2020-12-13 10:30:11,364 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.running_var           loaded from backbone.body.layer3.8.bn3.running_var           of shape (1024,)
2020-12-13 10:30:11,364 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.weight                loaded from backbone.body.layer3.8.bn3.weight                of shape (1024,)
2020-12-13 10:30:11,364 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv1.weight              loaded from backbone.body.layer3.8.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,364 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv2.weight              loaded from backbone.body.layer3.8.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,364 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv3.weight              loaded from backbone.body.layer3.8.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,364 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.bias                  loaded from backbone.body.layer3.9.bn1.bias                  of shape (1024,)
2020-12-13 10:30:11,364 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.running_mean          loaded from backbone.body.layer3.9.bn1.running_mean          of shape (1024,)
2020-12-13 10:30:11,364 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.running_var           loaded from backbone.body.layer3.9.bn1.running_var           of shape (1024,)
2020-12-13 10:30:11,364 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.weight                loaded from backbone.body.layer3.9.bn1.weight                of shape (1024,)
2020-12-13 10:30:11,365 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.bias                  loaded from backbone.body.layer3.9.bn2.bias                  of shape (1024,)
2020-12-13 10:30:11,365 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.running_mean          loaded from backbone.body.layer3.9.bn2.running_mean          of shape (1024,)
2020-12-13 10:30:11,365 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.running_var           loaded from backbone.body.layer3.9.bn2.running_var           of shape (1024,)
2020-12-13 10:30:11,365 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.weight                loaded from backbone.body.layer3.9.bn2.weight                of shape (1024,)
2020-12-13 10:30:11,365 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.bias                  loaded from backbone.body.layer3.9.bn3.bias                  of shape (1024,)
2020-12-13 10:30:11,365 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.running_mean          loaded from backbone.body.layer3.9.bn3.running_mean          of shape (1024,)
2020-12-13 10:30:11,365 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.running_var           loaded from backbone.body.layer3.9.bn3.running_var           of shape (1024,)
2020-12-13 10:30:11,365 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.weight                loaded from backbone.body.layer3.9.bn3.weight                of shape (1024,)
2020-12-13 10:30:11,365 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv1.weight              loaded from backbone.body.layer3.9.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,365 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv2.weight              loaded from backbone.body.layer3.9.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:30:11,366 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv3.weight              loaded from backbone.body.layer3.9.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:30:11,366 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                  loaded from backbone.body.layer4.0.bn1.bias                  of shape (2048,)
2020-12-13 10:30:11,366 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_mean          loaded from backbone.body.layer4.0.bn1.running_mean          of shape (2048,)
2020-12-13 10:30:11,366 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_var           loaded from backbone.body.layer4.0.bn1.running_var           of shape (2048,)
2020-12-13 10:30:11,366 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                loaded from backbone.body.layer4.0.bn1.weight                of shape (2048,)
2020-12-13 10:30:11,366 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                  loaded from backbone.body.layer4.0.bn2.bias                  of shape (2048,)
2020-12-13 10:30:11,366 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_mean          loaded from backbone.body.layer4.0.bn2.running_mean          of shape (2048,)
2020-12-13 10:30:11,366 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_var           loaded from backbone.body.layer4.0.bn2.running_var           of shape (2048,)
2020-12-13 10:30:11,366 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                loaded from backbone.body.layer4.0.bn2.weight                of shape (2048,)
2020-12-13 10:30:11,366 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                  loaded from backbone.body.layer4.0.bn3.bias                  of shape (2048,)
2020-12-13 10:30:11,367 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_mean          loaded from backbone.body.layer4.0.bn3.running_mean          of shape (2048,)
2020-12-13 10:30:11,367 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_var           loaded from backbone.body.layer4.0.bn3.running_var           of shape (2048,)
2020-12-13 10:30:11,367 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                loaded from backbone.body.layer4.0.bn3.weight                of shape (2048,)
2020-12-13 10:30:11,367 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight              loaded from backbone.body.layer4.0.conv1.weight              of shape (2048, 1024, 1, 1)
2020-12-13 10:30:11,367 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv2.weight              loaded from backbone.body.layer4.0.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 10:30:11,367 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight              loaded from backbone.body.layer4.0.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:30:11,367 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight       loaded from backbone.body.layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)
2020-12-13 10:30:11,367 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias         loaded from backbone.body.layer4.0.downsample.1.bias         of shape (2048,)
2020-12-13 10:30:11,367 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_mean loaded from backbone.body.layer4.0.downsample.1.running_mean of shape (2048,)
2020-12-13 10:30:11,367 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_var  loaded from backbone.body.layer4.0.downsample.1.running_var  of shape (2048,)
2020-12-13 10:30:11,368 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight       loaded from backbone.body.layer4.0.downsample.1.weight       of shape (2048,)
2020-12-13 10:30:11,368 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                  loaded from backbone.body.layer4.1.bn1.bias                  of shape (2048,)
2020-12-13 10:30:11,368 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_mean          loaded from backbone.body.layer4.1.bn1.running_mean          of shape (2048,)
2020-12-13 10:30:11,368 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_var           loaded from backbone.body.layer4.1.bn1.running_var           of shape (2048,)
2020-12-13 10:30:11,368 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                loaded from backbone.body.layer4.1.bn1.weight                of shape (2048,)
2020-12-13 10:30:11,368 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                  loaded from backbone.body.layer4.1.bn2.bias                  of shape (2048,)
2020-12-13 10:30:11,368 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_mean          loaded from backbone.body.layer4.1.bn2.running_mean          of shape (2048,)
2020-12-13 10:30:11,368 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_var           loaded from backbone.body.layer4.1.bn2.running_var           of shape (2048,)
2020-12-13 10:30:11,368 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                loaded from backbone.body.layer4.1.bn2.weight                of shape (2048,)
2020-12-13 10:30:11,368 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                  loaded from backbone.body.layer4.1.bn3.bias                  of shape (2048,)
2020-12-13 10:30:11,369 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_mean          loaded from backbone.body.layer4.1.bn3.running_mean          of shape (2048,)
2020-12-13 10:30:11,369 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_var           loaded from backbone.body.layer4.1.bn3.running_var           of shape (2048,)
2020-12-13 10:30:11,369 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                loaded from backbone.body.layer4.1.bn3.weight                of shape (2048,)
2020-12-13 10:30:11,369 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight              loaded from backbone.body.layer4.1.conv1.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:30:11,369 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv2.weight              loaded from backbone.body.layer4.1.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 10:30:11,369 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight              loaded from backbone.body.layer4.1.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:30:11,369 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                  loaded from backbone.body.layer4.2.bn1.bias                  of shape (2048,)
2020-12-13 10:30:11,369 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_mean          loaded from backbone.body.layer4.2.bn1.running_mean          of shape (2048,)
2020-12-13 10:30:11,369 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_var           loaded from backbone.body.layer4.2.bn1.running_var           of shape (2048,)
2020-12-13 10:30:11,369 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                loaded from backbone.body.layer4.2.bn1.weight                of shape (2048,)
2020-12-13 10:30:11,369 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                  loaded from backbone.body.layer4.2.bn2.bias                  of shape (2048,)
2020-12-13 10:30:11,370 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_mean          loaded from backbone.body.layer4.2.bn2.running_mean          of shape (2048,)
2020-12-13 10:30:11,370 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_var           loaded from backbone.body.layer4.2.bn2.running_var           of shape (2048,)
2020-12-13 10:30:11,370 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                loaded from backbone.body.layer4.2.bn2.weight                of shape (2048,)
2020-12-13 10:30:11,370 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                  loaded from backbone.body.layer4.2.bn3.bias                  of shape (2048,)
2020-12-13 10:30:11,370 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_mean          loaded from backbone.body.layer4.2.bn3.running_mean          of shape (2048,)
2020-12-13 10:30:11,370 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_var           loaded from backbone.body.layer4.2.bn3.running_var           of shape (2048,)
2020-12-13 10:30:11,370 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                loaded from backbone.body.layer4.2.bn3.weight                of shape (2048,)
2020-12-13 10:30:11,370 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight              loaded from backbone.body.layer4.2.conv1.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:30:11,370 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv2.weight              loaded from backbone.body.layer4.2.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 10:30:11,370 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight              loaded from backbone.body.layer4.2.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:30:11,370 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                      loaded from backbone.body.stem.bn1.bias                      of shape (64,)
2020-12-13 10:30:11,371 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_mean              loaded from backbone.body.stem.bn1.running_mean              of shape (64,)
2020-12-13 10:30:11,371 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_var               loaded from backbone.body.stem.bn1.running_var               of shape (64,)
2020-12-13 10:30:11,371 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                    loaded from backbone.body.stem.bn1.weight                    of shape (64,)
2020-12-13 10:30:11,371 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                  loaded from backbone.body.stem.conv1.weight                  of shape (64, 3, 7, 7)
2020-12-13 10:30:11,371 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.bias                     loaded from backbone.fpn.fpn_inner1.bias                     of shape (256,)
2020-12-13 10:30:11,371 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.weight                   loaded from backbone.fpn.fpn_inner1.weight                   of shape (256, 256, 1, 1)
2020-12-13 10:30:11,371 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                     loaded from backbone.fpn.fpn_inner2.bias                     of shape (256,)
2020-12-13 10:30:11,371 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                   loaded from backbone.fpn.fpn_inner2.weight                   of shape (256, 512, 1, 1)
2020-12-13 10:30:11,371 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                     loaded from backbone.fpn.fpn_inner3.bias                     of shape (256,)
2020-12-13 10:30:11,371 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                   loaded from backbone.fpn.fpn_inner3.weight                   of shape (256, 1024, 1, 1)
2020-12-13 10:30:11,372 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                     loaded from backbone.fpn.fpn_inner4.bias                     of shape (256,)
2020-12-13 10:30:11,372 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                   loaded from backbone.fpn.fpn_inner4.weight                   of shape (256, 2048, 1, 1)
2020-12-13 10:30:11,372 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.bias                     loaded from backbone.fpn.fpn_layer1.bias                     of shape (256,)
2020-12-13 10:30:11,372 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.weight                   loaded from backbone.fpn.fpn_layer1.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:30:11,372 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                     loaded from backbone.fpn.fpn_layer2.bias                     of shape (256,)
2020-12-13 10:30:11,372 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                   loaded from backbone.fpn.fpn_layer2.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:30:11,372 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                     loaded from backbone.fpn.fpn_layer3.bias                     of shape (256,)
2020-12-13 10:30:11,372 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                   loaded from backbone.fpn.fpn_layer3.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:30:11,372 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                     loaded from backbone.fpn.fpn_layer4.bias                     of shape (256,)
2020-12-13 10:30:11,372 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                   loaded from backbone.fpn.fpn_layer4.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:30:11,372 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.bias         loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (1024,)
2020-12-13 10:30:11,372 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.weight       loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (1024, 12544)
2020-12-13 10:30:11,373 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.bias         loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (1024,)
2020-12-13 10:30:11,373 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.weight       loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (1024, 1024)
2020-12-13 10:30:11,373 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.bias           loaded from roi_heads.box.predictor.bbox_pred.bias           of shape (324,)
2020-12-13 10:30:11,373 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.weight         loaded from roi_heads.box.predictor.bbox_pred.weight         of shape (324, 1024)
2020-12-13 10:30:11,373 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.bias           loaded from roi_heads.box.predictor.cls_score.bias           of shape (81,)
2020-12-13 10:30:11,373 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.weight         loaded from roi_heads.box.predictor.cls_score.weight         of shape (81, 1024)
2020-12-13 10:30:11,373 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.0              loaded from rpn.anchor_generator.cell_anchors.0              of shape (3, 4)
2020-12-13 10:30:11,373 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.1              loaded from rpn.anchor_generator.cell_anchors.1              of shape (3, 4)
2020-12-13 10:30:11,373 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.2              loaded from rpn.anchor_generator.cell_anchors.2              of shape (3, 4)
2020-12-13 10:30:11,373 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.3              loaded from rpn.anchor_generator.cell_anchors.3              of shape (3, 4)
2020-12-13 10:30:11,373 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.4              loaded from rpn.anchor_generator.cell_anchors.4              of shape (3, 4)
2020-12-13 10:30:11,374 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                          loaded from rpn.head.bbox_pred.bias                          of shape (12,)
2020-12-13 10:30:11,374 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                        loaded from rpn.head.bbox_pred.weight                        of shape (12, 256, 1, 1)
2020-12-13 10:30:11,374 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                         loaded from rpn.head.cls_logits.bias                         of shape (3,)
2020-12-13 10:30:11,374 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                       loaded from rpn.head.cls_logits.weight                       of shape (3, 256, 1, 1)
2020-12-13 10:30:11,374 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.bias                               loaded from rpn.head.conv.bias                               of shape (256,)
2020-12-13 10:30:11,374 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.weight                             loaded from rpn.head.conv.weight                             of shape (256, 256, 3, 3)
2020-12-13 10:30:11,553 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-13 10:30:11,553 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-13 10:30:11,553 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-13 10:30:11,553 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-13 10:30:13,520 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-13 10:30:13,987 maskrcnn_benchmark.trainer INFO: Start training
2020-12-13 10:31:34,600 maskrcnn_benchmark.trainer INFO: eta: 1:46:08  iter: 20  loss: 1.4247 (1.7763)  loss_classifier: 0.5744 (0.7960)  loss_box_reg: 0.0593 (0.1366)  loss_objectness: 0.6685 (0.7158)  loss_rpn_box_reg: 0.1195 (0.1279)  time: 3.8782 (4.0305)  data: 0.2388 (0.2505)  lr: 0.000360  max mem: 1312
2020-12-13 10:33:00,243 maskrcnn_benchmark.trainer INFO: eta: 1:48:03  iter: 40  loss: 1.5919 (1.6789)  loss_classifier: 0.3321 (0.6597)  loss_box_reg: 0.2209 (0.1669)  loss_objectness: 0.6565 (0.7195)  loss_rpn_box_reg: 0.1201 (0.1328)  time: 4.2788 (4.1563)  data: 0.2459 (0.2532)  lr: 0.000387  max mem: 1312
2020-12-13 10:34:25,238 maskrcnn_benchmark.trainer INFO: eta: 1:47:28  iter: 60  loss: 1.1473 (1.5103)  loss_classifier: 0.2561 (0.5281)  loss_box_reg: 0.0941 (0.1562)  loss_objectness: 0.6381 (0.6979)  loss_rpn_box_reg: 0.0960 (0.1282)  time: 4.2518 (4.1875)  data: 0.2493 (0.2523)  lr: 0.000413  max mem: 1312
2020-12-13 10:35:49,762 maskrcnn_benchmark.trainer INFO: eta: 1:46:19  iter: 80  loss: 1.1854 (1.4199)  loss_classifier: 0.1423 (0.4433)  loss_box_reg: 0.0238 (0.1367)  loss_objectness: 0.7421 (0.7090)  loss_rpn_box_reg: 0.1220 (0.1309)  time: 4.2445 (4.1972)  data: 0.2493 (0.2529)  lr: 0.000440  max mem: 1312
2020-12-13 10:37:14,442 maskrcnn_benchmark.trainer INFO: eta: 1:45:06  iter: 100  loss: 1.1470 (1.3808)  loss_classifier: 0.2375 (0.4045)  loss_box_reg: 0.1688 (0.1423)  loss_objectness: 0.6897 (0.7041)  loss_rpn_box_reg: 0.1129 (0.1299)  time: 4.2318 (4.2045)  data: 0.2555 (0.2542)  lr: 0.000467  max mem: 1312
2020-12-13 10:38:38,654 maskrcnn_benchmark.trainer INFO: eta: 1:43:44  iter: 120  loss: 1.2531 (1.3738)  loss_classifier: 0.2014 (0.3744)  loss_box_reg: 0.0958 (0.1391)  loss_objectness: 0.6996 (0.7251)  loss_rpn_box_reg: 0.1473 (0.1352)  time: 4.2061 (4.2055)  data: 0.2531 (0.2545)  lr: 0.000493  max mem: 1312
2020-12-13 10:40:01,738 maskrcnn_benchmark.trainer INFO: eta: 1:42:09  iter: 140  loss: 0.9732 (1.3287)  loss_classifier: 0.1466 (0.3442)  loss_box_reg: 0.0321 (0.1306)  loss_objectness: 0.6026 (0.7208)  loss_rpn_box_reg: 0.0950 (0.1332)  time: 4.1348 (4.1982)  data: 0.2490 (0.2539)  lr: 0.000520  max mem: 1312
2020-12-13 10:41:24,606 maskrcnn_benchmark.trainer INFO: eta: 1:40:35  iter: 160  loss: 1.0756 (1.3109)  loss_classifier: 0.1984 (0.3261)  loss_box_reg: 0.0617 (0.1274)  loss_objectness: 0.6472 (0.7245)  loss_rpn_box_reg: 0.1234 (0.1329)  time: 4.1389 (4.1914)  data: 0.2510 (0.2545)  lr: 0.000547  max mem: 1312
2020-12-13 10:42:47,936 maskrcnn_benchmark.trainer INFO: eta: 1:39:07  iter: 180  loss: 0.9552 (1.2799)  loss_classifier: 0.1598 (0.3091)  loss_box_reg: 0.0959 (0.1263)  loss_objectness: 0.6452 (0.7140)  loss_rpn_box_reg: 0.1058 (0.1305)  time: 4.1512 (4.1886)  data: 0.2596 (0.2559)  lr: 0.000573  max mem: 1312
2020-12-13 10:44:11,800 maskrcnn_benchmark.trainer INFO: eta: 1:37:44  iter: 200  loss: 1.0415 (1.2632)  loss_classifier: 0.1824 (0.2959)  loss_box_reg: 0.1277 (0.1245)  loss_objectness: 0.6334 (0.7121)  loss_rpn_box_reg: 0.1276 (0.1306)  time: 4.1850 (4.1891)  data: 0.2547 (0.2562)  lr: 0.000600  max mem: 1312
2020-12-13 10:44:11,802 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 10:44:11,847 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 10:44:18,461 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.613469 (1.6533673405647278 s / img per device, on 1 devices)
2020-12-13 10:44:18,461 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:06.111171 (1.5277926921844482 s / img per device, on 1 devices)
2020-12-13 10:44:18,461 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 10:44:18,940 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 10:44:18,940 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.0733), 'recalls': tensor([0.3667, 0.2333, 0.0667, 0.0333, 0.0333, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.5992, 0.5767, 0.5553, 0.5513, 0.5428, 0.3963, 0.0000, 0.0000, 0.5360,
        0.5260, 0.4508, 0.4423, 0.4350, 0.3297, 0.3146, 0.7341, 0.6421, 0.5248,
        0.3835, 0.3398, 0.3004, 0.0000, 0.0000, 0.5508, 0.4979, 0.4724, 0.3882,
        0.3295, 0.3007, 0.2911]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 1.]), 'best match scores': tensor([0.1959, 0.0703, 0.0506, 0.1728, 0.0537, 0.1406, 0.1451, 0.1603, 0.4138,
        0.0654, 0.1999, 0.0705, 0.6072, 0.1392, 0.1043, 0.2182, 0.1888, 0.1282,
        0.3383, 0.0595, 0.5838, 0.0947, 0.2134, 0.4613, 0.1241, 0.3375, 0.1019,
        0.4913, 0.2114, 0.0523]), 'num_pos': 30}
2020-12-13 10:44:18,949 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.033333
2020-12-13 10:44:18,952 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v7.pth
2020-12-13 10:44:20,006 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v7
2020-12-13 10:45:45,407 maskrcnn_benchmark.trainer INFO: eta: 1:37:22  iter: 220  loss: 1.0214 (1.2483)  loss_classifier: 0.1791 (0.2862)  loss_box_reg: 0.0859 (0.1217)  loss_objectness: 0.5755 (0.7103)  loss_rpn_box_reg: 0.1201 (0.1301)  time: 4.2288 (4.2337)  data: 0.2645 (0.2982)  lr: 0.000627  max mem: 1312
2020-12-13 10:49:22,985 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 10:49:22,985 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 10:49:22,985 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 10:49:26,178 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 10:49:26,179 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 10:49:26,179 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train", "giro4_train", "giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00004
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-13 10:49:26,181 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 4e-05
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-13 10:49:28,050 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from ./_best_acc_r5_v7.pth
2020-12-13 10:49:28,402 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                  loaded from backbone.body.layer1.0.bn1.bias                  of shape (256,)
2020-12-13 10:49:28,402 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_mean          loaded from backbone.body.layer1.0.bn1.running_mean          of shape (256,)
2020-12-13 10:49:28,402 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_var           loaded from backbone.body.layer1.0.bn1.running_var           of shape (256,)
2020-12-13 10:49:28,402 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                loaded from backbone.body.layer1.0.bn1.weight                of shape (256,)
2020-12-13 10:49:28,403 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                  loaded from backbone.body.layer1.0.bn2.bias                  of shape (256,)
2020-12-13 10:49:28,403 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_mean          loaded from backbone.body.layer1.0.bn2.running_mean          of shape (256,)
2020-12-13 10:49:28,403 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_var           loaded from backbone.body.layer1.0.bn2.running_var           of shape (256,)
2020-12-13 10:49:28,403 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                loaded from backbone.body.layer1.0.bn2.weight                of shape (256,)
2020-12-13 10:49:28,403 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                  loaded from backbone.body.layer1.0.bn3.bias                  of shape (256,)
2020-12-13 10:49:28,403 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_mean          loaded from backbone.body.layer1.0.bn3.running_mean          of shape (256,)
2020-12-13 10:49:28,403 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_var           loaded from backbone.body.layer1.0.bn3.running_var           of shape (256,)
2020-12-13 10:49:28,403 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                loaded from backbone.body.layer1.0.bn3.weight                of shape (256,)
2020-12-13 10:49:28,403 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight              loaded from backbone.body.layer1.0.conv1.weight              of shape (256, 64, 1, 1)
2020-12-13 10:49:28,403 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight              loaded from backbone.body.layer1.0.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 10:49:28,403 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight              loaded from backbone.body.layer1.0.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 10:49:28,403 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight       loaded from backbone.body.layer1.0.downsample.0.weight       of shape (256, 64, 1, 1)
2020-12-13 10:49:28,404 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias         loaded from backbone.body.layer1.0.downsample.1.bias         of shape (256,)
2020-12-13 10:49:28,404 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_mean loaded from backbone.body.layer1.0.downsample.1.running_mean of shape (256,)
2020-12-13 10:49:28,404 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_var  loaded from backbone.body.layer1.0.downsample.1.running_var  of shape (256,)
2020-12-13 10:49:28,404 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight       loaded from backbone.body.layer1.0.downsample.1.weight       of shape (256,)
2020-12-13 10:49:28,404 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                  loaded from backbone.body.layer1.1.bn1.bias                  of shape (256,)
2020-12-13 10:49:28,404 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_mean          loaded from backbone.body.layer1.1.bn1.running_mean          of shape (256,)
2020-12-13 10:49:28,404 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_var           loaded from backbone.body.layer1.1.bn1.running_var           of shape (256,)
2020-12-13 10:49:28,404 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                loaded from backbone.body.layer1.1.bn1.weight                of shape (256,)
2020-12-13 10:49:28,404 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                  loaded from backbone.body.layer1.1.bn2.bias                  of shape (256,)
2020-12-13 10:49:28,404 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_mean          loaded from backbone.body.layer1.1.bn2.running_mean          of shape (256,)
2020-12-13 10:49:28,404 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_var           loaded from backbone.body.layer1.1.bn2.running_var           of shape (256,)
2020-12-13 10:49:28,404 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                loaded from backbone.body.layer1.1.bn2.weight                of shape (256,)
2020-12-13 10:49:28,404 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                  loaded from backbone.body.layer1.1.bn3.bias                  of shape (256,)
2020-12-13 10:49:28,405 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_mean          loaded from backbone.body.layer1.1.bn3.running_mean          of shape (256,)
2020-12-13 10:49:28,405 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_var           loaded from backbone.body.layer1.1.bn3.running_var           of shape (256,)
2020-12-13 10:49:28,405 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                loaded from backbone.body.layer1.1.bn3.weight                of shape (256,)
2020-12-13 10:49:28,405 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight              loaded from backbone.body.layer1.1.conv1.weight              of shape (256, 256, 1, 1)
2020-12-13 10:49:28,405 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight              loaded from backbone.body.layer1.1.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 10:49:28,405 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight              loaded from backbone.body.layer1.1.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 10:49:28,405 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                  loaded from backbone.body.layer1.2.bn1.bias                  of shape (256,)
2020-12-13 10:49:28,405 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_mean          loaded from backbone.body.layer1.2.bn1.running_mean          of shape (256,)
2020-12-13 10:49:28,405 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_var           loaded from backbone.body.layer1.2.bn1.running_var           of shape (256,)
2020-12-13 10:49:28,406 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                loaded from backbone.body.layer1.2.bn1.weight                of shape (256,)
2020-12-13 10:49:28,406 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                  loaded from backbone.body.layer1.2.bn2.bias                  of shape (256,)
2020-12-13 10:49:28,406 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_mean          loaded from backbone.body.layer1.2.bn2.running_mean          of shape (256,)
2020-12-13 10:49:28,406 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_var           loaded from backbone.body.layer1.2.bn2.running_var           of shape (256,)
2020-12-13 10:49:28,406 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                loaded from backbone.body.layer1.2.bn2.weight                of shape (256,)
2020-12-13 10:49:28,406 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                  loaded from backbone.body.layer1.2.bn3.bias                  of shape (256,)
2020-12-13 10:49:28,406 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_mean          loaded from backbone.body.layer1.2.bn3.running_mean          of shape (256,)
2020-12-13 10:49:28,406 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_var           loaded from backbone.body.layer1.2.bn3.running_var           of shape (256,)
2020-12-13 10:49:28,406 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                loaded from backbone.body.layer1.2.bn3.weight                of shape (256,)
2020-12-13 10:49:28,406 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight              loaded from backbone.body.layer1.2.conv1.weight              of shape (256, 256, 1, 1)
2020-12-13 10:49:28,407 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight              loaded from backbone.body.layer1.2.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 10:49:28,407 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight              loaded from backbone.body.layer1.2.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 10:49:28,407 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                  loaded from backbone.body.layer2.0.bn1.bias                  of shape (512,)
2020-12-13 10:49:28,407 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_mean          loaded from backbone.body.layer2.0.bn1.running_mean          of shape (512,)
2020-12-13 10:49:28,407 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_var           loaded from backbone.body.layer2.0.bn1.running_var           of shape (512,)
2020-12-13 10:49:28,407 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                loaded from backbone.body.layer2.0.bn1.weight                of shape (512,)
2020-12-13 10:49:28,407 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                  loaded from backbone.body.layer2.0.bn2.bias                  of shape (512,)
2020-12-13 10:49:28,407 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_mean          loaded from backbone.body.layer2.0.bn2.running_mean          of shape (512,)
2020-12-13 10:49:28,407 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_var           loaded from backbone.body.layer2.0.bn2.running_var           of shape (512,)
2020-12-13 10:49:28,407 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                loaded from backbone.body.layer2.0.bn2.weight                of shape (512,)
2020-12-13 10:49:28,408 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                  loaded from backbone.body.layer2.0.bn3.bias                  of shape (512,)
2020-12-13 10:49:28,408 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_mean          loaded from backbone.body.layer2.0.bn3.running_mean          of shape (512,)
2020-12-13 10:49:28,408 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_var           loaded from backbone.body.layer2.0.bn3.running_var           of shape (512,)
2020-12-13 10:49:28,408 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                loaded from backbone.body.layer2.0.bn3.weight                of shape (512,)
2020-12-13 10:49:28,408 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight              loaded from backbone.body.layer2.0.conv1.weight              of shape (512, 256, 1, 1)
2020-12-13 10:49:28,408 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight              loaded from backbone.body.layer2.0.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:49:28,408 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight              loaded from backbone.body.layer2.0.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:49:28,408 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight       loaded from backbone.body.layer2.0.downsample.0.weight       of shape (512, 256, 1, 1)
2020-12-13 10:49:28,408 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias         loaded from backbone.body.layer2.0.downsample.1.bias         of shape (512,)
2020-12-13 10:49:28,408 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_mean loaded from backbone.body.layer2.0.downsample.1.running_mean of shape (512,)
2020-12-13 10:49:28,408 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_var  loaded from backbone.body.layer2.0.downsample.1.running_var  of shape (512,)
2020-12-13 10:49:28,408 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight       loaded from backbone.body.layer2.0.downsample.1.weight       of shape (512,)
2020-12-13 10:49:28,408 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                  loaded from backbone.body.layer2.1.bn1.bias                  of shape (512,)
2020-12-13 10:49:28,408 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_mean          loaded from backbone.body.layer2.1.bn1.running_mean          of shape (512,)
2020-12-13 10:49:28,409 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_var           loaded from backbone.body.layer2.1.bn1.running_var           of shape (512,)
2020-12-13 10:49:28,409 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                loaded from backbone.body.layer2.1.bn1.weight                of shape (512,)
2020-12-13 10:49:28,409 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                  loaded from backbone.body.layer2.1.bn2.bias                  of shape (512,)
2020-12-13 10:49:28,409 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_mean          loaded from backbone.body.layer2.1.bn2.running_mean          of shape (512,)
2020-12-13 10:49:28,409 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_var           loaded from backbone.body.layer2.1.bn2.running_var           of shape (512,)
2020-12-13 10:49:28,409 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                loaded from backbone.body.layer2.1.bn2.weight                of shape (512,)
2020-12-13 10:49:28,409 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                  loaded from backbone.body.layer2.1.bn3.bias                  of shape (512,)
2020-12-13 10:49:28,409 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_mean          loaded from backbone.body.layer2.1.bn3.running_mean          of shape (512,)
2020-12-13 10:49:28,409 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_var           loaded from backbone.body.layer2.1.bn3.running_var           of shape (512,)
2020-12-13 10:49:28,409 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                loaded from backbone.body.layer2.1.bn3.weight                of shape (512,)
2020-12-13 10:49:28,409 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight              loaded from backbone.body.layer2.1.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 10:49:28,409 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight              loaded from backbone.body.layer2.1.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:49:28,409 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight              loaded from backbone.body.layer2.1.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:49:28,409 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                  loaded from backbone.body.layer2.2.bn1.bias                  of shape (512,)
2020-12-13 10:49:28,410 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_mean          loaded from backbone.body.layer2.2.bn1.running_mean          of shape (512,)
2020-12-13 10:49:28,410 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_var           loaded from backbone.body.layer2.2.bn1.running_var           of shape (512,)
2020-12-13 10:49:28,410 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                loaded from backbone.body.layer2.2.bn1.weight                of shape (512,)
2020-12-13 10:49:28,410 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                  loaded from backbone.body.layer2.2.bn2.bias                  of shape (512,)
2020-12-13 10:49:28,410 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_mean          loaded from backbone.body.layer2.2.bn2.running_mean          of shape (512,)
2020-12-13 10:49:28,410 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_var           loaded from backbone.body.layer2.2.bn2.running_var           of shape (512,)
2020-12-13 10:49:28,410 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                loaded from backbone.body.layer2.2.bn2.weight                of shape (512,)
2020-12-13 10:49:28,410 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                  loaded from backbone.body.layer2.2.bn3.bias                  of shape (512,)
2020-12-13 10:49:28,410 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_mean          loaded from backbone.body.layer2.2.bn3.running_mean          of shape (512,)
2020-12-13 10:49:28,410 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_var           loaded from backbone.body.layer2.2.bn3.running_var           of shape (512,)
2020-12-13 10:49:28,410 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                loaded from backbone.body.layer2.2.bn3.weight                of shape (512,)
2020-12-13 10:49:28,410 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight              loaded from backbone.body.layer2.2.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 10:49:28,410 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight              loaded from backbone.body.layer2.2.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:49:28,411 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight              loaded from backbone.body.layer2.2.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:49:28,411 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                  loaded from backbone.body.layer2.3.bn1.bias                  of shape (512,)
2020-12-13 10:49:28,411 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_mean          loaded from backbone.body.layer2.3.bn1.running_mean          of shape (512,)
2020-12-13 10:49:28,411 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_var           loaded from backbone.body.layer2.3.bn1.running_var           of shape (512,)
2020-12-13 10:49:28,411 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                loaded from backbone.body.layer2.3.bn1.weight                of shape (512,)
2020-12-13 10:49:28,411 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                  loaded from backbone.body.layer2.3.bn2.bias                  of shape (512,)
2020-12-13 10:49:28,411 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_mean          loaded from backbone.body.layer2.3.bn2.running_mean          of shape (512,)
2020-12-13 10:49:28,411 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_var           loaded from backbone.body.layer2.3.bn2.running_var           of shape (512,)
2020-12-13 10:49:28,411 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                loaded from backbone.body.layer2.3.bn2.weight                of shape (512,)
2020-12-13 10:49:28,411 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                  loaded from backbone.body.layer2.3.bn3.bias                  of shape (512,)
2020-12-13 10:49:28,411 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_mean          loaded from backbone.body.layer2.3.bn3.running_mean          of shape (512,)
2020-12-13 10:49:28,411 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_var           loaded from backbone.body.layer2.3.bn3.running_var           of shape (512,)
2020-12-13 10:49:28,412 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                loaded from backbone.body.layer2.3.bn3.weight                of shape (512,)
2020-12-13 10:49:28,412 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight              loaded from backbone.body.layer2.3.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 10:49:28,412 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight              loaded from backbone.body.layer2.3.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:49:28,412 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight              loaded from backbone.body.layer2.3.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:49:28,412 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                  loaded from backbone.body.layer3.0.bn1.bias                  of shape (1024,)
2020-12-13 10:49:28,412 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_mean          loaded from backbone.body.layer3.0.bn1.running_mean          of shape (1024,)
2020-12-13 10:49:28,412 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_var           loaded from backbone.body.layer3.0.bn1.running_var           of shape (1024,)
2020-12-13 10:49:28,412 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                loaded from backbone.body.layer3.0.bn1.weight                of shape (1024,)
2020-12-13 10:49:28,412 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                  loaded from backbone.body.layer3.0.bn2.bias                  of shape (1024,)
2020-12-13 10:49:28,412 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_mean          loaded from backbone.body.layer3.0.bn2.running_mean          of shape (1024,)
2020-12-13 10:49:28,413 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_var           loaded from backbone.body.layer3.0.bn2.running_var           of shape (1024,)
2020-12-13 10:49:28,413 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                loaded from backbone.body.layer3.0.bn2.weight                of shape (1024,)
2020-12-13 10:49:28,413 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                  loaded from backbone.body.layer3.0.bn3.bias                  of shape (1024,)
2020-12-13 10:49:28,413 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_mean          loaded from backbone.body.layer3.0.bn3.running_mean          of shape (1024,)
2020-12-13 10:49:28,413 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_var           loaded from backbone.body.layer3.0.bn3.running_var           of shape (1024,)
2020-12-13 10:49:28,413 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                loaded from backbone.body.layer3.0.bn3.weight                of shape (1024,)
2020-12-13 10:49:28,413 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight              loaded from backbone.body.layer3.0.conv1.weight              of shape (1024, 512, 1, 1)
2020-12-13 10:49:28,413 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight              loaded from backbone.body.layer3.0.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,413 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight              loaded from backbone.body.layer3.0.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,413 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight       loaded from backbone.body.layer3.0.downsample.0.weight       of shape (1024, 512, 1, 1)
2020-12-13 10:49:28,414 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias         loaded from backbone.body.layer3.0.downsample.1.bias         of shape (1024,)
2020-12-13 10:49:28,414 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_mean loaded from backbone.body.layer3.0.downsample.1.running_mean of shape (1024,)
2020-12-13 10:49:28,414 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_var  loaded from backbone.body.layer3.0.downsample.1.running_var  of shape (1024,)
2020-12-13 10:49:28,414 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight       loaded from backbone.body.layer3.0.downsample.1.weight       of shape (1024,)
2020-12-13 10:49:28,414 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                  loaded from backbone.body.layer3.1.bn1.bias                  of shape (1024,)
2020-12-13 10:49:28,414 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_mean          loaded from backbone.body.layer3.1.bn1.running_mean          of shape (1024,)
2020-12-13 10:49:28,414 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_var           loaded from backbone.body.layer3.1.bn1.running_var           of shape (1024,)
2020-12-13 10:49:28,414 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                loaded from backbone.body.layer3.1.bn1.weight                of shape (1024,)
2020-12-13 10:49:28,414 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                  loaded from backbone.body.layer3.1.bn2.bias                  of shape (1024,)
2020-12-13 10:49:28,415 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_mean          loaded from backbone.body.layer3.1.bn2.running_mean          of shape (1024,)
2020-12-13 10:49:28,415 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_var           loaded from backbone.body.layer3.1.bn2.running_var           of shape (1024,)
2020-12-13 10:49:28,415 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                loaded from backbone.body.layer3.1.bn2.weight                of shape (1024,)
2020-12-13 10:49:28,415 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                  loaded from backbone.body.layer3.1.bn3.bias                  of shape (1024,)
2020-12-13 10:49:28,415 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_mean          loaded from backbone.body.layer3.1.bn3.running_mean          of shape (1024,)
2020-12-13 10:49:28,415 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_var           loaded from backbone.body.layer3.1.bn3.running_var           of shape (1024,)
2020-12-13 10:49:28,415 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                loaded from backbone.body.layer3.1.bn3.weight                of shape (1024,)
2020-12-13 10:49:28,415 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight              loaded from backbone.body.layer3.1.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,415 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight              loaded from backbone.body.layer3.1.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,415 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight              loaded from backbone.body.layer3.1.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,415 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.bias                 loaded from backbone.body.layer3.10.bn1.bias                 of shape (1024,)
2020-12-13 10:49:28,416 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.running_mean         loaded from backbone.body.layer3.10.bn1.running_mean         of shape (1024,)
2020-12-13 10:49:28,416 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.running_var          loaded from backbone.body.layer3.10.bn1.running_var          of shape (1024,)
2020-12-13 10:49:28,416 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.weight               loaded from backbone.body.layer3.10.bn1.weight               of shape (1024,)
2020-12-13 10:49:28,416 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.bias                 loaded from backbone.body.layer3.10.bn2.bias                 of shape (1024,)
2020-12-13 10:49:28,416 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.running_mean         loaded from backbone.body.layer3.10.bn2.running_mean         of shape (1024,)
2020-12-13 10:49:28,416 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.running_var          loaded from backbone.body.layer3.10.bn2.running_var          of shape (1024,)
2020-12-13 10:49:28,416 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.weight               loaded from backbone.body.layer3.10.bn2.weight               of shape (1024,)
2020-12-13 10:49:28,416 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.bias                 loaded from backbone.body.layer3.10.bn3.bias                 of shape (1024,)
2020-12-13 10:49:28,416 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.running_mean         loaded from backbone.body.layer3.10.bn3.running_mean         of shape (1024,)
2020-12-13 10:49:28,416 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.running_var          loaded from backbone.body.layer3.10.bn3.running_var          of shape (1024,)
2020-12-13 10:49:28,416 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.weight               loaded from backbone.body.layer3.10.bn3.weight               of shape (1024,)
2020-12-13 10:49:28,417 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv1.weight             loaded from backbone.body.layer3.10.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,417 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv2.weight             loaded from backbone.body.layer3.10.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,417 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv3.weight             loaded from backbone.body.layer3.10.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,417 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.bias                 loaded from backbone.body.layer3.11.bn1.bias                 of shape (1024,)
2020-12-13 10:49:28,417 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.running_mean         loaded from backbone.body.layer3.11.bn1.running_mean         of shape (1024,)
2020-12-13 10:49:28,417 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.running_var          loaded from backbone.body.layer3.11.bn1.running_var          of shape (1024,)
2020-12-13 10:49:28,417 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.weight               loaded from backbone.body.layer3.11.bn1.weight               of shape (1024,)
2020-12-13 10:49:28,417 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.bias                 loaded from backbone.body.layer3.11.bn2.bias                 of shape (1024,)
2020-12-13 10:49:28,417 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.running_mean         loaded from backbone.body.layer3.11.bn2.running_mean         of shape (1024,)
2020-12-13 10:49:28,417 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.running_var          loaded from backbone.body.layer3.11.bn2.running_var          of shape (1024,)
2020-12-13 10:49:28,417 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.weight               loaded from backbone.body.layer3.11.bn2.weight               of shape (1024,)
2020-12-13 10:49:28,418 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.bias                 loaded from backbone.body.layer3.11.bn3.bias                 of shape (1024,)
2020-12-13 10:49:28,418 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.running_mean         loaded from backbone.body.layer3.11.bn3.running_mean         of shape (1024,)
2020-12-13 10:49:28,418 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.running_var          loaded from backbone.body.layer3.11.bn3.running_var          of shape (1024,)
2020-12-13 10:49:28,418 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.weight               loaded from backbone.body.layer3.11.bn3.weight               of shape (1024,)
2020-12-13 10:49:28,418 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv1.weight             loaded from backbone.body.layer3.11.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,418 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv2.weight             loaded from backbone.body.layer3.11.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,418 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv3.weight             loaded from backbone.body.layer3.11.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,418 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.bias                 loaded from backbone.body.layer3.12.bn1.bias                 of shape (1024,)
2020-12-13 10:49:28,418 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.running_mean         loaded from backbone.body.layer3.12.bn1.running_mean         of shape (1024,)
2020-12-13 10:49:28,418 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.running_var          loaded from backbone.body.layer3.12.bn1.running_var          of shape (1024,)
2020-12-13 10:49:28,418 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.weight               loaded from backbone.body.layer3.12.bn1.weight               of shape (1024,)
2020-12-13 10:49:28,419 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.bias                 loaded from backbone.body.layer3.12.bn2.bias                 of shape (1024,)
2020-12-13 10:49:28,419 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.running_mean         loaded from backbone.body.layer3.12.bn2.running_mean         of shape (1024,)
2020-12-13 10:49:28,419 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.running_var          loaded from backbone.body.layer3.12.bn2.running_var          of shape (1024,)
2020-12-13 10:49:28,419 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.weight               loaded from backbone.body.layer3.12.bn2.weight               of shape (1024,)
2020-12-13 10:49:28,419 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.bias                 loaded from backbone.body.layer3.12.bn3.bias                 of shape (1024,)
2020-12-13 10:49:28,419 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.running_mean         loaded from backbone.body.layer3.12.bn3.running_mean         of shape (1024,)
2020-12-13 10:49:28,419 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.running_var          loaded from backbone.body.layer3.12.bn3.running_var          of shape (1024,)
2020-12-13 10:49:28,419 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.weight               loaded from backbone.body.layer3.12.bn3.weight               of shape (1024,)
2020-12-13 10:49:28,419 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv1.weight             loaded from backbone.body.layer3.12.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,419 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv2.weight             loaded from backbone.body.layer3.12.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,419 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv3.weight             loaded from backbone.body.layer3.12.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,419 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.bias                 loaded from backbone.body.layer3.13.bn1.bias                 of shape (1024,)
2020-12-13 10:49:28,420 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.running_mean         loaded from backbone.body.layer3.13.bn1.running_mean         of shape (1024,)
2020-12-13 10:49:28,420 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.running_var          loaded from backbone.body.layer3.13.bn1.running_var          of shape (1024,)
2020-12-13 10:49:28,420 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.weight               loaded from backbone.body.layer3.13.bn1.weight               of shape (1024,)
2020-12-13 10:49:28,420 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.bias                 loaded from backbone.body.layer3.13.bn2.bias                 of shape (1024,)
2020-12-13 10:49:28,420 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.running_mean         loaded from backbone.body.layer3.13.bn2.running_mean         of shape (1024,)
2020-12-13 10:49:28,420 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.running_var          loaded from backbone.body.layer3.13.bn2.running_var          of shape (1024,)
2020-12-13 10:49:28,420 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.weight               loaded from backbone.body.layer3.13.bn2.weight               of shape (1024,)
2020-12-13 10:49:28,420 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.bias                 loaded from backbone.body.layer3.13.bn3.bias                 of shape (1024,)
2020-12-13 10:49:28,420 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.running_mean         loaded from backbone.body.layer3.13.bn3.running_mean         of shape (1024,)
2020-12-13 10:49:28,420 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.running_var          loaded from backbone.body.layer3.13.bn3.running_var          of shape (1024,)
2020-12-13 10:49:28,420 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.weight               loaded from backbone.body.layer3.13.bn3.weight               of shape (1024,)
2020-12-13 10:49:28,421 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv1.weight             loaded from backbone.body.layer3.13.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,421 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv2.weight             loaded from backbone.body.layer3.13.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,421 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv3.weight             loaded from backbone.body.layer3.13.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,421 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.bias                 loaded from backbone.body.layer3.14.bn1.bias                 of shape (1024,)
2020-12-13 10:49:28,421 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.running_mean         loaded from backbone.body.layer3.14.bn1.running_mean         of shape (1024,)
2020-12-13 10:49:28,421 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.running_var          loaded from backbone.body.layer3.14.bn1.running_var          of shape (1024,)
2020-12-13 10:49:28,421 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.weight               loaded from backbone.body.layer3.14.bn1.weight               of shape (1024,)
2020-12-13 10:49:28,421 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.bias                 loaded from backbone.body.layer3.14.bn2.bias                 of shape (1024,)
2020-12-13 10:49:28,421 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.running_mean         loaded from backbone.body.layer3.14.bn2.running_mean         of shape (1024,)
2020-12-13 10:49:28,421 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.running_var          loaded from backbone.body.layer3.14.bn2.running_var          of shape (1024,)
2020-12-13 10:49:28,421 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.weight               loaded from backbone.body.layer3.14.bn2.weight               of shape (1024,)
2020-12-13 10:49:28,421 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.bias                 loaded from backbone.body.layer3.14.bn3.bias                 of shape (1024,)
2020-12-13 10:49:28,422 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.running_mean         loaded from backbone.body.layer3.14.bn3.running_mean         of shape (1024,)
2020-12-13 10:49:28,422 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.running_var          loaded from backbone.body.layer3.14.bn3.running_var          of shape (1024,)
2020-12-13 10:49:28,422 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.weight               loaded from backbone.body.layer3.14.bn3.weight               of shape (1024,)
2020-12-13 10:49:28,422 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv1.weight             loaded from backbone.body.layer3.14.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,422 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv2.weight             loaded from backbone.body.layer3.14.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,422 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv3.weight             loaded from backbone.body.layer3.14.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,422 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.bias                 loaded from backbone.body.layer3.15.bn1.bias                 of shape (1024,)
2020-12-13 10:49:28,422 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.running_mean         loaded from backbone.body.layer3.15.bn1.running_mean         of shape (1024,)
2020-12-13 10:49:28,422 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.running_var          loaded from backbone.body.layer3.15.bn1.running_var          of shape (1024,)
2020-12-13 10:49:28,422 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.weight               loaded from backbone.body.layer3.15.bn1.weight               of shape (1024,)
2020-12-13 10:49:28,422 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.bias                 loaded from backbone.body.layer3.15.bn2.bias                 of shape (1024,)
2020-12-13 10:49:28,422 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.running_mean         loaded from backbone.body.layer3.15.bn2.running_mean         of shape (1024,)
2020-12-13 10:49:28,422 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.running_var          loaded from backbone.body.layer3.15.bn2.running_var          of shape (1024,)
2020-12-13 10:49:28,423 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.weight               loaded from backbone.body.layer3.15.bn2.weight               of shape (1024,)
2020-12-13 10:49:28,423 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.bias                 loaded from backbone.body.layer3.15.bn3.bias                 of shape (1024,)
2020-12-13 10:49:28,423 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.running_mean         loaded from backbone.body.layer3.15.bn3.running_mean         of shape (1024,)
2020-12-13 10:49:28,423 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.running_var          loaded from backbone.body.layer3.15.bn3.running_var          of shape (1024,)
2020-12-13 10:49:28,423 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.weight               loaded from backbone.body.layer3.15.bn3.weight               of shape (1024,)
2020-12-13 10:49:28,423 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv1.weight             loaded from backbone.body.layer3.15.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,423 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv2.weight             loaded from backbone.body.layer3.15.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,423 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv3.weight             loaded from backbone.body.layer3.15.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,423 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.bias                 loaded from backbone.body.layer3.16.bn1.bias                 of shape (1024,)
2020-12-13 10:49:28,423 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.running_mean         loaded from backbone.body.layer3.16.bn1.running_mean         of shape (1024,)
2020-12-13 10:49:28,424 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.running_var          loaded from backbone.body.layer3.16.bn1.running_var          of shape (1024,)
2020-12-13 10:49:28,424 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.weight               loaded from backbone.body.layer3.16.bn1.weight               of shape (1024,)
2020-12-13 10:49:28,424 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.bias                 loaded from backbone.body.layer3.16.bn2.bias                 of shape (1024,)
2020-12-13 10:49:28,424 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.running_mean         loaded from backbone.body.layer3.16.bn2.running_mean         of shape (1024,)
2020-12-13 10:49:28,424 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.running_var          loaded from backbone.body.layer3.16.bn2.running_var          of shape (1024,)
2020-12-13 10:49:28,424 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.weight               loaded from backbone.body.layer3.16.bn2.weight               of shape (1024,)
2020-12-13 10:49:28,424 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.bias                 loaded from backbone.body.layer3.16.bn3.bias                 of shape (1024,)
2020-12-13 10:49:28,424 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.running_mean         loaded from backbone.body.layer3.16.bn3.running_mean         of shape (1024,)
2020-12-13 10:49:28,424 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.running_var          loaded from backbone.body.layer3.16.bn3.running_var          of shape (1024,)
2020-12-13 10:49:28,424 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.weight               loaded from backbone.body.layer3.16.bn3.weight               of shape (1024,)
2020-12-13 10:49:28,424 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv1.weight             loaded from backbone.body.layer3.16.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,425 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv2.weight             loaded from backbone.body.layer3.16.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,425 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv3.weight             loaded from backbone.body.layer3.16.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,425 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.bias                 loaded from backbone.body.layer3.17.bn1.bias                 of shape (1024,)
2020-12-13 10:49:28,425 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.running_mean         loaded from backbone.body.layer3.17.bn1.running_mean         of shape (1024,)
2020-12-13 10:49:28,425 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.running_var          loaded from backbone.body.layer3.17.bn1.running_var          of shape (1024,)
2020-12-13 10:49:28,425 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.weight               loaded from backbone.body.layer3.17.bn1.weight               of shape (1024,)
2020-12-13 10:49:28,425 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.bias                 loaded from backbone.body.layer3.17.bn2.bias                 of shape (1024,)
2020-12-13 10:49:28,425 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.running_mean         loaded from backbone.body.layer3.17.bn2.running_mean         of shape (1024,)
2020-12-13 10:49:28,425 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.running_var          loaded from backbone.body.layer3.17.bn2.running_var          of shape (1024,)
2020-12-13 10:49:28,425 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.weight               loaded from backbone.body.layer3.17.bn2.weight               of shape (1024,)
2020-12-13 10:49:28,425 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.bias                 loaded from backbone.body.layer3.17.bn3.bias                 of shape (1024,)
2020-12-13 10:49:28,425 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.running_mean         loaded from backbone.body.layer3.17.bn3.running_mean         of shape (1024,)
2020-12-13 10:49:28,425 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.running_var          loaded from backbone.body.layer3.17.bn3.running_var          of shape (1024,)
2020-12-13 10:49:28,425 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.weight               loaded from backbone.body.layer3.17.bn3.weight               of shape (1024,)
2020-12-13 10:49:28,426 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv1.weight             loaded from backbone.body.layer3.17.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,426 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv2.weight             loaded from backbone.body.layer3.17.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,426 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv3.weight             loaded from backbone.body.layer3.17.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,426 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.bias                 loaded from backbone.body.layer3.18.bn1.bias                 of shape (1024,)
2020-12-13 10:49:28,426 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.running_mean         loaded from backbone.body.layer3.18.bn1.running_mean         of shape (1024,)
2020-12-13 10:49:28,426 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.running_var          loaded from backbone.body.layer3.18.bn1.running_var          of shape (1024,)
2020-12-13 10:49:28,426 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.weight               loaded from backbone.body.layer3.18.bn1.weight               of shape (1024,)
2020-12-13 10:49:28,426 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.bias                 loaded from backbone.body.layer3.18.bn2.bias                 of shape (1024,)
2020-12-13 10:49:28,426 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.running_mean         loaded from backbone.body.layer3.18.bn2.running_mean         of shape (1024,)
2020-12-13 10:49:28,426 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.running_var          loaded from backbone.body.layer3.18.bn2.running_var          of shape (1024,)
2020-12-13 10:49:28,426 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.weight               loaded from backbone.body.layer3.18.bn2.weight               of shape (1024,)
2020-12-13 10:49:28,426 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.bias                 loaded from backbone.body.layer3.18.bn3.bias                 of shape (1024,)
2020-12-13 10:49:28,426 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.running_mean         loaded from backbone.body.layer3.18.bn3.running_mean         of shape (1024,)
2020-12-13 10:49:28,426 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.running_var          loaded from backbone.body.layer3.18.bn3.running_var          of shape (1024,)
2020-12-13 10:49:28,427 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.weight               loaded from backbone.body.layer3.18.bn3.weight               of shape (1024,)
2020-12-13 10:49:28,427 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv1.weight             loaded from backbone.body.layer3.18.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,427 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv2.weight             loaded from backbone.body.layer3.18.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,427 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv3.weight             loaded from backbone.body.layer3.18.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,427 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.bias                 loaded from backbone.body.layer3.19.bn1.bias                 of shape (1024,)
2020-12-13 10:49:28,427 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.running_mean         loaded from backbone.body.layer3.19.bn1.running_mean         of shape (1024,)
2020-12-13 10:49:28,427 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.running_var          loaded from backbone.body.layer3.19.bn1.running_var          of shape (1024,)
2020-12-13 10:49:28,427 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.weight               loaded from backbone.body.layer3.19.bn1.weight               of shape (1024,)
2020-12-13 10:49:28,427 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.bias                 loaded from backbone.body.layer3.19.bn2.bias                 of shape (1024,)
2020-12-13 10:49:28,427 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.running_mean         loaded from backbone.body.layer3.19.bn2.running_mean         of shape (1024,)
2020-12-13 10:49:28,427 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.running_var          loaded from backbone.body.layer3.19.bn2.running_var          of shape (1024,)
2020-12-13 10:49:28,427 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.weight               loaded from backbone.body.layer3.19.bn2.weight               of shape (1024,)
2020-12-13 10:49:28,427 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.bias                 loaded from backbone.body.layer3.19.bn3.bias                 of shape (1024,)
2020-12-13 10:49:28,428 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.running_mean         loaded from backbone.body.layer3.19.bn3.running_mean         of shape (1024,)
2020-12-13 10:49:28,428 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.running_var          loaded from backbone.body.layer3.19.bn3.running_var          of shape (1024,)
2020-12-13 10:49:28,428 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.weight               loaded from backbone.body.layer3.19.bn3.weight               of shape (1024,)
2020-12-13 10:49:28,428 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv1.weight             loaded from backbone.body.layer3.19.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,428 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv2.weight             loaded from backbone.body.layer3.19.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,428 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv3.weight             loaded from backbone.body.layer3.19.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,428 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                  loaded from backbone.body.layer3.2.bn1.bias                  of shape (1024,)
2020-12-13 10:49:28,428 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_mean          loaded from backbone.body.layer3.2.bn1.running_mean          of shape (1024,)
2020-12-13 10:49:28,428 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_var           loaded from backbone.body.layer3.2.bn1.running_var           of shape (1024,)
2020-12-13 10:49:28,428 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                loaded from backbone.body.layer3.2.bn1.weight                of shape (1024,)
2020-12-13 10:49:28,428 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                  loaded from backbone.body.layer3.2.bn2.bias                  of shape (1024,)
2020-12-13 10:49:28,428 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_mean          loaded from backbone.body.layer3.2.bn2.running_mean          of shape (1024,)
2020-12-13 10:49:28,428 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_var           loaded from backbone.body.layer3.2.bn2.running_var           of shape (1024,)
2020-12-13 10:49:28,428 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                loaded from backbone.body.layer3.2.bn2.weight                of shape (1024,)
2020-12-13 10:49:28,429 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                  loaded from backbone.body.layer3.2.bn3.bias                  of shape (1024,)
2020-12-13 10:49:28,429 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_mean          loaded from backbone.body.layer3.2.bn3.running_mean          of shape (1024,)
2020-12-13 10:49:28,429 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_var           loaded from backbone.body.layer3.2.bn3.running_var           of shape (1024,)
2020-12-13 10:49:28,429 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                loaded from backbone.body.layer3.2.bn3.weight                of shape (1024,)
2020-12-13 10:49:28,429 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight              loaded from backbone.body.layer3.2.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,429 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight              loaded from backbone.body.layer3.2.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,429 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight              loaded from backbone.body.layer3.2.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,429 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.bias                 loaded from backbone.body.layer3.20.bn1.bias                 of shape (1024,)
2020-12-13 10:49:28,429 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.running_mean         loaded from backbone.body.layer3.20.bn1.running_mean         of shape (1024,)
2020-12-13 10:49:28,429 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.running_var          loaded from backbone.body.layer3.20.bn1.running_var          of shape (1024,)
2020-12-13 10:49:28,429 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.weight               loaded from backbone.body.layer3.20.bn1.weight               of shape (1024,)
2020-12-13 10:49:28,429 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.bias                 loaded from backbone.body.layer3.20.bn2.bias                 of shape (1024,)
2020-12-13 10:49:28,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.running_mean         loaded from backbone.body.layer3.20.bn2.running_mean         of shape (1024,)
2020-12-13 10:49:28,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.running_var          loaded from backbone.body.layer3.20.bn2.running_var          of shape (1024,)
2020-12-13 10:49:28,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.weight               loaded from backbone.body.layer3.20.bn2.weight               of shape (1024,)
2020-12-13 10:49:28,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.bias                 loaded from backbone.body.layer3.20.bn3.bias                 of shape (1024,)
2020-12-13 10:49:28,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.running_mean         loaded from backbone.body.layer3.20.bn3.running_mean         of shape (1024,)
2020-12-13 10:49:28,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.running_var          loaded from backbone.body.layer3.20.bn3.running_var          of shape (1024,)
2020-12-13 10:49:28,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.weight               loaded from backbone.body.layer3.20.bn3.weight               of shape (1024,)
2020-12-13 10:49:28,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv1.weight             loaded from backbone.body.layer3.20.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv2.weight             loaded from backbone.body.layer3.20.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv3.weight             loaded from backbone.body.layer3.20.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.bias                 loaded from backbone.body.layer3.21.bn1.bias                 of shape (1024,)
2020-12-13 10:49:28,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.running_mean         loaded from backbone.body.layer3.21.bn1.running_mean         of shape (1024,)
2020-12-13 10:49:28,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.running_var          loaded from backbone.body.layer3.21.bn1.running_var          of shape (1024,)
2020-12-13 10:49:28,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.weight               loaded from backbone.body.layer3.21.bn1.weight               of shape (1024,)
2020-12-13 10:49:28,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.bias                 loaded from backbone.body.layer3.21.bn2.bias                 of shape (1024,)
2020-12-13 10:49:28,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.running_mean         loaded from backbone.body.layer3.21.bn2.running_mean         of shape (1024,)
2020-12-13 10:49:28,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.running_var          loaded from backbone.body.layer3.21.bn2.running_var          of shape (1024,)
2020-12-13 10:49:28,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.weight               loaded from backbone.body.layer3.21.bn2.weight               of shape (1024,)
2020-12-13 10:49:28,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.bias                 loaded from backbone.body.layer3.21.bn3.bias                 of shape (1024,)
2020-12-13 10:49:28,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.running_mean         loaded from backbone.body.layer3.21.bn3.running_mean         of shape (1024,)
2020-12-13 10:49:28,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.running_var          loaded from backbone.body.layer3.21.bn3.running_var          of shape (1024,)
2020-12-13 10:49:28,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.weight               loaded from backbone.body.layer3.21.bn3.weight               of shape (1024,)
2020-12-13 10:49:28,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv1.weight             loaded from backbone.body.layer3.21.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,431 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv2.weight             loaded from backbone.body.layer3.21.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv3.weight             loaded from backbone.body.layer3.21.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.bias                 loaded from backbone.body.layer3.22.bn1.bias                 of shape (1024,)
2020-12-13 10:49:28,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.running_mean         loaded from backbone.body.layer3.22.bn1.running_mean         of shape (1024,)
2020-12-13 10:49:28,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.running_var          loaded from backbone.body.layer3.22.bn1.running_var          of shape (1024,)
2020-12-13 10:49:28,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.weight               loaded from backbone.body.layer3.22.bn1.weight               of shape (1024,)
2020-12-13 10:49:28,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.bias                 loaded from backbone.body.layer3.22.bn2.bias                 of shape (1024,)
2020-12-13 10:49:28,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.running_mean         loaded from backbone.body.layer3.22.bn2.running_mean         of shape (1024,)
2020-12-13 10:49:28,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.running_var          loaded from backbone.body.layer3.22.bn2.running_var          of shape (1024,)
2020-12-13 10:49:28,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.weight               loaded from backbone.body.layer3.22.bn2.weight               of shape (1024,)
2020-12-13 10:49:28,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.bias                 loaded from backbone.body.layer3.22.bn3.bias                 of shape (1024,)
2020-12-13 10:49:28,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.running_mean         loaded from backbone.body.layer3.22.bn3.running_mean         of shape (1024,)
2020-12-13 10:49:28,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.running_var          loaded from backbone.body.layer3.22.bn3.running_var          of shape (1024,)
2020-12-13 10:49:28,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.weight               loaded from backbone.body.layer3.22.bn3.weight               of shape (1024,)
2020-12-13 10:49:28,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv1.weight             loaded from backbone.body.layer3.22.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv2.weight             loaded from backbone.body.layer3.22.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv3.weight             loaded from backbone.body.layer3.22.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                  loaded from backbone.body.layer3.3.bn1.bias                  of shape (1024,)
2020-12-13 10:49:28,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_mean          loaded from backbone.body.layer3.3.bn1.running_mean          of shape (1024,)
2020-12-13 10:49:28,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_var           loaded from backbone.body.layer3.3.bn1.running_var           of shape (1024,)
2020-12-13 10:49:28,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                loaded from backbone.body.layer3.3.bn1.weight                of shape (1024,)
2020-12-13 10:49:28,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                  loaded from backbone.body.layer3.3.bn2.bias                  of shape (1024,)
2020-12-13 10:49:28,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_mean          loaded from backbone.body.layer3.3.bn2.running_mean          of shape (1024,)
2020-12-13 10:49:28,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_var           loaded from backbone.body.layer3.3.bn2.running_var           of shape (1024,)
2020-12-13 10:49:28,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                loaded from backbone.body.layer3.3.bn2.weight                of shape (1024,)
2020-12-13 10:49:28,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                  loaded from backbone.body.layer3.3.bn3.bias                  of shape (1024,)
2020-12-13 10:49:28,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_mean          loaded from backbone.body.layer3.3.bn3.running_mean          of shape (1024,)
2020-12-13 10:49:28,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_var           loaded from backbone.body.layer3.3.bn3.running_var           of shape (1024,)
2020-12-13 10:49:28,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                loaded from backbone.body.layer3.3.bn3.weight                of shape (1024,)
2020-12-13 10:49:28,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight              loaded from backbone.body.layer3.3.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight              loaded from backbone.body.layer3.3.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight              loaded from backbone.body.layer3.3.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                  loaded from backbone.body.layer3.4.bn1.bias                  of shape (1024,)
2020-12-13 10:49:28,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_mean          loaded from backbone.body.layer3.4.bn1.running_mean          of shape (1024,)
2020-12-13 10:49:28,435 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_var           loaded from backbone.body.layer3.4.bn1.running_var           of shape (1024,)
2020-12-13 10:49:28,435 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                loaded from backbone.body.layer3.4.bn1.weight                of shape (1024,)
2020-12-13 10:49:28,435 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                  loaded from backbone.body.layer3.4.bn2.bias                  of shape (1024,)
2020-12-13 10:49:28,435 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_mean          loaded from backbone.body.layer3.4.bn2.running_mean          of shape (1024,)
2020-12-13 10:49:28,435 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_var           loaded from backbone.body.layer3.4.bn2.running_var           of shape (1024,)
2020-12-13 10:49:28,435 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                loaded from backbone.body.layer3.4.bn2.weight                of shape (1024,)
2020-12-13 10:49:28,435 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                  loaded from backbone.body.layer3.4.bn3.bias                  of shape (1024,)
2020-12-13 10:49:28,435 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_mean          loaded from backbone.body.layer3.4.bn3.running_mean          of shape (1024,)
2020-12-13 10:49:28,435 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_var           loaded from backbone.body.layer3.4.bn3.running_var           of shape (1024,)
2020-12-13 10:49:28,435 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                loaded from backbone.body.layer3.4.bn3.weight                of shape (1024,)
2020-12-13 10:49:28,435 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight              loaded from backbone.body.layer3.4.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,436 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight              loaded from backbone.body.layer3.4.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,436 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight              loaded from backbone.body.layer3.4.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,436 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                  loaded from backbone.body.layer3.5.bn1.bias                  of shape (1024,)
2020-12-13 10:49:28,436 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_mean          loaded from backbone.body.layer3.5.bn1.running_mean          of shape (1024,)
2020-12-13 10:49:28,436 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_var           loaded from backbone.body.layer3.5.bn1.running_var           of shape (1024,)
2020-12-13 10:49:28,436 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                loaded from backbone.body.layer3.5.bn1.weight                of shape (1024,)
2020-12-13 10:49:28,436 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                  loaded from backbone.body.layer3.5.bn2.bias                  of shape (1024,)
2020-12-13 10:49:28,436 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_mean          loaded from backbone.body.layer3.5.bn2.running_mean          of shape (1024,)
2020-12-13 10:49:28,436 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_var           loaded from backbone.body.layer3.5.bn2.running_var           of shape (1024,)
2020-12-13 10:49:28,437 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                loaded from backbone.body.layer3.5.bn2.weight                of shape (1024,)
2020-12-13 10:49:28,437 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                  loaded from backbone.body.layer3.5.bn3.bias                  of shape (1024,)
2020-12-13 10:49:28,437 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_mean          loaded from backbone.body.layer3.5.bn3.running_mean          of shape (1024,)
2020-12-13 10:49:28,437 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_var           loaded from backbone.body.layer3.5.bn3.running_var           of shape (1024,)
2020-12-13 10:49:28,437 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                loaded from backbone.body.layer3.5.bn3.weight                of shape (1024,)
2020-12-13 10:49:28,437 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight              loaded from backbone.body.layer3.5.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,437 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight              loaded from backbone.body.layer3.5.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,437 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight              loaded from backbone.body.layer3.5.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,438 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.bias                  loaded from backbone.body.layer3.6.bn1.bias                  of shape (1024,)
2020-12-13 10:49:28,438 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.running_mean          loaded from backbone.body.layer3.6.bn1.running_mean          of shape (1024,)
2020-12-13 10:49:28,438 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.running_var           loaded from backbone.body.layer3.6.bn1.running_var           of shape (1024,)
2020-12-13 10:49:28,438 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.weight                loaded from backbone.body.layer3.6.bn1.weight                of shape (1024,)
2020-12-13 10:49:28,438 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.bias                  loaded from backbone.body.layer3.6.bn2.bias                  of shape (1024,)
2020-12-13 10:49:28,438 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.running_mean          loaded from backbone.body.layer3.6.bn2.running_mean          of shape (1024,)
2020-12-13 10:49:28,438 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.running_var           loaded from backbone.body.layer3.6.bn2.running_var           of shape (1024,)
2020-12-13 10:49:28,438 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.weight                loaded from backbone.body.layer3.6.bn2.weight                of shape (1024,)
2020-12-13 10:49:28,439 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.bias                  loaded from backbone.body.layer3.6.bn3.bias                  of shape (1024,)
2020-12-13 10:49:28,439 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.running_mean          loaded from backbone.body.layer3.6.bn3.running_mean          of shape (1024,)
2020-12-13 10:49:28,439 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.running_var           loaded from backbone.body.layer3.6.bn3.running_var           of shape (1024,)
2020-12-13 10:49:28,439 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.weight                loaded from backbone.body.layer3.6.bn3.weight                of shape (1024,)
2020-12-13 10:49:28,439 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv1.weight              loaded from backbone.body.layer3.6.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,439 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv2.weight              loaded from backbone.body.layer3.6.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,439 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv3.weight              loaded from backbone.body.layer3.6.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,439 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.bias                  loaded from backbone.body.layer3.7.bn1.bias                  of shape (1024,)
2020-12-13 10:49:28,439 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.running_mean          loaded from backbone.body.layer3.7.bn1.running_mean          of shape (1024,)
2020-12-13 10:49:28,439 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.running_var           loaded from backbone.body.layer3.7.bn1.running_var           of shape (1024,)
2020-12-13 10:49:28,440 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.weight                loaded from backbone.body.layer3.7.bn1.weight                of shape (1024,)
2020-12-13 10:49:28,440 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.bias                  loaded from backbone.body.layer3.7.bn2.bias                  of shape (1024,)
2020-12-13 10:49:28,440 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.running_mean          loaded from backbone.body.layer3.7.bn2.running_mean          of shape (1024,)
2020-12-13 10:49:28,440 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.running_var           loaded from backbone.body.layer3.7.bn2.running_var           of shape (1024,)
2020-12-13 10:49:28,440 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.weight                loaded from backbone.body.layer3.7.bn2.weight                of shape (1024,)
2020-12-13 10:49:28,440 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.bias                  loaded from backbone.body.layer3.7.bn3.bias                  of shape (1024,)
2020-12-13 10:49:28,440 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.running_mean          loaded from backbone.body.layer3.7.bn3.running_mean          of shape (1024,)
2020-12-13 10:49:28,440 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.running_var           loaded from backbone.body.layer3.7.bn3.running_var           of shape (1024,)
2020-12-13 10:49:28,440 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.weight                loaded from backbone.body.layer3.7.bn3.weight                of shape (1024,)
2020-12-13 10:49:28,440 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv1.weight              loaded from backbone.body.layer3.7.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,441 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv2.weight              loaded from backbone.body.layer3.7.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,441 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv3.weight              loaded from backbone.body.layer3.7.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,441 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.bias                  loaded from backbone.body.layer3.8.bn1.bias                  of shape (1024,)
2020-12-13 10:49:28,441 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.running_mean          loaded from backbone.body.layer3.8.bn1.running_mean          of shape (1024,)
2020-12-13 10:49:28,441 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.running_var           loaded from backbone.body.layer3.8.bn1.running_var           of shape (1024,)
2020-12-13 10:49:28,441 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.weight                loaded from backbone.body.layer3.8.bn1.weight                of shape (1024,)
2020-12-13 10:49:28,441 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.bias                  loaded from backbone.body.layer3.8.bn2.bias                  of shape (1024,)
2020-12-13 10:49:28,441 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.running_mean          loaded from backbone.body.layer3.8.bn2.running_mean          of shape (1024,)
2020-12-13 10:49:28,441 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.running_var           loaded from backbone.body.layer3.8.bn2.running_var           of shape (1024,)
2020-12-13 10:49:28,441 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.weight                loaded from backbone.body.layer3.8.bn2.weight                of shape (1024,)
2020-12-13 10:49:28,441 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.bias                  loaded from backbone.body.layer3.8.bn3.bias                  of shape (1024,)
2020-12-13 10:49:28,442 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.running_mean          loaded from backbone.body.layer3.8.bn3.running_mean          of shape (1024,)
2020-12-13 10:49:28,442 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.running_var           loaded from backbone.body.layer3.8.bn3.running_var           of shape (1024,)
2020-12-13 10:49:28,442 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.weight                loaded from backbone.body.layer3.8.bn3.weight                of shape (1024,)
2020-12-13 10:49:28,442 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv1.weight              loaded from backbone.body.layer3.8.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,442 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv2.weight              loaded from backbone.body.layer3.8.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,442 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv3.weight              loaded from backbone.body.layer3.8.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,442 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.bias                  loaded from backbone.body.layer3.9.bn1.bias                  of shape (1024,)
2020-12-13 10:49:28,442 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.running_mean          loaded from backbone.body.layer3.9.bn1.running_mean          of shape (1024,)
2020-12-13 10:49:28,442 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.running_var           loaded from backbone.body.layer3.9.bn1.running_var           of shape (1024,)
2020-12-13 10:49:28,442 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.weight                loaded from backbone.body.layer3.9.bn1.weight                of shape (1024,)
2020-12-13 10:49:28,442 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.bias                  loaded from backbone.body.layer3.9.bn2.bias                  of shape (1024,)
2020-12-13 10:49:28,443 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.running_mean          loaded from backbone.body.layer3.9.bn2.running_mean          of shape (1024,)
2020-12-13 10:49:28,443 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.running_var           loaded from backbone.body.layer3.9.bn2.running_var           of shape (1024,)
2020-12-13 10:49:28,443 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.weight                loaded from backbone.body.layer3.9.bn2.weight                of shape (1024,)
2020-12-13 10:49:28,443 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.bias                  loaded from backbone.body.layer3.9.bn3.bias                  of shape (1024,)
2020-12-13 10:49:28,443 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.running_mean          loaded from backbone.body.layer3.9.bn3.running_mean          of shape (1024,)
2020-12-13 10:49:28,443 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.running_var           loaded from backbone.body.layer3.9.bn3.running_var           of shape (1024,)
2020-12-13 10:49:28,443 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.weight                loaded from backbone.body.layer3.9.bn3.weight                of shape (1024,)
2020-12-13 10:49:28,443 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv1.weight              loaded from backbone.body.layer3.9.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,443 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv2.weight              loaded from backbone.body.layer3.9.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:49:28,443 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv3.weight              loaded from backbone.body.layer3.9.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:49:28,443 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                  loaded from backbone.body.layer4.0.bn1.bias                  of shape (2048,)
2020-12-13 10:49:28,444 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_mean          loaded from backbone.body.layer4.0.bn1.running_mean          of shape (2048,)
2020-12-13 10:49:28,444 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_var           loaded from backbone.body.layer4.0.bn1.running_var           of shape (2048,)
2020-12-13 10:49:28,444 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                loaded from backbone.body.layer4.0.bn1.weight                of shape (2048,)
2020-12-13 10:49:28,444 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                  loaded from backbone.body.layer4.0.bn2.bias                  of shape (2048,)
2020-12-13 10:49:28,444 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_mean          loaded from backbone.body.layer4.0.bn2.running_mean          of shape (2048,)
2020-12-13 10:49:28,444 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_var           loaded from backbone.body.layer4.0.bn2.running_var           of shape (2048,)
2020-12-13 10:49:28,444 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                loaded from backbone.body.layer4.0.bn2.weight                of shape (2048,)
2020-12-13 10:49:28,444 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                  loaded from backbone.body.layer4.0.bn3.bias                  of shape (2048,)
2020-12-13 10:49:28,444 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_mean          loaded from backbone.body.layer4.0.bn3.running_mean          of shape (2048,)
2020-12-13 10:49:28,444 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_var           loaded from backbone.body.layer4.0.bn3.running_var           of shape (2048,)
2020-12-13 10:49:28,445 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                loaded from backbone.body.layer4.0.bn3.weight                of shape (2048,)
2020-12-13 10:49:28,445 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight              loaded from backbone.body.layer4.0.conv1.weight              of shape (2048, 1024, 1, 1)
2020-12-13 10:49:28,445 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv2.weight              loaded from backbone.body.layer4.0.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 10:49:28,445 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight              loaded from backbone.body.layer4.0.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:49:28,445 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight       loaded from backbone.body.layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)
2020-12-13 10:49:28,445 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias         loaded from backbone.body.layer4.0.downsample.1.bias         of shape (2048,)
2020-12-13 10:49:28,445 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_mean loaded from backbone.body.layer4.0.downsample.1.running_mean of shape (2048,)
2020-12-13 10:49:28,445 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_var  loaded from backbone.body.layer4.0.downsample.1.running_var  of shape (2048,)
2020-12-13 10:49:28,445 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight       loaded from backbone.body.layer4.0.downsample.1.weight       of shape (2048,)
2020-12-13 10:49:28,445 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                  loaded from backbone.body.layer4.1.bn1.bias                  of shape (2048,)
2020-12-13 10:49:28,445 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_mean          loaded from backbone.body.layer4.1.bn1.running_mean          of shape (2048,)
2020-12-13 10:49:28,446 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_var           loaded from backbone.body.layer4.1.bn1.running_var           of shape (2048,)
2020-12-13 10:49:28,446 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                loaded from backbone.body.layer4.1.bn1.weight                of shape (2048,)
2020-12-13 10:49:28,446 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                  loaded from backbone.body.layer4.1.bn2.bias                  of shape (2048,)
2020-12-13 10:49:28,446 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_mean          loaded from backbone.body.layer4.1.bn2.running_mean          of shape (2048,)
2020-12-13 10:49:28,446 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_var           loaded from backbone.body.layer4.1.bn2.running_var           of shape (2048,)
2020-12-13 10:49:28,446 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                loaded from backbone.body.layer4.1.bn2.weight                of shape (2048,)
2020-12-13 10:49:28,446 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                  loaded from backbone.body.layer4.1.bn3.bias                  of shape (2048,)
2020-12-13 10:49:28,446 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_mean          loaded from backbone.body.layer4.1.bn3.running_mean          of shape (2048,)
2020-12-13 10:49:28,446 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_var           loaded from backbone.body.layer4.1.bn3.running_var           of shape (2048,)
2020-12-13 10:49:28,446 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                loaded from backbone.body.layer4.1.bn3.weight                of shape (2048,)
2020-12-13 10:49:28,446 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight              loaded from backbone.body.layer4.1.conv1.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:49:28,447 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv2.weight              loaded from backbone.body.layer4.1.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 10:49:28,447 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight              loaded from backbone.body.layer4.1.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:49:28,447 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                  loaded from backbone.body.layer4.2.bn1.bias                  of shape (2048,)
2020-12-13 10:49:28,447 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_mean          loaded from backbone.body.layer4.2.bn1.running_mean          of shape (2048,)
2020-12-13 10:49:28,447 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_var           loaded from backbone.body.layer4.2.bn1.running_var           of shape (2048,)
2020-12-13 10:49:28,447 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                loaded from backbone.body.layer4.2.bn1.weight                of shape (2048,)
2020-12-13 10:49:28,447 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                  loaded from backbone.body.layer4.2.bn2.bias                  of shape (2048,)
2020-12-13 10:49:28,447 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_mean          loaded from backbone.body.layer4.2.bn2.running_mean          of shape (2048,)
2020-12-13 10:49:28,447 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_var           loaded from backbone.body.layer4.2.bn2.running_var           of shape (2048,)
2020-12-13 10:49:28,447 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                loaded from backbone.body.layer4.2.bn2.weight                of shape (2048,)
2020-12-13 10:49:28,447 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                  loaded from backbone.body.layer4.2.bn3.bias                  of shape (2048,)
2020-12-13 10:49:28,448 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_mean          loaded from backbone.body.layer4.2.bn3.running_mean          of shape (2048,)
2020-12-13 10:49:28,448 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_var           loaded from backbone.body.layer4.2.bn3.running_var           of shape (2048,)
2020-12-13 10:49:28,448 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                loaded from backbone.body.layer4.2.bn3.weight                of shape (2048,)
2020-12-13 10:49:28,448 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight              loaded from backbone.body.layer4.2.conv1.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:49:28,448 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv2.weight              loaded from backbone.body.layer4.2.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 10:49:28,448 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight              loaded from backbone.body.layer4.2.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:49:28,448 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                      loaded from backbone.body.stem.bn1.bias                      of shape (64,)
2020-12-13 10:49:28,448 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_mean              loaded from backbone.body.stem.bn1.running_mean              of shape (64,)
2020-12-13 10:49:28,448 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_var               loaded from backbone.body.stem.bn1.running_var               of shape (64,)
2020-12-13 10:49:28,448 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                    loaded from backbone.body.stem.bn1.weight                    of shape (64,)
2020-12-13 10:49:28,448 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                  loaded from backbone.body.stem.conv1.weight                  of shape (64, 3, 7, 7)
2020-12-13 10:49:28,449 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.bias                     loaded from backbone.fpn.fpn_inner1.bias                     of shape (256,)
2020-12-13 10:49:28,449 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.weight                   loaded from backbone.fpn.fpn_inner1.weight                   of shape (256, 256, 1, 1)
2020-12-13 10:49:28,449 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                     loaded from backbone.fpn.fpn_inner2.bias                     of shape (256,)
2020-12-13 10:49:28,449 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                   loaded from backbone.fpn.fpn_inner2.weight                   of shape (256, 512, 1, 1)
2020-12-13 10:49:28,449 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                     loaded from backbone.fpn.fpn_inner3.bias                     of shape (256,)
2020-12-13 10:49:28,449 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                   loaded from backbone.fpn.fpn_inner3.weight                   of shape (256, 1024, 1, 1)
2020-12-13 10:49:28,449 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                     loaded from backbone.fpn.fpn_inner4.bias                     of shape (256,)
2020-12-13 10:49:28,449 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                   loaded from backbone.fpn.fpn_inner4.weight                   of shape (256, 2048, 1, 1)
2020-12-13 10:49:28,449 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.bias                     loaded from backbone.fpn.fpn_layer1.bias                     of shape (256,)
2020-12-13 10:49:28,449 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.weight                   loaded from backbone.fpn.fpn_layer1.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:49:28,449 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                     loaded from backbone.fpn.fpn_layer2.bias                     of shape (256,)
2020-12-13 10:49:28,450 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                   loaded from backbone.fpn.fpn_layer2.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:49:28,450 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                     loaded from backbone.fpn.fpn_layer3.bias                     of shape (256,)
2020-12-13 10:49:28,450 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                   loaded from backbone.fpn.fpn_layer3.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:49:28,450 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                     loaded from backbone.fpn.fpn_layer4.bias                     of shape (256,)
2020-12-13 10:49:28,450 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                   loaded from backbone.fpn.fpn_layer4.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:49:28,450 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.bias         loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (1024,)
2020-12-13 10:49:28,450 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.weight       loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (1024, 12544)
2020-12-13 10:49:28,450 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.bias         loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (1024,)
2020-12-13 10:49:28,450 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.weight       loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (1024, 1024)
2020-12-13 10:49:28,450 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.bias           loaded from roi_heads.box.predictor.bbox_pred.bias           of shape (36,)
2020-12-13 10:49:28,451 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.weight         loaded from roi_heads.box.predictor.bbox_pred.weight         of shape (36, 1024)
2020-12-13 10:49:28,451 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.bias           loaded from roi_heads.box.predictor.cls_score.bias           of shape (9,)
2020-12-13 10:49:28,451 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.weight         loaded from roi_heads.box.predictor.cls_score.weight         of shape (9, 1024)
2020-12-13 10:49:28,451 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.0              loaded from rpn.anchor_generator.cell_anchors.0              of shape (3, 4)
2020-12-13 10:49:28,451 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.1              loaded from rpn.anchor_generator.cell_anchors.1              of shape (3, 4)
2020-12-13 10:49:28,451 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.2              loaded from rpn.anchor_generator.cell_anchors.2              of shape (3, 4)
2020-12-13 10:49:28,451 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.3              loaded from rpn.anchor_generator.cell_anchors.3              of shape (3, 4)
2020-12-13 10:49:28,451 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.4              loaded from rpn.anchor_generator.cell_anchors.4              of shape (3, 4)
2020-12-13 10:49:28,451 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                          loaded from rpn.head.bbox_pred.bias                          of shape (12,)
2020-12-13 10:49:28,451 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                        loaded from rpn.head.bbox_pred.weight                        of shape (12, 256, 1, 1)
2020-12-13 10:49:28,451 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                         loaded from rpn.head.cls_logits.bias                         of shape (3,)
2020-12-13 10:49:28,452 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                       loaded from rpn.head.cls_logits.weight                       of shape (3, 256, 1, 1)
2020-12-13 10:49:28,452 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.bias                               loaded from rpn.head.conv.bias                               of shape (256,)
2020-12-13 10:49:28,452 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.weight                             loaded from rpn.head.conv.weight                             of shape (256, 256, 3, 3)
2020-12-13 10:50:04,075 maskrcnn_benchmark INFO: Using 1 GPUs
2020-12-13 10:50:04,076 maskrcnn_benchmark INFO: Namespace(config_file='d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml', custom_dict='custom_dict.txt', distributed=False, local_rank=0, opts=[], skip_test=False, weights='visdrone_model_0360000.pth')
2020-12-13 10:50:04,076 maskrcnn_benchmark INFO: Collecting env info (might take some time)
2020-12-13 10:50:06,461 maskrcnn_benchmark INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.7 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
CMake version: version 3.5.1

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 950M
Nvidia driver version: 450.80.02
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.4

Versions of relevant libraries:
[pip3] numpy==1.19.4
[pip3] torch==1.1.0
[pip3] torchvision==0.3.0
[conda] blas                      1.0                         mkl  
[conda] mkl                       2020.2                      256  
[conda] mkl-service               2.3.0            py36he904b0f_0  
[conda] mkl_fft                   1.2.0            py36h23d657b_0  
[conda] mkl_random                1.1.1            py36h0573a6f_0  
[conda] pytorch                   1.1.0           py3.6_cuda9.0.176_cudnn7.5.1_0    pytorch
[conda] pytorch-nightly           1.0.0.dev20190328 py3.6_cuda9.0.176_cudnn7.4.2_0    pytorch
[conda] torchvision               0.3.0           py36_cu9.0.176_1    pytorch
        Pillow (8.0.1)
2020-12-13 10:50:06,461 maskrcnn_benchmark INFO: Loaded configuration file d_e2e_faster_rcnn_X_101_32x8d_FPN_1x_visdrone.yaml
2020-12-13 10:50:06,461 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "e2e_faster_rcnn_X_101_32x8d_FPN_1x.pth"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
    FREEZE_CONV_BODY_AT: 5
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
DATASETS:
  TRAIN: ("giro1_train", "giro4_train", "giro8_train",)
  TEST: ("giro1_test","giro4_test","giro8_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
  NUM_WORKERS: 0
SOLVER:
  BASE_LR: 0.00004
  WEIGHT_DECAY: 0.0001
  STEPS: (480000, 640000,)
  MAX_ITER: 1600
  IMS_PER_BATCH: 2
TEST:
  IMS_PER_BATCH: 1

2020-12-13 10:50:06,463 maskrcnn_benchmark INFO: Running with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 0
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('giro1_test', 'giro4_test', 'giro8_test')
  TRAIN: ('giro1_train', 'giro4_train', 'giro8_train')
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MODEL:
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 5
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 1000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  WEIGHT: visdrone_model_0360000.pth
OUTPUT_DIR: .
PATHS_CATALOG: /zold137/maskrcnn_benchmark/config/paths_catalog.py
SOLVER:
  BASE_LR: 4e-05
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  MAX_ITER: 1600
  MOMENTUM: 0.9
  STEPS: (480000, 640000)
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
2020-12-13 10:50:08,314 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from visdrone_model_0360000.pth
2020-12-13 10:50:09,477 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                  loaded from backbone.body.layer1.0.bn1.bias                  of shape (256,)
2020-12-13 10:50:09,477 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_mean          loaded from backbone.body.layer1.0.bn1.running_mean          of shape (256,)
2020-12-13 10:50:09,478 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_var           loaded from backbone.body.layer1.0.bn1.running_var           of shape (256,)
2020-12-13 10:50:09,478 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                loaded from backbone.body.layer1.0.bn1.weight                of shape (256,)
2020-12-13 10:50:09,478 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                  loaded from backbone.body.layer1.0.bn2.bias                  of shape (256,)
2020-12-13 10:50:09,478 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_mean          loaded from backbone.body.layer1.0.bn2.running_mean          of shape (256,)
2020-12-13 10:50:09,478 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_var           loaded from backbone.body.layer1.0.bn2.running_var           of shape (256,)
2020-12-13 10:50:09,478 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                loaded from backbone.body.layer1.0.bn2.weight                of shape (256,)
2020-12-13 10:50:09,478 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                  loaded from backbone.body.layer1.0.bn3.bias                  of shape (256,)
2020-12-13 10:50:09,478 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_mean          loaded from backbone.body.layer1.0.bn3.running_mean          of shape (256,)
2020-12-13 10:50:09,478 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_var           loaded from backbone.body.layer1.0.bn3.running_var           of shape (256,)
2020-12-13 10:50:09,479 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                loaded from backbone.body.layer1.0.bn3.weight                of shape (256,)
2020-12-13 10:50:09,479 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight              loaded from backbone.body.layer1.0.conv1.weight              of shape (256, 64, 1, 1)
2020-12-13 10:50:09,479 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight              loaded from backbone.body.layer1.0.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 10:50:09,479 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight              loaded from backbone.body.layer1.0.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 10:50:09,479 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight       loaded from backbone.body.layer1.0.downsample.0.weight       of shape (256, 64, 1, 1)
2020-12-13 10:50:09,479 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias         loaded from backbone.body.layer1.0.downsample.1.bias         of shape (256,)
2020-12-13 10:50:09,479 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_mean loaded from backbone.body.layer1.0.downsample.1.running_mean of shape (256,)
2020-12-13 10:50:09,479 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_var  loaded from backbone.body.layer1.0.downsample.1.running_var  of shape (256,)
2020-12-13 10:50:09,479 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight       loaded from backbone.body.layer1.0.downsample.1.weight       of shape (256,)
2020-12-13 10:50:09,480 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                  loaded from backbone.body.layer1.1.bn1.bias                  of shape (256,)
2020-12-13 10:50:09,480 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_mean          loaded from backbone.body.layer1.1.bn1.running_mean          of shape (256,)
2020-12-13 10:50:09,480 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_var           loaded from backbone.body.layer1.1.bn1.running_var           of shape (256,)
2020-12-13 10:50:09,480 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                loaded from backbone.body.layer1.1.bn1.weight                of shape (256,)
2020-12-13 10:50:09,480 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                  loaded from backbone.body.layer1.1.bn2.bias                  of shape (256,)
2020-12-13 10:50:09,480 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_mean          loaded from backbone.body.layer1.1.bn2.running_mean          of shape (256,)
2020-12-13 10:50:09,480 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_var           loaded from backbone.body.layer1.1.bn2.running_var           of shape (256,)
2020-12-13 10:50:09,480 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                loaded from backbone.body.layer1.1.bn2.weight                of shape (256,)
2020-12-13 10:50:09,480 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                  loaded from backbone.body.layer1.1.bn3.bias                  of shape (256,)
2020-12-13 10:50:09,481 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_mean          loaded from backbone.body.layer1.1.bn3.running_mean          of shape (256,)
2020-12-13 10:50:09,481 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_var           loaded from backbone.body.layer1.1.bn3.running_var           of shape (256,)
2020-12-13 10:50:09,481 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                loaded from backbone.body.layer1.1.bn3.weight                of shape (256,)
2020-12-13 10:50:09,481 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight              loaded from backbone.body.layer1.1.conv1.weight              of shape (256, 256, 1, 1)
2020-12-13 10:50:09,481 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight              loaded from backbone.body.layer1.1.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 10:50:09,481 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight              loaded from backbone.body.layer1.1.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 10:50:09,481 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                  loaded from backbone.body.layer1.2.bn1.bias                  of shape (256,)
2020-12-13 10:50:09,481 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_mean          loaded from backbone.body.layer1.2.bn1.running_mean          of shape (256,)
2020-12-13 10:50:09,481 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_var           loaded from backbone.body.layer1.2.bn1.running_var           of shape (256,)
2020-12-13 10:50:09,482 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                loaded from backbone.body.layer1.2.bn1.weight                of shape (256,)
2020-12-13 10:50:09,482 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                  loaded from backbone.body.layer1.2.bn2.bias                  of shape (256,)
2020-12-13 10:50:09,482 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_mean          loaded from backbone.body.layer1.2.bn2.running_mean          of shape (256,)
2020-12-13 10:50:09,482 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_var           loaded from backbone.body.layer1.2.bn2.running_var           of shape (256,)
2020-12-13 10:50:09,482 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                loaded from backbone.body.layer1.2.bn2.weight                of shape (256,)
2020-12-13 10:50:09,482 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                  loaded from backbone.body.layer1.2.bn3.bias                  of shape (256,)
2020-12-13 10:50:09,482 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_mean          loaded from backbone.body.layer1.2.bn3.running_mean          of shape (256,)
2020-12-13 10:50:09,482 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_var           loaded from backbone.body.layer1.2.bn3.running_var           of shape (256,)
2020-12-13 10:50:09,482 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                loaded from backbone.body.layer1.2.bn3.weight                of shape (256,)
2020-12-13 10:50:09,482 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight              loaded from backbone.body.layer1.2.conv1.weight              of shape (256, 256, 1, 1)
2020-12-13 10:50:09,483 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight              loaded from backbone.body.layer1.2.conv2.weight              of shape (256, 8, 3, 3)
2020-12-13 10:50:09,483 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight              loaded from backbone.body.layer1.2.conv3.weight              of shape (256, 256, 1, 1)
2020-12-13 10:50:09,483 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                  loaded from backbone.body.layer2.0.bn1.bias                  of shape (512,)
2020-12-13 10:50:09,483 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_mean          loaded from backbone.body.layer2.0.bn1.running_mean          of shape (512,)
2020-12-13 10:50:09,483 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_var           loaded from backbone.body.layer2.0.bn1.running_var           of shape (512,)
2020-12-13 10:50:09,483 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                loaded from backbone.body.layer2.0.bn1.weight                of shape (512,)
2020-12-13 10:50:09,483 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                  loaded from backbone.body.layer2.0.bn2.bias                  of shape (512,)
2020-12-13 10:50:09,483 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_mean          loaded from backbone.body.layer2.0.bn2.running_mean          of shape (512,)
2020-12-13 10:50:09,483 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_var           loaded from backbone.body.layer2.0.bn2.running_var           of shape (512,)
2020-12-13 10:50:09,483 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                loaded from backbone.body.layer2.0.bn2.weight                of shape (512,)
2020-12-13 10:50:09,483 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                  loaded from backbone.body.layer2.0.bn3.bias                  of shape (512,)
2020-12-13 10:50:09,484 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_mean          loaded from backbone.body.layer2.0.bn3.running_mean          of shape (512,)
2020-12-13 10:50:09,484 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_var           loaded from backbone.body.layer2.0.bn3.running_var           of shape (512,)
2020-12-13 10:50:09,484 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                loaded from backbone.body.layer2.0.bn3.weight                of shape (512,)
2020-12-13 10:50:09,484 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight              loaded from backbone.body.layer2.0.conv1.weight              of shape (512, 256, 1, 1)
2020-12-13 10:50:09,484 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight              loaded from backbone.body.layer2.0.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:50:09,484 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight              loaded from backbone.body.layer2.0.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:50:09,484 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight       loaded from backbone.body.layer2.0.downsample.0.weight       of shape (512, 256, 1, 1)
2020-12-13 10:50:09,484 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias         loaded from backbone.body.layer2.0.downsample.1.bias         of shape (512,)
2020-12-13 10:50:09,484 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_mean loaded from backbone.body.layer2.0.downsample.1.running_mean of shape (512,)
2020-12-13 10:50:09,484 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_var  loaded from backbone.body.layer2.0.downsample.1.running_var  of shape (512,)
2020-12-13 10:50:09,485 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight       loaded from backbone.body.layer2.0.downsample.1.weight       of shape (512,)
2020-12-13 10:50:09,485 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                  loaded from backbone.body.layer2.1.bn1.bias                  of shape (512,)
2020-12-13 10:50:09,485 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_mean          loaded from backbone.body.layer2.1.bn1.running_mean          of shape (512,)
2020-12-13 10:50:09,485 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_var           loaded from backbone.body.layer2.1.bn1.running_var           of shape (512,)
2020-12-13 10:50:09,485 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                loaded from backbone.body.layer2.1.bn1.weight                of shape (512,)
2020-12-13 10:50:09,485 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                  loaded from backbone.body.layer2.1.bn2.bias                  of shape (512,)
2020-12-13 10:50:09,485 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_mean          loaded from backbone.body.layer2.1.bn2.running_mean          of shape (512,)
2020-12-13 10:50:09,485 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_var           loaded from backbone.body.layer2.1.bn2.running_var           of shape (512,)
2020-12-13 10:50:09,485 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                loaded from backbone.body.layer2.1.bn2.weight                of shape (512,)
2020-12-13 10:50:09,485 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                  loaded from backbone.body.layer2.1.bn3.bias                  of shape (512,)
2020-12-13 10:50:09,485 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_mean          loaded from backbone.body.layer2.1.bn3.running_mean          of shape (512,)
2020-12-13 10:50:09,486 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_var           loaded from backbone.body.layer2.1.bn3.running_var           of shape (512,)
2020-12-13 10:50:09,486 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                loaded from backbone.body.layer2.1.bn3.weight                of shape (512,)
2020-12-13 10:50:09,486 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight              loaded from backbone.body.layer2.1.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 10:50:09,486 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight              loaded from backbone.body.layer2.1.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:50:09,486 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight              loaded from backbone.body.layer2.1.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:50:09,486 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                  loaded from backbone.body.layer2.2.bn1.bias                  of shape (512,)
2020-12-13 10:50:09,486 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_mean          loaded from backbone.body.layer2.2.bn1.running_mean          of shape (512,)
2020-12-13 10:50:09,486 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_var           loaded from backbone.body.layer2.2.bn1.running_var           of shape (512,)
2020-12-13 10:50:09,486 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                loaded from backbone.body.layer2.2.bn1.weight                of shape (512,)
2020-12-13 10:50:09,486 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                  loaded from backbone.body.layer2.2.bn2.bias                  of shape (512,)
2020-12-13 10:50:09,486 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_mean          loaded from backbone.body.layer2.2.bn2.running_mean          of shape (512,)
2020-12-13 10:50:09,487 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_var           loaded from backbone.body.layer2.2.bn2.running_var           of shape (512,)
2020-12-13 10:50:09,487 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                loaded from backbone.body.layer2.2.bn2.weight                of shape (512,)
2020-12-13 10:50:09,487 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                  loaded from backbone.body.layer2.2.bn3.bias                  of shape (512,)
2020-12-13 10:50:09,487 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_mean          loaded from backbone.body.layer2.2.bn3.running_mean          of shape (512,)
2020-12-13 10:50:09,487 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_var           loaded from backbone.body.layer2.2.bn3.running_var           of shape (512,)
2020-12-13 10:50:09,487 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                loaded from backbone.body.layer2.2.bn3.weight                of shape (512,)
2020-12-13 10:50:09,487 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight              loaded from backbone.body.layer2.2.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 10:50:09,487 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight              loaded from backbone.body.layer2.2.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:50:09,487 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight              loaded from backbone.body.layer2.2.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:50:09,487 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                  loaded from backbone.body.layer2.3.bn1.bias                  of shape (512,)
2020-12-13 10:50:09,487 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_mean          loaded from backbone.body.layer2.3.bn1.running_mean          of shape (512,)
2020-12-13 10:50:09,488 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_var           loaded from backbone.body.layer2.3.bn1.running_var           of shape (512,)
2020-12-13 10:50:09,488 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                loaded from backbone.body.layer2.3.bn1.weight                of shape (512,)
2020-12-13 10:50:09,488 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                  loaded from backbone.body.layer2.3.bn2.bias                  of shape (512,)
2020-12-13 10:50:09,488 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_mean          loaded from backbone.body.layer2.3.bn2.running_mean          of shape (512,)
2020-12-13 10:50:09,488 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_var           loaded from backbone.body.layer2.3.bn2.running_var           of shape (512,)
2020-12-13 10:50:09,488 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                loaded from backbone.body.layer2.3.bn2.weight                of shape (512,)
2020-12-13 10:50:09,488 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                  loaded from backbone.body.layer2.3.bn3.bias                  of shape (512,)
2020-12-13 10:50:09,488 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_mean          loaded from backbone.body.layer2.3.bn3.running_mean          of shape (512,)
2020-12-13 10:50:09,488 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_var           loaded from backbone.body.layer2.3.bn3.running_var           of shape (512,)
2020-12-13 10:50:09,488 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                loaded from backbone.body.layer2.3.bn3.weight                of shape (512,)
2020-12-13 10:50:09,489 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight              loaded from backbone.body.layer2.3.conv1.weight              of shape (512, 512, 1, 1)
2020-12-13 10:50:09,489 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight              loaded from backbone.body.layer2.3.conv2.weight              of shape (512, 16, 3, 3)
2020-12-13 10:50:09,489 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight              loaded from backbone.body.layer2.3.conv3.weight              of shape (512, 512, 1, 1)
2020-12-13 10:50:09,489 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                  loaded from backbone.body.layer3.0.bn1.bias                  of shape (1024,)
2020-12-13 10:50:09,489 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_mean          loaded from backbone.body.layer3.0.bn1.running_mean          of shape (1024,)
2020-12-13 10:50:09,489 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_var           loaded from backbone.body.layer3.0.bn1.running_var           of shape (1024,)
2020-12-13 10:50:09,489 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                loaded from backbone.body.layer3.0.bn1.weight                of shape (1024,)
2020-12-13 10:50:09,490 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                  loaded from backbone.body.layer3.0.bn2.bias                  of shape (1024,)
2020-12-13 10:50:09,490 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_mean          loaded from backbone.body.layer3.0.bn2.running_mean          of shape (1024,)
2020-12-13 10:50:09,490 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_var           loaded from backbone.body.layer3.0.bn2.running_var           of shape (1024,)
2020-12-13 10:50:09,490 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                loaded from backbone.body.layer3.0.bn2.weight                of shape (1024,)
2020-12-13 10:50:09,490 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                  loaded from backbone.body.layer3.0.bn3.bias                  of shape (1024,)
2020-12-13 10:50:09,490 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_mean          loaded from backbone.body.layer3.0.bn3.running_mean          of shape (1024,)
2020-12-13 10:50:09,490 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_var           loaded from backbone.body.layer3.0.bn3.running_var           of shape (1024,)
2020-12-13 10:50:09,490 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                loaded from backbone.body.layer3.0.bn3.weight                of shape (1024,)
2020-12-13 10:50:09,490 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight              loaded from backbone.body.layer3.0.conv1.weight              of shape (1024, 512, 1, 1)
2020-12-13 10:50:09,491 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight              loaded from backbone.body.layer3.0.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,491 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight              loaded from backbone.body.layer3.0.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,491 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight       loaded from backbone.body.layer3.0.downsample.0.weight       of shape (1024, 512, 1, 1)
2020-12-13 10:50:09,491 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias         loaded from backbone.body.layer3.0.downsample.1.bias         of shape (1024,)
2020-12-13 10:50:09,491 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_mean loaded from backbone.body.layer3.0.downsample.1.running_mean of shape (1024,)
2020-12-13 10:50:09,491 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_var  loaded from backbone.body.layer3.0.downsample.1.running_var  of shape (1024,)
2020-12-13 10:50:09,491 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight       loaded from backbone.body.layer3.0.downsample.1.weight       of shape (1024,)
2020-12-13 10:50:09,491 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                  loaded from backbone.body.layer3.1.bn1.bias                  of shape (1024,)
2020-12-13 10:50:09,492 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_mean          loaded from backbone.body.layer3.1.bn1.running_mean          of shape (1024,)
2020-12-13 10:50:09,492 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_var           loaded from backbone.body.layer3.1.bn1.running_var           of shape (1024,)
2020-12-13 10:50:09,492 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                loaded from backbone.body.layer3.1.bn1.weight                of shape (1024,)
2020-12-13 10:50:09,492 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                  loaded from backbone.body.layer3.1.bn2.bias                  of shape (1024,)
2020-12-13 10:50:09,492 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_mean          loaded from backbone.body.layer3.1.bn2.running_mean          of shape (1024,)
2020-12-13 10:50:09,492 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_var           loaded from backbone.body.layer3.1.bn2.running_var           of shape (1024,)
2020-12-13 10:50:09,492 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                loaded from backbone.body.layer3.1.bn2.weight                of shape (1024,)
2020-12-13 10:50:09,492 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                  loaded from backbone.body.layer3.1.bn3.bias                  of shape (1024,)
2020-12-13 10:50:09,492 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_mean          loaded from backbone.body.layer3.1.bn3.running_mean          of shape (1024,)
2020-12-13 10:50:09,493 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_var           loaded from backbone.body.layer3.1.bn3.running_var           of shape (1024,)
2020-12-13 10:50:09,493 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                loaded from backbone.body.layer3.1.bn3.weight                of shape (1024,)
2020-12-13 10:50:09,493 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight              loaded from backbone.body.layer3.1.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,493 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight              loaded from backbone.body.layer3.1.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,493 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight              loaded from backbone.body.layer3.1.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,493 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.bias                 loaded from backbone.body.layer3.10.bn1.bias                 of shape (1024,)
2020-12-13 10:50:09,493 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.running_mean         loaded from backbone.body.layer3.10.bn1.running_mean         of shape (1024,)
2020-12-13 10:50:09,493 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.running_var          loaded from backbone.body.layer3.10.bn1.running_var          of shape (1024,)
2020-12-13 10:50:09,494 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn1.weight               loaded from backbone.body.layer3.10.bn1.weight               of shape (1024,)
2020-12-13 10:50:09,494 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.bias                 loaded from backbone.body.layer3.10.bn2.bias                 of shape (1024,)
2020-12-13 10:50:09,494 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.running_mean         loaded from backbone.body.layer3.10.bn2.running_mean         of shape (1024,)
2020-12-13 10:50:09,494 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.running_var          loaded from backbone.body.layer3.10.bn2.running_var          of shape (1024,)
2020-12-13 10:50:09,494 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn2.weight               loaded from backbone.body.layer3.10.bn2.weight               of shape (1024,)
2020-12-13 10:50:09,494 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.bias                 loaded from backbone.body.layer3.10.bn3.bias                 of shape (1024,)
2020-12-13 10:50:09,494 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.running_mean         loaded from backbone.body.layer3.10.bn3.running_mean         of shape (1024,)
2020-12-13 10:50:09,494 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.running_var          loaded from backbone.body.layer3.10.bn3.running_var          of shape (1024,)
2020-12-13 10:50:09,494 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.bn3.weight               loaded from backbone.body.layer3.10.bn3.weight               of shape (1024,)
2020-12-13 10:50:09,495 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv1.weight             loaded from backbone.body.layer3.10.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,495 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv2.weight             loaded from backbone.body.layer3.10.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,495 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.10.conv3.weight             loaded from backbone.body.layer3.10.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,495 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.bias                 loaded from backbone.body.layer3.11.bn1.bias                 of shape (1024,)
2020-12-13 10:50:09,495 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.running_mean         loaded from backbone.body.layer3.11.bn1.running_mean         of shape (1024,)
2020-12-13 10:50:09,495 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.running_var          loaded from backbone.body.layer3.11.bn1.running_var          of shape (1024,)
2020-12-13 10:50:09,495 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn1.weight               loaded from backbone.body.layer3.11.bn1.weight               of shape (1024,)
2020-12-13 10:50:09,495 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.bias                 loaded from backbone.body.layer3.11.bn2.bias                 of shape (1024,)
2020-12-13 10:50:09,495 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.running_mean         loaded from backbone.body.layer3.11.bn2.running_mean         of shape (1024,)
2020-12-13 10:50:09,496 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.running_var          loaded from backbone.body.layer3.11.bn2.running_var          of shape (1024,)
2020-12-13 10:50:09,496 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn2.weight               loaded from backbone.body.layer3.11.bn2.weight               of shape (1024,)
2020-12-13 10:50:09,496 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.bias                 loaded from backbone.body.layer3.11.bn3.bias                 of shape (1024,)
2020-12-13 10:50:09,496 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.running_mean         loaded from backbone.body.layer3.11.bn3.running_mean         of shape (1024,)
2020-12-13 10:50:09,496 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.running_var          loaded from backbone.body.layer3.11.bn3.running_var          of shape (1024,)
2020-12-13 10:50:09,496 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.bn3.weight               loaded from backbone.body.layer3.11.bn3.weight               of shape (1024,)
2020-12-13 10:50:09,496 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv1.weight             loaded from backbone.body.layer3.11.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,496 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv2.weight             loaded from backbone.body.layer3.11.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,496 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.11.conv3.weight             loaded from backbone.body.layer3.11.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,497 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.bias                 loaded from backbone.body.layer3.12.bn1.bias                 of shape (1024,)
2020-12-13 10:50:09,497 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.running_mean         loaded from backbone.body.layer3.12.bn1.running_mean         of shape (1024,)
2020-12-13 10:50:09,497 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.running_var          loaded from backbone.body.layer3.12.bn1.running_var          of shape (1024,)
2020-12-13 10:50:09,497 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn1.weight               loaded from backbone.body.layer3.12.bn1.weight               of shape (1024,)
2020-12-13 10:50:09,497 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.bias                 loaded from backbone.body.layer3.12.bn2.bias                 of shape (1024,)
2020-12-13 10:50:09,497 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.running_mean         loaded from backbone.body.layer3.12.bn2.running_mean         of shape (1024,)
2020-12-13 10:50:09,497 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.running_var          loaded from backbone.body.layer3.12.bn2.running_var          of shape (1024,)
2020-12-13 10:50:09,497 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn2.weight               loaded from backbone.body.layer3.12.bn2.weight               of shape (1024,)
2020-12-13 10:50:09,497 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.bias                 loaded from backbone.body.layer3.12.bn3.bias                 of shape (1024,)
2020-12-13 10:50:09,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.running_mean         loaded from backbone.body.layer3.12.bn3.running_mean         of shape (1024,)
2020-12-13 10:50:09,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.running_var          loaded from backbone.body.layer3.12.bn3.running_var          of shape (1024,)
2020-12-13 10:50:09,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.bn3.weight               loaded from backbone.body.layer3.12.bn3.weight               of shape (1024,)
2020-12-13 10:50:09,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv1.weight             loaded from backbone.body.layer3.12.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv2.weight             loaded from backbone.body.layer3.12.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.12.conv3.weight             loaded from backbone.body.layer3.12.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.bias                 loaded from backbone.body.layer3.13.bn1.bias                 of shape (1024,)
2020-12-13 10:50:09,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.running_mean         loaded from backbone.body.layer3.13.bn1.running_mean         of shape (1024,)
2020-12-13 10:50:09,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.running_var          loaded from backbone.body.layer3.13.bn1.running_var          of shape (1024,)
2020-12-13 10:50:09,498 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn1.weight               loaded from backbone.body.layer3.13.bn1.weight               of shape (1024,)
2020-12-13 10:50:09,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.bias                 loaded from backbone.body.layer3.13.bn2.bias                 of shape (1024,)
2020-12-13 10:50:09,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.running_mean         loaded from backbone.body.layer3.13.bn2.running_mean         of shape (1024,)
2020-12-13 10:50:09,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.running_var          loaded from backbone.body.layer3.13.bn2.running_var          of shape (1024,)
2020-12-13 10:50:09,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn2.weight               loaded from backbone.body.layer3.13.bn2.weight               of shape (1024,)
2020-12-13 10:50:09,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.bias                 loaded from backbone.body.layer3.13.bn3.bias                 of shape (1024,)
2020-12-13 10:50:09,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.running_mean         loaded from backbone.body.layer3.13.bn3.running_mean         of shape (1024,)
2020-12-13 10:50:09,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.running_var          loaded from backbone.body.layer3.13.bn3.running_var          of shape (1024,)
2020-12-13 10:50:09,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.bn3.weight               loaded from backbone.body.layer3.13.bn3.weight               of shape (1024,)
2020-12-13 10:50:09,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv1.weight             loaded from backbone.body.layer3.13.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv2.weight             loaded from backbone.body.layer3.13.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.13.conv3.weight             loaded from backbone.body.layer3.13.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.bias                 loaded from backbone.body.layer3.14.bn1.bias                 of shape (1024,)
2020-12-13 10:50:09,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.running_mean         loaded from backbone.body.layer3.14.bn1.running_mean         of shape (1024,)
2020-12-13 10:50:09,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.running_var          loaded from backbone.body.layer3.14.bn1.running_var          of shape (1024,)
2020-12-13 10:50:09,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn1.weight               loaded from backbone.body.layer3.14.bn1.weight               of shape (1024,)
2020-12-13 10:50:09,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.bias                 loaded from backbone.body.layer3.14.bn2.bias                 of shape (1024,)
2020-12-13 10:50:09,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.running_mean         loaded from backbone.body.layer3.14.bn2.running_mean         of shape (1024,)
2020-12-13 10:50:09,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.running_var          loaded from backbone.body.layer3.14.bn2.running_var          of shape (1024,)
2020-12-13 10:50:09,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn2.weight               loaded from backbone.body.layer3.14.bn2.weight               of shape (1024,)
2020-12-13 10:50:09,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.bias                 loaded from backbone.body.layer3.14.bn3.bias                 of shape (1024,)
2020-12-13 10:50:09,501 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.running_mean         loaded from backbone.body.layer3.14.bn3.running_mean         of shape (1024,)
2020-12-13 10:50:09,501 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.running_var          loaded from backbone.body.layer3.14.bn3.running_var          of shape (1024,)
2020-12-13 10:50:09,501 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.bn3.weight               loaded from backbone.body.layer3.14.bn3.weight               of shape (1024,)
2020-12-13 10:50:09,501 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv1.weight             loaded from backbone.body.layer3.14.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,501 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv2.weight             loaded from backbone.body.layer3.14.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,501 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.14.conv3.weight             loaded from backbone.body.layer3.14.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,501 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.bias                 loaded from backbone.body.layer3.15.bn1.bias                 of shape (1024,)
2020-12-13 10:50:09,501 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.running_mean         loaded from backbone.body.layer3.15.bn1.running_mean         of shape (1024,)
2020-12-13 10:50:09,501 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.running_var          loaded from backbone.body.layer3.15.bn1.running_var          of shape (1024,)
2020-12-13 10:50:09,502 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn1.weight               loaded from backbone.body.layer3.15.bn1.weight               of shape (1024,)
2020-12-13 10:50:09,502 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.bias                 loaded from backbone.body.layer3.15.bn2.bias                 of shape (1024,)
2020-12-13 10:50:09,502 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.running_mean         loaded from backbone.body.layer3.15.bn2.running_mean         of shape (1024,)
2020-12-13 10:50:09,502 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.running_var          loaded from backbone.body.layer3.15.bn2.running_var          of shape (1024,)
2020-12-13 10:50:09,502 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn2.weight               loaded from backbone.body.layer3.15.bn2.weight               of shape (1024,)
2020-12-13 10:50:09,502 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.bias                 loaded from backbone.body.layer3.15.bn3.bias                 of shape (1024,)
2020-12-13 10:50:09,502 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.running_mean         loaded from backbone.body.layer3.15.bn3.running_mean         of shape (1024,)
2020-12-13 10:50:09,502 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.running_var          loaded from backbone.body.layer3.15.bn3.running_var          of shape (1024,)
2020-12-13 10:50:09,502 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.bn3.weight               loaded from backbone.body.layer3.15.bn3.weight               of shape (1024,)
2020-12-13 10:50:09,502 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv1.weight             loaded from backbone.body.layer3.15.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,503 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv2.weight             loaded from backbone.body.layer3.15.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,503 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.15.conv3.weight             loaded from backbone.body.layer3.15.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,503 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.bias                 loaded from backbone.body.layer3.16.bn1.bias                 of shape (1024,)
2020-12-13 10:50:09,503 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.running_mean         loaded from backbone.body.layer3.16.bn1.running_mean         of shape (1024,)
2020-12-13 10:50:09,503 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.running_var          loaded from backbone.body.layer3.16.bn1.running_var          of shape (1024,)
2020-12-13 10:50:09,503 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn1.weight               loaded from backbone.body.layer3.16.bn1.weight               of shape (1024,)
2020-12-13 10:50:09,503 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.bias                 loaded from backbone.body.layer3.16.bn2.bias                 of shape (1024,)
2020-12-13 10:50:09,503 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.running_mean         loaded from backbone.body.layer3.16.bn2.running_mean         of shape (1024,)
2020-12-13 10:50:09,503 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.running_var          loaded from backbone.body.layer3.16.bn2.running_var          of shape (1024,)
2020-12-13 10:50:09,503 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn2.weight               loaded from backbone.body.layer3.16.bn2.weight               of shape (1024,)
2020-12-13 10:50:09,504 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.bias                 loaded from backbone.body.layer3.16.bn3.bias                 of shape (1024,)
2020-12-13 10:50:09,504 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.running_mean         loaded from backbone.body.layer3.16.bn3.running_mean         of shape (1024,)
2020-12-13 10:50:09,504 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.running_var          loaded from backbone.body.layer3.16.bn3.running_var          of shape (1024,)
2020-12-13 10:50:09,504 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.bn3.weight               loaded from backbone.body.layer3.16.bn3.weight               of shape (1024,)
2020-12-13 10:50:09,504 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv1.weight             loaded from backbone.body.layer3.16.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,504 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv2.weight             loaded from backbone.body.layer3.16.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,504 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.16.conv3.weight             loaded from backbone.body.layer3.16.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,504 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.bias                 loaded from backbone.body.layer3.17.bn1.bias                 of shape (1024,)
2020-12-13 10:50:09,504 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.running_mean         loaded from backbone.body.layer3.17.bn1.running_mean         of shape (1024,)
2020-12-13 10:50:09,505 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.running_var          loaded from backbone.body.layer3.17.bn1.running_var          of shape (1024,)
2020-12-13 10:50:09,505 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn1.weight               loaded from backbone.body.layer3.17.bn1.weight               of shape (1024,)
2020-12-13 10:50:09,505 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.bias                 loaded from backbone.body.layer3.17.bn2.bias                 of shape (1024,)
2020-12-13 10:50:09,505 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.running_mean         loaded from backbone.body.layer3.17.bn2.running_mean         of shape (1024,)
2020-12-13 10:50:09,505 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.running_var          loaded from backbone.body.layer3.17.bn2.running_var          of shape (1024,)
2020-12-13 10:50:09,505 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn2.weight               loaded from backbone.body.layer3.17.bn2.weight               of shape (1024,)
2020-12-13 10:50:09,505 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.bias                 loaded from backbone.body.layer3.17.bn3.bias                 of shape (1024,)
2020-12-13 10:50:09,505 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.running_mean         loaded from backbone.body.layer3.17.bn3.running_mean         of shape (1024,)
2020-12-13 10:50:09,506 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.running_var          loaded from backbone.body.layer3.17.bn3.running_var          of shape (1024,)
2020-12-13 10:50:09,506 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.bn3.weight               loaded from backbone.body.layer3.17.bn3.weight               of shape (1024,)
2020-12-13 10:50:09,506 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv1.weight             loaded from backbone.body.layer3.17.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,506 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv2.weight             loaded from backbone.body.layer3.17.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,506 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.17.conv3.weight             loaded from backbone.body.layer3.17.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,506 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.bias                 loaded from backbone.body.layer3.18.bn1.bias                 of shape (1024,)
2020-12-13 10:50:09,506 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.running_mean         loaded from backbone.body.layer3.18.bn1.running_mean         of shape (1024,)
2020-12-13 10:50:09,506 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.running_var          loaded from backbone.body.layer3.18.bn1.running_var          of shape (1024,)
2020-12-13 10:50:09,506 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn1.weight               loaded from backbone.body.layer3.18.bn1.weight               of shape (1024,)
2020-12-13 10:50:09,507 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.bias                 loaded from backbone.body.layer3.18.bn2.bias                 of shape (1024,)
2020-12-13 10:50:09,507 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.running_mean         loaded from backbone.body.layer3.18.bn2.running_mean         of shape (1024,)
2020-12-13 10:50:09,507 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.running_var          loaded from backbone.body.layer3.18.bn2.running_var          of shape (1024,)
2020-12-13 10:50:09,507 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn2.weight               loaded from backbone.body.layer3.18.bn2.weight               of shape (1024,)
2020-12-13 10:50:09,507 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.bias                 loaded from backbone.body.layer3.18.bn3.bias                 of shape (1024,)
2020-12-13 10:50:09,507 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.running_mean         loaded from backbone.body.layer3.18.bn3.running_mean         of shape (1024,)
2020-12-13 10:50:09,507 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.running_var          loaded from backbone.body.layer3.18.bn3.running_var          of shape (1024,)
2020-12-13 10:50:09,507 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.bn3.weight               loaded from backbone.body.layer3.18.bn3.weight               of shape (1024,)
2020-12-13 10:50:09,507 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv1.weight             loaded from backbone.body.layer3.18.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,508 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv2.weight             loaded from backbone.body.layer3.18.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,508 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.18.conv3.weight             loaded from backbone.body.layer3.18.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,508 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.bias                 loaded from backbone.body.layer3.19.bn1.bias                 of shape (1024,)
2020-12-13 10:50:09,508 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.running_mean         loaded from backbone.body.layer3.19.bn1.running_mean         of shape (1024,)
2020-12-13 10:50:09,508 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.running_var          loaded from backbone.body.layer3.19.bn1.running_var          of shape (1024,)
2020-12-13 10:50:09,508 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn1.weight               loaded from backbone.body.layer3.19.bn1.weight               of shape (1024,)
2020-12-13 10:50:09,508 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.bias                 loaded from backbone.body.layer3.19.bn2.bias                 of shape (1024,)
2020-12-13 10:50:09,508 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.running_mean         loaded from backbone.body.layer3.19.bn2.running_mean         of shape (1024,)
2020-12-13 10:50:09,509 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.running_var          loaded from backbone.body.layer3.19.bn2.running_var          of shape (1024,)
2020-12-13 10:50:09,509 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn2.weight               loaded from backbone.body.layer3.19.bn2.weight               of shape (1024,)
2020-12-13 10:50:09,509 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.bias                 loaded from backbone.body.layer3.19.bn3.bias                 of shape (1024,)
2020-12-13 10:50:09,509 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.running_mean         loaded from backbone.body.layer3.19.bn3.running_mean         of shape (1024,)
2020-12-13 10:50:09,509 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.running_var          loaded from backbone.body.layer3.19.bn3.running_var          of shape (1024,)
2020-12-13 10:50:09,509 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.bn3.weight               loaded from backbone.body.layer3.19.bn3.weight               of shape (1024,)
2020-12-13 10:50:09,509 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv1.weight             loaded from backbone.body.layer3.19.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,509 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv2.weight             loaded from backbone.body.layer3.19.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,509 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.19.conv3.weight             loaded from backbone.body.layer3.19.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,509 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                  loaded from backbone.body.layer3.2.bn1.bias                  of shape (1024,)
2020-12-13 10:50:09,509 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_mean          loaded from backbone.body.layer3.2.bn1.running_mean          of shape (1024,)
2020-12-13 10:50:09,510 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_var           loaded from backbone.body.layer3.2.bn1.running_var           of shape (1024,)
2020-12-13 10:50:09,510 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                loaded from backbone.body.layer3.2.bn1.weight                of shape (1024,)
2020-12-13 10:50:09,510 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                  loaded from backbone.body.layer3.2.bn2.bias                  of shape (1024,)
2020-12-13 10:50:09,510 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_mean          loaded from backbone.body.layer3.2.bn2.running_mean          of shape (1024,)
2020-12-13 10:50:09,510 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_var           loaded from backbone.body.layer3.2.bn2.running_var           of shape (1024,)
2020-12-13 10:50:09,510 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                loaded from backbone.body.layer3.2.bn2.weight                of shape (1024,)
2020-12-13 10:50:09,510 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                  loaded from backbone.body.layer3.2.bn3.bias                  of shape (1024,)
2020-12-13 10:50:09,510 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_mean          loaded from backbone.body.layer3.2.bn3.running_mean          of shape (1024,)
2020-12-13 10:50:09,510 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_var           loaded from backbone.body.layer3.2.bn3.running_var           of shape (1024,)
2020-12-13 10:50:09,510 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                loaded from backbone.body.layer3.2.bn3.weight                of shape (1024,)
2020-12-13 10:50:09,511 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight              loaded from backbone.body.layer3.2.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,511 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight              loaded from backbone.body.layer3.2.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,511 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight              loaded from backbone.body.layer3.2.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,511 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.bias                 loaded from backbone.body.layer3.20.bn1.bias                 of shape (1024,)
2020-12-13 10:50:09,511 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.running_mean         loaded from backbone.body.layer3.20.bn1.running_mean         of shape (1024,)
2020-12-13 10:50:09,511 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.running_var          loaded from backbone.body.layer3.20.bn1.running_var          of shape (1024,)
2020-12-13 10:50:09,511 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn1.weight               loaded from backbone.body.layer3.20.bn1.weight               of shape (1024,)
2020-12-13 10:50:09,511 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.bias                 loaded from backbone.body.layer3.20.bn2.bias                 of shape (1024,)
2020-12-13 10:50:09,511 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.running_mean         loaded from backbone.body.layer3.20.bn2.running_mean         of shape (1024,)
2020-12-13 10:50:09,511 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.running_var          loaded from backbone.body.layer3.20.bn2.running_var          of shape (1024,)
2020-12-13 10:50:09,511 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn2.weight               loaded from backbone.body.layer3.20.bn2.weight               of shape (1024,)
2020-12-13 10:50:09,512 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.bias                 loaded from backbone.body.layer3.20.bn3.bias                 of shape (1024,)
2020-12-13 10:50:09,512 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.running_mean         loaded from backbone.body.layer3.20.bn3.running_mean         of shape (1024,)
2020-12-13 10:50:09,512 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.running_var          loaded from backbone.body.layer3.20.bn3.running_var          of shape (1024,)
2020-12-13 10:50:09,512 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.bn3.weight               loaded from backbone.body.layer3.20.bn3.weight               of shape (1024,)
2020-12-13 10:50:09,512 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv1.weight             loaded from backbone.body.layer3.20.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,512 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv2.weight             loaded from backbone.body.layer3.20.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,512 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.20.conv3.weight             loaded from backbone.body.layer3.20.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,512 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.bias                 loaded from backbone.body.layer3.21.bn1.bias                 of shape (1024,)
2020-12-13 10:50:09,512 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.running_mean         loaded from backbone.body.layer3.21.bn1.running_mean         of shape (1024,)
2020-12-13 10:50:09,512 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.running_var          loaded from backbone.body.layer3.21.bn1.running_var          of shape (1024,)
2020-12-13 10:50:09,512 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn1.weight               loaded from backbone.body.layer3.21.bn1.weight               of shape (1024,)
2020-12-13 10:50:09,513 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.bias                 loaded from backbone.body.layer3.21.bn2.bias                 of shape (1024,)
2020-12-13 10:50:09,513 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.running_mean         loaded from backbone.body.layer3.21.bn2.running_mean         of shape (1024,)
2020-12-13 10:50:09,513 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.running_var          loaded from backbone.body.layer3.21.bn2.running_var          of shape (1024,)
2020-12-13 10:50:09,513 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn2.weight               loaded from backbone.body.layer3.21.bn2.weight               of shape (1024,)
2020-12-13 10:50:09,513 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.bias                 loaded from backbone.body.layer3.21.bn3.bias                 of shape (1024,)
2020-12-13 10:50:09,513 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.running_mean         loaded from backbone.body.layer3.21.bn3.running_mean         of shape (1024,)
2020-12-13 10:50:09,513 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.running_var          loaded from backbone.body.layer3.21.bn3.running_var          of shape (1024,)
2020-12-13 10:50:09,513 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.bn3.weight               loaded from backbone.body.layer3.21.bn3.weight               of shape (1024,)
2020-12-13 10:50:09,513 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv1.weight             loaded from backbone.body.layer3.21.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,513 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv2.weight             loaded from backbone.body.layer3.21.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,514 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.21.conv3.weight             loaded from backbone.body.layer3.21.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,514 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.bias                 loaded from backbone.body.layer3.22.bn1.bias                 of shape (1024,)
2020-12-13 10:50:09,514 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.running_mean         loaded from backbone.body.layer3.22.bn1.running_mean         of shape (1024,)
2020-12-13 10:50:09,514 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.running_var          loaded from backbone.body.layer3.22.bn1.running_var          of shape (1024,)
2020-12-13 10:50:09,514 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn1.weight               loaded from backbone.body.layer3.22.bn1.weight               of shape (1024,)
2020-12-13 10:50:09,514 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.bias                 loaded from backbone.body.layer3.22.bn2.bias                 of shape (1024,)
2020-12-13 10:50:09,514 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.running_mean         loaded from backbone.body.layer3.22.bn2.running_mean         of shape (1024,)
2020-12-13 10:50:09,514 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.running_var          loaded from backbone.body.layer3.22.bn2.running_var          of shape (1024,)
2020-12-13 10:50:09,514 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn2.weight               loaded from backbone.body.layer3.22.bn2.weight               of shape (1024,)
2020-12-13 10:50:09,514 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.bias                 loaded from backbone.body.layer3.22.bn3.bias                 of shape (1024,)
2020-12-13 10:50:09,515 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.running_mean         loaded from backbone.body.layer3.22.bn3.running_mean         of shape (1024,)
2020-12-13 10:50:09,515 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.running_var          loaded from backbone.body.layer3.22.bn3.running_var          of shape (1024,)
2020-12-13 10:50:09,515 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.bn3.weight               loaded from backbone.body.layer3.22.bn3.weight               of shape (1024,)
2020-12-13 10:50:09,515 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv1.weight             loaded from backbone.body.layer3.22.conv1.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,515 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv2.weight             loaded from backbone.body.layer3.22.conv2.weight             of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,515 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.22.conv3.weight             loaded from backbone.body.layer3.22.conv3.weight             of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,515 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                  loaded from backbone.body.layer3.3.bn1.bias                  of shape (1024,)
2020-12-13 10:50:09,515 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_mean          loaded from backbone.body.layer3.3.bn1.running_mean          of shape (1024,)
2020-12-13 10:50:09,515 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_var           loaded from backbone.body.layer3.3.bn1.running_var           of shape (1024,)
2020-12-13 10:50:09,515 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                loaded from backbone.body.layer3.3.bn1.weight                of shape (1024,)
2020-12-13 10:50:09,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                  loaded from backbone.body.layer3.3.bn2.bias                  of shape (1024,)
2020-12-13 10:50:09,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_mean          loaded from backbone.body.layer3.3.bn2.running_mean          of shape (1024,)
2020-12-13 10:50:09,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_var           loaded from backbone.body.layer3.3.bn2.running_var           of shape (1024,)
2020-12-13 10:50:09,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                loaded from backbone.body.layer3.3.bn2.weight                of shape (1024,)
2020-12-13 10:50:09,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                  loaded from backbone.body.layer3.3.bn3.bias                  of shape (1024,)
2020-12-13 10:50:09,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_mean          loaded from backbone.body.layer3.3.bn3.running_mean          of shape (1024,)
2020-12-13 10:50:09,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_var           loaded from backbone.body.layer3.3.bn3.running_var           of shape (1024,)
2020-12-13 10:50:09,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                loaded from backbone.body.layer3.3.bn3.weight                of shape (1024,)
2020-12-13 10:50:09,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight              loaded from backbone.body.layer3.3.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight              loaded from backbone.body.layer3.3.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight              loaded from backbone.body.layer3.3.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                  loaded from backbone.body.layer3.4.bn1.bias                  of shape (1024,)
2020-12-13 10:50:09,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_mean          loaded from backbone.body.layer3.4.bn1.running_mean          of shape (1024,)
2020-12-13 10:50:09,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_var           loaded from backbone.body.layer3.4.bn1.running_var           of shape (1024,)
2020-12-13 10:50:09,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                loaded from backbone.body.layer3.4.bn1.weight                of shape (1024,)
2020-12-13 10:50:09,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                  loaded from backbone.body.layer3.4.bn2.bias                  of shape (1024,)
2020-12-13 10:50:09,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_mean          loaded from backbone.body.layer3.4.bn2.running_mean          of shape (1024,)
2020-12-13 10:50:09,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_var           loaded from backbone.body.layer3.4.bn2.running_var           of shape (1024,)
2020-12-13 10:50:09,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                loaded from backbone.body.layer3.4.bn2.weight                of shape (1024,)
2020-12-13 10:50:09,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                  loaded from backbone.body.layer3.4.bn3.bias                  of shape (1024,)
2020-12-13 10:50:09,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_mean          loaded from backbone.body.layer3.4.bn3.running_mean          of shape (1024,)
2020-12-13 10:50:09,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_var           loaded from backbone.body.layer3.4.bn3.running_var           of shape (1024,)
2020-12-13 10:50:09,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                loaded from backbone.body.layer3.4.bn3.weight                of shape (1024,)
2020-12-13 10:50:09,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight              loaded from backbone.body.layer3.4.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight              loaded from backbone.body.layer3.4.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight              loaded from backbone.body.layer3.4.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                  loaded from backbone.body.layer3.5.bn1.bias                  of shape (1024,)
2020-12-13 10:50:09,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_mean          loaded from backbone.body.layer3.5.bn1.running_mean          of shape (1024,)
2020-12-13 10:50:09,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_var           loaded from backbone.body.layer3.5.bn1.running_var           of shape (1024,)
2020-12-13 10:50:09,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                loaded from backbone.body.layer3.5.bn1.weight                of shape (1024,)
2020-12-13 10:50:09,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                  loaded from backbone.body.layer3.5.bn2.bias                  of shape (1024,)
2020-12-13 10:50:09,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_mean          loaded from backbone.body.layer3.5.bn2.running_mean          of shape (1024,)
2020-12-13 10:50:09,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_var           loaded from backbone.body.layer3.5.bn2.running_var           of shape (1024,)
2020-12-13 10:50:09,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                loaded from backbone.body.layer3.5.bn2.weight                of shape (1024,)
2020-12-13 10:50:09,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                  loaded from backbone.body.layer3.5.bn3.bias                  of shape (1024,)
2020-12-13 10:50:09,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_mean          loaded from backbone.body.layer3.5.bn3.running_mean          of shape (1024,)
2020-12-13 10:50:09,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_var           loaded from backbone.body.layer3.5.bn3.running_var           of shape (1024,)
2020-12-13 10:50:09,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                loaded from backbone.body.layer3.5.bn3.weight                of shape (1024,)
2020-12-13 10:50:09,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight              loaded from backbone.body.layer3.5.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight              loaded from backbone.body.layer3.5.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight              loaded from backbone.body.layer3.5.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.bias                  loaded from backbone.body.layer3.6.bn1.bias                  of shape (1024,)
2020-12-13 10:50:09,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.running_mean          loaded from backbone.body.layer3.6.bn1.running_mean          of shape (1024,)
2020-12-13 10:50:09,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.running_var           loaded from backbone.body.layer3.6.bn1.running_var           of shape (1024,)
2020-12-13 10:50:09,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn1.weight                loaded from backbone.body.layer3.6.bn1.weight                of shape (1024,)
2020-12-13 10:50:09,521 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.bias                  loaded from backbone.body.layer3.6.bn2.bias                  of shape (1024,)
2020-12-13 10:50:09,521 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.running_mean          loaded from backbone.body.layer3.6.bn2.running_mean          of shape (1024,)
2020-12-13 10:50:09,521 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.running_var           loaded from backbone.body.layer3.6.bn2.running_var           of shape (1024,)
2020-12-13 10:50:09,521 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn2.weight                loaded from backbone.body.layer3.6.bn2.weight                of shape (1024,)
2020-12-13 10:50:09,521 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.bias                  loaded from backbone.body.layer3.6.bn3.bias                  of shape (1024,)
2020-12-13 10:50:09,521 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.running_mean          loaded from backbone.body.layer3.6.bn3.running_mean          of shape (1024,)
2020-12-13 10:50:09,521 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.running_var           loaded from backbone.body.layer3.6.bn3.running_var           of shape (1024,)
2020-12-13 10:50:09,521 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.bn3.weight                loaded from backbone.body.layer3.6.bn3.weight                of shape (1024,)
2020-12-13 10:50:09,522 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv1.weight              loaded from backbone.body.layer3.6.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,522 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv2.weight              loaded from backbone.body.layer3.6.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,522 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.6.conv3.weight              loaded from backbone.body.layer3.6.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,522 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.bias                  loaded from backbone.body.layer3.7.bn1.bias                  of shape (1024,)
2020-12-13 10:50:09,522 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.running_mean          loaded from backbone.body.layer3.7.bn1.running_mean          of shape (1024,)
2020-12-13 10:50:09,522 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.running_var           loaded from backbone.body.layer3.7.bn1.running_var           of shape (1024,)
2020-12-13 10:50:09,522 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn1.weight                loaded from backbone.body.layer3.7.bn1.weight                of shape (1024,)
2020-12-13 10:50:09,522 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.bias                  loaded from backbone.body.layer3.7.bn2.bias                  of shape (1024,)
2020-12-13 10:50:09,522 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.running_mean          loaded from backbone.body.layer3.7.bn2.running_mean          of shape (1024,)
2020-12-13 10:50:09,523 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.running_var           loaded from backbone.body.layer3.7.bn2.running_var           of shape (1024,)
2020-12-13 10:50:09,523 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn2.weight                loaded from backbone.body.layer3.7.bn2.weight                of shape (1024,)
2020-12-13 10:50:09,523 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.bias                  loaded from backbone.body.layer3.7.bn3.bias                  of shape (1024,)
2020-12-13 10:50:09,523 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.running_mean          loaded from backbone.body.layer3.7.bn3.running_mean          of shape (1024,)
2020-12-13 10:50:09,523 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.running_var           loaded from backbone.body.layer3.7.bn3.running_var           of shape (1024,)
2020-12-13 10:50:09,523 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.bn3.weight                loaded from backbone.body.layer3.7.bn3.weight                of shape (1024,)
2020-12-13 10:50:09,523 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv1.weight              loaded from backbone.body.layer3.7.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,523 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv2.weight              loaded from backbone.body.layer3.7.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,524 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.7.conv3.weight              loaded from backbone.body.layer3.7.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,524 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.bias                  loaded from backbone.body.layer3.8.bn1.bias                  of shape (1024,)
2020-12-13 10:50:09,524 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.running_mean          loaded from backbone.body.layer3.8.bn1.running_mean          of shape (1024,)
2020-12-13 10:50:09,524 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.running_var           loaded from backbone.body.layer3.8.bn1.running_var           of shape (1024,)
2020-12-13 10:50:09,524 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn1.weight                loaded from backbone.body.layer3.8.bn1.weight                of shape (1024,)
2020-12-13 10:50:09,524 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.bias                  loaded from backbone.body.layer3.8.bn2.bias                  of shape (1024,)
2020-12-13 10:50:09,524 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.running_mean          loaded from backbone.body.layer3.8.bn2.running_mean          of shape (1024,)
2020-12-13 10:50:09,524 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.running_var           loaded from backbone.body.layer3.8.bn2.running_var           of shape (1024,)
2020-12-13 10:50:09,524 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn2.weight                loaded from backbone.body.layer3.8.bn2.weight                of shape (1024,)
2020-12-13 10:50:09,525 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.bias                  loaded from backbone.body.layer3.8.bn3.bias                  of shape (1024,)
2020-12-13 10:50:09,525 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.running_mean          loaded from backbone.body.layer3.8.bn3.running_mean          of shape (1024,)
2020-12-13 10:50:09,525 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.running_var           loaded from backbone.body.layer3.8.bn3.running_var           of shape (1024,)
2020-12-13 10:50:09,525 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.bn3.weight                loaded from backbone.body.layer3.8.bn3.weight                of shape (1024,)
2020-12-13 10:50:09,525 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv1.weight              loaded from backbone.body.layer3.8.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,525 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv2.weight              loaded from backbone.body.layer3.8.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,525 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.8.conv3.weight              loaded from backbone.body.layer3.8.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,525 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.bias                  loaded from backbone.body.layer3.9.bn1.bias                  of shape (1024,)
2020-12-13 10:50:09,525 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.running_mean          loaded from backbone.body.layer3.9.bn1.running_mean          of shape (1024,)
2020-12-13 10:50:09,526 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.running_var           loaded from backbone.body.layer3.9.bn1.running_var           of shape (1024,)
2020-12-13 10:50:09,526 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn1.weight                loaded from backbone.body.layer3.9.bn1.weight                of shape (1024,)
2020-12-13 10:50:09,526 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.bias                  loaded from backbone.body.layer3.9.bn2.bias                  of shape (1024,)
2020-12-13 10:50:09,526 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.running_mean          loaded from backbone.body.layer3.9.bn2.running_mean          of shape (1024,)
2020-12-13 10:50:09,526 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.running_var           loaded from backbone.body.layer3.9.bn2.running_var           of shape (1024,)
2020-12-13 10:50:09,526 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn2.weight                loaded from backbone.body.layer3.9.bn2.weight                of shape (1024,)
2020-12-13 10:50:09,526 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.bias                  loaded from backbone.body.layer3.9.bn3.bias                  of shape (1024,)
2020-12-13 10:50:09,526 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.running_mean          loaded from backbone.body.layer3.9.bn3.running_mean          of shape (1024,)
2020-12-13 10:50:09,526 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.running_var           loaded from backbone.body.layer3.9.bn3.running_var           of shape (1024,)
2020-12-13 10:50:09,527 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.bn3.weight                loaded from backbone.body.layer3.9.bn3.weight                of shape (1024,)
2020-12-13 10:50:09,527 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv1.weight              loaded from backbone.body.layer3.9.conv1.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,527 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv2.weight              loaded from backbone.body.layer3.9.conv2.weight              of shape (1024, 32, 3, 3)
2020-12-13 10:50:09,527 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.9.conv3.weight              loaded from backbone.body.layer3.9.conv3.weight              of shape (1024, 1024, 1, 1)
2020-12-13 10:50:09,527 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                  loaded from backbone.body.layer4.0.bn1.bias                  of shape (2048,)
2020-12-13 10:50:09,527 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_mean          loaded from backbone.body.layer4.0.bn1.running_mean          of shape (2048,)
2020-12-13 10:50:09,527 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_var           loaded from backbone.body.layer4.0.bn1.running_var           of shape (2048,)
2020-12-13 10:50:09,527 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                loaded from backbone.body.layer4.0.bn1.weight                of shape (2048,)
2020-12-13 10:50:09,528 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                  loaded from backbone.body.layer4.0.bn2.bias                  of shape (2048,)
2020-12-13 10:50:09,528 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_mean          loaded from backbone.body.layer4.0.bn2.running_mean          of shape (2048,)
2020-12-13 10:50:09,528 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_var           loaded from backbone.body.layer4.0.bn2.running_var           of shape (2048,)
2020-12-13 10:50:09,528 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                loaded from backbone.body.layer4.0.bn2.weight                of shape (2048,)
2020-12-13 10:50:09,528 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                  loaded from backbone.body.layer4.0.bn3.bias                  of shape (2048,)
2020-12-13 10:50:09,528 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_mean          loaded from backbone.body.layer4.0.bn3.running_mean          of shape (2048,)
2020-12-13 10:50:09,528 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_var           loaded from backbone.body.layer4.0.bn3.running_var           of shape (2048,)
2020-12-13 10:50:09,528 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                loaded from backbone.body.layer4.0.bn3.weight                of shape (2048,)
2020-12-13 10:50:09,528 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight              loaded from backbone.body.layer4.0.conv1.weight              of shape (2048, 1024, 1, 1)
2020-12-13 10:50:09,529 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv2.weight              loaded from backbone.body.layer4.0.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 10:50:09,529 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight              loaded from backbone.body.layer4.0.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:50:09,529 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight       loaded from backbone.body.layer4.0.downsample.0.weight       of shape (2048, 1024, 1, 1)
2020-12-13 10:50:09,529 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias         loaded from backbone.body.layer4.0.downsample.1.bias         of shape (2048,)
2020-12-13 10:50:09,529 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_mean loaded from backbone.body.layer4.0.downsample.1.running_mean of shape (2048,)
2020-12-13 10:50:09,529 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_var  loaded from backbone.body.layer4.0.downsample.1.running_var  of shape (2048,)
2020-12-13 10:50:09,529 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight       loaded from backbone.body.layer4.0.downsample.1.weight       of shape (2048,)
2020-12-13 10:50:09,529 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                  loaded from backbone.body.layer4.1.bn1.bias                  of shape (2048,)
2020-12-13 10:50:09,529 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_mean          loaded from backbone.body.layer4.1.bn1.running_mean          of shape (2048,)
2020-12-13 10:50:09,530 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_var           loaded from backbone.body.layer4.1.bn1.running_var           of shape (2048,)
2020-12-13 10:50:09,530 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                loaded from backbone.body.layer4.1.bn1.weight                of shape (2048,)
2020-12-13 10:50:09,530 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                  loaded from backbone.body.layer4.1.bn2.bias                  of shape (2048,)
2020-12-13 10:50:09,530 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_mean          loaded from backbone.body.layer4.1.bn2.running_mean          of shape (2048,)
2020-12-13 10:50:09,530 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_var           loaded from backbone.body.layer4.1.bn2.running_var           of shape (2048,)
2020-12-13 10:50:09,530 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                loaded from backbone.body.layer4.1.bn2.weight                of shape (2048,)
2020-12-13 10:50:09,530 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                  loaded from backbone.body.layer4.1.bn3.bias                  of shape (2048,)
2020-12-13 10:50:09,530 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_mean          loaded from backbone.body.layer4.1.bn3.running_mean          of shape (2048,)
2020-12-13 10:50:09,530 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_var           loaded from backbone.body.layer4.1.bn3.running_var           of shape (2048,)
2020-12-13 10:50:09,531 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                loaded from backbone.body.layer4.1.bn3.weight                of shape (2048,)
2020-12-13 10:50:09,531 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight              loaded from backbone.body.layer4.1.conv1.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:50:09,531 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv2.weight              loaded from backbone.body.layer4.1.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 10:50:09,531 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight              loaded from backbone.body.layer4.1.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:50:09,531 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                  loaded from backbone.body.layer4.2.bn1.bias                  of shape (2048,)
2020-12-13 10:50:09,531 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_mean          loaded from backbone.body.layer4.2.bn1.running_mean          of shape (2048,)
2020-12-13 10:50:09,531 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_var           loaded from backbone.body.layer4.2.bn1.running_var           of shape (2048,)
2020-12-13 10:50:09,531 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                loaded from backbone.body.layer4.2.bn1.weight                of shape (2048,)
2020-12-13 10:50:09,531 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                  loaded from backbone.body.layer4.2.bn2.bias                  of shape (2048,)
2020-12-13 10:50:09,532 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_mean          loaded from backbone.body.layer4.2.bn2.running_mean          of shape (2048,)
2020-12-13 10:50:09,532 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_var           loaded from backbone.body.layer4.2.bn2.running_var           of shape (2048,)
2020-12-13 10:50:09,532 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                loaded from backbone.body.layer4.2.bn2.weight                of shape (2048,)
2020-12-13 10:50:09,532 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                  loaded from backbone.body.layer4.2.bn3.bias                  of shape (2048,)
2020-12-13 10:50:09,532 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_mean          loaded from backbone.body.layer4.2.bn3.running_mean          of shape (2048,)
2020-12-13 10:50:09,532 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_var           loaded from backbone.body.layer4.2.bn3.running_var           of shape (2048,)
2020-12-13 10:50:09,532 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                loaded from backbone.body.layer4.2.bn3.weight                of shape (2048,)
2020-12-13 10:50:09,532 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight              loaded from backbone.body.layer4.2.conv1.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:50:09,532 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv2.weight              loaded from backbone.body.layer4.2.conv2.weight              of shape (2048, 64, 3, 3)
2020-12-13 10:50:09,532 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight              loaded from backbone.body.layer4.2.conv3.weight              of shape (2048, 2048, 1, 1)
2020-12-13 10:50:09,533 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                      loaded from backbone.body.stem.bn1.bias                      of shape (64,)
2020-12-13 10:50:09,533 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_mean              loaded from backbone.body.stem.bn1.running_mean              of shape (64,)
2020-12-13 10:50:09,533 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_var               loaded from backbone.body.stem.bn1.running_var               of shape (64,)
2020-12-13 10:50:09,533 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                    loaded from backbone.body.stem.bn1.weight                    of shape (64,)
2020-12-13 10:50:09,533 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                  loaded from backbone.body.stem.conv1.weight                  of shape (64, 3, 7, 7)
2020-12-13 10:50:09,533 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.bias                     loaded from backbone.fpn.fpn_inner1.bias                     of shape (256,)
2020-12-13 10:50:09,533 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.weight                   loaded from backbone.fpn.fpn_inner1.weight                   of shape (256, 256, 1, 1)
2020-12-13 10:50:09,533 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                     loaded from backbone.fpn.fpn_inner2.bias                     of shape (256,)
2020-12-13 10:50:09,533 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                   loaded from backbone.fpn.fpn_inner2.weight                   of shape (256, 512, 1, 1)
2020-12-13 10:50:09,534 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                     loaded from backbone.fpn.fpn_inner3.bias                     of shape (256,)
2020-12-13 10:50:09,534 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                   loaded from backbone.fpn.fpn_inner3.weight                   of shape (256, 1024, 1, 1)
2020-12-13 10:50:09,534 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                     loaded from backbone.fpn.fpn_inner4.bias                     of shape (256,)
2020-12-13 10:50:09,534 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                   loaded from backbone.fpn.fpn_inner4.weight                   of shape (256, 2048, 1, 1)
2020-12-13 10:50:09,534 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.bias                     loaded from backbone.fpn.fpn_layer1.bias                     of shape (256,)
2020-12-13 10:50:09,534 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.weight                   loaded from backbone.fpn.fpn_layer1.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:50:09,534 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                     loaded from backbone.fpn.fpn_layer2.bias                     of shape (256,)
2020-12-13 10:50:09,534 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                   loaded from backbone.fpn.fpn_layer2.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:50:09,534 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                     loaded from backbone.fpn.fpn_layer3.bias                     of shape (256,)
2020-12-13 10:50:09,535 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                   loaded from backbone.fpn.fpn_layer3.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:50:09,535 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                     loaded from backbone.fpn.fpn_layer4.bias                     of shape (256,)
2020-12-13 10:50:09,535 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                   loaded from backbone.fpn.fpn_layer4.weight                   of shape (256, 256, 3, 3)
2020-12-13 10:50:09,535 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.bias         loaded from roi_heads.box.feature_extractor.fc6.bias         of shape (1024,)
2020-12-13 10:50:09,535 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.weight       loaded from roi_heads.box.feature_extractor.fc6.weight       of shape (1024, 12544)
2020-12-13 10:50:09,535 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.bias         loaded from roi_heads.box.feature_extractor.fc7.bias         of shape (1024,)
2020-12-13 10:50:09,535 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.weight       loaded from roi_heads.box.feature_extractor.fc7.weight       of shape (1024, 1024)
2020-12-13 10:50:09,535 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.bias           loaded from roi_heads.box.predictor.bbox_pred.bias           of shape (324,)
2020-12-13 10:50:09,536 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.weight         loaded from roi_heads.box.predictor.bbox_pred.weight         of shape (324, 1024)
2020-12-13 10:50:09,536 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.bias           loaded from roi_heads.box.predictor.cls_score.bias           of shape (81,)
2020-12-13 10:50:09,536 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.weight         loaded from roi_heads.box.predictor.cls_score.weight         of shape (81, 1024)
2020-12-13 10:50:09,536 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.0              loaded from rpn.anchor_generator.cell_anchors.0              of shape (3, 4)
2020-12-13 10:50:09,536 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.1              loaded from rpn.anchor_generator.cell_anchors.1              of shape (3, 4)
2020-12-13 10:50:09,536 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.2              loaded from rpn.anchor_generator.cell_anchors.2              of shape (3, 4)
2020-12-13 10:50:09,536 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.3              loaded from rpn.anchor_generator.cell_anchors.3              of shape (3, 4)
2020-12-13 10:50:09,536 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.4              loaded from rpn.anchor_generator.cell_anchors.4              of shape (3, 4)
2020-12-13 10:50:09,536 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                          loaded from rpn.head.bbox_pred.bias                          of shape (12,)
2020-12-13 10:50:09,537 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                        loaded from rpn.head.bbox_pred.weight                        of shape (12, 256, 1, 1)
2020-12-13 10:50:09,537 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                         loaded from rpn.head.cls_logits.bias                         of shape (3,)
2020-12-13 10:50:09,537 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                       loaded from rpn.head.cls_logits.weight                       of shape (3, 256, 1, 1)
2020-12-13 10:50:09,537 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.bias                               loaded from rpn.head.conv.bias                               of shape (256,)
2020-12-13 10:50:09,537 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.weight                             loaded from rpn.head.conv.weight                             of shape (256, 256, 3, 3)
2020-12-13 10:50:09,722 maskrcnn_benchmark INFO: reloading weigts from _best_acc_r5_v7.pth
2020-12-13 10:50:15,308 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.weight
2020-12-13 10:50:15,309 maskrcnn_benchmark INFO: unfroze: rpn.head.conv.bias
2020-12-13 10:50:15,309 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.weight
2020-12-13 10:50:15,309 maskrcnn_benchmark INFO: unfroze: rpn.head.cls_logits.bias
2020-12-13 10:50:15,309 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.weight
2020-12-13 10:50:15,309 maskrcnn_benchmark INFO: unfroze: rpn.head.bbox_pred.bias
2020-12-13 10:50:15,310 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.weight
2020-12-13 10:50:15,310 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc6.bias
2020-12-13 10:50:15,310 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.weight
2020-12-13 10:50:15,310 maskrcnn_benchmark INFO: unfroze: roi_heads.box.feature_extractor.fc7.bias
2020-12-13 10:50:15,310 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.weight
2020-12-13 10:50:15,310 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.cls_score.bias
2020-12-13 10:50:15,311 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.weight
2020-12-13 10:50:15,311 maskrcnn_benchmark INFO: unfroze: roi_heads.box.predictor.bbox_pred.bias
2020-12-13 10:50:15,505 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2020-12-13 10:50:36,166 maskrcnn_benchmark.trainer INFO: Start training
2020-12-13 10:52:01,780 maskrcnn_benchmark.trainer INFO: eta: 1:52:43  iter: 20  loss: 1.0546 (1.0698)  loss_classifier: 0.1579 (0.1795)  loss_box_reg: 0.0671 (0.0915)  loss_objectness: 0.6029 (0.6727)  loss_rpn_box_reg: 0.1257 (0.1261)  time: 4.2661 (4.2805)  data: 0.2626 (0.2624)  lr: 0.000014  max mem: 1423
2020-12-13 10:53:20,937 maskrcnn_benchmark.trainer INFO: eta: 1:47:05  iter: 40  loss: 1.0692 (1.0664)  loss_classifier: 0.1867 (0.1753)  loss_box_reg: 0.1126 (0.0971)  loss_objectness: 0.6695 (0.6705)  loss_rpn_box_reg: 0.1135 (0.1236)  time: 3.8990 (4.1192)  data: 0.2349 (0.2551)  lr: 0.000015  max mem: 1423
2020-12-13 10:54:38,583 maskrcnn_benchmark.trainer INFO: eta: 1:43:41  iter: 60  loss: 0.8810 (1.0124)  loss_classifier: 0.1627 (0.1720)  loss_box_reg: 0.1171 (0.0986)  loss_objectness: 0.5118 (0.6280)  loss_rpn_box_reg: 0.0957 (0.1137)  time: 3.8824 (4.0402)  data: 0.2246 (0.2457)  lr: 0.000017  max mem: 1423
2020-12-13 10:55:56,245 maskrcnn_benchmark.trainer INFO: eta: 1:41:21  iter: 80  loss: 0.9222 (0.9957)  loss_classifier: 0.1238 (0.1634)  loss_box_reg: 0.0273 (0.0896)  loss_objectness: 0.6300 (0.6311)  loss_rpn_box_reg: 0.0905 (0.1115)  time: 3.8792 (4.0009)  data: 0.2273 (0.2422)  lr: 0.000018  max mem: 1423
2020-12-13 10:57:13,908 maskrcnn_benchmark.trainer INFO: eta: 1:39:26  iter: 100  loss: 0.7499 (0.9556)  loss_classifier: 0.1037 (0.1584)  loss_box_reg: 0.0165 (0.0852)  loss_objectness: 0.4816 (0.6045)  loss_rpn_box_reg: 0.0832 (0.1075)  time: 3.8838 (3.9774)  data: 0.2315 (0.2404)  lr: 0.000019  max mem: 1423
2020-12-13 10:58:31,515 maskrcnn_benchmark.trainer INFO: eta: 1:37:42  iter: 120  loss: 0.7923 (0.9290)  loss_classifier: 0.1285 (0.1565)  loss_box_reg: 0.0318 (0.0840)  loss_objectness: 0.4543 (0.5830)  loss_rpn_box_reg: 0.0860 (0.1054)  time: 3.8823 (3.9612)  data: 0.2291 (0.2389)  lr: 0.000020  max mem: 1423
2020-12-13 10:59:49,112 maskrcnn_benchmark.trainer INFO: eta: 1:36:06  iter: 140  loss: 0.7481 (0.9086)  loss_classifier: 0.1315 (0.1543)  loss_box_reg: 0.0763 (0.0837)  loss_objectness: 0.4298 (0.5674)  loss_rpn_box_reg: 0.0887 (0.1032)  time: 3.8746 (3.9496)  data: 0.2233 (0.2373)  lr: 0.000021  max mem: 1423
2020-12-13 10:59:49,114 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 10:59:49,138 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 10:59:55,232 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.093193 (1.5232982635498047 s / img per device, on 1 devices)
2020-12-13 10:59:55,232 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.635847 (1.408961832523346 s / img per device, on 1 devices)
2020-12-13 10:59:55,232 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 10:59:55,651 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 10:59:55,651 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.0733), 'recalls': tensor([0.3333, 0.1333, 0.0667, 0.0667, 0.0667, 0.0667, 0.0000, 0.0000, 0.0000,
        0.0000]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.5862, 0.5332, 0.5074, 0.3984, 0.3824, 0.0000, 0.0000, 0.0000, 0.5391,
        0.5171, 0.4772, 0.4387, 0.4328, 0.4261, 0.3502, 0.7750, 0.7525, 0.5756,
        0.5019, 0.4888, 0.3394, 0.0090, 0.0000, 0.5328, 0.4911, 0.4292, 0.4108,
        0.3868, 0.3854, 0.3357]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([2., 2., 2., 2., 2., 2., 2., 2., 1., 2., 2., 2., 1., 2., 2., 2., 1., 2.,
        2., 2., 1., 2., 1., 2., 2., 2., 2., 1., 2., 2.]), 'best match scores': tensor([0.1786, 0.0601, 0.0726, 0.1727, 0.1206, 0.4263, 0.0507, 0.1740, 0.0534,
        0.0722, 0.2263, 0.0748, 0.0532, 0.1597, 0.1029, 0.2191, 0.0542, 0.0643,
        0.2788, 0.0804, 0.0513, 0.0979, 0.0594, 0.4566, 0.1379, 0.3339, 0.1072,
        0.0501, 0.3064, 0.1007]), 'num_pos': 30}
2020-12-13 10:59:55,661 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.200000
2020-12-13 10:59:55,665 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v8.pth
2020-12-13 10:59:56,329 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v8
2020-12-13 11:01:15,069 maskrcnn_benchmark.trainer INFO: eta: 1:35:50  iter: 160  loss: 0.6422 (0.8876)  loss_classifier: 0.1073 (0.1503)  loss_box_reg: 0.0152 (0.0793)  loss_objectness: 0.4868 (0.5551)  loss_rpn_box_reg: 0.0996 (0.1030)  time: 3.8786 (3.9931)  data: 0.2293 (0.2886)  lr: 0.000022  max mem: 1423
2020-12-13 11:02:32,813 maskrcnn_benchmark.trainer INFO: eta: 1:34:13  iter: 180  loss: 0.5876 (0.8607)  loss_classifier: 0.1274 (0.1485)  loss_box_reg: 0.0261 (0.0761)  loss_objectness: 0.3253 (0.5350)  loss_rpn_box_reg: 0.0839 (0.1010)  time: 3.8849 (3.9814)  data: 0.2302 (0.2827)  lr: 0.000023  max mem: 1423
2020-12-13 11:03:50,468 maskrcnn_benchmark.trainer INFO: eta: 1:32:40  iter: 200  loss: 0.5101 (0.8296)  loss_classifier: 0.1515 (0.1492)  loss_box_reg: 0.1000 (0.0783)  loss_objectness: 0.2207 (0.5055)  loss_rpn_box_reg: 0.0491 (0.0966)  time: 3.8759 (3.9715)  data: 0.2270 (0.2774)  lr: 0.000024  max mem: 1423
2020-12-13 11:05:08,030 maskrcnn_benchmark.trainer INFO: eta: 1:31:08  iter: 220  loss: 0.4285 (0.7982)  loss_classifier: 0.1379 (0.1488)  loss_box_reg: 0.0699 (0.0784)  loss_objectness: 0.1700 (0.4773)  loss_rpn_box_reg: 0.0612 (0.0937)  time: 3.8753 (3.9630)  data: 0.2327 (0.2734)  lr: 0.000025  max mem: 1423
2020-12-13 11:06:25,742 maskrcnn_benchmark.trainer INFO: eta: 1:29:40  iter: 240  loss: 0.4706 (0.7741)  loss_classifier: 0.1644 (0.1498)  loss_box_reg: 0.0992 (0.0795)  loss_objectness: 0.1629 (0.4536)  loss_rpn_box_reg: 0.0598 (0.0911)  time: 3.8811 (3.9566)  data: 0.2309 (0.2700)  lr: 0.000026  max mem: 1423
2020-12-13 11:07:43,795 maskrcnn_benchmark.trainer INFO: eta: 1:28:16  iter: 260  loss: 0.3612 (0.7452)  loss_classifier: 0.0944 (0.1478)  loss_box_reg: 0.0166 (0.0785)  loss_objectness: 0.1524 (0.4312)  loss_rpn_box_reg: 0.0381 (0.0878)  time: 3.8920 (3.9524)  data: 0.2281 (0.2670)  lr: 0.000027  max mem: 1423
2020-12-13 11:09:01,441 maskrcnn_benchmark.trainer INFO: eta: 1:26:50  iter: 280  loss: 0.3852 (0.7209)  loss_classifier: 0.1153 (0.1462)  loss_box_reg: 0.0227 (0.0765)  loss_objectness: 0.1554 (0.4121)  loss_rpn_box_reg: 0.0565 (0.0861)  time: 3.8826 (3.9474)  data: 0.2273 (0.2643)  lr: 0.000028  max mem: 1423
2020-12-13 11:09:01,443 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 11:09:01,453 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 11:09:07,547 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.093535 (1.5233838558197021 s / img per device, on 1 devices)
2020-12-13 11:09:07,547 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.635466 (1.4088665843009949 s / img per device, on 1 devices)
2020-12-13 11:09:07,548 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 11:09:07,956 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 11:09:07,957 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.0733), 'recalls': tensor([0.2667, 0.2000, 0.1333, 0.0667, 0.0333, 0.0333, 0.0000, 0.0000, 0.0000,
        0.0000]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.6045, 0.5993, 0.5912, 0.4429, 0.0121, 0.0085, 0.0000, 0.0000, 0.6374,
        0.4760, 0.4529, 0.4369, 0.4195, 0.3937, 0.3334, 0.7633, 0.6535, 0.5489,
        0.5001, 0.4708, 0.4294, 0.0083, 0.0000, 0.4976, 0.4873, 0.4827, 0.4427,
        0.4321, 0.4023, 0.3846]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([2., 2., 2., 2., 2., 1., 2., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2.,
        2., 2., 1., 2., 1., 1., 2., 2., 2., 2., 2., 2.]), 'best match scores': tensor([0.1653, 0.3711, 0.0621, 0.1396, 0.3712, 0.0510, 0.1527, 0.0616, 0.0539,
        0.0599, 0.0507, 0.0719, 0.5318, 0.2640, 0.0737, 0.1716, 0.1637, 0.0535,
        0.2319, 0.1074, 0.0526, 0.0958, 0.0600, 0.0514, 0.1354, 0.2784, 0.1048,
        0.4631, 0.1880, 0.0627]), 'num_pos': 30}
2020-12-13 11:09:07,966 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.200000
2020-12-13 11:10:25,505 maskrcnn_benchmark.trainer INFO: eta: 1:25:53  iter: 300  loss: 0.4773 (0.7037)  loss_classifier: 0.1577 (0.1474)  loss_box_reg: 0.0677 (0.0761)  loss_objectness: 0.1538 (0.3954)  loss_rpn_box_reg: 0.0663 (0.0848)  time: 3.8763 (3.9644)  data: 0.2226 (0.2833)  lr: 0.000029  max mem: 1423
2020-12-13 11:11:43,153 maskrcnn_benchmark.trainer INFO: eta: 1:24:27  iter: 320  loss: 0.3686 (0.6832)  loss_classifier: 0.1445 (0.1464)  loss_box_reg: 0.0538 (0.0753)  loss_objectness: 0.1024 (0.3790)  loss_rpn_box_reg: 0.0405 (0.0824)  time: 3.8815 (3.9593)  data: 0.2244 (0.2796)  lr: 0.000030  max mem: 1423
2020-12-13 11:13:00,848 maskrcnn_benchmark.trainer INFO: eta: 1:23:03  iter: 340  loss: 0.3464 (0.6656)  loss_classifier: 0.1125 (0.1466)  loss_box_reg: 0.0689 (0.0746)  loss_objectness: 0.0975 (0.3636)  loss_rpn_box_reg: 0.0538 (0.0808)  time: 3.8774 (3.9549)  data: 0.2310 (0.2770)  lr: 0.000031  max mem: 1423
2020-12-13 11:14:18,778 maskrcnn_benchmark.trainer INFO: eta: 1:21:40  iter: 360  loss: 0.3959 (0.6506)  loss_classifier: 0.1338 (0.1462)  loss_box_reg: 0.0313 (0.0745)  loss_objectness: 0.1132 (0.3509)  loss_rpn_box_reg: 0.0430 (0.0789)  time: 3.8920 (3.9517)  data: 0.2307 (0.2746)  lr: 0.000033  max mem: 1423
2020-12-13 11:15:36,320 maskrcnn_benchmark.trainer INFO: eta: 1:20:16  iter: 380  loss: 0.3760 (0.6362)  loss_classifier: 0.1276 (0.1454)  loss_box_reg: 0.0560 (0.0745)  loss_objectness: 0.1094 (0.3394)  loss_rpn_box_reg: 0.0323 (0.0770)  time: 3.8731 (3.9478)  data: 0.2223 (0.2720)  lr: 0.000034  max mem: 1423
2020-12-13 11:16:54,057 maskrcnn_benchmark.trainer INFO: eta: 1:18:53  iter: 400  loss: 0.3599 (0.6251)  loss_classifier: 0.1097 (0.1456)  loss_box_reg: 0.0251 (0.0747)  loss_objectness: 0.1086 (0.3293)  loss_rpn_box_reg: 0.0415 (0.0755)  time: 3.8778 (3.9447)  data: 0.2264 (0.2699)  lr: 0.000035  max mem: 1423
2020-12-13 11:18:11,426 maskrcnn_benchmark.trainer INFO: eta: 1:17:30  iter: 420  loss: 0.3334 (0.6135)  loss_classifier: 0.1109 (0.1449)  loss_box_reg: 0.0221 (0.0736)  loss_objectness: 0.1296 (0.3202)  loss_rpn_box_reg: 0.0583 (0.0748)  time: 3.8622 (3.9411)  data: 0.2309 (0.2682)  lr: 0.000036  max mem: 1423
2020-12-13 11:18:11,428 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 11:18:11,438 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 11:18:17,543 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.104713 (1.5261783003807068 s / img per device, on 1 devices)
2020-12-13 11:18:17,543 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.647432 (1.4118579626083374 s / img per device, on 1 devices)
2020-12-13 11:18:17,544 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 11:18:17,956 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 11:18:17,956 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.1167), 'recalls': tensor([0.3667, 0.3000, 0.1667, 0.1667, 0.1000, 0.0667, 0.0000, 0.0000, 0.0000,
        0.0000]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.5886, 0.5879, 0.5685, 0.4532, 0.4275, 0.0082, 0.0000, 0.0000, 0.6610,
        0.6525, 0.5670, 0.4865, 0.4676, 0.4542, 0.4063, 0.7617, 0.7120, 0.5063,
        0.5046, 0.4409, 0.4282, 0.0088, 0.0000, 0.7945, 0.4817, 0.4590, 0.4497,
        0.4455, 0.4353, 0.3794]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([2., 2., 2., 2., 2., 1., 2., 1., 1., 2., 2., 1., 1., 1., 1., 2., 1., 2.,
        2., 2., 1., 2., 2., 1., 2., 2., 2., 1., 1., 1.]), 'best match scores': tensor([0.2194, 0.0675, 0.0604, 0.1779, 0.0540, 0.0665, 0.0858, 0.0862, 0.0807,
        0.0764, 0.0932, 0.0506, 0.0707, 0.0604, 0.0511, 0.1998, 0.0666, 0.0506,
        0.2736, 0.0593, 0.0703, 0.1061, 0.1096, 0.0751, 0.1585, 0.0553, 0.1060,
        0.0787, 0.0656, 0.0555]), 'num_pos': 30}
2020-12-13 11:18:17,966 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.433333
2020-12-13 11:18:17,969 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v8.pth
2020-12-13 11:18:22,415 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v8
2020-12-13 11:19:40,142 maskrcnn_benchmark.trainer INFO: eta: 1:16:37  iter: 440  loss: 0.3594 (0.6019)  loss_classifier: 0.1105 (0.1441)  loss_box_reg: 0.0460 (0.0731)  loss_objectness: 0.1056 (0.3111)  loss_rpn_box_reg: 0.0471 (0.0736)  time: 3.8755 (3.9636)  data: 0.2232 (0.2916)  lr: 0.000037  max mem: 1423
2020-12-13 11:20:57,764 maskrcnn_benchmark.trainer INFO: eta: 1:15:14  iter: 460  loss: 0.3381 (0.5915)  loss_classifier: 0.1126 (0.1434)  loss_box_reg: 0.0681 (0.0729)  loss_objectness: 0.1060 (0.3024)  loss_rpn_box_reg: 0.0481 (0.0727)  time: 3.8754 (3.9600)  data: 0.2246 (0.2889)  lr: 0.000038  max mem: 1423
2020-12-13 11:22:15,289 maskrcnn_benchmark.trainer INFO: eta: 1:13:51  iter: 480  loss: 0.3916 (0.5830)  loss_classifier: 0.1263 (0.1432)  loss_box_reg: 0.0606 (0.0727)  loss_objectness: 0.1067 (0.2954)  loss_rpn_box_reg: 0.0436 (0.0716)  time: 3.8711 (3.9565)  data: 0.2223 (0.2862)  lr: 0.000039  max mem: 1423
2020-12-13 11:23:33,022 maskrcnn_benchmark.trainer INFO: eta: 1:12:29  iter: 500  loss: 0.3732 (0.5749)  loss_classifier: 0.1432 (0.1436)  loss_box_reg: 0.0572 (0.0730)  loss_objectness: 0.0818 (0.2878)  loss_rpn_box_reg: 0.0429 (0.0706)  time: 3.8872 (3.9537)  data: 0.2265 (0.2838)  lr: 0.000040  max mem: 1423
2020-12-13 11:24:50,622 maskrcnn_benchmark.trainer INFO: eta: 1:11:06  iter: 520  loss: 0.3563 (0.5665)  loss_classifier: 0.1287 (0.1429)  loss_box_reg: 0.0639 (0.0726)  loss_objectness: 0.1076 (0.2813)  loss_rpn_box_reg: 0.0400 (0.0698)  time: 3.8821 (3.9509)  data: 0.2324 (0.2819)  lr: 0.000040  max mem: 1423
2020-12-13 11:26:08,013 maskrcnn_benchmark.trainer INFO: eta: 1:09:44  iter: 540  loss: 0.3362 (0.5587)  loss_classifier: 0.1374 (0.1424)  loss_box_reg: 0.0522 (0.0725)  loss_objectness: 0.0898 (0.2750)  loss_rpn_box_reg: 0.0423 (0.0688)  time: 3.8675 (3.9479)  data: 0.2335 (0.2801)  lr: 0.000040  max mem: 1423
2020-12-13 11:27:25,581 maskrcnn_benchmark.trainer INFO: eta: 1:08:23  iter: 560  loss: 0.3420 (0.5521)  loss_classifier: 0.1125 (0.1421)  loss_box_reg: 0.0443 (0.0720)  loss_objectness: 0.1150 (0.2700)  loss_rpn_box_reg: 0.0415 (0.0680)  time: 3.8816 (3.9454)  data: 0.2303 (0.2782)  lr: 0.000040  max mem: 1423
2020-12-13 11:27:25,583 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 11:27:25,593 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 11:27:31,691 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.097301 (1.5243253111839294 s / img per device, on 1 devices)
2020-12-13 11:27:31,691 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.644081 (1.4110202193260193 s / img per device, on 1 devices)
2020-12-13 11:27:31,691 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 11:27:32,104 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 11:27:32,105 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.2267), 'recalls': tensor([0.5667, 0.5333, 0.5000, 0.4333, 0.1667, 0.0667, 0.0000, 0.0000, 0.0000,
        0.0000]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.6450, 0.6241, 0.5657, 0.5348, 0.4590, 0.4232, 0.0067, 0.0000, 0.6666,
        0.6649, 0.6629, 0.4781, 0.4689, 0.4401, 0.3958, 0.7912, 0.7570, 0.7362,
        0.6617, 0.6585, 0.4242, 0.0000, 0.0000, 0.7454, 0.7093, 0.6970, 0.6942,
        0.6679, 0.4450, 0.3795]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([2., 2., 1., 2., 2., 1., 2., 1., 2., 2., 2., 1., 1., 1., 2., 2., 1., 2.,
        2., 2., 1., 2., 2., 1., 2., 2., 1., 1., 1., 2.]), 'best match scores': tensor([0.1779, 0.0715, 0.0526, 0.1818, 0.0538, 0.0681, 0.0839, 0.0939, 0.4176,
        0.0750, 0.1231, 0.0642, 0.0738, 0.0691, 0.0546, 0.2274, 0.0567, 0.0639,
        0.2610, 0.0622, 0.0503, 0.0591, 0.1442, 0.0540, 0.1530, 0.0673, 0.0566,
        0.0596, 0.0685, 0.0653]), 'num_pos': 30}
2020-12-13 11:27:32,114 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.400000
2020-12-13 11:28:49,933 maskrcnn_benchmark.trainer INFO: eta: 1:07:13  iter: 580  loss: 0.3087 (0.5442)  loss_classifier: 0.1063 (0.1414)  loss_box_reg: 0.0577 (0.0719)  loss_objectness: 0.0859 (0.2639)  loss_rpn_box_reg: 0.0320 (0.0670)  time: 3.8833 (3.9548)  data: 0.2244 (0.2878)  lr: 0.000040  max mem: 1423
2020-12-13 11:30:07,632 maskrcnn_benchmark.trainer INFO: eta: 1:05:52  iter: 600  loss: 0.4362 (0.5402)  loss_classifier: 0.1460 (0.1421)  loss_box_reg: 0.0809 (0.0720)  loss_objectness: 0.0995 (0.2595)  loss_rpn_box_reg: 0.0453 (0.0665)  time: 3.8808 (3.9524)  data: 0.2237 (0.2858)  lr: 0.000040  max mem: 1423
2020-12-13 11:31:25,218 maskrcnn_benchmark.trainer INFO: eta: 1:04:31  iter: 620  loss: 0.3937 (0.5353)  loss_classifier: 0.1506 (0.1427)  loss_box_reg: 0.0993 (0.0731)  loss_objectness: 0.0691 (0.2536)  loss_rpn_box_reg: 0.0449 (0.0660)  time: 3.8757 (3.9501)  data: 0.2246 (0.2839)  lr: 0.000040  max mem: 1423
2020-12-13 11:32:42,911 maskrcnn_benchmark.trainer INFO: eta: 1:03:10  iter: 640  loss: 0.3892 (0.5303)  loss_classifier: 0.1528 (0.1429)  loss_box_reg: 0.0876 (0.0733)  loss_objectness: 0.0781 (0.2487)  loss_rpn_box_reg: 0.0430 (0.0654)  time: 3.8801 (3.9480)  data: 0.2241 (0.2821)  lr: 0.000040  max mem: 1423
2020-12-13 11:34:00,455 maskrcnn_benchmark.trainer INFO: eta: 1:01:49  iter: 660  loss: 0.3991 (0.5271)  loss_classifier: 0.1529 (0.1436)  loss_box_reg: 0.0827 (0.0735)  loss_objectness: 0.0863 (0.2448)  loss_rpn_box_reg: 0.0505 (0.0652)  time: 3.8773 (3.9459)  data: 0.2251 (0.2805)  lr: 0.000040  max mem: 1423
2020-12-13 11:35:17,939 maskrcnn_benchmark.trainer INFO: eta: 1:00:28  iter: 680  loss: 0.4066 (0.5228)  loss_classifier: 0.1424 (0.1433)  loss_box_reg: 0.0719 (0.0735)  loss_objectness: 0.1137 (0.2412)  loss_rpn_box_reg: 0.0479 (0.0648)  time: 3.8746 (3.9438)  data: 0.2246 (0.2789)  lr: 0.000040  max mem: 1423
2020-12-13 11:36:35,506 maskrcnn_benchmark.trainer INFO: eta: 0:59:07  iter: 700  loss: 0.3572 (0.5186)  loss_classifier: 0.1480 (0.1436)  loss_box_reg: 0.1020 (0.0740)  loss_objectness: 0.0807 (0.2369)  loss_rpn_box_reg: 0.0310 (0.0640)  time: 3.8785 (3.9419)  data: 0.2235 (0.2773)  lr: 0.000040  max mem: 1423
2020-12-13 11:36:35,508 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 11:36:35,518 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 11:36:41,626 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.107972 (1.5269930362701416 s / img per device, on 1 devices)
2020-12-13 11:36:41,627 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.646577 (1.4116443395614624 s / img per device, on 1 devices)
2020-12-13 11:36:41,627 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 11:36:42,040 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 11:36:42,040 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.3633), 'recalls': tensor([0.9000, 0.9000, 0.8000, 0.6333, 0.3000, 0.1000, 0.0000, 0.0000, 0.0000,
        0.0000]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.7157, 0.7145, 0.6679, 0.6421, 0.6160, 0.6021, 0.5707, 0.0000, 0.7739,
        0.6753, 0.6291, 0.6223, 0.5775, 0.5755, 0.4403, 0.7674, 0.7616, 0.7307,
        0.6914, 0.6786, 0.6768, 0.6676, 0.0000, 0.7368, 0.7226, 0.7084, 0.6960,
        0.6820, 0.6745, 0.6604]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([2., 1., 1., 1., 2., 2., 1., 1., 1., 1., 2., 2., 1., 1., 1., 2., 1., 1.,
        1., 2., 1., 2., 2., 1., 1., 2., 1., 1., 1., 2.]), 'best match scores': tensor([0.2593, 0.0624, 0.1111, 0.0711, 0.0579, 0.0644, 0.1027, 0.1461, 0.1365,
        0.0696, 0.0991, 0.0942, 0.1141, 0.0940, 0.1443, 0.2878, 0.1171, 0.0867,
        0.0832, 0.0989, 0.1180, 0.0923, 0.2569, 0.1120, 0.0622, 0.1273, 0.1127,
        0.1129, 0.0825, 0.1030]), 'num_pos': 30}
2020-12-13 11:36:42,050 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.633333
2020-12-13 11:36:42,052 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v8.pth
2020-12-13 11:36:46,213 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v8
2020-12-13 11:38:04,143 maskrcnn_benchmark.trainer INFO: eta: 0:58:00  iter: 720  loss: 0.3121 (0.5131)  loss_classifier: 0.1212 (0.1431)  loss_box_reg: 0.0399 (0.0738)  loss_objectness: 0.0776 (0.2328)  loss_rpn_box_reg: 0.0303 (0.0634)  time: 3.8866 (3.9555)  data: 0.2250 (0.2911)  lr: 0.000040  max mem: 1423
2020-12-13 11:39:21,655 maskrcnn_benchmark.trainer INFO: eta: 0:56:39  iter: 740  loss: 0.3678 (0.5089)  loss_classifier: 0.1167 (0.1429)  loss_box_reg: 0.0797 (0.0740)  loss_objectness: 0.0924 (0.2292)  loss_rpn_box_reg: 0.0348 (0.0627)  time: 3.8760 (3.9534)  data: 0.2230 (0.2894)  lr: 0.000040  max mem: 1423
2020-12-13 11:40:39,294 maskrcnn_benchmark.trainer INFO: eta: 0:55:19  iter: 760  loss: 0.3732 (0.5053)  loss_classifier: 0.1539 (0.1433)  loss_box_reg: 0.0900 (0.0744)  loss_objectness: 0.0794 (0.2255)  loss_rpn_box_reg: 0.0359 (0.0620)  time: 3.8852 (3.9515)  data: 0.2229 (0.2877)  lr: 0.000040  max mem: 1423
2020-12-13 11:41:56,904 maskrcnn_benchmark.trainer INFO: eta: 0:53:58  iter: 780  loss: 0.3620 (0.5015)  loss_classifier: 0.1356 (0.1429)  loss_box_reg: 0.0933 (0.0748)  loss_objectness: 0.0935 (0.2225)  loss_rpn_box_reg: 0.0343 (0.0614)  time: 3.8792 (3.9497)  data: 0.2242 (0.2861)  lr: 0.000040  max mem: 1423
2020-12-13 11:43:14,564 maskrcnn_benchmark.trainer INFO: eta: 0:52:38  iter: 800  loss: 0.3119 (0.4978)  loss_classifier: 0.1308 (0.1428)  loss_box_reg: 0.0761 (0.0748)  loss_objectness: 0.0871 (0.2194)  loss_rpn_box_reg: 0.0302 (0.0608)  time: 3.8786 (3.9480)  data: 0.2230 (0.2846)  lr: 0.000040  max mem: 1423
2020-12-13 11:44:34,716 maskrcnn_benchmark.trainer INFO: eta: 0:51:20  iter: 820  loss: 0.3138 (0.4938)  loss_classifier: 0.1257 (0.1427)  loss_box_reg: 0.0396 (0.0745)  loss_objectness: 0.0824 (0.2161)  loss_rpn_box_reg: 0.0408 (0.0605)  time: 3.9373 (3.9494)  data: 0.2380 (0.2841)  lr: 0.000040  max mem: 1423
2020-12-13 11:45:59,882 maskrcnn_benchmark.trainer INFO: eta: 0:50:07  iter: 840  loss: 0.3577 (0.4904)  loss_classifier: 0.1266 (0.1426)  loss_box_reg: 0.0821 (0.0746)  loss_objectness: 0.0686 (0.2130)  loss_rpn_box_reg: 0.0470 (0.0601)  time: 4.2828 (3.9568)  data: 0.2704 (0.2838)  lr: 0.000040  max mem: 1423
2020-12-13 11:45:59,885 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 11:45:59,896 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 11:46:06,483 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.585836 (1.6464591026306152 s / img per device, on 1 devices)
2020-12-13 11:46:06,483 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:06.078674 (1.5196685194969177 s / img per device, on 1 devices)
2020-12-13 11:46:06,483 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 11:46:06,943 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 11:46:06,943 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.3633), 'recalls': tensor([0.9000, 0.8667, 0.7333, 0.5667, 0.3667, 0.1667, 0.0333, 0.0000, 0.0000,
        0.0000]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.7289, 0.7176, 0.6764, 0.6553, 0.6314, 0.6091, 0.5648, 0.0000, 0.7867,
        0.6831, 0.6404, 0.5847, 0.5662, 0.5122, 0.4385, 0.8127, 0.7773, 0.7757,
        0.7021, 0.6815, 0.6500, 0.6202, 0.0000, 0.7519, 0.7314, 0.7305, 0.7294,
        0.6868, 0.6549, 0.5765]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([2., 1., 1., 1., 2., 1., 1., 1., 1., 1., 2., 2., 1., 2., 1., 1., 1., 1.,
        1., 2., 1., 1., 2., 1., 1., 2., 1., 1., 1., 1.]), 'best match scores': tensor([0.2227, 0.0685, 0.1206, 0.0782, 0.0769, 0.0932, 0.1195, 0.1484, 0.1438,
        0.0767, 0.0899, 0.0871, 0.1167, 0.2918, 0.1555, 0.1343, 0.1230, 0.0934,
        0.0882, 0.2078, 0.1219, 0.0891, 0.2127, 0.1187, 0.0584, 0.1175, 0.1202,
        0.0753, 0.0533, 0.1327]), 'num_pos': 30}
2020-12-13 11:46:06,953 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.733333
2020-12-13 11:46:06,956 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v8.pth
2020-12-13 11:46:11,328 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v8
2020-12-13 11:47:36,000 maskrcnn_benchmark.trainer INFO: eta: 0:49:02  iter: 860  loss: 0.3318 (0.4873)  loss_classifier: 0.1244 (0.1425)  loss_box_reg: 0.0481 (0.0746)  loss_objectness: 0.0906 (0.2106)  loss_rpn_box_reg: 0.0363 (0.0596)  time: 4.2253 (3.9765)  data: 0.2519 (0.2967)  lr: 0.000040  max mem: 1423
2020-12-13 11:48:58,124 maskrcnn_benchmark.trainer INFO: eta: 0:47:45  iter: 880  loss: 0.3386 (0.4850)  loss_classifier: 0.1281 (0.1429)  loss_box_reg: 0.0402 (0.0744)  loss_objectness: 0.0925 (0.2084)  loss_rpn_box_reg: 0.0483 (0.0594)  time: 4.1071 (3.9795)  data: 0.2610 (0.2968)  lr: 0.000040  max mem: 1423
2020-12-13 11:50:19,583 maskrcnn_benchmark.trainer INFO: eta: 0:46:27  iter: 900  loss: 0.2830 (0.4812)  loss_classifier: 0.1113 (0.1425)  loss_box_reg: 0.0328 (0.0740)  loss_objectness: 0.0711 (0.2057)  loss_rpn_box_reg: 0.0439 (0.0591)  time: 4.1107 (3.9816)  data: 0.2457 (0.2958)  lr: 0.000040  max mem: 1423
2020-12-13 11:51:39,090 maskrcnn_benchmark.trainer INFO: eta: 0:45:07  iter: 920  loss: 0.3525 (0.4790)  loss_classifier: 0.1280 (0.1426)  loss_box_reg: 0.0918 (0.0742)  loss_objectness: 0.0919 (0.2035)  loss_rpn_box_reg: 0.0349 (0.0588)  time: 3.9661 (3.9814)  data: 0.2454 (0.2948)  lr: 0.000040  max mem: 1423
2020-12-13 11:52:59,522 maskrcnn_benchmark.trainer INFO: eta: 0:43:48  iter: 940  loss: 0.3566 (0.4773)  loss_classifier: 0.1525 (0.1430)  loss_box_reg: 0.1005 (0.0746)  loss_objectness: 0.0890 (0.2013)  loss_rpn_box_reg: 0.0400 (0.0585)  time: 3.9883 (3.9823)  data: 0.2412 (0.2938)  lr: 0.000040  max mem: 1423
2020-12-13 11:54:20,962 maskrcnn_benchmark.trainer INFO: eta: 0:42:29  iter: 960  loss: 0.3340 (0.4745)  loss_classifier: 0.1414 (0.1430)  loss_box_reg: 0.0839 (0.0748)  loss_objectness: 0.0622 (0.1987)  loss_rpn_box_reg: 0.0339 (0.0580)  time: 4.0194 (3.9842)  data: 0.2529 (0.2931)  lr: 0.000040  max mem: 1423
2020-12-13 11:55:41,257 maskrcnn_benchmark.trainer INFO: eta: 0:41:10  iter: 980  loss: 0.2805 (0.4712)  loss_classifier: 0.1141 (0.1427)  loss_box_reg: 0.0405 (0.0747)  loss_objectness: 0.0686 (0.1960)  loss_rpn_box_reg: 0.0436 (0.0577)  time: 3.9991 (3.9848)  data: 0.2412 (0.2923)  lr: 0.000040  max mem: 1423
2020-12-13 11:55:41,259 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 11:55:41,271 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 11:55:47,728 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.456610 (1.6141524910926819 s / img per device, on 1 devices)
2020-12-13 11:55:47,728 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.905019 (1.476254642009735 s / img per device, on 1 devices)
2020-12-13 11:55:47,728 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 11:55:48,166 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 11:55:48,167 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.3800), 'recalls': tensor([0.9667, 0.9333, 0.7333, 0.6333, 0.3333, 0.1333, 0.0667, 0.0000, 0.0000,
        0.0000]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.7580, 0.7251, 0.7008, 0.6518, 0.6504, 0.6483, 0.5901, 0.5442, 0.7706,
        0.6885, 0.6624, 0.5940, 0.5917, 0.5775, 0.5647, 0.8309, 0.8082, 0.7454,
        0.6867, 0.6774, 0.6536, 0.6400, 0.6387, 0.7396, 0.7020, 0.7006, 0.6753,
        0.6710, 0.5934, 0.4967]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 1., 1., 1., 1., 2., 1.,
        1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1.]), 'best match scores': tensor([0.2179, 0.1078, 0.1719, 0.1238, 0.0816, 0.1334, 0.1773, 0.1970, 0.1994,
        0.1213, 0.1168, 0.0989, 0.1590, 0.1258, 0.2262, 0.1723, 0.0550, 0.1401,
        0.1360, 0.0672, 0.1628, 0.1305, 0.2217, 0.1705, 0.0992, 0.1944, 0.1726,
        0.1557, 0.0823, 0.1865]), 'num_pos': 30}
2020-12-13 11:55:48,177 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.866667
2020-12-13 11:55:48,181 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./_best_acc_r5_v8.pth
2020-12-13 11:55:52,634 maskrcnn_benchmark.trainer INFO: current record in accuracy, saving model to: _best_acc_r5_v8
2020-12-13 11:57:14,037 maskrcnn_benchmark.trainer INFO: eta: 0:39:58  iter: 1000  loss: 0.3567 (0.4691)  loss_classifier: 0.1412 (0.1427)  loss_box_reg: 0.0669 (0.0749)  loss_objectness: 0.1003 (0.1942)  loss_rpn_box_reg: 0.0280 (0.0572)  time: 4.0318 (3.9979)  data: 0.2496 (0.3030)  lr: 0.000040  max mem: 1423
2020-12-13 11:58:34,531 maskrcnn_benchmark.trainer INFO: eta: 0:38:39  iter: 1020  loss: 0.3292 (0.4669)  loss_classifier: 0.1389 (0.1429)  loss_box_reg: 0.0933 (0.0753)  loss_objectness: 0.0679 (0.1919)  loss_rpn_box_reg: 0.0318 (0.0569)  time: 3.9844 (3.9984)  data: 0.2460 (0.3020)  lr: 0.000040  max mem: 1423
2020-12-13 11:59:55,501 maskrcnn_benchmark.trainer INFO: eta: 0:37:19  iter: 1040  loss: 0.2990 (0.4639)  loss_classifier: 0.1182 (0.1426)  loss_box_reg: 0.0436 (0.0750)  loss_objectness: 0.0701 (0.1898)  loss_rpn_box_reg: 0.0327 (0.0566)  time: 4.0336 (3.9994)  data: 0.2487 (0.3011)  lr: 0.000040  max mem: 1423
2020-12-13 12:01:16,924 maskrcnn_benchmark.trainer INFO: eta: 0:36:00  iter: 1060  loss: 0.3242 (0.4616)  loss_classifier: 0.1420 (0.1426)  loss_box_reg: 0.0942 (0.0753)  loss_objectness: 0.0586 (0.1875)  loss_rpn_box_reg: 0.0335 (0.0562)  time: 4.0384 (4.0007)  data: 0.2579 (0.3004)  lr: 0.000040  max mem: 1423
2020-12-13 12:02:37,779 maskrcnn_benchmark.trainer INFO: eta: 0:34:40  iter: 1080  loss: 0.3332 (0.4597)  loss_classifier: 0.1347 (0.1425)  loss_box_reg: 0.0949 (0.0757)  loss_objectness: 0.0683 (0.1855)  loss_rpn_box_reg: 0.0292 (0.0559)  time: 4.0006 (4.0015)  data: 0.2483 (0.2998)  lr: 0.000040  max mem: 1423
2020-12-13 12:03:58,628 maskrcnn_benchmark.trainer INFO: eta: 0:33:21  iter: 1100  loss: 0.3779 (0.4587)  loss_classifier: 0.1410 (0.1428)  loss_box_reg: 0.0776 (0.0759)  loss_objectness: 0.0891 (0.1842)  loss_rpn_box_reg: 0.0476 (0.0558)  time: 3.9884 (4.0022)  data: 0.2525 (0.2990)  lr: 0.000040  max mem: 1423
2020-12-13 12:05:19,577 maskrcnn_benchmark.trainer INFO: eta: 0:32:01  iter: 1120  loss: 0.3459 (0.4565)  loss_classifier: 0.1319 (0.1427)  loss_box_reg: 0.0954 (0.0761)  loss_objectness: 0.0746 (0.1823)  loss_rpn_box_reg: 0.0324 (0.0554)  time: 4.0143 (4.0030)  data: 0.2602 (0.2984)  lr: 0.000040  max mem: 1423
2020-12-13 12:05:19,579 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 12:05:19,591 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 12:05:25,973 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.382418 (1.5956044793128967 s / img per device, on 1 devices)
2020-12-13 12:05:25,974 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.843394 (1.4608483910560608 s / img per device, on 1 devices)
2020-12-13 12:05:25,974 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 12:05:26,441 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 12:05:26,441 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.3567), 'recalls': tensor([0.9667, 0.9333, 0.8000, 0.5000, 0.2000, 0.1000, 0.0667, 0.0000, 0.0000,
        0.0000]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.7156, 0.7013, 0.6545, 0.6467, 0.6466, 0.6302, 0.6023, 0.5336, 0.6994,
        0.6762, 0.6670, 0.5945, 0.5858, 0.5824, 0.5551, 0.8297, 0.8031, 0.7541,
        0.7228, 0.6834, 0.6482, 0.6407, 0.6385, 0.6993, 0.6935, 0.6777, 0.6676,
        0.6352, 0.6027, 0.4896]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 1., 1., 1., 1., 2., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1.]), 'best match scores': tensor([0.2246, 0.1046, 0.1658, 0.1236, 0.0816, 0.1449, 0.1787, 0.1821, 0.1967,
        0.1215, 0.2348, 0.0914, 0.1501, 0.1199, 0.2253, 0.1626, 0.0534, 0.1371,
        0.1379, 0.0652, 0.1542, 0.1270, 0.0922, 0.0930, 0.0979, 0.1899, 0.1300,
        0.1442, 0.1208, 0.1814]), 'num_pos': 30}
2020-12-13 12:05:26,450 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.833333
2020-12-13 12:06:46,137 maskrcnn_benchmark.trainer INFO: eta: 0:30:44  iter: 1140  loss: 0.3746 (0.4557)  loss_classifier: 0.1654 (0.1432)  loss_box_reg: 0.0667 (0.0763)  loss_objectness: 0.0946 (0.1809)  loss_rpn_box_reg: 0.0406 (0.0553)  time: 3.9607 (4.0087)  data: 0.2542 (0.3036)  lr: 0.000040  max mem: 1423
2020-12-13 12:08:05,155 maskrcnn_benchmark.trainer INFO: eta: 0:29:23  iter: 1160  loss: 0.3333 (0.4539)  loss_classifier: 0.1288 (0.1431)  loss_box_reg: 0.0801 (0.0762)  loss_objectness: 0.0907 (0.1794)  loss_rpn_box_reg: 0.0444 (0.0551)  time: 3.9367 (4.0077)  data: 0.2512 (0.3027)  lr: 0.000040  max mem: 1423
2020-12-13 12:09:23,927 maskrcnn_benchmark.trainer INFO: eta: 0:28:02  iter: 1180  loss: 0.3555 (0.4526)  loss_classifier: 0.1439 (0.1433)  loss_box_reg: 0.1056 (0.0766)  loss_objectness: 0.0648 (0.1780)  loss_rpn_box_reg: 0.0321 (0.0548)  time: 3.9374 (4.0066)  data: 0.2333 (0.3016)  lr: 0.000040  max mem: 1423
2020-12-13 12:10:42,981 maskrcnn_benchmark.trainer INFO: eta: 0:26:42  iter: 1200  loss: 0.2517 (0.4500)  loss_classifier: 0.1022 (0.1428)  loss_box_reg: 0.0272 (0.0761)  loss_objectness: 0.0713 (0.1766)  loss_rpn_box_reg: 0.0363 (0.0545)  time: 3.9478 (4.0057)  data: 0.2472 (0.3008)  lr: 0.000040  max mem: 1423
2020-12-13 12:12:02,084 maskrcnn_benchmark.trainer INFO: eta: 0:25:21  iter: 1220  loss: 0.2984 (0.4478)  loss_classifier: 0.1108 (0.1425)  loss_box_reg: 0.0489 (0.0758)  loss_objectness: 0.0629 (0.1752)  loss_rpn_box_reg: 0.0334 (0.0543)  time: 3.9401 (4.0048)  data: 0.2517 (0.2999)  lr: 0.000040  max mem: 1423
2020-12-13 12:13:21,364 maskrcnn_benchmark.trainer INFO: eta: 0:24:01  iter: 1240  loss: 0.3219 (0.4458)  loss_classifier: 0.1330 (0.1424)  loss_box_reg: 0.1082 (0.0762)  loss_objectness: 0.0589 (0.1734)  loss_rpn_box_reg: 0.0305 (0.0539)  time: 3.9655 (4.0042)  data: 0.2420 (0.2992)  lr: 0.000040  max mem: 1423
2020-12-13 12:14:41,222 maskrcnn_benchmark.trainer INFO: eta: 0:22:41  iter: 1260  loss: 0.3073 (0.4441)  loss_classifier: 0.1445 (0.1424)  loss_box_reg: 0.0422 (0.0762)  loss_objectness: 0.0617 (0.1718)  loss_rpn_box_reg: 0.0360 (0.0537)  time: 3.9904 (4.0040)  data: 0.2479 (0.2985)  lr: 0.000040  max mem: 1423
2020-12-13 12:14:41,225 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 12:14:41,238 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 12:14:47,761 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.523342 (1.630835473537445 s / img per device, on 1 devices)
2020-12-13 12:14:47,762 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:06.013928 (1.5034821033477783 s / img per device, on 1 devices)
2020-12-13 12:14:47,762 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 12:14:48,220 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 12:14:48,220 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.3500), 'recalls': tensor([0.9667, 0.9000, 0.7333, 0.4667, 0.3000, 0.1000, 0.0333, 0.0000, 0.0000,
        0.0000]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.7884, 0.7057, 0.6605, 0.6495, 0.6362, 0.6343, 0.6060, 0.5320, 0.7015,
        0.6732, 0.6648, 0.5909, 0.5893, 0.5784, 0.5553, 0.8084, 0.7605, 0.7325,
        0.7102, 0.7021, 0.6849, 0.6485, 0.6320, 0.7047, 0.6848, 0.6450, 0.6260,
        0.5967, 0.5336, 0.4820]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([2., 1., 1., 1., 1., 1., 1., 2., 1., 1., 2., 2., 1., 1., 1., 1., 2., 1.,
        1., 1., 1., 2., 1., 1., 1., 1., 2., 1., 1., 2.]), 'best match scores': tensor([0.2159, 0.1103, 0.1745, 0.1264, 0.0913, 0.1509, 0.1879, 0.1678, 0.2044,
        0.1300, 0.2455, 0.0904, 0.1531, 0.1270, 0.2397, 0.1621, 0.0541, 0.1409,
        0.1585, 0.0709, 0.1577, 0.0987, 0.0930, 0.0825, 0.1058, 0.1985, 0.1312,
        0.1473, 0.1309, 0.1262]), 'num_pos': 30}
2020-12-13 12:14:48,230 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.733333
2020-12-13 12:16:07,004 maskrcnn_benchmark.trainer INFO: eta: 0:21:22  iter: 1280  loss: 0.3312 (0.4424)  loss_classifier: 0.1247 (0.1422)  loss_box_reg: 0.0518 (0.0760)  loss_objectness: 0.0864 (0.1707)  loss_rpn_box_reg: 0.0334 (0.0535)  time: 3.9353 (4.0085)  data: 0.2398 (0.3031)  lr: 0.000040  max mem: 1423
2020-12-13 12:17:25,903 maskrcnn_benchmark.trainer INFO: eta: 0:20:02  iter: 1300  loss: 0.3142 (0.4408)  loss_classifier: 0.1350 (0.1423)  loss_box_reg: 0.1004 (0.0762)  loss_objectness: 0.0503 (0.1691)  loss_rpn_box_reg: 0.0323 (0.0532)  time: 3.9397 (4.0075)  data: 0.2456 (0.3022)  lr: 0.000040  max mem: 1423
2020-12-13 12:18:44,783 maskrcnn_benchmark.trainer INFO: eta: 0:18:41  iter: 1320  loss: 0.3150 (0.4394)  loss_classifier: 0.1183 (0.1422)  loss_box_reg: 0.1013 (0.0765)  loss_objectness: 0.0592 (0.1676)  loss_rpn_box_reg: 0.0395 (0.0530)  time: 3.9439 (4.0065)  data: 0.2459 (0.3014)  lr: 0.000040  max mem: 1423
2020-12-13 12:20:03,304 maskrcnn_benchmark.trainer INFO: eta: 0:17:21  iter: 1340  loss: 0.2988 (0.4376)  loss_classifier: 0.1158 (0.1420)  loss_box_reg: 0.0393 (0.0764)  loss_objectness: 0.0743 (0.1664)  loss_rpn_box_reg: 0.0384 (0.0528)  time: 3.9333 (4.0053)  data: 0.2426 (0.3006)  lr: 0.000040  max mem: 1423
2020-12-13 12:21:23,373 maskrcnn_benchmark.trainer INFO: eta: 0:16:01  iter: 1360  loss: 0.3391 (0.4370)  loss_classifier: 0.1466 (0.1422)  loss_box_reg: 0.0906 (0.0768)  loss_objectness: 0.0805 (0.1652)  loss_rpn_box_reg: 0.0429 (0.0527)  time: 3.9852 (4.0053)  data: 0.2491 (0.3001)  lr: 0.000040  max mem: 1423
2020-12-13 12:22:43,417 maskrcnn_benchmark.trainer INFO: eta: 0:14:41  iter: 1380  loss: 0.3592 (0.4362)  loss_classifier: 0.1488 (0.1425)  loss_box_reg: 0.1005 (0.0772)  loss_objectness: 0.0633 (0.1638)  loss_rpn_box_reg: 0.0511 (0.0526)  time: 3.9844 (4.0053)  data: 0.2588 (0.2995)  lr: 0.000040  max mem: 1423
2020-12-13 12:24:02,642 maskrcnn_benchmark.trainer INFO: eta: 0:13:20  iter: 1400  loss: 0.3167 (0.4350)  loss_classifier: 0.1219 (0.1425)  loss_box_reg: 0.0793 (0.0777)  loss_objectness: 0.0505 (0.1625)  loss_rpn_box_reg: 0.0259 (0.0523)  time: 3.9496 (4.0046)  data: 0.2421 (0.2988)  lr: 0.000040  max mem: 1423
2020-12-13 12:24:02,644 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 12:24:02,656 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 12:24:08,806 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.150116 (1.5375290513038635 s / img per device, on 1 devices)
2020-12-13 12:24:08,806 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.646197 (1.4115492105484009 s / img per device, on 1 devices)
2020-12-13 12:24:08,806 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 12:24:09,258 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 12:24:09,259 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.3400), 'recalls': tensor([0.9667, 0.8667, 0.7000, 0.5333, 0.2333, 0.1000, 0.0000, 0.0000, 0.0000,
        0.0000]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.7772, 0.7352, 0.6766, 0.6592, 0.6454, 0.6231, 0.5974, 0.5254, 0.6840,
        0.6737, 0.6596, 0.5883, 0.5799, 0.5762, 0.5477, 0.7995, 0.7613, 0.7222,
        0.7094, 0.6944, 0.6795, 0.6559, 0.6275, 0.7187, 0.6794, 0.6325, 0.6264,
        0.5952, 0.5252, 0.4789]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([2., 1., 1., 1., 1., 1., 2., 1., 1., 1., 2., 2., 1., 1., 1., 1., 2., 1.,
        1., 1., 1., 2., 1., 1., 1., 1., 2., 1., 1., 2.]), 'best match scores': tensor([0.2384, 0.1649, 0.2259, 0.1828, 0.1446, 0.2123, 0.0532, 0.2357, 0.2675,
        0.1939, 0.2846, 0.1014, 0.2122, 0.1883, 0.3202, 0.2079, 0.0658, 0.1984,
        0.2310, 0.1118, 0.2110, 0.1216, 0.1210, 0.2368, 0.1597, 0.2700, 0.1487,
        0.2098, 0.1929, 0.1439]), 'num_pos': 30}
2020-12-13 12:24:09,270 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.733333
2020-12-13 12:25:28,155 maskrcnn_benchmark.trainer INFO: eta: 0:12:01  iter: 1420  loss: 0.3598 (0.4341)  loss_classifier: 0.1490 (0.1426)  loss_box_reg: 0.0937 (0.0781)  loss_objectness: 0.0569 (0.1612)  loss_rpn_box_reg: 0.0455 (0.0521)  time: 3.9282 (4.0084)  data: 0.2440 (0.3027)  lr: 0.000040  max mem: 1423
2020-12-13 12:26:47,049 maskrcnn_benchmark.trainer INFO: eta: 0:10:41  iter: 1440  loss: 0.2744 (0.4324)  loss_classifier: 0.1200 (0.1424)  loss_box_reg: 0.0424 (0.0780)  loss_objectness: 0.0706 (0.1602)  loss_rpn_box_reg: 0.0351 (0.0519)  time: 3.9425 (4.0076)  data: 0.2420 (0.3020)  lr: 0.000040  max mem: 1423
2020-12-13 12:28:05,839 maskrcnn_benchmark.trainer INFO: eta: 0:09:20  iter: 1460  loss: 0.3255 (0.4312)  loss_classifier: 0.1086 (0.1424)  loss_box_reg: 0.0450 (0.0781)  loss_objectness: 0.0599 (0.1590)  loss_rpn_box_reg: 0.0307 (0.0517)  time: 3.9312 (4.0066)  data: 0.2373 (0.3012)  lr: 0.000040  max mem: 1423
2020-12-13 12:29:25,499 maskrcnn_benchmark.trainer INFO: eta: 0:08:00  iter: 1480  loss: 0.2512 (0.4292)  loss_classifier: 0.0985 (0.1420)  loss_box_reg: 0.0386 (0.0779)  loss_objectness: 0.0636 (0.1578)  loss_rpn_box_reg: 0.0389 (0.0515)  time: 3.9630 (4.0063)  data: 0.2446 (0.3004)  lr: 0.000040  max mem: 1423
2020-12-13 12:30:46,257 maskrcnn_benchmark.trainer INFO: eta: 0:06:40  iter: 1500  loss: 0.3376 (0.4282)  loss_classifier: 0.1353 (0.1421)  loss_box_reg: 0.0680 (0.0781)  loss_objectness: 0.0595 (0.1566)  loss_rpn_box_reg: 0.0415 (0.0514)  time: 4.0354 (4.0067)  data: 0.2366 (0.2996)  lr: 0.000040  max mem: 1423
2020-12-13 12:32:06,334 maskrcnn_benchmark.trainer INFO: eta: 0:05:20  iter: 1520  loss: 0.3597 (0.4275)  loss_classifier: 0.1404 (0.1422)  loss_box_reg: 0.0987 (0.0784)  loss_objectness: 0.0682 (0.1555)  loss_rpn_box_reg: 0.0356 (0.0513)  time: 3.9941 (4.0067)  data: 0.2436 (0.2989)  lr: 0.000040  max mem: 1423
2020-12-13 12:33:26,990 maskrcnn_benchmark.trainer INFO: eta: 0:04:00  iter: 1540  loss: 0.3155 (0.4265)  loss_classifier: 0.1259 (0.1423)  loss_box_reg: 0.0877 (0.0786)  loss_objectness: 0.0713 (0.1545)  loss_rpn_box_reg: 0.0425 (0.0511)  time: 4.0381 (4.0070)  data: 0.2379 (0.2982)  lr: 0.000040  max mem: 1423
2020-12-13 12:33:26,992 maskrcnn_benchmark.trainer INFO: validation circle
2020-12-13 12:33:27,004 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_valid dataset(4 images).
2020-12-13 12:33:33,362 maskrcnn_benchmark.inference INFO: Total run time: 0:00:06.357247 (1.5893117785453796 s / img per device, on 1 devices)
2020-12-13 12:33:33,362 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:05.851619 (1.4629047513008118 s / img per device, on 1 devices)
2020-12-13 12:33:33,362 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 12:33:33,791 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 12:33:33,792 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.3367), 'recalls': tensor([0.9667, 0.9000, 0.6667, 0.5000, 0.2000, 0.1000, 0.0333, 0.0000, 0.0000,
        0.0000]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.7791, 0.7538, 0.6729, 0.6582, 0.6481, 0.6211, 0.5896, 0.5174, 0.6890,
        0.6756, 0.6590, 0.5991, 0.5883, 0.5740, 0.5511, 0.8005, 0.7316, 0.7265,
        0.6968, 0.6918, 0.6684, 0.6297, 0.5865, 0.7261, 0.6816, 0.6326, 0.6251,
        0.5998, 0.5258, 0.4804]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1]), 'best match labels': tensor([2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 2., 1., 1., 1., 1., 2., 1., 1., 2.]), 'best match scores': tensor([0.2169, 0.1872, 0.2482, 0.2078, 0.1665, 0.2375, 0.2868, 0.2553, 0.3008,
        0.2222, 0.2692, 0.0911, 0.2455, 0.2159, 0.3523, 0.2294, 0.2760, 0.2202,
        0.2685, 0.1278, 0.2365, 0.1121, 0.1293, 0.2616, 0.1799, 0.3067, 0.1353,
        0.2357, 0.2221, 0.1340]), 'num_pos': 30}
2020-12-13 12:33:33,801 maskrcnn_benchmark.trainer INFO: validation accuracy: 0.800000
2020-12-13 12:34:52,169 maskrcnn_benchmark.trainer INFO: eta: 0:02:40  iter: 1560  loss: 0.3402 (0.4254)  loss_classifier: 0.1378 (0.1422)  loss_box_reg: 0.0787 (0.0788)  loss_objectness: 0.0764 (0.1535)  loss_rpn_box_reg: 0.0324 (0.0509)  time: 3.8890 (4.0103)  data: 0.2392 (0.3019)  lr: 0.000040  max mem: 1423
2020-12-13 12:36:12,039 maskrcnn_benchmark.trainer INFO: eta: 0:01:20  iter: 1580  loss: 0.3117 (0.4241)  loss_classifier: 0.1327 (0.1421)  loss_box_reg: 0.0877 (0.0789)  loss_objectness: 0.0522 (0.1524)  loss_rpn_box_reg: 0.0406 (0.0508)  time: 3.9639 (4.0100)  data: 0.2430 (0.3012)  lr: 0.000040  max mem: 1423
2020-12-13 12:37:31,263 maskrcnn_benchmark.trainer INFO: eta: 0:00:00  iter: 1600  loss: 0.3537 (0.4232)  loss_classifier: 0.1437 (0.1421)  loss_box_reg: 0.0851 (0.0790)  loss_objectness: 0.0581 (0.1515)  loss_rpn_box_reg: 0.0296 (0.0506)  time: 3.9576 (4.0094)  data: 0.2385 (0.3004)  lr: 0.000040  max mem: 1423
2020-12-13 12:37:31,266 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to ./final_mode_r5_v8.pth
2020-12-13 12:37:32,291 maskrcnn_benchmark.trainer INFO: final model, saving model to: final_mode_r5_v8
2020-12-13 12:37:32,312 maskrcnn_benchmark.trainer INFO: Total training time: 1:46:56.142684 (4.0101 s / it)
2020-12-13 12:37:36,048 maskrcnn_benchmark.inference INFO: Start evaluation on giro1_test dataset(258 images).
2020-12-13 12:44:14,093 maskrcnn_benchmark.inference INFO: Total run time: 0:06:38.045131 (1.5428105869958566 s / img per device, on 1 devices)
2020-12-13 12:44:14,093 maskrcnn_benchmark.inference INFO: Model inference time: 0:06:06.925633 (1.422192374865214 s / img per device, on 1 devices)
2020-12-13 12:44:14,191 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 12:44:41,005 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 12:44:41,005 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.4556), 'recalls': tensor([8.4103e-01, 8.1596e-01, 7.8034e-01, 7.1900e-01, 5.8641e-01, 4.3074e-01,
        2.4340e-01, 1.1016e-01, 2.8364e-02, 6.5963e-04]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.7637, 0.3552, 0.0306,  ..., 0.4498, 0.2364, 0.1634]), 'gt_labels': tensor([7, 7, 4,  ..., 2, 2, 2]), 'best match labels': tensor([7., 7., 1.,  ..., 2., 2., 2.]), 'best match scores': tensor([0.7132, 0.1114, 0.2612,  ..., 0.8010, 0.1487, 0.7375]), 'num_pos': 1516}
2020-12-13 12:44:41,011 maskrcnn_benchmark.inference INFO: Start evaluation on giro4_test dataset(7 images).
2020-12-13 12:44:51,647 maskrcnn_benchmark.inference INFO: Total run time: 0:00:10.635227 (1.5193182059696742 s / img per device, on 1 devices)
2020-12-13 12:44:51,647 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:09.890922 (1.4129887989589147 s / img per device, on 1 devices)
2020-12-13 12:44:51,649 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 12:44:52,365 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 12:44:52,365 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.0278), 'recalls': tensor([0.0556, 0.0556, 0.0556, 0.0556, 0.0556, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.0000, 0.0000, 0.0000, 0.1423, 0.0000, 0.0000, 0.1815, 0.0000, 0.2529,
        0.0000, 0.0398, 0.0000, 0.0000, 0.0333, 0.0156, 0.7362, 0.0000, 0.0000]), 'gt_labels': tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), 'best match labels': tensor([7., 7., 7., 2., 7., 7., 1., 7., 1., 7., 2., 7., 7., 1., 1., 1., 7., 7.]), 'best match scores': tensor([0.2521, 0.0658, 0.0968, 0.1210, 0.1805, 0.0557, 0.1353, 0.0603, 0.0613,
        0.0502, 0.0879, 0.1844, 0.3674, 0.1459, 0.0869, 0.0554, 0.0586, 0.0525]), 'num_pos': 18}
2020-12-13 12:44:52,372 maskrcnn_benchmark.inference INFO: Start evaluation on giro8_test dataset(3 images).
2020-12-13 12:44:56,948 maskrcnn_benchmark.inference INFO: Total run time: 0:00:04.575753 (1.525251070658366 s / img per device, on 1 devices)
2020-12-13 12:44:56,949 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:04.245245 (1.4150818188985188 s / img per device, on 1 devices)
2020-12-13 12:44:56,949 maskrcnn_benchmark.inference INFO: Evaluating bbox proposals
2020-12-13 12:44:57,252 maskrcnn_benchmark.inference INFO: box sizes: all
2020-12-13 12:44:57,252 maskrcnn_benchmark.inference INFO: {'ar': tensor(0.4240), 'recalls': tensor([0.9200, 0.9200, 0.7200, 0.6800, 0.5200, 0.3200, 0.1600, 0.0000, 0.0000,
        0.0000]), 'thresholds': tensor([0.5000, 0.5500, 0.6000, 0.6500, 0.7000, 0.7500, 0.8000, 0.8500, 0.9000,
        0.9500]), 'gt_overlaps': tensor([0.8440, 0.7198, 0.7033, 0.6994, 0.6921, 0.6855, 0.6503, 0.5700, 0.8471,
        0.8378, 0.7000, 0.6213, 0.5734, 0.5645, 0.4744, 0.4717, 0.8430, 0.7984,
        0.7863, 0.7830, 0.7519, 0.7397, 0.7221, 0.5866, 0.5602]), 'gt_labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1]), 'best match labels': tensor([1., 1., 1., 1., 1., 1., 1., 2., 2., 1., 2., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 2., 2., 1.]), 'best match scores': tensor([0.2171, 0.2366, 0.2461, 0.1902, 0.1305, 0.0843, 0.2159, 0.1950, 0.1299,
        0.0613, 0.3031, 0.2127, 0.0997, 0.2647, 0.1339, 0.0719, 0.2431, 0.1184,
        0.1798, 0.1377, 0.1453, 0.1726, 0.1326, 0.0644, 0.1038]), 'num_pos': 25}
