{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom dataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9D4p6r_oulU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MkIXR59pGJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e626bf2d-a2e1-418a-d764-10ef5fff5ea1"
      },
      "source": [
        "#importing the drive (where the data currently is)\n",
        "from google.colab import drive \n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "o9dCLcHsowcF",
        "outputId": "fc7269f4-2a41-45e5-e1fc-d67ce7cd7e65"
      },
      "source": [
        "#reading the text file of the annotation into a pandas dataframe\n",
        "annot = pd.read_csv('/gdrive/My Drive/giro1_1_TXT.txt_moving.txt', header = None ,sep = ' ' )\n",
        "annot = annot.rename(columns={0: \"dr1\", 1: \"frame\", 2: \"ID\", 3: \"X1\", 4: \"Y1\", 5: \"X2\", 6: \"Y2\", 7: \"dr2\", 8: \"object\", 9: \"dr3\"})\n",
        "annot.drop(columns = [\"dr1\", \"dr2\", \"dr3\"], inplace = True)\n",
        "annot.head()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frame</th>\n",
              "      <th>ID</th>\n",
              "      <th>X1</th>\n",
              "      <th>Y1</th>\n",
              "      <th>X2</th>\n",
              "      <th>Y2</th>\n",
              "      <th>object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>215</td>\n",
              "      <td>1</td>\n",
              "      <td>538</td>\n",
              "      <td>503</td>\n",
              "      <td>608</td>\n",
              "      <td>705</td>\n",
              "      <td>1F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>215</td>\n",
              "      <td>2</td>\n",
              "      <td>638</td>\n",
              "      <td>506</td>\n",
              "      <td>713</td>\n",
              "      <td>705</td>\n",
              "      <td>1F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>215</td>\n",
              "      <td>3</td>\n",
              "      <td>742</td>\n",
              "      <td>508</td>\n",
              "      <td>810</td>\n",
              "      <td>708</td>\n",
              "      <td>1F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>215</td>\n",
              "      <td>4</td>\n",
              "      <td>857</td>\n",
              "      <td>507</td>\n",
              "      <td>920</td>\n",
              "      <td>708</td>\n",
              "      <td>1F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>215</td>\n",
              "      <td>5</td>\n",
              "      <td>967</td>\n",
              "      <td>509</td>\n",
              "      <td>1027</td>\n",
              "      <td>707</td>\n",
              "      <td>1F</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   frame  ID   X1   Y1    X2   Y2 object\n",
              "0    215   1  538  503   608  705     1F\n",
              "1    215   2  638  506   713  705     1F\n",
              "2    215   3  742  508   810  708     1F\n",
              "3    215   4  857  507   920  708     1F\n",
              "4    215   5  967  509  1027  707     1F"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu3_-BVEowel"
      },
      "source": [
        "#the classes\n",
        "class_={\n",
        "    '1F': 'Front View',\n",
        "    '1B': 'Back View',\n",
        "    '1L': 'Left View',\n",
        "    '1R': 'Right View',\n",
        "    '2': ' Bicycle Crowd',\n",
        "    '5H': 'High-Density Human Crowd',\n",
        "    '5L': 'Low-Density Human Crowd',\n",
        "    '0': 'irrelevant TV graphics'\n",
        "}\n",
        "#a list of the frames that have annotation\n",
        "af = list(annot.frame.unique())\n",
        "\n",
        "#a list of the frames that have pictures from a rear view\n",
        "af_backview = list(annot[annot[\"object\"] == '1B'].frame.unique())\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZVpapb7oZCt"
      },
      "source": [
        "import torch\n",
        "\n",
        "class BoxList(object):\n",
        "  def __init__(self, bbox, image_size, mode=\"xyxy\"):\n",
        "      device = bbox.device if isinstance(bbox, torch.Tensor) else torch.device(\"cpu\") #selecting the hardware#\n",
        "      bbox = torch.as_tensor(bbox, dtype=torch.float32, device=device)\n",
        "      if bbox.ndimension() != 2: #should be a 2dim tensor (matrix)#\n",
        "          raise ValueError(\n",
        "              \"bbox should have 2 dimensions, got {}\".format(bbox.ndimension())\n",
        "          )\n",
        "      if bbox.size(-1) != 4: #the length of the annotation must be 4#\n",
        "          raise ValueError(\n",
        "              \"last dimension of bbox should have a \"\n",
        "              \"size of 4, got {}\".format(bbox.size(-1))\n",
        "          )\n",
        "      if mode not in (\"xyxy\", \"xywh\"):\n",
        "          raise ValueError(\"mode should be 'xyxy' or 'xywh'\")\n",
        "  \n",
        "      self.bbox = bbox #the matrix of the annotations as a tensor#\n",
        "      self.size = image_size  # (image_width, image_height)\n",
        "      self.mode = mode\n",
        "      self.extra_fields = {}\n",
        "  \n",
        "  def add_field(self, field, field_data):\n",
        "      self.extra_fields[field] = field_data\n",
        "  \n",
        "  def get_field(self, field):\n",
        "      return self.extra_fields[field]\n",
        "  \n",
        "  def has_field(self, field):\n",
        "      return field in self.extra_fields\n",
        "  \n",
        "  def fields(self):\n",
        "      return list(self.extra_fields.keys())\n",
        "  \n",
        "  def _copy_extra_fields(self, bbox):\n",
        "      for k, v in bbox.extra_fields.items():\n",
        "          self.extra_fields[k] = v\n",
        "  \n",
        "  def convert(self, mode):\n",
        "      if mode not in (\"xyxy\", \"xywh\"):\n",
        "          raise ValueError(\"mode should be 'xyxy' or 'xywh'\")\n",
        "      if mode == self.mode:\n",
        "          return self\n",
        "      # we only have two modes, so don't need to check\n",
        "      # self.mode\n",
        "      xmin, ymin, xmax, ymax = self._split_into_xyxy() #splits the annotation matrix into its columns#\n",
        "      if mode == \"xyxy\": #this is what we use#\n",
        "          bbox = torch.cat((xmin, ymin, xmax, ymax), dim=-1) #recreates the matrix#\n",
        "          bbox = BoxList(bbox, self.size, mode=mode)\n",
        "      else:\n",
        "          TO_REMOVE = 1\n",
        "          bbox = torch.cat(\n",
        "              (xmin, ymin, xmax - xmin + TO_REMOVE, ymax - ymin + TO_REMOVE), dim=-1\n",
        "          )\n",
        "          bbox = BoxList(bbox, self.size, mode=mode)\n",
        "      bbox._copy_extra_fields(self)\n",
        "      return bbox\n",
        "  \n",
        "  def _split_into_xyxy(self):\n",
        "      if self.mode == \"xyxy\":\n",
        "          xmin, ymin, xmax, ymax = self.bbox.split(1, dim=-1)\n",
        "          return xmin, ymin, xmax, ymax\n",
        "      elif self.mode == \"xywh\":\n",
        "          TO_REMOVE = 1\n",
        "          xmin, ymin, w, h = self.bbox.split(1, dim=-1)\n",
        "          return (\n",
        "              xmin,\n",
        "              ymin,\n",
        "              xmin + (w - TO_REMOVE).clamp(min=0),\n",
        "              ymin + (h - TO_REMOVE).clamp(min=0),\n",
        "          )\n",
        "      else:\n",
        "          raise RuntimeError(\"Should not be here\")\n",
        "  \n",
        "  def resize(self, size, *args, **kwargs):\n",
        "      \"\"\"\n",
        "      Returns a resized copy of this bounding box\n",
        "      :param size: The requested size in pixels, as a 2-tuple:\n",
        "          (width, height).\n",
        "      \"\"\"\n",
        "  \n",
        "      ratios = tuple(float(s) / float(s_orig) for s, s_orig in zip(size, self.size)) #s?#\n",
        "      if ratios[0] == ratios[1]:\n",
        "          ratio = ratios[0]\n",
        "          scaled_box = self.bbox * ratio\n",
        "          bbox = BoxList(scaled_box, size, mode=self.mode)\n",
        "          # bbox._copy_extra_fields(self)\n",
        "          for k, v in self.extra_fields.items():\n",
        "              if not isinstance(v, torch.Tensor):\n",
        "                  v = v.resize(size, *args, **kwargs)\n",
        "              bbox.add_field(k, v)\n",
        "          return bbox\n",
        "  \n",
        "      ratio_width, ratio_height = ratios\n",
        "      xmin, ymin, xmax, ymax = self._split_into_xyxy()\n",
        "      scaled_xmin = xmin * ratio_width\n",
        "      scaled_xmax = xmax * ratio_width\n",
        "      scaled_ymin = ymin * ratio_height\n",
        "      scaled_ymax = ymax * ratio_height\n",
        "      scaled_box = torch.cat(\n",
        "          (scaled_xmin, scaled_ymin, scaled_xmax, scaled_ymax), dim=-1\n",
        "      )\n",
        "      bbox = BoxList(scaled_box, size, mode=\"xyxy\")\n",
        "      # bbox._copy_extra_fields(self)\n",
        "      for k, v in self.extra_fields.items():\n",
        "          if not isinstance(v, torch.Tensor):\n",
        "              v = v.resize(size, *args, **kwargs)\n",
        "          bbox.add_field(k, v)\n",
        "  \n",
        "      return bbox.convert(self.mode)\n",
        "  \n",
        "  def transpose(self, method):\n",
        "      \"\"\"\n",
        "      Transpose bounding box (flip or rotate in 90 degree steps)\n",
        "      :param method: One of :py:attr:`PIL.Image.FLIP_LEFT_RIGHT`,\n",
        "        :py:attr:`PIL.Image.FLIP_TOP_BOTTOM`, :py:attr:`PIL.Image.ROTATE_90`,\n",
        "        :py:attr:`PIL.Image.ROTATE_180`, :py:attr:`PIL.Image.ROTATE_270`,\n",
        "        :py:attr:`PIL.Image.TRANSPOSE` or :py:attr:`PIL.Image.TRANSVERSE`.\n",
        "      \"\"\"\n",
        "      if method not in (FLIP_LEFT_RIGHT, FLIP_TOP_BOTTOM):\n",
        "          raise NotImplementedError(\n",
        "              \"Only FLIP_LEFT_RIGHT and FLIP_TOP_BOTTOM implemented\"\n",
        "          )\n",
        "  \n",
        "      image_width, image_height = self.size\n",
        "      xmin, ymin, xmax, ymax = self._split_into_xyxy()\n",
        "      if method == FLIP_LEFT_RIGHT:\n",
        "          TO_REMOVE = 1\n",
        "          transposed_xmin = image_width - xmax - TO_REMOVE\n",
        "          transposed_xmax = image_width - xmin - TO_REMOVE\n",
        "          transposed_ymin = ymin\n",
        "          transposed_ymax = ymax\n",
        "      elif method == FLIP_TOP_BOTTOM:\n",
        "          transposed_xmin = xmin\n",
        "          transposed_xmax = xmax\n",
        "          transposed_ymin = image_height - ymax\n",
        "          transposed_ymax = image_height - ymin\n",
        "  \n",
        "      transposed_boxes = torch.cat(\n",
        "          (transposed_xmin, transposed_ymin, transposed_xmax, transposed_ymax), dim=-1\n",
        "      )\n",
        "      bbox = BoxList(transposed_boxes, self.size, mode=\"xyxy\")\n",
        "      # bbox._copy_extra_fields(self)\n",
        "      for k, v in self.extra_fields.items():\n",
        "          if not isinstance(v, torch.Tensor):\n",
        "              v = v.transpose(method)\n",
        "          bbox.add_field(k, v)\n",
        "      return bbox.convert(self.mode)\n",
        "  \n",
        "  def crop(self, box):\n",
        "      \"\"\"\n",
        "      Cropss a rectangular region from this bounding box. The box is a\n",
        "      4-tuple defining the left, upper, right, and lower pixel\n",
        "      coordinate.\n",
        "      \"\"\"\n",
        "      xmin, ymin, xmax, ymax = self._split_into_xyxy()\n",
        "      w, h = box[2] - box[0], box[3] - box[1]\n",
        "      cropped_xmin = (xmin - box[0]).clamp(min=0, max=w)\n",
        "      cropped_ymin = (ymin - box[1]).clamp(min=0, max=h)\n",
        "      cropped_xmax = (xmax - box[0]).clamp(min=0, max=w)\n",
        "      cropped_ymax = (ymax - box[1]).clamp(min=0, max=h)\n",
        "  \n",
        "      # TODO should I filter empty boxes here?\n",
        "      if False:\n",
        "          is_empty = (cropped_xmin == cropped_xmax) | (cropped_ymin == cropped_ymax)\n",
        "  \n",
        "      cropped_box = torch.cat(\n",
        "          (cropped_xmin, cropped_ymin, cropped_xmax, cropped_ymax), dim=-1\n",
        "      )\n",
        "      bbox = BoxList(cropped_box, (w, h), mode=\"xyxy\")\n",
        "      # bbox._copy_extra_fields(self)\n",
        "      for k, v in self.extra_fields.items():\n",
        "          if not isinstance(v, torch.Tensor):\n",
        "              v = v.crop(box)\n",
        "          bbox.add_field(k, v)\n",
        "      return bbox.convert(self.mode)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YussC97uohj9"
      },
      "source": [
        "#read and image from drive referenced by the frame number\n",
        "from PIL import Image\n",
        "\n",
        "def load_image(image):\n",
        "  im = Image.open('/gdrive/My Drive/bicycle/giro1_'+str(image)+'.jpg')\n",
        "  return im\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e8blQZBrUCc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "b2037abc-e581-48b2-ee03-56d2cf6eccf5"
      },
      "source": [
        "#preak at the data\n",
        "annot.head(5)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frame</th>\n",
              "      <th>ID</th>\n",
              "      <th>X1</th>\n",
              "      <th>Y1</th>\n",
              "      <th>X2</th>\n",
              "      <th>Y2</th>\n",
              "      <th>object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>215</td>\n",
              "      <td>1</td>\n",
              "      <td>538</td>\n",
              "      <td>503</td>\n",
              "      <td>608</td>\n",
              "      <td>705</td>\n",
              "      <td>1F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>215</td>\n",
              "      <td>2</td>\n",
              "      <td>638</td>\n",
              "      <td>506</td>\n",
              "      <td>713</td>\n",
              "      <td>705</td>\n",
              "      <td>1F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>215</td>\n",
              "      <td>3</td>\n",
              "      <td>742</td>\n",
              "      <td>508</td>\n",
              "      <td>810</td>\n",
              "      <td>708</td>\n",
              "      <td>1F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>215</td>\n",
              "      <td>4</td>\n",
              "      <td>857</td>\n",
              "      <td>507</td>\n",
              "      <td>920</td>\n",
              "      <td>708</td>\n",
              "      <td>1F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>215</td>\n",
              "      <td>5</td>\n",
              "      <td>967</td>\n",
              "      <td>509</td>\n",
              "      <td>1027</td>\n",
              "      <td>707</td>\n",
              "      <td>1F</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   frame  ID   X1   Y1    X2   Y2 object\n",
              "0    215   1  538  503   608  705     1F\n",
              "1    215   2  638  506   713  705     1F\n",
              "2    215   3  742  508   810  708     1F\n",
              "3    215   4  857  507   920  708     1F\n",
              "4    215   5  967  509  1027  707     1F"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGG1J3vBohme"
      },
      "source": [
        "class MyDataset(object):\n",
        "  def __init__(self, size): #the size value controls how big the pictures we want to be\n",
        "    self.name = \"test\" #\n",
        "    self.size = size # \n",
        "        # as you would do normally\n",
        "\n",
        "  def transforms(self, psize, image, boxlist): #whole function defined by me#\n",
        "    l = (image.size[0]/psize[0])*1.5 #our annotations are for larger pictures than the saved by a ratio of 1.5#\n",
        "    h = (image.size[1]/psize[1])*1.5\n",
        "\n",
        "    image = image.resize(psize) #resizes the picture#\n",
        "\n",
        "    r, g, b = image.split() #getting the channels#\n",
        "    b = b.point(lambda i: i * 1.2) #modifying the blue channel#\n",
        "    r = r.point(lambda i: 1*0.9)\n",
        "    result = Image.merge('RGB', (r, g, b))  #creating a new picture from the modified channels#\n",
        "    for i in range(len(boxlist.bbox)): #rescaling the boxes#\n",
        "      if i%2 ==0:\n",
        "          boxlist.bbox[i] = boxlist.bbox[i]/l\n",
        "      else:\n",
        "        boxlist.bbox[i] = boxlist.bbox[i]/h\n",
        "\n",
        "    return result, boxlist\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx, im, boxes): #originally the parameters were: self, idx#\n",
        "        # load the image as a PIL Image\n",
        "    image = im #I passed the picture when calling the function#\n",
        "\n",
        "        # load the bounding boxes as a list of list of boxes\n",
        "        # in this case, for illustrative purposes, we use\n",
        "        # x1, y1, x2, y2 order.\n",
        "    labels = None\n",
        "    boxes = boxes #also passed it when calling#\n",
        "        # and labels\n",
        "    #labels = torch.tensor([10, 20]) #we don't need labels (as on now)#\n",
        "\n",
        "        # create a BoxList from the boxes\n",
        "    boxlist = BoxList(boxes, image.size, mode=\"xyxy\")\n",
        "        # add the labels to the boxlist\n",
        "    boxlist.add_field(\"labels\", labels)\n",
        "\n",
        "    size = self.size\n",
        "    if self.transforms: #?#\n",
        "      image, boxlist = self.transforms(size, image, boxlist) #originally: image, boxlist, could be that way#\n",
        "      #by getting size in the definition of the function#\n",
        "\n",
        "        # return the image, the boxlist and the idx in your dataset\n",
        "    return image, boxlist, idx\n",
        "\n",
        "\n",
        "\n",
        "  def get_img_info(self, idx):\n",
        "        # get img_height and img_width. This is used if\n",
        "        # we want to split the batches according to the aspect ratio\n",
        "        # of the image, as it can be more efficient than loading the\n",
        "        # image from disk\n",
        "      return {\"height\": img_height, \"width\": img_width}"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NoeIxdaq2ke"
      },
      "source": [
        "size_of_data = (240, 240)\n",
        "data = MyDataset(size_of_data)\n",
        "\n",
        "#selecting all the pictures in the dataset#\n",
        "A = annot.frame.values\n",
        "\n",
        "#selecting the back view ones#\n",
        "#A= annot[annot[\"object\"] == '1B']\n",
        "\n",
        "for a in af[0:3]: #or af_backview#\n",
        "  p = load_image(a) #loads the references image#\n",
        "  B = A == a #selects the annotations for it#\n",
        "  M = annot.loc[B,[\"X1\", \"Y1\", \"X2\", \"Y2\"]].values.tolist() #creates a list of lists for the annotations as expected#\n",
        "  processed_pic, boxlist, idx = data.__getitem__(a, p, M ) #calls the function#\n",
        "\n",
        "  #forward it to the network here or save it into a variable?#"
      ],
      "execution_count": 40,
      "outputs": []
    }
  ]
}