{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgg\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_={\n",
    "    0: 'ignored regions',\n",
    "    1: 'pedestrian',\n",
    "    2: 'people',\n",
    "    3: 'bicycle',\n",
    "    4: 'car',\n",
    "    5: 'van',\n",
    "    6: 'truck',\n",
    "    7: 'tricycle',\n",
    "    8: 'awning-tricycle',\n",
    "    9: 'bus',\n",
    "    10: 'motor', \n",
    "    11: 'others'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annot(path='VisDrone2019-DET-train/annotations/0000002_00005_d_0000014.txt'):\n",
    "    \n",
    "    # process annotation files, return pandas dataframe\n",
    "    \n",
    "    annot=pd.read_csv(path,header=None)\n",
    "    annot.columns=['x','y','w','h','conf','class','truncation','occlusion']\n",
    "    \n",
    "    annot['x_']=annot['x']+annot['w']\n",
    "    annot['y_']=annot['y']+annot['h']\n",
    "    \n",
    "    return annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image,boxes):\n",
    "    \n",
    "    # draw all given boxes onto image\n",
    "    # boxes is list of tuples of (x,y,x_,y_)\n",
    "    \n",
    "    rec=Image.new('RGBA',image.size,(255,255,255,0))\n",
    "    draw=ImageDraw.Draw(rec)\n",
    "    \n",
    "    for box in boxes: \n",
    "        draw.rectangle(box,outline=(255,255,0)) # yellow outline\n",
    "        \n",
    "    out=Image.alpha_composite(image.convert('RGBA'),rec)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resized_box(image,box,new_size=(128,128),as_numpy=True):\n",
    "    \n",
    "    # from box, crop image and resize to desired size\n",
    "    # box is tuple of (x,y,x_,y_)\n",
    "    \n",
    "    box_=image.crop(box)\n",
    "    box_=box_.resize(new_size)\n",
    "    \n",
    "    if as_numpy:\n",
    "        return np.array(box_)\n",
    "    else:\n",
    "        return box_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo, using VisDrone trainset\n",
    "\n",
    "get from https://github.com/VisDrone/VisDrone-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "im=Image.open('VisDrone2019-DET-train/images/0000002_00005_d_0000014.jpg')\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>conf</th>\n",
       "      <th>class</th>\n",
       "      <th>truncation</th>\n",
       "      <th>occlusion</th>\n",
       "      <th>x_</th>\n",
       "      <th>y_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>684</td>\n",
       "      <td>8</td>\n",
       "      <td>273</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>957</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>406</td>\n",
       "      <td>119</td>\n",
       "      <td>265</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>671</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255</td>\n",
       "      <td>22</td>\n",
       "      <td>119</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>209</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>708</td>\n",
       "      <td>471</td>\n",
       "      <td>74</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>782</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x    y    w    h  conf  class  truncation  occlusion   x_   y_\n",
       "0  684    8  273  116     0      0           0          0  957  124\n",
       "1  406  119  265   70     0      0           0          0  671  189\n",
       "2  255   22  119  128     0      0           0          0  374  150\n",
       "3    1    3  209   78     0      0           0          0  210   81\n",
       "4  708  471   74   33     1      4           0          1  782  504"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot=read_annot('VisDrone2019-DET-train/annotations/0000002_00005_d_0000014.txt')\n",
    "annot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in range(annot.shape[0]):\n",
    "    l.append(tuple(annot[['x','y','x_','y_']].iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxed=draw_boxes(im,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars=[]\n",
    "crs=annot[annot['class']==4]\n",
    "for i in range(crs.shape[0]):\n",
    "    cars.append(tuple(crs[['x','y','x_','y_']].iloc[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxed_cars=draw_boxes(im,cars)\n",
    "boxed_cars.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras models used like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.applications.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(tf.keras.applications.vgg16.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# works on numpy arrays!\n",
    "\n",
    "pp_img=tf.keras.applications.vgg16.preprocess_input(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(pp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.applications.vgg16.decode_predictions(np.array(model(ppp_img.reshape((1,224,224,3)))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
